Log file created at: 2016/08/18 17:43:09
Running on machine: jaychou-OptiPlex-9010
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0818 17:43:09.800427  2522 caffe.cpp:217] Using GPUs 0
I0818 17:43:09.830734  2522 caffe.cpp:222] GPU 0: GeForce GTX 650 Ti
I0818 17:43:09.929924  2522 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 10000
snapshot_prefix: "models/gender_glasses/gg_net_train"
solver_mode: GPU
device_id: 0
net: "models/gender_glasses/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0818 17:43:09.930107  2522 solver.cpp:91] Creating training net from net file: models/gender_glasses/train_val.prototxt
I0818 17:43:09.930605  2522 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0818 17:43:09.930624  2522 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer labels
I0818 17:43:09.930644  2522 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_glasses
I0818 17:43:09.930655  2522 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_gender
I0818 17:43:09.930780  2522 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.4
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.6
}
I0818 17:43:09.931371  2522 layer_factory.hpp:77] Creating layer data
I0818 17:43:09.931743  2522 net.cpp:100] Creating Layer data
I0818 17:43:09.931769  2522 net.cpp:408] data -> data
I0818 17:43:09.933048  2526 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb
I0818 17:43:09.941548  2522 data_layer.cpp:41] output data size: 100,3,80,80
I0818 17:43:09.952411  2522 net.cpp:150] Setting up data
I0818 17:43:09.952466  2522 net.cpp:157] Top shape: 100 3 80 80 (1920000)
I0818 17:43:09.952476  2522 net.cpp:165] Memory required for data: 7680000
I0818 17:43:09.952491  2522 layer_factory.hpp:77] Creating layer labels
I0818 17:43:09.952595  2522 net.cpp:100] Creating Layer labels
I0818 17:43:09.952612  2522 net.cpp:408] labels -> labels
I0818 17:43:09.954917  2528 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb
I0818 17:43:09.955507  2522 data_layer.cpp:41] output data size: 100,2,1,1
I0818 17:43:09.955637  2522 net.cpp:150] Setting up labels
I0818 17:43:09.955654  2522 net.cpp:157] Top shape: 100 2 1 1 (200)
I0818 17:43:09.955663  2522 net.cpp:165] Memory required for data: 7680800
I0818 17:43:09.955672  2522 layer_factory.hpp:77] Creating layer slice1
I0818 17:43:09.955687  2522 net.cpp:100] Creating Layer slice1
I0818 17:43:09.955699  2522 net.cpp:434] slice1 <- labels
I0818 17:43:09.955715  2522 net.cpp:408] slice1 -> glasses
I0818 17:43:09.955731  2522 net.cpp:408] slice1 -> gender
I0818 17:43:09.955775  2522 net.cpp:150] Setting up slice1
I0818 17:43:09.955787  2522 net.cpp:157] Top shape: 100 1 1 1 (100)
I0818 17:43:09.955801  2522 net.cpp:157] Top shape: 100 1 1 1 (100)
I0818 17:43:09.955808  2522 net.cpp:165] Memory required for data: 7681600
I0818 17:43:09.955817  2522 layer_factory.hpp:77] Creating layer conv1
I0818 17:43:09.955838  2522 net.cpp:100] Creating Layer conv1
I0818 17:43:09.955848  2522 net.cpp:434] conv1 <- data
I0818 17:43:09.955860  2522 net.cpp:408] conv1 -> conv1
I0818 17:43:10.084538  2522 net.cpp:150] Setting up conv1
I0818 17:43:10.084594  2522 net.cpp:157] Top shape: 100 20 76 76 (11552000)
I0818 17:43:10.084604  2522 net.cpp:165] Memory required for data: 53889600
I0818 17:43:10.084631  2522 layer_factory.hpp:77] Creating layer relu1
I0818 17:43:10.084651  2522 net.cpp:100] Creating Layer relu1
I0818 17:43:10.084662  2522 net.cpp:434] relu1 <- conv1
I0818 17:43:10.084674  2522 net.cpp:395] relu1 -> conv1 (in-place)
I0818 17:43:10.085177  2522 net.cpp:150] Setting up relu1
I0818 17:43:10.085196  2522 net.cpp:157] Top shape: 100 20 76 76 (11552000)
I0818 17:43:10.085206  2522 net.cpp:165] Memory required for data: 100097600
I0818 17:43:10.085219  2522 layer_factory.hpp:77] Creating layer pool1
I0818 17:43:10.085232  2522 net.cpp:100] Creating Layer pool1
I0818 17:43:10.085247  2522 net.cpp:434] pool1 <- conv1
I0818 17:43:10.085258  2522 net.cpp:408] pool1 -> pool1
I0818 17:43:10.085307  2522 net.cpp:150] Setting up pool1
I0818 17:43:10.085320  2522 net.cpp:157] Top shape: 100 20 38 38 (2888000)
I0818 17:43:10.085330  2522 net.cpp:165] Memory required for data: 111649600
I0818 17:43:10.085338  2522 layer_factory.hpp:77] Creating layer conv2
I0818 17:43:10.085355  2522 net.cpp:100] Creating Layer conv2
I0818 17:43:10.085363  2522 net.cpp:434] conv2 <- pool1
I0818 17:43:10.085376  2522 net.cpp:408] conv2 -> conv2
I0818 17:43:10.086683  2522 net.cpp:150] Setting up conv2
I0818 17:43:10.086704  2522 net.cpp:157] Top shape: 100 48 34 34 (5548800)
I0818 17:43:10.086714  2522 net.cpp:165] Memory required for data: 133844800
I0818 17:43:10.086750  2522 layer_factory.hpp:77] Creating layer relu2
I0818 17:43:10.086766  2522 net.cpp:100] Creating Layer relu2
I0818 17:43:10.086776  2522 net.cpp:434] relu2 <- conv2
I0818 17:43:10.086786  2522 net.cpp:395] relu2 -> conv2 (in-place)
I0818 17:43:10.086894  2522 net.cpp:150] Setting up relu2
I0818 17:43:10.086910  2522 net.cpp:157] Top shape: 100 48 34 34 (5548800)
I0818 17:43:10.086918  2522 net.cpp:165] Memory required for data: 156040000
I0818 17:43:10.086930  2522 layer_factory.hpp:77] Creating layer pool2
I0818 17:43:10.086942  2522 net.cpp:100] Creating Layer pool2
I0818 17:43:10.086951  2522 net.cpp:434] pool2 <- conv2
I0818 17:43:10.086962  2522 net.cpp:408] pool2 -> pool2
I0818 17:43:10.086999  2522 net.cpp:150] Setting up pool2
I0818 17:43:10.087013  2522 net.cpp:157] Top shape: 100 48 17 17 (1387200)
I0818 17:43:10.087020  2522 net.cpp:165] Memory required for data: 161588800
I0818 17:43:10.087029  2522 layer_factory.hpp:77] Creating layer conv3
I0818 17:43:10.087044  2522 net.cpp:100] Creating Layer conv3
I0818 17:43:10.087054  2522 net.cpp:434] conv3 <- pool2
I0818 17:43:10.087064  2522 net.cpp:408] conv3 -> conv3
I0818 17:43:10.087895  2522 net.cpp:150] Setting up conv3
I0818 17:43:10.087914  2522 net.cpp:157] Top shape: 100 64 15 15 (1440000)
I0818 17:43:10.087924  2522 net.cpp:165] Memory required for data: 167348800
I0818 17:43:10.087936  2522 layer_factory.hpp:77] Creating layer relu3
I0818 17:43:10.087949  2522 net.cpp:100] Creating Layer relu3
I0818 17:43:10.087957  2522 net.cpp:434] relu3 <- conv3
I0818 17:43:10.087967  2522 net.cpp:395] relu3 -> conv3 (in-place)
I0818 17:43:10.088057  2522 net.cpp:150] Setting up relu3
I0818 17:43:10.088073  2522 net.cpp:157] Top shape: 100 64 15 15 (1440000)
I0818 17:43:10.088081  2522 net.cpp:165] Memory required for data: 173108800
I0818 17:43:10.088094  2522 layer_factory.hpp:77] Creating layer ip1
I0818 17:43:10.088111  2522 net.cpp:100] Creating Layer ip1
I0818 17:43:10.088121  2522 net.cpp:434] ip1 <- conv3
I0818 17:43:10.088132  2522 net.cpp:408] ip1 -> ip1
I0818 17:43:10.142132  2522 net.cpp:150] Setting up ip1
I0818 17:43:10.142179  2522 net.cpp:157] Top shape: 100 512 (51200)
I0818 17:43:10.142189  2522 net.cpp:165] Memory required for data: 173313600
I0818 17:43:10.142206  2522 layer_factory.hpp:77] Creating layer relu5
I0818 17:43:10.142221  2522 net.cpp:100] Creating Layer relu5
I0818 17:43:10.142231  2522 net.cpp:434] relu5 <- ip1
I0818 17:43:10.142243  2522 net.cpp:395] relu5 -> ip1 (in-place)
I0818 17:43:10.142321  2522 net.cpp:150] Setting up relu5
I0818 17:43:10.142335  2522 net.cpp:157] Top shape: 100 512 (51200)
I0818 17:43:10.142344  2522 net.cpp:165] Memory required for data: 173518400
I0818 17:43:10.142355  2522 layer_factory.hpp:77] Creating layer drop1
I0818 17:43:10.142374  2522 net.cpp:100] Creating Layer drop1
I0818 17:43:10.142384  2522 net.cpp:434] drop1 <- ip1
I0818 17:43:10.142393  2522 net.cpp:395] drop1 -> ip1 (in-place)
I0818 17:43:10.142426  2522 net.cpp:150] Setting up drop1
I0818 17:43:10.142438  2522 net.cpp:157] Top shape: 100 512 (51200)
I0818 17:43:10.142446  2522 net.cpp:165] Memory required for data: 173723200
I0818 17:43:10.142455  2522 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0818 17:43:10.142469  2522 net.cpp:100] Creating Layer ip1_drop1_0_split
I0818 17:43:10.142477  2522 net.cpp:434] ip1_drop1_0_split <- ip1
I0818 17:43:10.142488  2522 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0818 17:43:10.142501  2522 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0818 17:43:10.142535  2522 net.cpp:150] Setting up ip1_drop1_0_split
I0818 17:43:10.142549  2522 net.cpp:157] Top shape: 100 512 (51200)
I0818 17:43:10.142559  2522 net.cpp:157] Top shape: 100 512 (51200)
I0818 17:43:10.142566  2522 net.cpp:165] Memory required for data: 174132800
I0818 17:43:10.142575  2522 layer_factory.hpp:77] Creating layer ip2
I0818 17:43:10.142586  2522 net.cpp:100] Creating Layer ip2
I0818 17:43:10.142601  2522 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0818 17:43:10.142635  2522 net.cpp:408] ip2 -> ip2
I0818 17:43:10.142724  2522 net.cpp:150] Setting up ip2
I0818 17:43:10.142738  2522 net.cpp:157] Top shape: 100 2 (200)
I0818 17:43:10.142747  2522 net.cpp:165] Memory required for data: 174133600
I0818 17:43:10.142760  2522 layer_factory.hpp:77] Creating layer loss1
I0818 17:43:10.142773  2522 net.cpp:100] Creating Layer loss1
I0818 17:43:10.142783  2522 net.cpp:434] loss1 <- ip2
I0818 17:43:10.142793  2522 net.cpp:434] loss1 <- glasses
I0818 17:43:10.142804  2522 net.cpp:408] loss1 -> loss1
I0818 17:43:10.142819  2522 layer_factory.hpp:77] Creating layer loss1
I0818 17:43:10.143215  2522 net.cpp:150] Setting up loss1
I0818 17:43:10.143232  2522 net.cpp:157] Top shape: (1)
I0818 17:43:10.143241  2522 net.cpp:160]     with loss weight 0.4
I0818 17:43:10.143267  2522 net.cpp:165] Memory required for data: 174133604
I0818 17:43:10.143276  2522 layer_factory.hpp:77] Creating layer ip3
I0818 17:43:10.143288  2522 net.cpp:100] Creating Layer ip3
I0818 17:43:10.143297  2522 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0818 17:43:10.143308  2522 net.cpp:408] ip3 -> ip3
I0818 17:43:10.143396  2522 net.cpp:150] Setting up ip3
I0818 17:43:10.143409  2522 net.cpp:157] Top shape: 100 2 (200)
I0818 17:43:10.143419  2522 net.cpp:165] Memory required for data: 174134404
I0818 17:43:10.143429  2522 layer_factory.hpp:77] Creating layer loss2
I0818 17:43:10.143441  2522 net.cpp:100] Creating Layer loss2
I0818 17:43:10.143450  2522 net.cpp:434] loss2 <- ip3
I0818 17:43:10.143460  2522 net.cpp:434] loss2 <- gender
I0818 17:43:10.143470  2522 net.cpp:408] loss2 -> loss2
I0818 17:43:10.143482  2522 layer_factory.hpp:77] Creating layer loss2
I0818 17:43:10.143662  2522 net.cpp:150] Setting up loss2
I0818 17:43:10.143677  2522 net.cpp:157] Top shape: (1)
I0818 17:43:10.143685  2522 net.cpp:160]     with loss weight 0.6
I0818 17:43:10.143697  2522 net.cpp:165] Memory required for data: 174134408
I0818 17:43:10.143705  2522 net.cpp:226] loss2 needs backward computation.
I0818 17:43:10.143714  2522 net.cpp:226] ip3 needs backward computation.
I0818 17:43:10.143723  2522 net.cpp:226] loss1 needs backward computation.
I0818 17:43:10.143733  2522 net.cpp:226] ip2 needs backward computation.
I0818 17:43:10.143740  2522 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0818 17:43:10.143749  2522 net.cpp:226] drop1 needs backward computation.
I0818 17:43:10.143757  2522 net.cpp:226] relu5 needs backward computation.
I0818 17:43:10.143765  2522 net.cpp:226] ip1 needs backward computation.
I0818 17:43:10.143774  2522 net.cpp:226] relu3 needs backward computation.
I0818 17:43:10.143782  2522 net.cpp:226] conv3 needs backward computation.
I0818 17:43:10.143790  2522 net.cpp:226] pool2 needs backward computation.
I0818 17:43:10.143800  2522 net.cpp:226] relu2 needs backward computation.
I0818 17:43:10.143807  2522 net.cpp:226] conv2 needs backward computation.
I0818 17:43:10.143816  2522 net.cpp:226] pool1 needs backward computation.
I0818 17:43:10.143824  2522 net.cpp:226] relu1 needs backward computation.
I0818 17:43:10.143832  2522 net.cpp:226] conv1 needs backward computation.
I0818 17:43:10.143841  2522 net.cpp:228] slice1 does not need backward computation.
I0818 17:43:10.143851  2522 net.cpp:228] labels does not need backward computation.
I0818 17:43:10.143859  2522 net.cpp:228] data does not need backward computation.
I0818 17:43:10.143867  2522 net.cpp:270] This network produces output loss1
I0818 17:43:10.143875  2522 net.cpp:270] This network produces output loss2
I0818 17:43:10.143893  2522 net.cpp:283] Network initialization done.
I0818 17:43:10.144405  2522 solver.cpp:181] Creating test net (#0) specified by net file: models/gender_glasses/train_val.prototxt
I0818 17:43:10.144449  2522 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0818 17:43:10.144461  2522 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer labels
I0818 17:43:10.144599  2522 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.4
}
layer {
  name: "accuracy_glasses"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "glasses"
  top: "accuracy_glasses"
  include {
    phase: TEST
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.6
}
layer {
  name: "accuracy_gender"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "gender"
  top: "accuracy_gender"
  include {
    phase: TEST
  }
}
I0818 17:43:10.145159  2522 layer_factory.hpp:77] Creating layer data
I0818 17:43:10.145254  2522 net.cpp:100] Creating Layer data
I0818 17:43:10.145272  2522 net.cpp:408] data -> data
I0818 17:43:10.145977  2530 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb
I0818 17:43:10.146131  2522 data_layer.cpp:41] output data size: 64,3,80,80
I0818 17:43:10.153255  2522 net.cpp:150] Setting up data
I0818 17:43:10.153321  2522 net.cpp:157] Top shape: 64 3 80 80 (1228800)
I0818 17:43:10.153331  2522 net.cpp:165] Memory required for data: 4915200
I0818 17:43:10.153342  2522 layer_factory.hpp:77] Creating layer labels
I0818 17:43:10.153422  2522 net.cpp:100] Creating Layer labels
I0818 17:43:10.153436  2522 net.cpp:408] labels -> labels
I0818 17:43:10.155930  2532 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb
I0818 17:43:10.156386  2522 data_layer.cpp:41] output data size: 64,2,1,1
I0818 17:43:10.156623  2522 net.cpp:150] Setting up labels
I0818 17:43:10.156641  2522 net.cpp:157] Top shape: 64 2 1 1 (128)
I0818 17:43:10.156651  2522 net.cpp:165] Memory required for data: 4915712
I0818 17:43:10.156659  2522 layer_factory.hpp:77] Creating layer slice1
I0818 17:43:10.156673  2522 net.cpp:100] Creating Layer slice1
I0818 17:43:10.156682  2522 net.cpp:434] slice1 <- labels
I0818 17:43:10.156694  2522 net.cpp:408] slice1 -> glasses
I0818 17:43:10.156709  2522 net.cpp:408] slice1 -> gender
I0818 17:43:10.156749  2522 net.cpp:150] Setting up slice1
I0818 17:43:10.156761  2522 net.cpp:157] Top shape: 64 1 1 1 (64)
I0818 17:43:10.156774  2522 net.cpp:157] Top shape: 64 1 1 1 (64)
I0818 17:43:10.156782  2522 net.cpp:165] Memory required for data: 4916224
I0818 17:43:10.156790  2522 layer_factory.hpp:77] Creating layer glasses_slice1_0_split
I0818 17:43:10.156801  2522 net.cpp:100] Creating Layer glasses_slice1_0_split
I0818 17:43:10.156810  2522 net.cpp:434] glasses_slice1_0_split <- glasses
I0818 17:43:10.156821  2522 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_0
I0818 17:43:10.156833  2522 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_1
I0818 17:43:10.156869  2522 net.cpp:150] Setting up glasses_slice1_0_split
I0818 17:43:10.156883  2522 net.cpp:157] Top shape: 64 1 1 1 (64)
I0818 17:43:10.156893  2522 net.cpp:157] Top shape: 64 1 1 1 (64)
I0818 17:43:10.156901  2522 net.cpp:165] Memory required for data: 4916736
I0818 17:43:10.156910  2522 layer_factory.hpp:77] Creating layer gender_slice1_1_split
I0818 17:43:10.156920  2522 net.cpp:100] Creating Layer gender_slice1_1_split
I0818 17:43:10.156929  2522 net.cpp:434] gender_slice1_1_split <- gender
I0818 17:43:10.156939  2522 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_0
I0818 17:43:10.156951  2522 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_1
I0818 17:43:10.156986  2522 net.cpp:150] Setting up gender_slice1_1_split
I0818 17:43:10.156998  2522 net.cpp:157] Top shape: 64 1 1 1 (64)
I0818 17:43:10.157008  2522 net.cpp:157] Top shape: 64 1 1 1 (64)
I0818 17:43:10.157016  2522 net.cpp:165] Memory required for data: 4917248
I0818 17:43:10.157027  2522 layer_factory.hpp:77] Creating layer conv1
I0818 17:43:10.157043  2522 net.cpp:100] Creating Layer conv1
I0818 17:43:10.157052  2522 net.cpp:434] conv1 <- data
I0818 17:43:10.157064  2522 net.cpp:408] conv1 -> conv1
I0818 17:43:10.158192  2522 net.cpp:150] Setting up conv1
I0818 17:43:10.158218  2522 net.cpp:157] Top shape: 64 20 76 76 (7393280)
I0818 17:43:10.158229  2522 net.cpp:165] Memory required for data: 34490368
I0818 17:43:10.158253  2522 layer_factory.hpp:77] Creating layer relu1
I0818 17:43:10.158267  2522 net.cpp:100] Creating Layer relu1
I0818 17:43:10.158277  2522 net.cpp:434] relu1 <- conv1
I0818 17:43:10.158293  2522 net.cpp:395] relu1 -> conv1 (in-place)
I0818 17:43:10.158532  2522 net.cpp:150] Setting up relu1
I0818 17:43:10.158547  2522 net.cpp:157] Top shape: 64 20 76 76 (7393280)
I0818 17:43:10.158557  2522 net.cpp:165] Memory required for data: 64063488
I0818 17:43:10.158570  2522 layer_factory.hpp:77] Creating layer pool1
I0818 17:43:10.158581  2522 net.cpp:100] Creating Layer pool1
I0818 17:43:10.158591  2522 net.cpp:434] pool1 <- conv1
I0818 17:43:10.158601  2522 net.cpp:408] pool1 -> pool1
I0818 17:43:10.158643  2522 net.cpp:150] Setting up pool1
I0818 17:43:10.158655  2522 net.cpp:157] Top shape: 64 20 38 38 (1848320)
I0818 17:43:10.158665  2522 net.cpp:165] Memory required for data: 71456768
I0818 17:43:10.158695  2522 layer_factory.hpp:77] Creating layer conv2
I0818 17:43:10.158712  2522 net.cpp:100] Creating Layer conv2
I0818 17:43:10.158722  2522 net.cpp:434] conv2 <- pool1
I0818 17:43:10.158733  2522 net.cpp:408] conv2 -> conv2
I0818 17:43:10.159809  2522 net.cpp:150] Setting up conv2
I0818 17:43:10.159829  2522 net.cpp:157] Top shape: 64 48 34 34 (3551232)
I0818 17:43:10.159839  2522 net.cpp:165] Memory required for data: 85661696
I0818 17:43:10.159853  2522 layer_factory.hpp:77] Creating layer relu2
I0818 17:43:10.159868  2522 net.cpp:100] Creating Layer relu2
I0818 17:43:10.159878  2522 net.cpp:434] relu2 <- conv2
I0818 17:43:10.159888  2522 net.cpp:395] relu2 -> conv2 (in-place)
I0818 17:43:10.160050  2522 net.cpp:150] Setting up relu2
I0818 17:43:10.160064  2522 net.cpp:157] Top shape: 64 48 34 34 (3551232)
I0818 17:43:10.160073  2522 net.cpp:165] Memory required for data: 99866624
I0818 17:43:10.160084  2522 layer_factory.hpp:77] Creating layer pool2
I0818 17:43:10.160096  2522 net.cpp:100] Creating Layer pool2
I0818 17:43:10.160105  2522 net.cpp:434] pool2 <- conv2
I0818 17:43:10.160115  2522 net.cpp:408] pool2 -> pool2
I0818 17:43:10.160156  2522 net.cpp:150] Setting up pool2
I0818 17:43:10.160168  2522 net.cpp:157] Top shape: 64 48 17 17 (887808)
I0818 17:43:10.160176  2522 net.cpp:165] Memory required for data: 103417856
I0818 17:43:10.160184  2522 layer_factory.hpp:77] Creating layer conv3
I0818 17:43:10.160199  2522 net.cpp:100] Creating Layer conv3
I0818 17:43:10.160209  2522 net.cpp:434] conv3 <- pool2
I0818 17:43:10.160221  2522 net.cpp:408] conv3 -> conv3
I0818 17:43:10.161654  2522 net.cpp:150] Setting up conv3
I0818 17:43:10.161677  2522 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 17:43:10.161690  2522 net.cpp:165] Memory required for data: 107104256
I0818 17:43:10.161702  2522 layer_factory.hpp:77] Creating layer relu3
I0818 17:43:10.161715  2522 net.cpp:100] Creating Layer relu3
I0818 17:43:10.161725  2522 net.cpp:434] relu3 <- conv3
I0818 17:43:10.161736  2522 net.cpp:395] relu3 -> conv3 (in-place)
I0818 17:43:10.161844  2522 net.cpp:150] Setting up relu3
I0818 17:43:10.161859  2522 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0818 17:43:10.161867  2522 net.cpp:165] Memory required for data: 110790656
I0818 17:43:10.161881  2522 layer_factory.hpp:77] Creating layer ip1
I0818 17:43:10.161896  2522 net.cpp:100] Creating Layer ip1
I0818 17:43:10.161906  2522 net.cpp:434] ip1 <- conv3
I0818 17:43:10.161917  2522 net.cpp:408] ip1 -> ip1
I0818 17:43:10.216828  2522 net.cpp:150] Setting up ip1
I0818 17:43:10.216871  2522 net.cpp:157] Top shape: 64 512 (32768)
I0818 17:43:10.216881  2522 net.cpp:165] Memory required for data: 110921728
I0818 17:43:10.216897  2522 layer_factory.hpp:77] Creating layer relu5
I0818 17:43:10.216912  2522 net.cpp:100] Creating Layer relu5
I0818 17:43:10.216922  2522 net.cpp:434] relu5 <- ip1
I0818 17:43:10.216933  2522 net.cpp:395] relu5 -> ip1 (in-place)
I0818 17:43:10.217021  2522 net.cpp:150] Setting up relu5
I0818 17:43:10.217036  2522 net.cpp:157] Top shape: 64 512 (32768)
I0818 17:43:10.217044  2522 net.cpp:165] Memory required for data: 111052800
I0818 17:43:10.217054  2522 layer_factory.hpp:77] Creating layer drop1
I0818 17:43:10.217069  2522 net.cpp:100] Creating Layer drop1
I0818 17:43:10.217078  2522 net.cpp:434] drop1 <- ip1
I0818 17:43:10.217087  2522 net.cpp:395] drop1 -> ip1 (in-place)
I0818 17:43:10.217120  2522 net.cpp:150] Setting up drop1
I0818 17:43:10.217133  2522 net.cpp:157] Top shape: 64 512 (32768)
I0818 17:43:10.217142  2522 net.cpp:165] Memory required for data: 111183872
I0818 17:43:10.217150  2522 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0818 17:43:10.217164  2522 net.cpp:100] Creating Layer ip1_drop1_0_split
I0818 17:43:10.217172  2522 net.cpp:434] ip1_drop1_0_split <- ip1
I0818 17:43:10.217186  2522 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0818 17:43:10.217206  2522 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0818 17:43:10.217242  2522 net.cpp:150] Setting up ip1_drop1_0_split
I0818 17:43:10.217279  2522 net.cpp:157] Top shape: 64 512 (32768)
I0818 17:43:10.217290  2522 net.cpp:157] Top shape: 64 512 (32768)
I0818 17:43:10.217298  2522 net.cpp:165] Memory required for data: 111446016
I0818 17:43:10.217306  2522 layer_factory.hpp:77] Creating layer ip2
I0818 17:43:10.217326  2522 net.cpp:100] Creating Layer ip2
I0818 17:43:10.217336  2522 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0818 17:43:10.217350  2522 net.cpp:408] ip2 -> ip2
I0818 17:43:10.217452  2522 net.cpp:150] Setting up ip2
I0818 17:43:10.217466  2522 net.cpp:157] Top shape: 64 2 (128)
I0818 17:43:10.217474  2522 net.cpp:165] Memory required for data: 111446528
I0818 17:43:10.217486  2522 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0818 17:43:10.217497  2522 net.cpp:100] Creating Layer ip2_ip2_0_split
I0818 17:43:10.217506  2522 net.cpp:434] ip2_ip2_0_split <- ip2
I0818 17:43:10.217516  2522 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0818 17:43:10.217530  2522 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0818 17:43:10.217566  2522 net.cpp:150] Setting up ip2_ip2_0_split
I0818 17:43:10.217579  2522 net.cpp:157] Top shape: 64 2 (128)
I0818 17:43:10.217589  2522 net.cpp:157] Top shape: 64 2 (128)
I0818 17:43:10.217597  2522 net.cpp:165] Memory required for data: 111447552
I0818 17:43:10.217605  2522 layer_factory.hpp:77] Creating layer loss1
I0818 17:43:10.217618  2522 net.cpp:100] Creating Layer loss1
I0818 17:43:10.217628  2522 net.cpp:434] loss1 <- ip2_ip2_0_split_0
I0818 17:43:10.217638  2522 net.cpp:434] loss1 <- glasses_slice1_0_split_0
I0818 17:43:10.217648  2522 net.cpp:408] loss1 -> loss1
I0818 17:43:10.217663  2522 layer_factory.hpp:77] Creating layer loss1
I0818 17:43:10.217903  2522 net.cpp:150] Setting up loss1
I0818 17:43:10.217919  2522 net.cpp:157] Top shape: (1)
I0818 17:43:10.217927  2522 net.cpp:160]     with loss weight 0.4
I0818 17:43:10.217944  2522 net.cpp:165] Memory required for data: 111447556
I0818 17:43:10.217953  2522 layer_factory.hpp:77] Creating layer accuracy_glasses
I0818 17:43:10.217964  2522 net.cpp:100] Creating Layer accuracy_glasses
I0818 17:43:10.217975  2522 net.cpp:434] accuracy_glasses <- ip2_ip2_0_split_1
I0818 17:43:10.217984  2522 net.cpp:434] accuracy_glasses <- glasses_slice1_0_split_1
I0818 17:43:10.217998  2522 net.cpp:408] accuracy_glasses -> accuracy_glasses
I0818 17:43:10.218013  2522 net.cpp:150] Setting up accuracy_glasses
I0818 17:43:10.218024  2522 net.cpp:157] Top shape: (1)
I0818 17:43:10.218032  2522 net.cpp:165] Memory required for data: 111447560
I0818 17:43:10.218040  2522 layer_factory.hpp:77] Creating layer ip3
I0818 17:43:10.218051  2522 net.cpp:100] Creating Layer ip3
I0818 17:43:10.218060  2522 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0818 17:43:10.218071  2522 net.cpp:408] ip3 -> ip3
I0818 17:43:10.218170  2522 net.cpp:150] Setting up ip3
I0818 17:43:10.218183  2522 net.cpp:157] Top shape: 64 2 (128)
I0818 17:43:10.218191  2522 net.cpp:165] Memory required for data: 111448072
I0818 17:43:10.218204  2522 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0818 17:43:10.218214  2522 net.cpp:100] Creating Layer ip3_ip3_0_split
I0818 17:43:10.218222  2522 net.cpp:434] ip3_ip3_0_split <- ip3
I0818 17:43:10.218231  2522 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0818 17:43:10.218243  2522 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0818 17:43:10.218281  2522 net.cpp:150] Setting up ip3_ip3_0_split
I0818 17:43:10.218293  2522 net.cpp:157] Top shape: 64 2 (128)
I0818 17:43:10.218302  2522 net.cpp:157] Top shape: 64 2 (128)
I0818 17:43:10.218310  2522 net.cpp:165] Memory required for data: 111449096
I0818 17:43:10.218318  2522 layer_factory.hpp:77] Creating layer loss2
I0818 17:43:10.218330  2522 net.cpp:100] Creating Layer loss2
I0818 17:43:10.218339  2522 net.cpp:434] loss2 <- ip3_ip3_0_split_0
I0818 17:43:10.218349  2522 net.cpp:434] loss2 <- gender_slice1_1_split_0
I0818 17:43:10.218359  2522 net.cpp:408] loss2 -> loss2
I0818 17:43:10.218371  2522 layer_factory.hpp:77] Creating layer loss2
I0818 17:43:10.218782  2522 net.cpp:150] Setting up loss2
I0818 17:43:10.218799  2522 net.cpp:157] Top shape: (1)
I0818 17:43:10.218807  2522 net.cpp:160]     with loss weight 0.6
I0818 17:43:10.218818  2522 net.cpp:165] Memory required for data: 111449100
I0818 17:43:10.218827  2522 layer_factory.hpp:77] Creating layer accuracy_gender
I0818 17:43:10.218839  2522 net.cpp:100] Creating Layer accuracy_gender
I0818 17:43:10.218849  2522 net.cpp:434] accuracy_gender <- ip3_ip3_0_split_1
I0818 17:43:10.218858  2522 net.cpp:434] accuracy_gender <- gender_slice1_1_split_1
I0818 17:43:10.218870  2522 net.cpp:408] accuracy_gender -> accuracy_gender
I0818 17:43:10.218885  2522 net.cpp:150] Setting up accuracy_gender
I0818 17:43:10.218895  2522 net.cpp:157] Top shape: (1)
I0818 17:43:10.218904  2522 net.cpp:165] Memory required for data: 111449104
I0818 17:43:10.218912  2522 net.cpp:228] accuracy_gender does not need backward computation.
I0818 17:43:10.218921  2522 net.cpp:226] loss2 needs backward computation.
I0818 17:43:10.218930  2522 net.cpp:226] ip3_ip3_0_split needs backward computation.
I0818 17:43:10.218938  2522 net.cpp:226] ip3 needs backward computation.
I0818 17:43:10.218947  2522 net.cpp:228] accuracy_glasses does not need backward computation.
I0818 17:43:10.218956  2522 net.cpp:226] loss1 needs backward computation.
I0818 17:43:10.218964  2522 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0818 17:43:10.218973  2522 net.cpp:226] ip2 needs backward computation.
I0818 17:43:10.218981  2522 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0818 17:43:10.218991  2522 net.cpp:226] drop1 needs backward computation.
I0818 17:43:10.218998  2522 net.cpp:226] relu5 needs backward computation.
I0818 17:43:10.219007  2522 net.cpp:226] ip1 needs backward computation.
I0818 17:43:10.219014  2522 net.cpp:226] relu3 needs backward computation.
I0818 17:43:10.219022  2522 net.cpp:226] conv3 needs backward computation.
I0818 17:43:10.219032  2522 net.cpp:226] pool2 needs backward computation.
I0818 17:43:10.219039  2522 net.cpp:226] relu2 needs backward computation.
I0818 17:43:10.219048  2522 net.cpp:226] conv2 needs backward computation.
I0818 17:43:10.219056  2522 net.cpp:226] pool1 needs backward computation.
I0818 17:43:10.219064  2522 net.cpp:226] relu1 needs backward computation.
I0818 17:43:10.219072  2522 net.cpp:226] conv1 needs backward computation.
I0818 17:43:10.219081  2522 net.cpp:228] gender_slice1_1_split does not need backward computation.
I0818 17:43:10.219090  2522 net.cpp:228] glasses_slice1_0_split does not need backward computation.
I0818 17:43:10.219100  2522 net.cpp:228] slice1 does not need backward computation.
I0818 17:43:10.219108  2522 net.cpp:228] labels does not need backward computation.
I0818 17:43:10.219116  2522 net.cpp:228] data does not need backward computation.
I0818 17:43:10.219125  2522 net.cpp:270] This network produces output accuracy_gender
I0818 17:43:10.219132  2522 net.cpp:270] This network produces output accuracy_glasses
I0818 17:43:10.219141  2522 net.cpp:270] This network produces output loss1
I0818 17:43:10.219149  2522 net.cpp:270] This network produces output loss2
I0818 17:43:10.219174  2522 net.cpp:283] Network initialization done.
I0818 17:43:10.219269  2522 solver.cpp:60] Solver scaffolding done.
I0818 17:43:10.219756  2522 caffe.cpp:251] Starting Optimization
I0818 17:43:10.219769  2522 solver.cpp:279] Solving multi_task
I0818 17:43:10.219776  2522 solver.cpp:280] Learning Rate Policy: step
I0818 17:43:10.220674  2522 solver.cpp:337] Iteration 0, Testing net (#0)
I0818 17:43:23.344451  2522 blocking_queue.cpp:50] Data layer prefetch queue empty
I0818 17:43:44.859426  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.513203
I0818 17:43:44.859521  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.340062
I0818 17:43:44.859551  2522 solver.cpp:404]     Test net output #2: loss1 = 0.70101 (* 0.4 = 0.280404 loss)
I0818 17:43:44.859570  2522 solver.cpp:404]     Test net output #3: loss2 = 0.689135 (* 0.6 = 0.413481 loss)
I0818 17:43:45.031595  2522 solver.cpp:228] Iteration 0, loss = 0.69287
I0818 17:43:45.031657  2522 solver.cpp:244]     Train net output #0: loss1 = 0.703509 (* 0.4 = 0.281404 loss)
I0818 17:43:45.031680  2522 solver.cpp:244]     Train net output #1: loss2 = 0.685777 (* 0.6 = 0.411466 loss)
I0818 17:43:45.031709  2522 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0818 17:43:47.896662  2522 solver.cpp:228] Iteration 20, loss = 0.653788
I0818 17:43:47.896711  2522 solver.cpp:244]     Train net output #0: loss1 = 0.658915 (* 0.4 = 0.263566 loss)
I0818 17:43:47.896726  2522 solver.cpp:244]     Train net output #1: loss2 = 0.650371 (* 0.6 = 0.390222 loss)
I0818 17:43:47.896739  2522 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0818 17:43:50.843895  2522 solver.cpp:228] Iteration 40, loss = 0.603339
I0818 17:43:50.843945  2522 solver.cpp:244]     Train net output #0: loss1 = 0.592462 (* 0.4 = 0.236985 loss)
I0818 17:43:50.843960  2522 solver.cpp:244]     Train net output #1: loss2 = 0.610591 (* 0.6 = 0.366354 loss)
I0818 17:43:50.843972  2522 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0818 17:43:53.789480  2522 solver.cpp:228] Iteration 60, loss = 0.563538
I0818 17:43:53.789535  2522 solver.cpp:244]     Train net output #0: loss1 = 0.507904 (* 0.4 = 0.203162 loss)
I0818 17:43:53.789551  2522 solver.cpp:244]     Train net output #1: loss2 = 0.600628 (* 0.6 = 0.360377 loss)
I0818 17:43:53.789563  2522 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0818 17:43:56.733726  2522 solver.cpp:228] Iteration 80, loss = 0.491669
I0818 17:43:56.733775  2522 solver.cpp:244]     Train net output #0: loss1 = 0.482 (* 0.4 = 0.1928 loss)
I0818 17:43:56.733790  2522 solver.cpp:244]     Train net output #1: loss2 = 0.498114 (* 0.6 = 0.298868 loss)
I0818 17:43:56.733803  2522 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0818 17:43:59.679770  2522 solver.cpp:228] Iteration 100, loss = 0.532448
I0818 17:43:59.679824  2522 solver.cpp:244]     Train net output #0: loss1 = 0.343893 (* 0.4 = 0.137557 loss)
I0818 17:43:59.679839  2522 solver.cpp:244]     Train net output #1: loss2 = 0.658152 (* 0.6 = 0.394891 loss)
I0818 17:43:59.679852  2522 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0818 17:44:02.629393  2522 solver.cpp:228] Iteration 120, loss = 0.464981
I0818 17:44:02.629446  2522 solver.cpp:244]     Train net output #0: loss1 = 0.393887 (* 0.4 = 0.157555 loss)
I0818 17:44:02.629462  2522 solver.cpp:244]     Train net output #1: loss2 = 0.512377 (* 0.6 = 0.307426 loss)
I0818 17:44:02.629475  2522 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0818 17:44:05.578655  2522 solver.cpp:228] Iteration 140, loss = 0.531175
I0818 17:44:05.578704  2522 solver.cpp:244]     Train net output #0: loss1 = 0.454669 (* 0.4 = 0.181868 loss)
I0818 17:44:05.578721  2522 solver.cpp:244]     Train net output #1: loss2 = 0.582178 (* 0.6 = 0.349307 loss)
I0818 17:44:05.578733  2522 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0818 17:44:08.527871  2522 solver.cpp:228] Iteration 160, loss = 0.422087
I0818 17:44:08.527925  2522 solver.cpp:244]     Train net output #0: loss1 = 0.272711 (* 0.4 = 0.109084 loss)
I0818 17:44:08.527940  2522 solver.cpp:244]     Train net output #1: loss2 = 0.521671 (* 0.6 = 0.313003 loss)
I0818 17:44:08.527952  2522 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0818 17:44:11.474939  2522 solver.cpp:228] Iteration 180, loss = 0.465251
I0818 17:44:11.474993  2522 solver.cpp:244]     Train net output #0: loss1 = 0.254143 (* 0.4 = 0.101657 loss)
I0818 17:44:11.475008  2522 solver.cpp:244]     Train net output #1: loss2 = 0.60599 (* 0.6 = 0.363594 loss)
I0818 17:44:11.475021  2522 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0818 17:44:14.426684  2522 solver.cpp:228] Iteration 200, loss = 0.437563
I0818 17:44:14.426734  2522 solver.cpp:244]     Train net output #0: loss1 = 0.30711 (* 0.4 = 0.122844 loss)
I0818 17:44:14.426780  2522 solver.cpp:244]     Train net output #1: loss2 = 0.524531 (* 0.6 = 0.314719 loss)
I0818 17:44:14.426795  2522 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0818 17:44:17.375890  2522 solver.cpp:228] Iteration 220, loss = 0.423625
I0818 17:44:17.376041  2522 solver.cpp:244]     Train net output #0: loss1 = 0.375063 (* 0.4 = 0.150025 loss)
I0818 17:44:17.376058  2522 solver.cpp:244]     Train net output #1: loss2 = 0.455999 (* 0.6 = 0.273599 loss)
I0818 17:44:17.376071  2522 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0818 17:44:20.322962  2522 solver.cpp:228] Iteration 240, loss = 0.423641
I0818 17:44:20.323015  2522 solver.cpp:244]     Train net output #0: loss1 = 0.268099 (* 0.4 = 0.107239 loss)
I0818 17:44:20.323031  2522 solver.cpp:244]     Train net output #1: loss2 = 0.527335 (* 0.6 = 0.316401 loss)
I0818 17:44:20.323043  2522 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0818 17:44:23.271368  2522 solver.cpp:228] Iteration 260, loss = 0.374733
I0818 17:44:23.271421  2522 solver.cpp:244]     Train net output #0: loss1 = 0.233446 (* 0.4 = 0.0933784 loss)
I0818 17:44:23.271437  2522 solver.cpp:244]     Train net output #1: loss2 = 0.468924 (* 0.6 = 0.281354 loss)
I0818 17:44:23.271450  2522 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0818 17:44:26.217281  2522 solver.cpp:228] Iteration 280, loss = 0.420842
I0818 17:44:26.217332  2522 solver.cpp:244]     Train net output #0: loss1 = 0.322496 (* 0.4 = 0.128999 loss)
I0818 17:44:26.217347  2522 solver.cpp:244]     Train net output #1: loss2 = 0.486405 (* 0.6 = 0.291843 loss)
I0818 17:44:26.217360  2522 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0818 17:44:29.172277  2522 solver.cpp:228] Iteration 300, loss = 0.319813
I0818 17:44:29.172329  2522 solver.cpp:244]     Train net output #0: loss1 = 0.295362 (* 0.4 = 0.118145 loss)
I0818 17:44:29.172345  2522 solver.cpp:244]     Train net output #1: loss2 = 0.336114 (* 0.6 = 0.201668 loss)
I0818 17:44:29.172358  2522 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0818 17:44:32.120887  2522 solver.cpp:228] Iteration 320, loss = 0.335762
I0818 17:44:32.120941  2522 solver.cpp:244]     Train net output #0: loss1 = 0.17749 (* 0.4 = 0.0709959 loss)
I0818 17:44:32.120957  2522 solver.cpp:244]     Train net output #1: loss2 = 0.441277 (* 0.6 = 0.264766 loss)
I0818 17:44:32.120970  2522 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0818 17:44:35.067883  2522 solver.cpp:228] Iteration 340, loss = 0.331036
I0818 17:44:35.067935  2522 solver.cpp:244]     Train net output #0: loss1 = 0.263749 (* 0.4 = 0.1055 loss)
I0818 17:44:35.067951  2522 solver.cpp:244]     Train net output #1: loss2 = 0.375894 (* 0.6 = 0.225536 loss)
I0818 17:44:35.067965  2522 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0818 17:44:38.015944  2522 solver.cpp:228] Iteration 360, loss = 0.362831
I0818 17:44:38.015997  2522 solver.cpp:244]     Train net output #0: loss1 = 0.243271 (* 0.4 = 0.0973085 loss)
I0818 17:44:38.016013  2522 solver.cpp:244]     Train net output #1: loss2 = 0.442537 (* 0.6 = 0.265522 loss)
I0818 17:44:38.016026  2522 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0818 17:44:40.966603  2522 solver.cpp:228] Iteration 380, loss = 0.324308
I0818 17:44:40.966653  2522 solver.cpp:244]     Train net output #0: loss1 = 0.209831 (* 0.4 = 0.0839323 loss)
I0818 17:44:40.966670  2522 solver.cpp:244]     Train net output #1: loss2 = 0.400627 (* 0.6 = 0.240376 loss)
I0818 17:44:40.966682  2522 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0818 17:44:43.913802  2522 solver.cpp:228] Iteration 400, loss = 0.364634
I0818 17:44:43.913856  2522 solver.cpp:244]     Train net output #0: loss1 = 0.228363 (* 0.4 = 0.0913451 loss)
I0818 17:44:43.913873  2522 solver.cpp:244]     Train net output #1: loss2 = 0.455481 (* 0.6 = 0.273289 loss)
I0818 17:44:43.913885  2522 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0818 17:44:46.862754  2522 solver.cpp:228] Iteration 420, loss = 0.30301
I0818 17:44:46.862804  2522 solver.cpp:244]     Train net output #0: loss1 = 0.190183 (* 0.4 = 0.0760733 loss)
I0818 17:44:46.862820  2522 solver.cpp:244]     Train net output #1: loss2 = 0.378227 (* 0.6 = 0.226936 loss)
I0818 17:44:46.862833  2522 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0818 17:44:49.810647  2522 solver.cpp:228] Iteration 440, loss = 0.35821
I0818 17:44:49.810776  2522 solver.cpp:244]     Train net output #0: loss1 = 0.175768 (* 0.4 = 0.0703073 loss)
I0818 17:44:49.810793  2522 solver.cpp:244]     Train net output #1: loss2 = 0.479837 (* 0.6 = 0.287902 loss)
I0818 17:44:49.810806  2522 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0818 17:44:52.762070  2522 solver.cpp:228] Iteration 460, loss = 0.434217
I0818 17:44:52.762123  2522 solver.cpp:244]     Train net output #0: loss1 = 0.29382 (* 0.4 = 0.117528 loss)
I0818 17:44:52.762140  2522 solver.cpp:244]     Train net output #1: loss2 = 0.527816 (* 0.6 = 0.316689 loss)
I0818 17:44:52.762151  2522 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0818 17:44:55.711307  2522 solver.cpp:228] Iteration 480, loss = 0.322952
I0818 17:44:55.711360  2522 solver.cpp:244]     Train net output #0: loss1 = 0.141424 (* 0.4 = 0.0565697 loss)
I0818 17:44:55.711376  2522 solver.cpp:244]     Train net output #1: loss2 = 0.44397 (* 0.6 = 0.266382 loss)
I0818 17:44:55.711390  2522 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0818 17:44:58.659773  2522 solver.cpp:228] Iteration 500, loss = 0.360248
I0818 17:44:58.659826  2522 solver.cpp:244]     Train net output #0: loss1 = 0.184817 (* 0.4 = 0.0739266 loss)
I0818 17:44:58.659842  2522 solver.cpp:244]     Train net output #1: loss2 = 0.477202 (* 0.6 = 0.286321 loss)
I0818 17:44:58.659855  2522 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0818 17:45:01.610131  2522 solver.cpp:228] Iteration 520, loss = 0.28282
I0818 17:45:01.610183  2522 solver.cpp:244]     Train net output #0: loss1 = 0.126218 (* 0.4 = 0.0504871 loss)
I0818 17:45:01.610199  2522 solver.cpp:244]     Train net output #1: loss2 = 0.387221 (* 0.6 = 0.232333 loss)
I0818 17:45:01.610213  2522 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0818 17:45:04.561416  2522 solver.cpp:228] Iteration 540, loss = 0.269306
I0818 17:45:04.561470  2522 solver.cpp:244]     Train net output #0: loss1 = 0.205763 (* 0.4 = 0.082305 loss)
I0818 17:45:04.561486  2522 solver.cpp:244]     Train net output #1: loss2 = 0.311668 (* 0.6 = 0.187001 loss)
I0818 17:45:04.561499  2522 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0818 17:45:07.510082  2522 solver.cpp:228] Iteration 560, loss = 0.286811
I0818 17:45:07.510136  2522 solver.cpp:244]     Train net output #0: loss1 = 0.17275 (* 0.4 = 0.0691001 loss)
I0818 17:45:07.510152  2522 solver.cpp:244]     Train net output #1: loss2 = 0.362852 (* 0.6 = 0.217711 loss)
I0818 17:45:07.510165  2522 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0818 17:45:10.458490  2522 solver.cpp:228] Iteration 580, loss = 0.360802
I0818 17:45:10.458542  2522 solver.cpp:244]     Train net output #0: loss1 = 0.191568 (* 0.4 = 0.0766272 loss)
I0818 17:45:10.458559  2522 solver.cpp:244]     Train net output #1: loss2 = 0.473624 (* 0.6 = 0.284174 loss)
I0818 17:45:10.458571  2522 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0818 17:45:13.407335  2522 solver.cpp:228] Iteration 600, loss = 0.286894
I0818 17:45:13.407388  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0625333 (* 0.4 = 0.0250133 loss)
I0818 17:45:13.407404  2522 solver.cpp:244]     Train net output #1: loss2 = 0.436469 (* 0.6 = 0.261881 loss)
I0818 17:45:13.407418  2522 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0818 17:45:16.361181  2522 solver.cpp:228] Iteration 620, loss = 0.260363
I0818 17:45:16.361235  2522 solver.cpp:244]     Train net output #0: loss1 = 0.151299 (* 0.4 = 0.0605197 loss)
I0818 17:45:16.361251  2522 solver.cpp:244]     Train net output #1: loss2 = 0.333073 (* 0.6 = 0.199844 loss)
I0818 17:45:16.361265  2522 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0818 17:45:19.309216  2522 solver.cpp:228] Iteration 640, loss = 0.367324
I0818 17:45:19.309270  2522 solver.cpp:244]     Train net output #0: loss1 = 0.265787 (* 0.4 = 0.106315 loss)
I0818 17:45:19.309285  2522 solver.cpp:244]     Train net output #1: loss2 = 0.435015 (* 0.6 = 0.261009 loss)
I0818 17:45:19.309298  2522 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0818 17:45:22.257470  2522 solver.cpp:228] Iteration 660, loss = 0.282943
I0818 17:45:22.257625  2522 solver.cpp:244]     Train net output #0: loss1 = 0.128518 (* 0.4 = 0.0514072 loss)
I0818 17:45:22.257642  2522 solver.cpp:244]     Train net output #1: loss2 = 0.385893 (* 0.6 = 0.231536 loss)
I0818 17:45:22.257655  2522 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0818 17:45:25.207360  2522 solver.cpp:228] Iteration 680, loss = 0.336898
I0818 17:45:25.207412  2522 solver.cpp:244]     Train net output #0: loss1 = 0.225699 (* 0.4 = 0.0902795 loss)
I0818 17:45:25.207427  2522 solver.cpp:244]     Train net output #1: loss2 = 0.411031 (* 0.6 = 0.246618 loss)
I0818 17:45:25.207440  2522 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0818 17:45:28.155791  2522 solver.cpp:228] Iteration 700, loss = 0.334254
I0818 17:45:28.155843  2522 solver.cpp:244]     Train net output #0: loss1 = 0.160709 (* 0.4 = 0.0642834 loss)
I0818 17:45:28.155859  2522 solver.cpp:244]     Train net output #1: loss2 = 0.44995 (* 0.6 = 0.26997 loss)
I0818 17:45:28.155872  2522 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0818 17:45:31.105327  2522 solver.cpp:228] Iteration 720, loss = 0.273442
I0818 17:45:31.105381  2522 solver.cpp:244]     Train net output #0: loss1 = 0.182228 (* 0.4 = 0.072891 loss)
I0818 17:45:31.105396  2522 solver.cpp:244]     Train net output #1: loss2 = 0.334251 (* 0.6 = 0.200551 loss)
I0818 17:45:31.105410  2522 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0818 17:45:34.052891  2522 solver.cpp:228] Iteration 740, loss = 0.277949
I0818 17:45:34.052943  2522 solver.cpp:244]     Train net output #0: loss1 = 0.177146 (* 0.4 = 0.0708584 loss)
I0818 17:45:34.052959  2522 solver.cpp:244]     Train net output #1: loss2 = 0.345151 (* 0.6 = 0.207091 loss)
I0818 17:45:34.052971  2522 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0818 17:45:37.002009  2522 solver.cpp:228] Iteration 760, loss = 0.20311
I0818 17:45:37.002063  2522 solver.cpp:244]     Train net output #0: loss1 = 0.094276 (* 0.4 = 0.0377104 loss)
I0818 17:45:37.002079  2522 solver.cpp:244]     Train net output #1: loss2 = 0.275666 (* 0.6 = 0.165399 loss)
I0818 17:45:37.002091  2522 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0818 17:45:39.956092  2522 solver.cpp:228] Iteration 780, loss = 0.241311
I0818 17:45:39.956147  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0754028 (* 0.4 = 0.0301611 loss)
I0818 17:45:39.956162  2522 solver.cpp:244]     Train net output #1: loss2 = 0.351916 (* 0.6 = 0.21115 loss)
I0818 17:45:39.956176  2522 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0818 17:45:42.906720  2522 solver.cpp:228] Iteration 800, loss = 0.200435
I0818 17:45:42.906774  2522 solver.cpp:244]     Train net output #0: loss1 = 0.112985 (* 0.4 = 0.0451939 loss)
I0818 17:45:42.906790  2522 solver.cpp:244]     Train net output #1: loss2 = 0.258735 (* 0.6 = 0.155241 loss)
I0818 17:45:42.906802  2522 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0818 17:45:45.855221  2522 solver.cpp:228] Iteration 820, loss = 0.199425
I0818 17:45:45.855273  2522 solver.cpp:244]     Train net output #0: loss1 = 0.106498 (* 0.4 = 0.0425991 loss)
I0818 17:45:45.855289  2522 solver.cpp:244]     Train net output #1: loss2 = 0.261376 (* 0.6 = 0.156826 loss)
I0818 17:45:45.855303  2522 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0818 17:45:48.803575  2522 solver.cpp:228] Iteration 840, loss = 0.211223
I0818 17:45:48.803628  2522 solver.cpp:244]     Train net output #0: loss1 = 0.106473 (* 0.4 = 0.0425893 loss)
I0818 17:45:48.803644  2522 solver.cpp:244]     Train net output #1: loss2 = 0.281057 (* 0.6 = 0.168634 loss)
I0818 17:45:48.803658  2522 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0818 17:45:51.758102  2522 solver.cpp:228] Iteration 860, loss = 0.251801
I0818 17:45:51.758154  2522 solver.cpp:244]     Train net output #0: loss1 = 0.10705 (* 0.4 = 0.0428201 loss)
I0818 17:45:51.758170  2522 solver.cpp:244]     Train net output #1: loss2 = 0.348302 (* 0.6 = 0.208981 loss)
I0818 17:45:51.758183  2522 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0818 17:45:54.707242  2522 solver.cpp:228] Iteration 880, loss = 0.24431
I0818 17:45:54.707357  2522 solver.cpp:244]     Train net output #0: loss1 = 0.17046 (* 0.4 = 0.0681842 loss)
I0818 17:45:54.707375  2522 solver.cpp:244]     Train net output #1: loss2 = 0.293542 (* 0.6 = 0.176125 loss)
I0818 17:45:54.707387  2522 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0818 17:45:57.657011  2522 solver.cpp:228] Iteration 900, loss = 0.229769
I0818 17:45:57.657065  2522 solver.cpp:244]     Train net output #0: loss1 = 0.2267 (* 0.4 = 0.0906801 loss)
I0818 17:45:57.657081  2522 solver.cpp:244]     Train net output #1: loss2 = 0.231815 (* 0.6 = 0.139089 loss)
I0818 17:45:57.657094  2522 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0818 17:46:00.608888  2522 solver.cpp:228] Iteration 920, loss = 0.284482
I0818 17:46:00.608943  2522 solver.cpp:244]     Train net output #0: loss1 = 0.155526 (* 0.4 = 0.0622104 loss)
I0818 17:46:00.608959  2522 solver.cpp:244]     Train net output #1: loss2 = 0.370453 (* 0.6 = 0.222272 loss)
I0818 17:46:00.608973  2522 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0818 17:46:03.560855  2522 solver.cpp:228] Iteration 940, loss = 0.227038
I0818 17:46:03.560909  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0995857 (* 0.4 = 0.0398343 loss)
I0818 17:46:03.560925  2522 solver.cpp:244]     Train net output #1: loss2 = 0.312005 (* 0.6 = 0.187203 loss)
I0818 17:46:03.560937  2522 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0818 17:46:06.511345  2522 solver.cpp:228] Iteration 960, loss = 0.223297
I0818 17:46:06.511399  2522 solver.cpp:244]     Train net output #0: loss1 = 0.209307 (* 0.4 = 0.083723 loss)
I0818 17:46:06.511414  2522 solver.cpp:244]     Train net output #1: loss2 = 0.232624 (* 0.6 = 0.139574 loss)
I0818 17:46:06.511426  2522 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0818 17:46:09.462178  2522 solver.cpp:228] Iteration 980, loss = 0.213397
I0818 17:46:09.462231  2522 solver.cpp:244]     Train net output #0: loss1 = 0.125907 (* 0.4 = 0.0503626 loss)
I0818 17:46:09.462247  2522 solver.cpp:244]     Train net output #1: loss2 = 0.271724 (* 0.6 = 0.163034 loss)
I0818 17:46:09.462260  2522 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0818 17:46:12.262878  2522 solver.cpp:337] Iteration 1000, Testing net (#0)
I0818 17:46:47.207608  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.809578
I0818 17:46:47.207697  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.945625
I0818 17:46:47.207717  2522 solver.cpp:404]     Test net output #2: loss1 = 0.177659 (* 0.4 = 0.0710638 loss)
I0818 17:46:47.207731  2522 solver.cpp:404]     Test net output #3: loss2 = 0.395306 (* 0.6 = 0.237184 loss)
I0818 17:46:47.255511  2522 solver.cpp:228] Iteration 1000, loss = 0.218326
I0818 17:46:47.255563  2522 solver.cpp:244]     Train net output #0: loss1 = 0.109076 (* 0.4 = 0.0436306 loss)
I0818 17:46:47.255578  2522 solver.cpp:244]     Train net output #1: loss2 = 0.291159 (* 0.6 = 0.174695 loss)
I0818 17:46:47.255592  2522 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0818 17:46:50.207253  2522 solver.cpp:228] Iteration 1020, loss = 0.19867
I0818 17:46:50.207306  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0739278 (* 0.4 = 0.0295711 loss)
I0818 17:46:50.207322  2522 solver.cpp:244]     Train net output #1: loss2 = 0.281832 (* 0.6 = 0.169099 loss)
I0818 17:46:50.207335  2522 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0818 17:46:53.156429  2522 solver.cpp:228] Iteration 1040, loss = 0.233238
I0818 17:46:53.156482  2522 solver.cpp:244]     Train net output #0: loss1 = 0.137432 (* 0.4 = 0.0549729 loss)
I0818 17:46:53.156498  2522 solver.cpp:244]     Train net output #1: loss2 = 0.297108 (* 0.6 = 0.178265 loss)
I0818 17:46:53.156512  2522 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0818 17:46:56.106267  2522 solver.cpp:228] Iteration 1060, loss = 0.263259
I0818 17:46:56.106323  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0919711 (* 0.4 = 0.0367884 loss)
I0818 17:46:56.106339  2522 solver.cpp:244]     Train net output #1: loss2 = 0.37745 (* 0.6 = 0.22647 loss)
I0818 17:46:56.106351  2522 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0818 17:46:59.061076  2522 solver.cpp:228] Iteration 1080, loss = 0.246514
I0818 17:46:59.061132  2522 solver.cpp:244]     Train net output #0: loss1 = 0.120419 (* 0.4 = 0.0481678 loss)
I0818 17:46:59.061148  2522 solver.cpp:244]     Train net output #1: loss2 = 0.330576 (* 0.6 = 0.198346 loss)
I0818 17:46:59.061161  2522 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0818 17:47:02.011008  2522 solver.cpp:228] Iteration 1100, loss = 0.227685
I0818 17:47:02.011060  2522 solver.cpp:244]     Train net output #0: loss1 = 0.138154 (* 0.4 = 0.0552616 loss)
I0818 17:47:02.011076  2522 solver.cpp:244]     Train net output #1: loss2 = 0.287373 (* 0.6 = 0.172424 loss)
I0818 17:47:02.011090  2522 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0818 17:47:04.960741  2522 solver.cpp:228] Iteration 1120, loss = 0.210786
I0818 17:47:04.960793  2522 solver.cpp:244]     Train net output #0: loss1 = 0.122926 (* 0.4 = 0.0491703 loss)
I0818 17:47:04.960808  2522 solver.cpp:244]     Train net output #1: loss2 = 0.26936 (* 0.6 = 0.161616 loss)
I0818 17:47:04.960821  2522 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0818 17:47:07.918261  2522 solver.cpp:228] Iteration 1140, loss = 0.312276
I0818 17:47:07.918314  2522 solver.cpp:244]     Train net output #0: loss1 = 0.220569 (* 0.4 = 0.0882277 loss)
I0818 17:47:07.918330  2522 solver.cpp:244]     Train net output #1: loss2 = 0.373414 (* 0.6 = 0.224048 loss)
I0818 17:47:07.918344  2522 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0818 17:47:10.869761  2522 solver.cpp:228] Iteration 1160, loss = 0.15791
I0818 17:47:10.869814  2522 solver.cpp:244]     Train net output #0: loss1 = 0.086978 (* 0.4 = 0.0347912 loss)
I0818 17:47:10.869830  2522 solver.cpp:244]     Train net output #1: loss2 = 0.205197 (* 0.6 = 0.123118 loss)
I0818 17:47:10.869843  2522 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0818 17:47:13.820240  2522 solver.cpp:228] Iteration 1180, loss = 0.17968
I0818 17:47:13.820291  2522 solver.cpp:244]     Train net output #0: loss1 = 0.117711 (* 0.4 = 0.0470843 loss)
I0818 17:47:13.820307  2522 solver.cpp:244]     Train net output #1: loss2 = 0.220992 (* 0.6 = 0.132595 loss)
I0818 17:47:13.820318  2522 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0818 17:47:16.772130  2522 solver.cpp:228] Iteration 1200, loss = 0.197346
I0818 17:47:16.772210  2522 solver.cpp:244]     Train net output #0: loss1 = 0.143133 (* 0.4 = 0.0572533 loss)
I0818 17:47:16.772228  2522 solver.cpp:244]     Train net output #1: loss2 = 0.233487 (* 0.6 = 0.140092 loss)
I0818 17:47:16.772240  2522 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0818 17:47:19.726238  2522 solver.cpp:228] Iteration 1220, loss = 0.219122
I0818 17:47:19.726351  2522 solver.cpp:244]     Train net output #0: loss1 = 0.073754 (* 0.4 = 0.0295016 loss)
I0818 17:47:19.726368  2522 solver.cpp:244]     Train net output #1: loss2 = 0.316034 (* 0.6 = 0.18962 loss)
I0818 17:47:19.726382  2522 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0818 17:47:22.676846  2522 solver.cpp:228] Iteration 1240, loss = 0.259559
I0818 17:47:22.676899  2522 solver.cpp:244]     Train net output #0: loss1 = 0.228178 (* 0.4 = 0.0912713 loss)
I0818 17:47:22.676914  2522 solver.cpp:244]     Train net output #1: loss2 = 0.280479 (* 0.6 = 0.168287 loss)
I0818 17:47:22.676928  2522 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0818 17:47:25.627257  2522 solver.cpp:228] Iteration 1260, loss = 0.203369
I0818 17:47:25.627311  2522 solver.cpp:244]     Train net output #0: loss1 = 0.112551 (* 0.4 = 0.0450204 loss)
I0818 17:47:25.627327  2522 solver.cpp:244]     Train net output #1: loss2 = 0.263915 (* 0.6 = 0.158349 loss)
I0818 17:47:25.627341  2522 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0818 17:47:28.578912  2522 solver.cpp:228] Iteration 1280, loss = 0.283088
I0818 17:47:28.578965  2522 solver.cpp:244]     Train net output #0: loss1 = 0.243557 (* 0.4 = 0.097423 loss)
I0818 17:47:28.578981  2522 solver.cpp:244]     Train net output #1: loss2 = 0.309442 (* 0.6 = 0.185665 loss)
I0818 17:47:28.578994  2522 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0818 17:47:31.534159  2522 solver.cpp:228] Iteration 1300, loss = 0.230809
I0818 17:47:31.534214  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0732211 (* 0.4 = 0.0292884 loss)
I0818 17:47:31.534230  2522 solver.cpp:244]     Train net output #1: loss2 = 0.335867 (* 0.6 = 0.20152 loss)
I0818 17:47:31.534242  2522 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0818 17:47:34.485083  2522 solver.cpp:228] Iteration 1320, loss = 0.171909
I0818 17:47:34.485138  2522 solver.cpp:244]     Train net output #0: loss1 = 0.110108 (* 0.4 = 0.0440432 loss)
I0818 17:47:34.485154  2522 solver.cpp:244]     Train net output #1: loss2 = 0.21311 (* 0.6 = 0.127866 loss)
I0818 17:47:34.485167  2522 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0818 17:47:37.436450  2522 solver.cpp:228] Iteration 1340, loss = 0.181814
I0818 17:47:37.436501  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0466582 (* 0.4 = 0.0186633 loss)
I0818 17:47:37.436517  2522 solver.cpp:244]     Train net output #1: loss2 = 0.271919 (* 0.6 = 0.163151 loss)
I0818 17:47:37.436530  2522 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0818 17:47:40.387785  2522 solver.cpp:228] Iteration 1360, loss = 0.249769
I0818 17:47:40.387838  2522 solver.cpp:244]     Train net output #0: loss1 = 0.141102 (* 0.4 = 0.0564406 loss)
I0818 17:47:40.387854  2522 solver.cpp:244]     Train net output #1: loss2 = 0.322214 (* 0.6 = 0.193328 loss)
I0818 17:47:40.387867  2522 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0818 17:47:43.339864  2522 solver.cpp:228] Iteration 1380, loss = 0.240819
I0818 17:47:43.339915  2522 solver.cpp:244]     Train net output #0: loss1 = 0.130829 (* 0.4 = 0.0523316 loss)
I0818 17:47:43.339931  2522 solver.cpp:244]     Train net output #1: loss2 = 0.314145 (* 0.6 = 0.188487 loss)
I0818 17:47:43.339942  2522 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0818 17:47:46.302331  2522 solver.cpp:228] Iteration 1400, loss = 0.243135
I0818 17:47:46.302382  2522 solver.cpp:244]     Train net output #0: loss1 = 0.110091 (* 0.4 = 0.0440366 loss)
I0818 17:47:46.302398  2522 solver.cpp:244]     Train net output #1: loss2 = 0.331831 (* 0.6 = 0.199099 loss)
I0818 17:47:46.302412  2522 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0818 17:47:49.268152  2522 solver.cpp:228] Iteration 1420, loss = 0.155595
I0818 17:47:49.268203  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0791396 (* 0.4 = 0.0316558 loss)
I0818 17:47:49.268218  2522 solver.cpp:244]     Train net output #1: loss2 = 0.206566 (* 0.6 = 0.123939 loss)
I0818 17:47:49.268231  2522 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0818 17:47:52.222306  2522 solver.cpp:228] Iteration 1440, loss = 0.182603
I0818 17:47:52.222442  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0819649 (* 0.4 = 0.032786 loss)
I0818 17:47:52.222460  2522 solver.cpp:244]     Train net output #1: loss2 = 0.249694 (* 0.6 = 0.149817 loss)
I0818 17:47:52.222472  2522 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0818 17:47:55.170235  2522 solver.cpp:228] Iteration 1460, loss = 0.238868
I0818 17:47:55.170289  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0826489 (* 0.4 = 0.0330595 loss)
I0818 17:47:55.170305  2522 solver.cpp:244]     Train net output #1: loss2 = 0.343015 (* 0.6 = 0.205809 loss)
I0818 17:47:55.170317  2522 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0818 17:47:58.120611  2522 solver.cpp:228] Iteration 1480, loss = 0.224832
I0818 17:47:58.120664  2522 solver.cpp:244]     Train net output #0: loss1 = 0.114292 (* 0.4 = 0.0457167 loss)
I0818 17:47:58.120679  2522 solver.cpp:244]     Train net output #1: loss2 = 0.298525 (* 0.6 = 0.179115 loss)
I0818 17:47:58.120692  2522 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0818 17:48:01.075640  2522 solver.cpp:228] Iteration 1500, loss = 0.152965
I0818 17:48:01.075692  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0587152 (* 0.4 = 0.0234861 loss)
I0818 17:48:01.075708  2522 solver.cpp:244]     Train net output #1: loss2 = 0.215798 (* 0.6 = 0.129479 loss)
I0818 17:48:01.075721  2522 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0818 17:48:04.025365  2522 solver.cpp:228] Iteration 1520, loss = 0.178519
I0818 17:48:04.025418  2522 solver.cpp:244]     Train net output #0: loss1 = 0.201069 (* 0.4 = 0.0804275 loss)
I0818 17:48:04.025434  2522 solver.cpp:244]     Train net output #1: loss2 = 0.163485 (* 0.6 = 0.0980912 loss)
I0818 17:48:04.025446  2522 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0818 17:48:06.975342  2522 solver.cpp:228] Iteration 1540, loss = 0.220303
I0818 17:48:06.975394  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0954056 (* 0.4 = 0.0381622 loss)
I0818 17:48:06.975409  2522 solver.cpp:244]     Train net output #1: loss2 = 0.303568 (* 0.6 = 0.182141 loss)
I0818 17:48:06.975422  2522 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0818 17:48:09.921838  2522 solver.cpp:228] Iteration 1560, loss = 0.138863
I0818 17:48:09.921891  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0341737 (* 0.4 = 0.0136695 loss)
I0818 17:48:09.921907  2522 solver.cpp:244]     Train net output #1: loss2 = 0.208656 (* 0.6 = 0.125193 loss)
I0818 17:48:09.921919  2522 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0818 17:48:12.872385  2522 solver.cpp:228] Iteration 1580, loss = 0.16855
I0818 17:48:12.872437  2522 solver.cpp:244]     Train net output #0: loss1 = 0.119332 (* 0.4 = 0.0477326 loss)
I0818 17:48:12.872453  2522 solver.cpp:244]     Train net output #1: loss2 = 0.201362 (* 0.6 = 0.120817 loss)
I0818 17:48:12.872467  2522 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0818 17:48:15.820621  2522 solver.cpp:228] Iteration 1600, loss = 0.110834
I0818 17:48:15.820672  2522 solver.cpp:244]     Train net output #0: loss1 = 0.044573 (* 0.4 = 0.0178292 loss)
I0818 17:48:15.820688  2522 solver.cpp:244]     Train net output #1: loss2 = 0.155008 (* 0.6 = 0.093005 loss)
I0818 17:48:15.820700  2522 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0818 17:48:18.771188  2522 solver.cpp:228] Iteration 1620, loss = 0.248076
I0818 17:48:18.771242  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0792414 (* 0.4 = 0.0316965 loss)
I0818 17:48:18.771258  2522 solver.cpp:244]     Train net output #1: loss2 = 0.360633 (* 0.6 = 0.21638 loss)
I0818 17:48:18.771271  2522 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0818 17:48:21.720953  2522 solver.cpp:228] Iteration 1640, loss = 0.134319
I0818 17:48:21.721005  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0413923 (* 0.4 = 0.0165569 loss)
I0818 17:48:21.721021  2522 solver.cpp:244]     Train net output #1: loss2 = 0.19627 (* 0.6 = 0.117762 loss)
I0818 17:48:21.721035  2522 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0818 17:48:24.673492  2522 solver.cpp:228] Iteration 1660, loss = 0.150565
I0818 17:48:24.673658  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0977649 (* 0.4 = 0.039106 loss)
I0818 17:48:24.673676  2522 solver.cpp:244]     Train net output #1: loss2 = 0.185766 (* 0.6 = 0.111459 loss)
I0818 17:48:24.673688  2522 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0818 17:48:27.624078  2522 solver.cpp:228] Iteration 1680, loss = 0.159319
I0818 17:48:27.624132  2522 solver.cpp:244]     Train net output #0: loss1 = 0.1078 (* 0.4 = 0.0431201 loss)
I0818 17:48:27.624148  2522 solver.cpp:244]     Train net output #1: loss2 = 0.193664 (* 0.6 = 0.116199 loss)
I0818 17:48:27.624161  2522 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0818 17:48:30.570426  2522 solver.cpp:228] Iteration 1700, loss = 0.234252
I0818 17:48:30.570477  2522 solver.cpp:244]     Train net output #0: loss1 = 0.195333 (* 0.4 = 0.0781333 loss)
I0818 17:48:30.570493  2522 solver.cpp:244]     Train net output #1: loss2 = 0.260198 (* 0.6 = 0.156119 loss)
I0818 17:48:30.570507  2522 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0818 17:48:33.519057  2522 solver.cpp:228] Iteration 1720, loss = 0.145522
I0818 17:48:33.519107  2522 solver.cpp:244]     Train net output #0: loss1 = 0.119588 (* 0.4 = 0.0478353 loss)
I0818 17:48:33.519124  2522 solver.cpp:244]     Train net output #1: loss2 = 0.162811 (* 0.6 = 0.0976866 loss)
I0818 17:48:33.519136  2522 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0818 17:48:36.470978  2522 solver.cpp:228] Iteration 1740, loss = 0.213067
I0818 17:48:36.471029  2522 solver.cpp:244]     Train net output #0: loss1 = 0.107114 (* 0.4 = 0.0428455 loss)
I0818 17:48:36.471045  2522 solver.cpp:244]     Train net output #1: loss2 = 0.283702 (* 0.6 = 0.170221 loss)
I0818 17:48:36.471058  2522 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0818 17:48:39.419899  2522 solver.cpp:228] Iteration 1760, loss = 0.149556
I0818 17:48:39.419952  2522 solver.cpp:244]     Train net output #0: loss1 = 0.057612 (* 0.4 = 0.0230448 loss)
I0818 17:48:39.419968  2522 solver.cpp:244]     Train net output #1: loss2 = 0.210851 (* 0.6 = 0.126511 loss)
I0818 17:48:39.419981  2522 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0818 17:48:42.371827  2522 solver.cpp:228] Iteration 1780, loss = 0.194677
I0818 17:48:42.371881  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0976017 (* 0.4 = 0.0390407 loss)
I0818 17:48:42.371897  2522 solver.cpp:244]     Train net output #1: loss2 = 0.259394 (* 0.6 = 0.155636 loss)
I0818 17:48:42.371911  2522 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0818 17:48:45.322530  2522 solver.cpp:228] Iteration 1800, loss = 0.133468
I0818 17:48:45.322585  2522 solver.cpp:244]     Train net output #0: loss1 = 0.06238 (* 0.4 = 0.024952 loss)
I0818 17:48:45.322602  2522 solver.cpp:244]     Train net output #1: loss2 = 0.18086 (* 0.6 = 0.108516 loss)
I0818 17:48:45.322613  2522 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0818 17:48:48.273120  2522 solver.cpp:228] Iteration 1820, loss = 0.2275
I0818 17:48:48.273174  2522 solver.cpp:244]     Train net output #0: loss1 = 0.146436 (* 0.4 = 0.0585745 loss)
I0818 17:48:48.273190  2522 solver.cpp:244]     Train net output #1: loss2 = 0.281543 (* 0.6 = 0.168926 loss)
I0818 17:48:48.273202  2522 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0818 17:48:51.219360  2522 solver.cpp:228] Iteration 1840, loss = 0.198439
I0818 17:48:51.219413  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0525221 (* 0.4 = 0.0210089 loss)
I0818 17:48:51.219429  2522 solver.cpp:244]     Train net output #1: loss2 = 0.295717 (* 0.6 = 0.17743 loss)
I0818 17:48:51.219441  2522 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0818 17:48:54.169203  2522 solver.cpp:228] Iteration 1860, loss = 0.0845096
I0818 17:48:54.169256  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0612797 (* 0.4 = 0.0245119 loss)
I0818 17:48:54.169272  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0999962 (* 0.6 = 0.0599977 loss)
I0818 17:48:54.169286  2522 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0818 17:48:57.119899  2522 solver.cpp:228] Iteration 1880, loss = 0.190375
I0818 17:48:57.120044  2522 solver.cpp:244]     Train net output #0: loss1 = 0.202155 (* 0.4 = 0.0808619 loss)
I0818 17:48:57.120061  2522 solver.cpp:244]     Train net output #1: loss2 = 0.182522 (* 0.6 = 0.109513 loss)
I0818 17:48:57.120074  2522 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0818 17:49:00.070153  2522 solver.cpp:228] Iteration 1900, loss = 0.154573
I0818 17:49:00.070207  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0642692 (* 0.4 = 0.0257077 loss)
I0818 17:49:00.070224  2522 solver.cpp:244]     Train net output #1: loss2 = 0.214775 (* 0.6 = 0.128865 loss)
I0818 17:49:00.070236  2522 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0818 17:49:03.048197  2522 solver.cpp:228] Iteration 1920, loss = 0.12796
I0818 17:49:03.048249  2522 solver.cpp:244]     Train net output #0: loss1 = 0.120874 (* 0.4 = 0.0483497 loss)
I0818 17:49:03.048265  2522 solver.cpp:244]     Train net output #1: loss2 = 0.132683 (* 0.6 = 0.0796099 loss)
I0818 17:49:03.048279  2522 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0818 17:49:06.000880  2522 solver.cpp:228] Iteration 1940, loss = 0.127421
I0818 17:49:06.000928  2522 solver.cpp:244]     Train net output #0: loss1 = 0.102476 (* 0.4 = 0.0409903 loss)
I0818 17:49:06.000946  2522 solver.cpp:244]     Train net output #1: loss2 = 0.144052 (* 0.6 = 0.0864309 loss)
I0818 17:49:06.000957  2522 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0818 17:49:08.954514  2522 solver.cpp:228] Iteration 1960, loss = 0.200977
I0818 17:49:08.954567  2522 solver.cpp:244]     Train net output #0: loss1 = 0.181121 (* 0.4 = 0.0724483 loss)
I0818 17:49:08.954583  2522 solver.cpp:244]     Train net output #1: loss2 = 0.214214 (* 0.6 = 0.128528 loss)
I0818 17:49:08.954596  2522 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0818 17:49:11.907037  2522 solver.cpp:228] Iteration 1980, loss = 0.155259
I0818 17:49:11.907088  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0377041 (* 0.4 = 0.0150816 loss)
I0818 17:49:11.907104  2522 solver.cpp:244]     Train net output #1: loss2 = 0.233628 (* 0.6 = 0.140177 loss)
I0818 17:49:11.907117  2522 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0818 17:49:14.715328  2522 solver.cpp:337] Iteration 2000, Testing net (#0)
I0818 17:49:49.921735  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.873703
I0818 17:49:49.921901  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.959188
I0818 17:49:49.921921  2522 solver.cpp:404]     Test net output #2: loss1 = 0.127797 (* 0.4 = 0.051119 loss)
I0818 17:49:49.921934  2522 solver.cpp:404]     Test net output #3: loss2 = 0.305752 (* 0.6 = 0.183451 loss)
I0818 17:49:49.970243  2522 solver.cpp:228] Iteration 2000, loss = 0.183759
I0818 17:49:49.970293  2522 solver.cpp:244]     Train net output #0: loss1 = 0.157468 (* 0.4 = 0.0629871 loss)
I0818 17:49:49.970307  2522 solver.cpp:244]     Train net output #1: loss2 = 0.201286 (* 0.6 = 0.120771 loss)
I0818 17:49:49.970322  2522 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0818 17:49:52.954911  2522 solver.cpp:228] Iteration 2020, loss = 0.171493
I0818 17:49:52.954963  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0479165 (* 0.4 = 0.0191666 loss)
I0818 17:49:52.954979  2522 solver.cpp:244]     Train net output #1: loss2 = 0.253877 (* 0.6 = 0.152326 loss)
I0818 17:49:52.954993  2522 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0818 17:49:56.027957  2522 solver.cpp:228] Iteration 2040, loss = 0.164017
I0818 17:49:56.028012  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0808692 (* 0.4 = 0.0323477 loss)
I0818 17:49:56.028028  2522 solver.cpp:244]     Train net output #1: loss2 = 0.219449 (* 0.6 = 0.131669 loss)
I0818 17:49:56.028041  2522 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0818 17:49:59.115049  2522 solver.cpp:228] Iteration 2060, loss = 0.194916
I0818 17:49:59.115097  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0655163 (* 0.4 = 0.0262065 loss)
I0818 17:49:59.115108  2522 solver.cpp:244]     Train net output #1: loss2 = 0.281182 (* 0.6 = 0.168709 loss)
I0818 17:49:59.115118  2522 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0818 17:50:02.064285  2522 solver.cpp:228] Iteration 2080, loss = 0.153499
I0818 17:50:02.064339  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0580573 (* 0.4 = 0.0232229 loss)
I0818 17:50:02.064355  2522 solver.cpp:244]     Train net output #1: loss2 = 0.217127 (* 0.6 = 0.130276 loss)
I0818 17:50:02.064368  2522 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0818 17:50:05.021824  2522 solver.cpp:228] Iteration 2100, loss = 0.247191
I0818 17:50:05.021880  2522 solver.cpp:244]     Train net output #0: loss1 = 0.174465 (* 0.4 = 0.0697862 loss)
I0818 17:50:05.021896  2522 solver.cpp:244]     Train net output #1: loss2 = 0.295675 (* 0.6 = 0.177405 loss)
I0818 17:50:05.021909  2522 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0818 17:50:07.990648  2522 solver.cpp:228] Iteration 2120, loss = 0.111284
I0818 17:50:07.990696  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0364831 (* 0.4 = 0.0145932 loss)
I0818 17:50:07.990712  2522 solver.cpp:244]     Train net output #1: loss2 = 0.161151 (* 0.6 = 0.0966908 loss)
I0818 17:50:07.990725  2522 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0818 17:50:10.974288  2522 solver.cpp:228] Iteration 2140, loss = 0.19472
I0818 17:50:10.974344  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0902864 (* 0.4 = 0.0361146 loss)
I0818 17:50:10.974359  2522 solver.cpp:244]     Train net output #1: loss2 = 0.264343 (* 0.6 = 0.158606 loss)
I0818 17:50:10.974371  2522 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0818 17:50:13.923578  2522 solver.cpp:228] Iteration 2160, loss = 0.15209
I0818 17:50:13.923635  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0591138 (* 0.4 = 0.0236455 loss)
I0818 17:50:13.923651  2522 solver.cpp:244]     Train net output #1: loss2 = 0.214075 (* 0.6 = 0.128445 loss)
I0818 17:50:13.923663  2522 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0818 17:50:16.870409  2522 solver.cpp:228] Iteration 2180, loss = 0.10976
I0818 17:50:16.870462  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0367789 (* 0.4 = 0.0147116 loss)
I0818 17:50:16.870478  2522 solver.cpp:244]     Train net output #1: loss2 = 0.158415 (* 0.6 = 0.0950489 loss)
I0818 17:50:16.870491  2522 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0818 17:50:19.819727  2522 solver.cpp:228] Iteration 2200, loss = 0.180272
I0818 17:50:19.819808  2522 solver.cpp:244]     Train net output #0: loss1 = 0.112811 (* 0.4 = 0.0451244 loss)
I0818 17:50:19.819825  2522 solver.cpp:244]     Train net output #1: loss2 = 0.225246 (* 0.6 = 0.135147 loss)
I0818 17:50:19.819839  2522 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0818 17:50:22.784325  2522 solver.cpp:228] Iteration 2220, loss = 0.177774
I0818 17:50:22.784448  2522 solver.cpp:244]     Train net output #0: loss1 = 0.110685 (* 0.4 = 0.0442739 loss)
I0818 17:50:22.784466  2522 solver.cpp:244]     Train net output #1: loss2 = 0.222499 (* 0.6 = 0.1335 loss)
I0818 17:50:22.784479  2522 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0818 17:50:25.752389  2522 solver.cpp:228] Iteration 2240, loss = 0.145263
I0818 17:50:25.752439  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0395308 (* 0.4 = 0.0158123 loss)
I0818 17:50:25.752454  2522 solver.cpp:244]     Train net output #1: loss2 = 0.215751 (* 0.6 = 0.129451 loss)
I0818 17:50:25.752466  2522 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0818 17:50:28.707836  2522 solver.cpp:228] Iteration 2260, loss = 0.178021
I0818 17:50:28.707890  2522 solver.cpp:244]     Train net output #0: loss1 = 0.125544 (* 0.4 = 0.0502175 loss)
I0818 17:50:28.707906  2522 solver.cpp:244]     Train net output #1: loss2 = 0.213006 (* 0.6 = 0.127804 loss)
I0818 17:50:28.707919  2522 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0818 17:50:31.678782  2522 solver.cpp:228] Iteration 2280, loss = 0.156952
I0818 17:50:31.678835  2522 solver.cpp:244]     Train net output #0: loss1 = 0.036679 (* 0.4 = 0.0146716 loss)
I0818 17:50:31.678851  2522 solver.cpp:244]     Train net output #1: loss2 = 0.237134 (* 0.6 = 0.14228 loss)
I0818 17:50:31.678864  2522 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0818 17:50:34.672581  2522 solver.cpp:228] Iteration 2300, loss = 0.0978315
I0818 17:50:34.672631  2522 solver.cpp:244]     Train net output #0: loss1 = 0.071438 (* 0.4 = 0.0285752 loss)
I0818 17:50:34.672646  2522 solver.cpp:244]     Train net output #1: loss2 = 0.115427 (* 0.6 = 0.0692563 loss)
I0818 17:50:34.672659  2522 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0818 17:50:37.641490  2522 solver.cpp:228] Iteration 2320, loss = 0.102379
I0818 17:50:37.641543  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0377646 (* 0.4 = 0.0151058 loss)
I0818 17:50:37.641559  2522 solver.cpp:244]     Train net output #1: loss2 = 0.145455 (* 0.6 = 0.087273 loss)
I0818 17:50:37.641572  2522 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0818 17:50:40.594794  2522 solver.cpp:228] Iteration 2340, loss = 0.172662
I0818 17:50:40.594849  2522 solver.cpp:244]     Train net output #0: loss1 = 0.04493 (* 0.4 = 0.017972 loss)
I0818 17:50:40.594864  2522 solver.cpp:244]     Train net output #1: loss2 = 0.257817 (* 0.6 = 0.15469 loss)
I0818 17:50:40.594877  2522 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0818 17:50:43.580132  2522 solver.cpp:228] Iteration 2360, loss = 0.0859658
I0818 17:50:43.580184  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0225495 (* 0.4 = 0.00901981 loss)
I0818 17:50:43.580200  2522 solver.cpp:244]     Train net output #1: loss2 = 0.128243 (* 0.6 = 0.0769459 loss)
I0818 17:50:43.580214  2522 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0818 17:50:46.553685  2522 solver.cpp:228] Iteration 2380, loss = 0.161732
I0818 17:50:46.553735  2522 solver.cpp:244]     Train net output #0: loss1 = 0.075989 (* 0.4 = 0.0303956 loss)
I0818 17:50:46.553751  2522 solver.cpp:244]     Train net output #1: loss2 = 0.218895 (* 0.6 = 0.131337 loss)
I0818 17:50:46.553763  2522 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0818 17:50:49.500972  2522 solver.cpp:228] Iteration 2400, loss = 0.180171
I0818 17:50:49.501022  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0312199 (* 0.4 = 0.012488 loss)
I0818 17:50:49.501039  2522 solver.cpp:244]     Train net output #1: loss2 = 0.279472 (* 0.6 = 0.167683 loss)
I0818 17:50:49.501051  2522 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0818 17:50:52.486939  2522 solver.cpp:228] Iteration 2420, loss = 0.185248
I0818 17:50:52.486989  2522 solver.cpp:244]     Train net output #0: loss1 = 0.047957 (* 0.4 = 0.0191828 loss)
I0818 17:50:52.487004  2522 solver.cpp:244]     Train net output #1: loss2 = 0.276775 (* 0.6 = 0.166065 loss)
I0818 17:50:52.487016  2522 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0818 17:50:55.462769  2522 solver.cpp:228] Iteration 2440, loss = 0.116363
I0818 17:50:55.462918  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0483281 (* 0.4 = 0.0193312 loss)
I0818 17:50:55.462934  2522 solver.cpp:244]     Train net output #1: loss2 = 0.16172 (* 0.6 = 0.0970321 loss)
I0818 17:50:55.462947  2522 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0818 17:50:58.499735  2522 solver.cpp:228] Iteration 2460, loss = 0.126533
I0818 17:50:58.499788  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0350738 (* 0.4 = 0.0140295 loss)
I0818 17:50:58.499804  2522 solver.cpp:244]     Train net output #1: loss2 = 0.187505 (* 0.6 = 0.112503 loss)
I0818 17:50:58.499815  2522 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0818 17:51:01.456755  2522 solver.cpp:228] Iteration 2480, loss = 0.134875
I0818 17:51:01.456804  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0660313 (* 0.4 = 0.0264125 loss)
I0818 17:51:01.456820  2522 solver.cpp:244]     Train net output #1: loss2 = 0.180771 (* 0.6 = 0.108463 loss)
I0818 17:51:01.456833  2522 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0818 17:51:04.421321  2522 solver.cpp:228] Iteration 2500, loss = 0.12365
I0818 17:51:04.421375  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0998236 (* 0.4 = 0.0399294 loss)
I0818 17:51:04.421391  2522 solver.cpp:244]     Train net output #1: loss2 = 0.139535 (* 0.6 = 0.083721 loss)
I0818 17:51:04.421404  2522 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0818 17:51:07.410660  2522 solver.cpp:228] Iteration 2520, loss = 0.10756
I0818 17:51:07.410709  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0472902 (* 0.4 = 0.0189161 loss)
I0818 17:51:07.410724  2522 solver.cpp:244]     Train net output #1: loss2 = 0.14774 (* 0.6 = 0.0886437 loss)
I0818 17:51:07.410737  2522 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0818 17:51:10.368279  2522 solver.cpp:228] Iteration 2540, loss = 0.15152
I0818 17:51:10.368330  2522 solver.cpp:244]     Train net output #0: loss1 = 0.079984 (* 0.4 = 0.0319936 loss)
I0818 17:51:10.368345  2522 solver.cpp:244]     Train net output #1: loss2 = 0.19921 (* 0.6 = 0.119526 loss)
I0818 17:51:10.368358  2522 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0818 17:51:13.358628  2522 solver.cpp:228] Iteration 2560, loss = 0.162673
I0818 17:51:13.358677  2522 solver.cpp:244]     Train net output #0: loss1 = 0.103403 (* 0.4 = 0.0413614 loss)
I0818 17:51:13.358693  2522 solver.cpp:244]     Train net output #1: loss2 = 0.202186 (* 0.6 = 0.121312 loss)
I0818 17:51:13.358705  2522 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0818 17:51:16.316257  2522 solver.cpp:228] Iteration 2580, loss = 0.11421
I0818 17:51:16.316311  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0445124 (* 0.4 = 0.017805 loss)
I0818 17:51:16.316328  2522 solver.cpp:244]     Train net output #1: loss2 = 0.160676 (* 0.6 = 0.0964054 loss)
I0818 17:51:16.316339  2522 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0818 17:51:19.266006  2522 solver.cpp:228] Iteration 2600, loss = 0.159553
I0818 17:51:19.266059  2522 solver.cpp:244]     Train net output #0: loss1 = 0.07954 (* 0.4 = 0.031816 loss)
I0818 17:51:19.266077  2522 solver.cpp:244]     Train net output #1: loss2 = 0.212896 (* 0.6 = 0.127737 loss)
I0818 17:51:19.266088  2522 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0818 17:51:22.217133  2522 solver.cpp:228] Iteration 2620, loss = 0.116646
I0818 17:51:22.217186  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0107153 (* 0.4 = 0.00428611 loss)
I0818 17:51:22.217202  2522 solver.cpp:244]     Train net output #1: loss2 = 0.187266 (* 0.6 = 0.11236 loss)
I0818 17:51:22.217216  2522 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0818 17:51:25.166069  2522 solver.cpp:228] Iteration 2640, loss = 0.0878897
I0818 17:51:25.166124  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0333591 (* 0.4 = 0.0133436 loss)
I0818 17:51:25.166141  2522 solver.cpp:244]     Train net output #1: loss2 = 0.124243 (* 0.6 = 0.074546 loss)
I0818 17:51:25.166153  2522 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0818 17:51:28.114120  2522 solver.cpp:228] Iteration 2660, loss = 0.140595
I0818 17:51:28.114259  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0340493 (* 0.4 = 0.0136197 loss)
I0818 17:51:28.114276  2522 solver.cpp:244]     Train net output #1: loss2 = 0.211626 (* 0.6 = 0.126975 loss)
I0818 17:51:28.114289  2522 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0818 17:51:31.059646  2522 solver.cpp:228] Iteration 2680, loss = 0.0981587
I0818 17:51:31.059698  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0622406 (* 0.4 = 0.0248962 loss)
I0818 17:51:31.059715  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122104 (* 0.6 = 0.0732625 loss)
I0818 17:51:31.059727  2522 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0818 17:51:34.007526  2522 solver.cpp:228] Iteration 2700, loss = 0.129719
I0818 17:51:34.007576  2522 solver.cpp:244]     Train net output #0: loss1 = 0.073203 (* 0.4 = 0.0292812 loss)
I0818 17:51:34.007592  2522 solver.cpp:244]     Train net output #1: loss2 = 0.167396 (* 0.6 = 0.100438 loss)
I0818 17:51:34.007606  2522 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0818 17:51:36.956856  2522 solver.cpp:228] Iteration 2720, loss = 0.149912
I0818 17:51:36.956909  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0563627 (* 0.4 = 0.0225451 loss)
I0818 17:51:36.956925  2522 solver.cpp:244]     Train net output #1: loss2 = 0.212279 (* 0.6 = 0.127367 loss)
I0818 17:51:36.956938  2522 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0818 17:51:39.907224  2522 solver.cpp:228] Iteration 2740, loss = 0.111986
I0818 17:51:39.907322  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0436862 (* 0.4 = 0.0174745 loss)
I0818 17:51:39.907340  2522 solver.cpp:244]     Train net output #1: loss2 = 0.15752 (* 0.6 = 0.0945118 loss)
I0818 17:51:39.907357  2522 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0818 17:51:42.851744  2522 solver.cpp:228] Iteration 2760, loss = 0.0913377
I0818 17:51:42.851795  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0220912 (* 0.4 = 0.00883647 loss)
I0818 17:51:42.851811  2522 solver.cpp:244]     Train net output #1: loss2 = 0.137502 (* 0.6 = 0.0825013 loss)
I0818 17:51:42.851824  2522 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0818 17:51:45.800377  2522 solver.cpp:228] Iteration 2780, loss = 0.133065
I0818 17:51:45.800428  2522 solver.cpp:244]     Train net output #0: loss1 = 0.089341 (* 0.4 = 0.0357364 loss)
I0818 17:51:45.800444  2522 solver.cpp:244]     Train net output #1: loss2 = 0.162215 (* 0.6 = 0.0973289 loss)
I0818 17:51:45.800457  2522 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0818 17:51:48.749200  2522 solver.cpp:228] Iteration 2800, loss = 0.08344
I0818 17:51:48.749254  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0188239 (* 0.4 = 0.00752955 loss)
I0818 17:51:48.749270  2522 solver.cpp:244]     Train net output #1: loss2 = 0.126517 (* 0.6 = 0.0759104 loss)
I0818 17:51:48.749284  2522 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0818 17:51:51.699623  2522 solver.cpp:228] Iteration 2820, loss = 0.117169
I0818 17:51:51.699681  2522 solver.cpp:244]     Train net output #0: loss1 = 0.057189 (* 0.4 = 0.0228756 loss)
I0818 17:51:51.699697  2522 solver.cpp:244]     Train net output #1: loss2 = 0.157156 (* 0.6 = 0.0942935 loss)
I0818 17:51:51.699709  2522 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0818 17:51:54.647444  2522 solver.cpp:228] Iteration 2840, loss = 0.0852492
I0818 17:51:54.647495  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0633976 (* 0.4 = 0.025359 loss)
I0818 17:51:54.647511  2522 solver.cpp:244]     Train net output #1: loss2 = 0.099817 (* 0.6 = 0.0598902 loss)
I0818 17:51:54.647523  2522 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0818 17:51:57.597998  2522 solver.cpp:228] Iteration 2860, loss = 0.155381
I0818 17:51:57.598052  2522 solver.cpp:244]     Train net output #0: loss1 = 0.132348 (* 0.4 = 0.0529392 loss)
I0818 17:51:57.598067  2522 solver.cpp:244]     Train net output #1: loss2 = 0.170736 (* 0.6 = 0.102442 loss)
I0818 17:51:57.598079  2522 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0818 17:52:00.548020  2522 solver.cpp:228] Iteration 2880, loss = 0.130444
I0818 17:52:00.548158  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0190749 (* 0.4 = 0.00762996 loss)
I0818 17:52:00.548176  2522 solver.cpp:244]     Train net output #1: loss2 = 0.204689 (* 0.6 = 0.122814 loss)
I0818 17:52:00.548188  2522 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0818 17:52:03.495717  2522 solver.cpp:228] Iteration 2900, loss = 0.113784
I0818 17:52:03.495769  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0903307 (* 0.4 = 0.0361323 loss)
I0818 17:52:03.495780  2522 solver.cpp:244]     Train net output #1: loss2 = 0.129419 (* 0.6 = 0.0776516 loss)
I0818 17:52:03.495790  2522 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0818 17:52:06.477845  2522 solver.cpp:228] Iteration 2920, loss = 0.188617
I0818 17:52:06.477896  2522 solver.cpp:244]     Train net output #0: loss1 = 0.121648 (* 0.4 = 0.0486592 loss)
I0818 17:52:06.477912  2522 solver.cpp:244]     Train net output #1: loss2 = 0.233262 (* 0.6 = 0.139957 loss)
I0818 17:52:06.477926  2522 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0818 17:52:09.435703  2522 solver.cpp:228] Iteration 2940, loss = 0.0989272
I0818 17:52:09.435765  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0208592 (* 0.4 = 0.00834369 loss)
I0818 17:52:09.435781  2522 solver.cpp:244]     Train net output #1: loss2 = 0.150972 (* 0.6 = 0.0905835 loss)
I0818 17:52:09.435794  2522 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0818 17:52:12.412901  2522 solver.cpp:228] Iteration 2960, loss = 0.162996
I0818 17:52:12.412958  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0554719 (* 0.4 = 0.0221888 loss)
I0818 17:52:12.412974  2522 solver.cpp:244]     Train net output #1: loss2 = 0.234679 (* 0.6 = 0.140808 loss)
I0818 17:52:12.412987  2522 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0818 17:52:15.378612  2522 solver.cpp:228] Iteration 2980, loss = 0.0931594
I0818 17:52:15.378666  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0209266 (* 0.4 = 0.00837063 loss)
I0818 17:52:15.378681  2522 solver.cpp:244]     Train net output #1: loss2 = 0.141315 (* 0.6 = 0.0847888 loss)
I0818 17:52:15.378695  2522 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0818 17:52:18.208328  2522 solver.cpp:337] Iteration 3000, Testing net (#0)
I0818 17:52:53.271942  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.88425
I0818 17:52:53.272020  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.960172
I0818 17:52:53.272039  2522 solver.cpp:404]     Test net output #2: loss1 = 0.113489 (* 0.4 = 0.0453956 loss)
I0818 17:52:53.272053  2522 solver.cpp:404]     Test net output #3: loss2 = 0.292043 (* 0.6 = 0.175226 loss)
I0818 17:52:53.317467  2522 solver.cpp:228] Iteration 3000, loss = 0.114348
I0818 17:52:53.317517  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0919669 (* 0.4 = 0.0367867 loss)
I0818 17:52:53.317533  2522 solver.cpp:244]     Train net output #1: loss2 = 0.129268 (* 0.6 = 0.0775609 loss)
I0818 17:52:53.317546  2522 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0818 17:52:56.290701  2522 solver.cpp:228] Iteration 3020, loss = 0.090985
I0818 17:52:56.290756  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0333886 (* 0.4 = 0.0133555 loss)
I0818 17:52:56.290772  2522 solver.cpp:244]     Train net output #1: loss2 = 0.129383 (* 0.6 = 0.0776295 loss)
I0818 17:52:56.290786  2522 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0818 17:52:59.285125  2522 solver.cpp:228] Iteration 3040, loss = 0.110072
I0818 17:52:59.285183  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0965801 (* 0.4 = 0.038632 loss)
I0818 17:52:59.285199  2522 solver.cpp:244]     Train net output #1: loss2 = 0.119067 (* 0.6 = 0.07144 loss)
I0818 17:52:59.285212  2522 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0818 17:53:02.257122  2522 solver.cpp:228] Iteration 3060, loss = 0.18971
I0818 17:53:02.257185  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0459988 (* 0.4 = 0.0183995 loss)
I0818 17:53:02.257201  2522 solver.cpp:244]     Train net output #1: loss2 = 0.285517 (* 0.6 = 0.17131 loss)
I0818 17:53:02.257215  2522 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0818 17:53:05.203788  2522 solver.cpp:228] Iteration 3080, loss = 0.162333
I0818 17:53:05.203840  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0414762 (* 0.4 = 0.0165905 loss)
I0818 17:53:05.203856  2522 solver.cpp:244]     Train net output #1: loss2 = 0.242905 (* 0.6 = 0.145743 loss)
I0818 17:53:05.203869  2522 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0818 17:53:08.152252  2522 solver.cpp:228] Iteration 3100, loss = 0.156381
I0818 17:53:08.152302  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0300636 (* 0.4 = 0.0120254 loss)
I0818 17:53:08.152318  2522 solver.cpp:244]     Train net output #1: loss2 = 0.240592 (* 0.6 = 0.144355 loss)
I0818 17:53:08.152331  2522 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0818 17:53:11.200636  2522 solver.cpp:228] Iteration 3120, loss = 0.120625
I0818 17:53:11.200750  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0329813 (* 0.4 = 0.0131925 loss)
I0818 17:53:11.200803  2522 solver.cpp:244]     Train net output #1: loss2 = 0.179054 (* 0.6 = 0.107433 loss)
I0818 17:53:11.200848  2522 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0818 17:53:14.206688  2522 solver.cpp:228] Iteration 3140, loss = 0.209382
I0818 17:53:14.206742  2522 solver.cpp:244]     Train net output #0: loss1 = 0.137746 (* 0.4 = 0.0550986 loss)
I0818 17:53:14.206758  2522 solver.cpp:244]     Train net output #1: loss2 = 0.257139 (* 0.6 = 0.154284 loss)
I0818 17:53:14.206770  2522 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0818 17:53:17.191563  2522 solver.cpp:228] Iteration 3160, loss = 0.0745973
I0818 17:53:17.191617  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0203921 (* 0.4 = 0.00815685 loss)
I0818 17:53:17.191632  2522 solver.cpp:244]     Train net output #1: loss2 = 0.110734 (* 0.6 = 0.0664404 loss)
I0818 17:53:17.191645  2522 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0818 17:53:20.159446  2522 solver.cpp:228] Iteration 3180, loss = 0.146829
I0818 17:53:20.159497  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0928482 (* 0.4 = 0.0371393 loss)
I0818 17:53:20.159512  2522 solver.cpp:244]     Train net output #1: loss2 = 0.182817 (* 0.6 = 0.10969 loss)
I0818 17:53:20.159525  2522 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0818 17:53:23.135080  2522 solver.cpp:228] Iteration 3200, loss = 0.148846
I0818 17:53:23.135157  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0390644 (* 0.4 = 0.0156258 loss)
I0818 17:53:23.135174  2522 solver.cpp:244]     Train net output #1: loss2 = 0.222033 (* 0.6 = 0.13322 loss)
I0818 17:53:23.135187  2522 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0818 17:53:26.113684  2522 solver.cpp:228] Iteration 3220, loss = 0.115954
I0818 17:53:26.113793  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0628885 (* 0.4 = 0.0251554 loss)
I0818 17:53:26.113811  2522 solver.cpp:244]     Train net output #1: loss2 = 0.151331 (* 0.6 = 0.0907989 loss)
I0818 17:53:26.113823  2522 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0818 17:53:29.119806  2522 solver.cpp:228] Iteration 3240, loss = 0.105391
I0818 17:53:29.119856  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0494654 (* 0.4 = 0.0197862 loss)
I0818 17:53:29.119873  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142675 (* 0.6 = 0.0856051 loss)
I0818 17:53:29.119884  2522 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0818 17:53:32.105330  2522 solver.cpp:228] Iteration 3260, loss = 0.103984
I0818 17:53:32.105381  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0234259 (* 0.4 = 0.00937034 loss)
I0818 17:53:32.105396  2522 solver.cpp:244]     Train net output #1: loss2 = 0.157689 (* 0.6 = 0.0946132 loss)
I0818 17:53:32.105408  2522 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0818 17:53:35.086447  2522 solver.cpp:228] Iteration 3280, loss = 0.122713
I0818 17:53:35.086498  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0466355 (* 0.4 = 0.0186542 loss)
I0818 17:53:35.086513  2522 solver.cpp:244]     Train net output #1: loss2 = 0.173432 (* 0.6 = 0.104059 loss)
I0818 17:53:35.086526  2522 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0818 17:53:38.068310  2522 solver.cpp:228] Iteration 3300, loss = 0.116608
I0818 17:53:38.068359  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0666049 (* 0.4 = 0.026642 loss)
I0818 17:53:38.068380  2522 solver.cpp:244]     Train net output #1: loss2 = 0.149944 (* 0.6 = 0.0899663 loss)
I0818 17:53:38.068394  2522 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0818 17:53:41.051420  2522 solver.cpp:228] Iteration 3320, loss = 0.102252
I0818 17:53:41.051471  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0268766 (* 0.4 = 0.0107506 loss)
I0818 17:53:41.051487  2522 solver.cpp:244]     Train net output #1: loss2 = 0.152502 (* 0.6 = 0.0915011 loss)
I0818 17:53:41.051501  2522 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0818 17:53:44.031975  2522 solver.cpp:228] Iteration 3340, loss = 0.0879
I0818 17:53:44.032022  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0208497 (* 0.4 = 0.00833987 loss)
I0818 17:53:44.032038  2522 solver.cpp:244]     Train net output #1: loss2 = 0.1326 (* 0.6 = 0.0795602 loss)
I0818 17:53:44.032050  2522 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0818 17:53:47.013686  2522 solver.cpp:228] Iteration 3360, loss = 0.134992
I0818 17:53:47.013738  2522 solver.cpp:244]     Train net output #0: loss1 = 0.050087 (* 0.4 = 0.0200348 loss)
I0818 17:53:47.013754  2522 solver.cpp:244]     Train net output #1: loss2 = 0.191595 (* 0.6 = 0.114957 loss)
I0818 17:53:47.013767  2522 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0818 17:53:49.996600  2522 solver.cpp:228] Iteration 3380, loss = 0.15055
I0818 17:53:49.996654  2522 solver.cpp:244]     Train net output #0: loss1 = 0.107729 (* 0.4 = 0.0430915 loss)
I0818 17:53:49.996670  2522 solver.cpp:244]     Train net output #1: loss2 = 0.179098 (* 0.6 = 0.107459 loss)
I0818 17:53:49.996681  2522 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0818 17:53:52.978818  2522 solver.cpp:228] Iteration 3400, loss = 0.124059
I0818 17:53:52.978871  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0473228 (* 0.4 = 0.0189291 loss)
I0818 17:53:52.978888  2522 solver.cpp:244]     Train net output #1: loss2 = 0.175216 (* 0.6 = 0.10513 loss)
I0818 17:53:52.978900  2522 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0818 17:53:55.976879  2522 solver.cpp:228] Iteration 3420, loss = 0.11845
I0818 17:53:55.976930  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0575677 (* 0.4 = 0.0230271 loss)
I0818 17:53:55.976946  2522 solver.cpp:244]     Train net output #1: loss2 = 0.159039 (* 0.6 = 0.0954232 loss)
I0818 17:53:55.976959  2522 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0818 17:53:58.982971  2522 solver.cpp:228] Iteration 3440, loss = 0.125415
I0818 17:53:58.983105  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0485228 (* 0.4 = 0.0194091 loss)
I0818 17:53:58.983122  2522 solver.cpp:244]     Train net output #1: loss2 = 0.176677 (* 0.6 = 0.106006 loss)
I0818 17:53:58.983135  2522 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0818 17:54:01.985597  2522 solver.cpp:228] Iteration 3460, loss = 0.113439
I0818 17:54:01.985651  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0244536 (* 0.4 = 0.00978146 loss)
I0818 17:54:01.985666  2522 solver.cpp:244]     Train net output #1: loss2 = 0.172762 (* 0.6 = 0.103657 loss)
I0818 17:54:01.985679  2522 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0818 17:54:04.966217  2522 solver.cpp:228] Iteration 3480, loss = 0.0849246
I0818 17:54:04.966269  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0610121 (* 0.4 = 0.0244048 loss)
I0818 17:54:04.966284  2522 solver.cpp:244]     Train net output #1: loss2 = 0.100866 (* 0.6 = 0.0605198 loss)
I0818 17:54:04.966296  2522 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0818 17:54:07.946524  2522 solver.cpp:228] Iteration 3500, loss = 0.168788
I0818 17:54:07.946574  2522 solver.cpp:244]     Train net output #0: loss1 = 0.067212 (* 0.4 = 0.0268848 loss)
I0818 17:54:07.946590  2522 solver.cpp:244]     Train net output #1: loss2 = 0.236506 (* 0.6 = 0.141904 loss)
I0818 17:54:07.946602  2522 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0818 17:54:10.928769  2522 solver.cpp:228] Iteration 3520, loss = 0.103124
I0818 17:54:10.928820  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0616909 (* 0.4 = 0.0246764 loss)
I0818 17:54:10.928836  2522 solver.cpp:244]     Train net output #1: loss2 = 0.130746 (* 0.6 = 0.0784475 loss)
I0818 17:54:10.928849  2522 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0818 17:54:13.914244  2522 solver.cpp:228] Iteration 3540, loss = 0.118876
I0818 17:54:13.914297  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0795338 (* 0.4 = 0.0318135 loss)
I0818 17:54:13.914314  2522 solver.cpp:244]     Train net output #1: loss2 = 0.145104 (* 0.6 = 0.0870622 loss)
I0818 17:54:13.914325  2522 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0818 17:54:16.895447  2522 solver.cpp:228] Iteration 3560, loss = 0.0957914
I0818 17:54:16.895503  2522 solver.cpp:244]     Train net output #0: loss1 = 0.051015 (* 0.4 = 0.020406 loss)
I0818 17:54:16.895519  2522 solver.cpp:244]     Train net output #1: loss2 = 0.125642 (* 0.6 = 0.0753854 loss)
I0818 17:54:16.895530  2522 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0818 17:54:19.882129  2522 solver.cpp:228] Iteration 3580, loss = 0.185505
I0818 17:54:19.882181  2522 solver.cpp:244]     Train net output #0: loss1 = 0.108388 (* 0.4 = 0.043355 loss)
I0818 17:54:19.882197  2522 solver.cpp:244]     Train net output #1: loss2 = 0.236917 (* 0.6 = 0.14215 loss)
I0818 17:54:19.882210  2522 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0818 17:54:22.867377  2522 solver.cpp:228] Iteration 3600, loss = 0.0812037
I0818 17:54:22.867427  2522 solver.cpp:244]     Train net output #0: loss1 = 0.028501 (* 0.4 = 0.0114004 loss)
I0818 17:54:22.867444  2522 solver.cpp:244]     Train net output #1: loss2 = 0.116339 (* 0.6 = 0.0698033 loss)
I0818 17:54:22.867456  2522 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0818 17:54:25.864025  2522 solver.cpp:228] Iteration 3620, loss = 0.0682604
I0818 17:54:25.864074  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0217915 (* 0.4 = 0.00871662 loss)
I0818 17:54:25.864089  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0992396 (* 0.6 = 0.0595438 loss)
I0818 17:54:25.864102  2522 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0818 17:54:28.873276  2522 solver.cpp:228] Iteration 3640, loss = 0.172802
I0818 17:54:28.873329  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0548204 (* 0.4 = 0.0219282 loss)
I0818 17:54:28.873345  2522 solver.cpp:244]     Train net output #1: loss2 = 0.251456 (* 0.6 = 0.150874 loss)
I0818 17:54:28.873358  2522 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0818 17:54:31.871160  2522 solver.cpp:228] Iteration 3660, loss = 0.177176
I0818 17:54:31.871281  2522 solver.cpp:244]     Train net output #0: loss1 = 0.145769 (* 0.4 = 0.0583074 loss)
I0818 17:54:31.871299  2522 solver.cpp:244]     Train net output #1: loss2 = 0.198115 (* 0.6 = 0.118869 loss)
I0818 17:54:31.871311  2522 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0818 17:54:34.863689  2522 solver.cpp:228] Iteration 3680, loss = 0.124724
I0818 17:54:34.863744  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0600555 (* 0.4 = 0.0240222 loss)
I0818 17:54:34.863760  2522 solver.cpp:244]     Train net output #1: loss2 = 0.167836 (* 0.6 = 0.100702 loss)
I0818 17:54:34.863773  2522 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0818 17:54:37.866225  2522 solver.cpp:228] Iteration 3700, loss = 0.121469
I0818 17:54:37.866279  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0306049 (* 0.4 = 0.012242 loss)
I0818 17:54:37.866295  2522 solver.cpp:244]     Train net output #1: loss2 = 0.182045 (* 0.6 = 0.109227 loss)
I0818 17:54:37.866307  2522 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0818 17:54:40.848975  2522 solver.cpp:228] Iteration 3720, loss = 0.0813931
I0818 17:54:40.849027  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0194832 (* 0.4 = 0.00779327 loss)
I0818 17:54:40.849043  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122666 (* 0.6 = 0.0735998 loss)
I0818 17:54:40.849056  2522 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0818 17:54:43.836844  2522 solver.cpp:228] Iteration 3740, loss = 0.111641
I0818 17:54:43.836895  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0646544 (* 0.4 = 0.0258618 loss)
I0818 17:54:43.836911  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142965 (* 0.6 = 0.0857789 loss)
I0818 17:54:43.836925  2522 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0818 17:54:46.831347  2522 solver.cpp:228] Iteration 3760, loss = 0.137439
I0818 17:54:46.831398  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0536395 (* 0.4 = 0.0214558 loss)
I0818 17:54:46.831414  2522 solver.cpp:244]     Train net output #1: loss2 = 0.193306 (* 0.6 = 0.115984 loss)
I0818 17:54:46.831428  2522 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0818 17:54:49.818856  2522 solver.cpp:228] Iteration 3780, loss = 0.137655
I0818 17:54:49.818909  2522 solver.cpp:244]     Train net output #0: loss1 = 0.091849 (* 0.4 = 0.0367396 loss)
I0818 17:54:49.818925  2522 solver.cpp:244]     Train net output #1: loss2 = 0.168192 (* 0.6 = 0.100915 loss)
I0818 17:54:49.818938  2522 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0818 17:54:52.817471  2522 solver.cpp:228] Iteration 3800, loss = 0.113663
I0818 17:54:52.817519  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0223112 (* 0.4 = 0.0089245 loss)
I0818 17:54:52.817534  2522 solver.cpp:244]     Train net output #1: loss2 = 0.174564 (* 0.6 = 0.104739 loss)
I0818 17:54:52.817548  2522 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0818 17:54:55.813385  2522 solver.cpp:228] Iteration 3820, loss = 0.157058
I0818 17:54:55.813433  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0552742 (* 0.4 = 0.0221097 loss)
I0818 17:54:55.813448  2522 solver.cpp:244]     Train net output #1: loss2 = 0.224913 (* 0.6 = 0.134948 loss)
I0818 17:54:55.813462  2522 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0818 17:54:58.806215  2522 solver.cpp:228] Iteration 3840, loss = 0.162954
I0818 17:54:58.806262  2522 solver.cpp:244]     Train net output #0: loss1 = 0.078122 (* 0.4 = 0.0312488 loss)
I0818 17:54:58.806277  2522 solver.cpp:244]     Train net output #1: loss2 = 0.219509 (* 0.6 = 0.131705 loss)
I0818 17:54:58.806289  2522 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0818 17:55:01.820523  2522 solver.cpp:228] Iteration 3860, loss = 0.145895
I0818 17:55:01.820574  2522 solver.cpp:244]     Train net output #0: loss1 = 0.093003 (* 0.4 = 0.0372012 loss)
I0818 17:55:01.820588  2522 solver.cpp:244]     Train net output #1: loss2 = 0.181157 (* 0.6 = 0.108694 loss)
I0818 17:55:01.820601  2522 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0818 17:55:04.832569  2522 solver.cpp:228] Iteration 3880, loss = 0.113562
I0818 17:55:04.832672  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0492894 (* 0.4 = 0.0197158 loss)
I0818 17:55:04.832690  2522 solver.cpp:244]     Train net output #1: loss2 = 0.15641 (* 0.6 = 0.093846 loss)
I0818 17:55:04.832703  2522 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0818 17:55:07.814980  2522 solver.cpp:228] Iteration 3900, loss = 0.118331
I0818 17:55:07.815031  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0447427 (* 0.4 = 0.0178971 loss)
I0818 17:55:07.815047  2522 solver.cpp:244]     Train net output #1: loss2 = 0.16739 (* 0.6 = 0.100434 loss)
I0818 17:55:07.815059  2522 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0818 17:55:10.795606  2522 solver.cpp:228] Iteration 3920, loss = 0.117899
I0818 17:55:10.795660  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0315956 (* 0.4 = 0.0126382 loss)
I0818 17:55:10.795675  2522 solver.cpp:244]     Train net output #1: loss2 = 0.175435 (* 0.6 = 0.105261 loss)
I0818 17:55:10.795688  2522 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0818 17:55:13.777050  2522 solver.cpp:228] Iteration 3940, loss = 0.0792159
I0818 17:55:13.777101  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0517157 (* 0.4 = 0.0206863 loss)
I0818 17:55:13.777117  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0975494 (* 0.6 = 0.0585297 loss)
I0818 17:55:13.777129  2522 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0818 17:55:16.758014  2522 solver.cpp:228] Iteration 3960, loss = 0.120755
I0818 17:55:16.758065  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0806866 (* 0.4 = 0.0322746 loss)
I0818 17:55:16.758081  2522 solver.cpp:244]     Train net output #1: loss2 = 0.147467 (* 0.6 = 0.0884799 loss)
I0818 17:55:16.758093  2522 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0818 17:55:19.739094  2522 solver.cpp:228] Iteration 3980, loss = 0.173762
I0818 17:55:19.739146  2522 solver.cpp:244]     Train net output #0: loss1 = 0.105489 (* 0.4 = 0.0421957 loss)
I0818 17:55:19.739161  2522 solver.cpp:244]     Train net output #1: loss2 = 0.219277 (* 0.6 = 0.131566 loss)
I0818 17:55:19.739174  2522 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0818 17:55:22.568065  2522 solver.cpp:337] Iteration 4000, Testing net (#0)
I0818 17:55:57.614751  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.878531
I0818 17:55:57.614852  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.963016
I0818 17:55:57.614871  2522 solver.cpp:404]     Test net output #2: loss1 = 0.11028 (* 0.4 = 0.0441122 loss)
I0818 17:55:57.614884  2522 solver.cpp:404]     Test net output #3: loss2 = 0.283882 (* 0.6 = 0.170329 loss)
I0818 17:55:57.662483  2522 solver.cpp:228] Iteration 4000, loss = 0.0937398
I0818 17:55:57.662533  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0456869 (* 0.4 = 0.0182748 loss)
I0818 17:55:57.662549  2522 solver.cpp:244]     Train net output #1: loss2 = 0.125775 (* 0.6 = 0.0754651 loss)
I0818 17:55:57.662562  2522 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0818 17:56:00.645777  2522 solver.cpp:228] Iteration 4020, loss = 0.111722
I0818 17:56:00.645831  2522 solver.cpp:244]     Train net output #0: loss1 = 0.076079 (* 0.4 = 0.0304316 loss)
I0818 17:56:00.645848  2522 solver.cpp:244]     Train net output #1: loss2 = 0.135484 (* 0.6 = 0.0812906 loss)
I0818 17:56:00.645860  2522 sgd_solver.cpp:106] Iteration 4020, lr = 0.0001
I0818 17:56:03.630882  2522 solver.cpp:228] Iteration 4040, loss = 0.121173
I0818 17:56:03.630931  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0533932 (* 0.4 = 0.0213573 loss)
I0818 17:56:03.630947  2522 solver.cpp:244]     Train net output #1: loss2 = 0.16636 (* 0.6 = 0.0998159 loss)
I0818 17:56:03.630960  2522 sgd_solver.cpp:106] Iteration 4040, lr = 0.0001
I0818 17:56:06.613281  2522 solver.cpp:228] Iteration 4060, loss = 0.117381
I0818 17:56:06.613334  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0791082 (* 0.4 = 0.0316433 loss)
I0818 17:56:06.613350  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142896 (* 0.6 = 0.0857374 loss)
I0818 17:56:06.613363  2522 sgd_solver.cpp:106] Iteration 4060, lr = 0.0001
I0818 17:56:09.625169  2522 solver.cpp:228] Iteration 4080, loss = 0.171625
I0818 17:56:09.625221  2522 solver.cpp:244]     Train net output #0: loss1 = 0.123989 (* 0.4 = 0.0495956 loss)
I0818 17:56:09.625236  2522 solver.cpp:244]     Train net output #1: loss2 = 0.203383 (* 0.6 = 0.12203 loss)
I0818 17:56:09.625248  2522 sgd_solver.cpp:106] Iteration 4080, lr = 0.0001
I0818 17:56:12.624264  2522 solver.cpp:228] Iteration 4100, loss = 0.0876039
I0818 17:56:12.624315  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0372898 (* 0.4 = 0.0149159 loss)
I0818 17:56:12.624331  2522 solver.cpp:244]     Train net output #1: loss2 = 0.121147 (* 0.6 = 0.072688 loss)
I0818 17:56:12.624344  2522 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0818 17:56:15.631569  2522 solver.cpp:228] Iteration 4120, loss = 0.0793964
I0818 17:56:15.631621  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0233223 (* 0.4 = 0.00932893 loss)
I0818 17:56:15.631636  2522 solver.cpp:244]     Train net output #1: loss2 = 0.116779 (* 0.6 = 0.0700675 loss)
I0818 17:56:15.631649  2522 sgd_solver.cpp:106] Iteration 4120, lr = 0.0001
I0818 17:56:18.655966  2522 solver.cpp:228] Iteration 4140, loss = 0.176556
I0818 17:56:18.656020  2522 solver.cpp:244]     Train net output #0: loss1 = 0.169909 (* 0.4 = 0.0679637 loss)
I0818 17:56:18.656036  2522 solver.cpp:244]     Train net output #1: loss2 = 0.180988 (* 0.6 = 0.108593 loss)
I0818 17:56:18.656049  2522 sgd_solver.cpp:106] Iteration 4140, lr = 0.0001
I0818 17:56:21.682164  2522 solver.cpp:228] Iteration 4160, loss = 0.101497
I0818 17:56:21.682220  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0700391 (* 0.4 = 0.0280156 loss)
I0818 17:56:21.682236  2522 solver.cpp:244]     Train net output #1: loss2 = 0.12247 (* 0.6 = 0.0734818 loss)
I0818 17:56:21.682250  2522 sgd_solver.cpp:106] Iteration 4160, lr = 0.0001
I0818 17:56:24.671991  2522 solver.cpp:228] Iteration 4180, loss = 0.0893563
I0818 17:56:24.672047  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0303559 (* 0.4 = 0.0121423 loss)
I0818 17:56:24.672063  2522 solver.cpp:244]     Train net output #1: loss2 = 0.12869 (* 0.6 = 0.077214 loss)
I0818 17:56:24.672076  2522 sgd_solver.cpp:106] Iteration 4180, lr = 0.0001
I0818 17:56:27.671205  2522 solver.cpp:228] Iteration 4200, loss = 0.116212
I0818 17:56:27.671314  2522 solver.cpp:244]     Train net output #0: loss1 = 0.116396 (* 0.4 = 0.0465584 loss)
I0818 17:56:27.671334  2522 solver.cpp:244]     Train net output #1: loss2 = 0.116089 (* 0.6 = 0.0696537 loss)
I0818 17:56:27.671349  2522 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0818 17:56:30.675961  2522 solver.cpp:228] Iteration 4220, loss = 0.133039
I0818 17:56:30.676017  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0264079 (* 0.4 = 0.0105631 loss)
I0818 17:56:30.676033  2522 solver.cpp:244]     Train net output #1: loss2 = 0.204126 (* 0.6 = 0.122476 loss)
I0818 17:56:30.676046  2522 sgd_solver.cpp:106] Iteration 4220, lr = 0.0001
I0818 17:56:33.685575  2522 solver.cpp:228] Iteration 4240, loss = 0.135877
I0818 17:56:33.685623  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0587313 (* 0.4 = 0.0234925 loss)
I0818 17:56:33.685634  2522 solver.cpp:244]     Train net output #1: loss2 = 0.187307 (* 0.6 = 0.112384 loss)
I0818 17:56:33.685643  2522 sgd_solver.cpp:106] Iteration 4240, lr = 0.0001
I0818 17:56:36.670687  2522 solver.cpp:228] Iteration 4260, loss = 0.113064
I0818 17:56:36.670743  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0422093 (* 0.4 = 0.0168837 loss)
I0818 17:56:36.670759  2522 solver.cpp:244]     Train net output #1: loss2 = 0.1603 (* 0.6 = 0.0961802 loss)
I0818 17:56:36.670773  2522 sgd_solver.cpp:106] Iteration 4260, lr = 0.0001
I0818 17:56:39.658596  2522 solver.cpp:228] Iteration 4280, loss = 0.131845
I0818 17:56:39.658648  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0848836 (* 0.4 = 0.0339534 loss)
I0818 17:56:39.658664  2522 solver.cpp:244]     Train net output #1: loss2 = 0.163153 (* 0.6 = 0.0978917 loss)
I0818 17:56:39.658677  2522 sgd_solver.cpp:106] Iteration 4280, lr = 0.0001
I0818 17:56:42.673668  2522 solver.cpp:228] Iteration 4300, loss = 0.09326
I0818 17:56:42.673719  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0323342 (* 0.4 = 0.0129337 loss)
I0818 17:56:42.673735  2522 solver.cpp:244]     Train net output #1: loss2 = 0.133877 (* 0.6 = 0.0803263 loss)
I0818 17:56:42.673748  2522 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0818 17:56:45.660419  2522 solver.cpp:228] Iteration 4320, loss = 0.11782
I0818 17:56:45.660472  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0835487 (* 0.4 = 0.0334195 loss)
I0818 17:56:45.660488  2522 solver.cpp:244]     Train net output #1: loss2 = 0.140668 (* 0.6 = 0.0844007 loss)
I0818 17:56:45.660501  2522 sgd_solver.cpp:106] Iteration 4320, lr = 0.0001
I0818 17:56:48.657014  2522 solver.cpp:228] Iteration 4340, loss = 0.0747287
I0818 17:56:48.657068  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0330025 (* 0.4 = 0.013201 loss)
I0818 17:56:48.657083  2522 solver.cpp:244]     Train net output #1: loss2 = 0.102546 (* 0.6 = 0.0615277 loss)
I0818 17:56:48.657096  2522 sgd_solver.cpp:106] Iteration 4340, lr = 0.0001
I0818 17:56:51.674710  2522 solver.cpp:228] Iteration 4360, loss = 0.0923814
I0818 17:56:51.674762  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0394054 (* 0.4 = 0.0157622 loss)
I0818 17:56:51.674777  2522 solver.cpp:244]     Train net output #1: loss2 = 0.127699 (* 0.6 = 0.0766193 loss)
I0818 17:56:51.674790  2522 sgd_solver.cpp:106] Iteration 4360, lr = 0.0001
I0818 17:56:54.675227  2522 solver.cpp:228] Iteration 4380, loss = 0.0631931
I0818 17:56:54.675284  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0179171 (* 0.4 = 0.00716684 loss)
I0818 17:56:54.675300  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0933772 (* 0.6 = 0.0560263 loss)
I0818 17:56:54.675313  2522 sgd_solver.cpp:106] Iteration 4380, lr = 0.0001
I0818 17:56:57.685870  2522 solver.cpp:228] Iteration 4400, loss = 0.058931
I0818 17:56:57.689226  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0279469 (* 0.4 = 0.0111788 loss)
I0818 17:56:57.689247  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0795871 (* 0.6 = 0.0477523 loss)
I0818 17:56:57.689261  2522 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0818 17:57:00.704149  2522 solver.cpp:228] Iteration 4420, loss = 0.0762088
I0818 17:57:00.704202  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0367328 (* 0.4 = 0.0146931 loss)
I0818 17:57:00.704217  2522 solver.cpp:244]     Train net output #1: loss2 = 0.102526 (* 0.6 = 0.0615157 loss)
I0818 17:57:00.704231  2522 sgd_solver.cpp:106] Iteration 4420, lr = 0.0001
I0818 17:57:03.712504  2522 solver.cpp:228] Iteration 4440, loss = 0.122787
I0818 17:57:03.712554  2522 solver.cpp:244]     Train net output #0: loss1 = 0.117879 (* 0.4 = 0.0471515 loss)
I0818 17:57:03.712570  2522 solver.cpp:244]     Train net output #1: loss2 = 0.126059 (* 0.6 = 0.0756352 loss)
I0818 17:57:03.712582  2522 sgd_solver.cpp:106] Iteration 4440, lr = 0.0001
I0818 17:57:06.797395  2522 solver.cpp:228] Iteration 4460, loss = 0.118107
I0818 17:57:06.797441  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0500042 (* 0.4 = 0.0200017 loss)
I0818 17:57:06.797453  2522 solver.cpp:244]     Train net output #1: loss2 = 0.163508 (* 0.6 = 0.0981051 loss)
I0818 17:57:06.797462  2522 sgd_solver.cpp:106] Iteration 4460, lr = 0.0001
I0818 17:57:09.806498  2522 solver.cpp:228] Iteration 4480, loss = 0.118191
I0818 17:57:09.806548  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0236119 (* 0.4 = 0.00944475 loss)
I0818 17:57:09.806565  2522 solver.cpp:244]     Train net output #1: loss2 = 0.181244 (* 0.6 = 0.108746 loss)
I0818 17:57:09.806577  2522 sgd_solver.cpp:106] Iteration 4480, lr = 0.0001
I0818 17:57:12.798377  2522 solver.cpp:228] Iteration 4500, loss = 0.0986193
I0818 17:57:12.798429  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0296263 (* 0.4 = 0.0118505 loss)
I0818 17:57:12.798444  2522 solver.cpp:244]     Train net output #1: loss2 = 0.144615 (* 0.6 = 0.0867688 loss)
I0818 17:57:12.798457  2522 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0818 17:57:15.807355  2522 solver.cpp:228] Iteration 4520, loss = 0.0706567
I0818 17:57:15.807405  2522 solver.cpp:244]     Train net output #0: loss1 = 0.033457 (* 0.4 = 0.0133828 loss)
I0818 17:57:15.807421  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0954565 (* 0.6 = 0.0572739 loss)
I0818 17:57:15.807435  2522 sgd_solver.cpp:106] Iteration 4520, lr = 0.0001
I0818 17:57:18.822082  2522 solver.cpp:228] Iteration 4540, loss = 0.119879
I0818 17:57:18.822139  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0451014 (* 0.4 = 0.0180406 loss)
I0818 17:57:18.822155  2522 solver.cpp:244]     Train net output #1: loss2 = 0.169731 (* 0.6 = 0.101839 loss)
I0818 17:57:18.822167  2522 sgd_solver.cpp:106] Iteration 4540, lr = 0.0001
I0818 17:57:21.858417  2522 solver.cpp:228] Iteration 4560, loss = 0.115301
I0818 17:57:21.858467  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0260595 (* 0.4 = 0.0104238 loss)
I0818 17:57:21.858484  2522 solver.cpp:244]     Train net output #1: loss2 = 0.174795 (* 0.6 = 0.104877 loss)
I0818 17:57:21.858496  2522 sgd_solver.cpp:106] Iteration 4560, lr = 0.0001
I0818 17:57:24.850433  2522 solver.cpp:228] Iteration 4580, loss = 0.0872682
I0818 17:57:24.850486  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0408424 (* 0.4 = 0.0163369 loss)
I0818 17:57:24.850502  2522 solver.cpp:244]     Train net output #1: loss2 = 0.118219 (* 0.6 = 0.0709313 loss)
I0818 17:57:24.850514  2522 sgd_solver.cpp:106] Iteration 4580, lr = 0.0001
I0818 17:57:27.863661  2522 solver.cpp:228] Iteration 4600, loss = 0.0909817
I0818 17:57:27.863793  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0755102 (* 0.4 = 0.0302041 loss)
I0818 17:57:27.863811  2522 solver.cpp:244]     Train net output #1: loss2 = 0.101296 (* 0.6 = 0.0607777 loss)
I0818 17:57:27.863823  2522 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0818 17:57:30.856251  2522 solver.cpp:228] Iteration 4620, loss = 0.117631
I0818 17:57:30.856305  2522 solver.cpp:244]     Train net output #0: loss1 = 0.125326 (* 0.4 = 0.0501305 loss)
I0818 17:57:30.856322  2522 solver.cpp:244]     Train net output #1: loss2 = 0.112501 (* 0.6 = 0.0675009 loss)
I0818 17:57:30.856334  2522 sgd_solver.cpp:106] Iteration 4620, lr = 0.0001
I0818 17:57:33.859670  2522 solver.cpp:228] Iteration 4640, loss = 0.074525
I0818 17:57:33.859724  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0332724 (* 0.4 = 0.0133089 loss)
I0818 17:57:33.859740  2522 solver.cpp:244]     Train net output #1: loss2 = 0.102027 (* 0.6 = 0.0612161 loss)
I0818 17:57:33.859752  2522 sgd_solver.cpp:106] Iteration 4640, lr = 0.0001
I0818 17:57:36.865969  2522 solver.cpp:228] Iteration 4660, loss = 0.108229
I0818 17:57:36.866024  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0240861 (* 0.4 = 0.00963446 loss)
I0818 17:57:36.866040  2522 solver.cpp:244]     Train net output #1: loss2 = 0.164324 (* 0.6 = 0.0985943 loss)
I0818 17:57:36.866053  2522 sgd_solver.cpp:106] Iteration 4660, lr = 0.0001
I0818 17:57:39.867368  2522 solver.cpp:228] Iteration 4680, loss = 0.110404
I0818 17:57:39.867419  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0798331 (* 0.4 = 0.0319333 loss)
I0818 17:57:39.867434  2522 solver.cpp:244]     Train net output #1: loss2 = 0.130785 (* 0.6 = 0.0784711 loss)
I0818 17:57:39.867447  2522 sgd_solver.cpp:106] Iteration 4680, lr = 0.0001
I0818 17:57:42.857997  2522 solver.cpp:228] Iteration 4700, loss = 0.10401
I0818 17:57:42.858047  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0283238 (* 0.4 = 0.0113295 loss)
I0818 17:57:42.858064  2522 solver.cpp:244]     Train net output #1: loss2 = 0.154468 (* 0.6 = 0.0926806 loss)
I0818 17:57:42.858078  2522 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0818 17:57:45.838860  2522 solver.cpp:228] Iteration 4720, loss = 0.101256
I0818 17:57:45.838912  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0676352 (* 0.4 = 0.0270541 loss)
I0818 17:57:45.838928  2522 solver.cpp:244]     Train net output #1: loss2 = 0.12367 (* 0.6 = 0.0742018 loss)
I0818 17:57:45.838942  2522 sgd_solver.cpp:106] Iteration 4720, lr = 0.0001
I0818 17:57:48.819749  2522 solver.cpp:228] Iteration 4740, loss = 0.0746527
I0818 17:57:48.819802  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0211944 (* 0.4 = 0.00847777 loss)
I0818 17:57:48.819818  2522 solver.cpp:244]     Train net output #1: loss2 = 0.110292 (* 0.6 = 0.0661749 loss)
I0818 17:57:48.819831  2522 sgd_solver.cpp:106] Iteration 4740, lr = 0.0001
I0818 17:57:51.798674  2522 solver.cpp:228] Iteration 4760, loss = 0.143096
I0818 17:57:51.798728  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0778529 (* 0.4 = 0.0311412 loss)
I0818 17:57:51.798744  2522 solver.cpp:244]     Train net output #1: loss2 = 0.186591 (* 0.6 = 0.111955 loss)
I0818 17:57:51.798756  2522 sgd_solver.cpp:106] Iteration 4760, lr = 0.0001
I0818 17:57:54.779403  2522 solver.cpp:228] Iteration 4780, loss = 0.125116
I0818 17:57:54.779455  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0639823 (* 0.4 = 0.0255929 loss)
I0818 17:57:54.779471  2522 solver.cpp:244]     Train net output #1: loss2 = 0.165872 (* 0.6 = 0.0995229 loss)
I0818 17:57:54.779484  2522 sgd_solver.cpp:106] Iteration 4780, lr = 0.0001
I0818 17:57:57.761564  2522 solver.cpp:228] Iteration 4800, loss = 0.11697
I0818 17:57:57.761615  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0387955 (* 0.4 = 0.0155182 loss)
I0818 17:57:57.761631  2522 solver.cpp:244]     Train net output #1: loss2 = 0.169086 (* 0.6 = 0.101451 loss)
I0818 17:57:57.761643  2522 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0818 17:58:00.744071  2522 solver.cpp:228] Iteration 4820, loss = 0.121987
I0818 17:58:00.744194  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0253375 (* 0.4 = 0.010135 loss)
I0818 17:58:00.744211  2522 solver.cpp:244]     Train net output #1: loss2 = 0.186421 (* 0.6 = 0.111852 loss)
I0818 17:58:00.744225  2522 sgd_solver.cpp:106] Iteration 4820, lr = 0.0001
I0818 17:58:03.725204  2522 solver.cpp:228] Iteration 4840, loss = 0.116404
I0818 17:58:03.725258  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0645586 (* 0.4 = 0.0258235 loss)
I0818 17:58:03.725273  2522 solver.cpp:244]     Train net output #1: loss2 = 0.150968 (* 0.6 = 0.0905807 loss)
I0818 17:58:03.725286  2522 sgd_solver.cpp:106] Iteration 4840, lr = 0.0001
I0818 17:58:06.707867  2522 solver.cpp:228] Iteration 4860, loss = 0.15891
I0818 17:58:06.707918  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0929338 (* 0.4 = 0.0371735 loss)
I0818 17:58:06.707934  2522 solver.cpp:244]     Train net output #1: loss2 = 0.202894 (* 0.6 = 0.121736 loss)
I0818 17:58:06.707947  2522 sgd_solver.cpp:106] Iteration 4860, lr = 0.0001
I0818 17:58:09.689935  2522 solver.cpp:228] Iteration 4880, loss = 0.120824
I0818 17:58:09.689986  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0432237 (* 0.4 = 0.0172895 loss)
I0818 17:58:09.690002  2522 solver.cpp:244]     Train net output #1: loss2 = 0.172557 (* 0.6 = 0.103534 loss)
I0818 17:58:09.690016  2522 sgd_solver.cpp:106] Iteration 4880, lr = 0.0001
I0818 17:58:12.672798  2522 solver.cpp:228] Iteration 4900, loss = 0.102231
I0818 17:58:12.672848  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0404522 (* 0.4 = 0.0161809 loss)
I0818 17:58:12.672863  2522 solver.cpp:244]     Train net output #1: loss2 = 0.143418 (* 0.6 = 0.0860506 loss)
I0818 17:58:12.672876  2522 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0818 17:58:15.656276  2522 solver.cpp:228] Iteration 4920, loss = 0.123856
I0818 17:58:15.656327  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0593327 (* 0.4 = 0.0237331 loss)
I0818 17:58:15.656342  2522 solver.cpp:244]     Train net output #1: loss2 = 0.166871 (* 0.6 = 0.100123 loss)
I0818 17:58:15.656357  2522 sgd_solver.cpp:106] Iteration 4920, lr = 0.0001
I0818 17:58:18.639147  2522 solver.cpp:228] Iteration 4940, loss = 0.128613
I0818 17:58:18.639201  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0612266 (* 0.4 = 0.0244906 loss)
I0818 17:58:18.639217  2522 solver.cpp:244]     Train net output #1: loss2 = 0.173537 (* 0.6 = 0.104122 loss)
I0818 17:58:18.639230  2522 sgd_solver.cpp:106] Iteration 4940, lr = 0.0001
I0818 17:58:21.622426  2522 solver.cpp:228] Iteration 4960, loss = 0.107548
I0818 17:58:21.622475  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0625167 (* 0.4 = 0.0250067 loss)
I0818 17:58:21.622490  2522 solver.cpp:244]     Train net output #1: loss2 = 0.137569 (* 0.6 = 0.0825417 loss)
I0818 17:58:21.622503  2522 sgd_solver.cpp:106] Iteration 4960, lr = 0.0001
I0818 17:58:24.606171  2522 solver.cpp:228] Iteration 4980, loss = 0.147997
I0818 17:58:24.606226  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0731011 (* 0.4 = 0.0292404 loss)
I0818 17:58:24.606242  2522 solver.cpp:244]     Train net output #1: loss2 = 0.197927 (* 0.6 = 0.118756 loss)
I0818 17:58:24.606254  2522 sgd_solver.cpp:106] Iteration 4980, lr = 0.0001
I0818 17:58:27.441365  2522 solver.cpp:337] Iteration 5000, Testing net (#0)
I0818 17:59:02.482162  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.889156
I0818 17:59:02.482275  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.962125
I0818 17:59:02.482293  2522 solver.cpp:404]     Test net output #2: loss1 = 0.107817 (* 0.4 = 0.0431268 loss)
I0818 17:59:02.482306  2522 solver.cpp:404]     Test net output #3: loss2 = 0.280824 (* 0.6 = 0.168494 loss)
I0818 17:59:02.529911  2522 solver.cpp:228] Iteration 5000, loss = 0.0530478
I0818 17:59:02.529959  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0239569 (* 0.4 = 0.00958277 loss)
I0818 17:59:02.529974  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0724419 (* 0.6 = 0.0434651 loss)
I0818 17:59:02.529989  2522 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0818 17:59:05.513592  2522 solver.cpp:228] Iteration 5020, loss = 0.0409584
I0818 17:59:05.513643  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0451284 (* 0.4 = 0.0180514 loss)
I0818 17:59:05.513659  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0381784 (* 0.6 = 0.0229071 loss)
I0818 17:59:05.513671  2522 sgd_solver.cpp:106] Iteration 5020, lr = 0.0001
I0818 17:59:08.496821  2522 solver.cpp:228] Iteration 5040, loss = 0.138498
I0818 17:59:08.496870  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0466513 (* 0.4 = 0.0186605 loss)
I0818 17:59:08.496886  2522 solver.cpp:244]     Train net output #1: loss2 = 0.19973 (* 0.6 = 0.119838 loss)
I0818 17:59:08.496899  2522 sgd_solver.cpp:106] Iteration 5040, lr = 0.0001
I0818 17:59:11.479316  2522 solver.cpp:228] Iteration 5060, loss = 0.102894
I0818 17:59:11.479367  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0149195 (* 0.4 = 0.00596779 loss)
I0818 17:59:11.479382  2522 solver.cpp:244]     Train net output #1: loss2 = 0.161544 (* 0.6 = 0.0969262 loss)
I0818 17:59:11.479394  2522 sgd_solver.cpp:106] Iteration 5060, lr = 0.0001
I0818 17:59:14.462414  2522 solver.cpp:228] Iteration 5080, loss = 0.0879714
I0818 17:59:14.462466  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0378982 (* 0.4 = 0.0151593 loss)
I0818 17:59:14.462482  2522 solver.cpp:244]     Train net output #1: loss2 = 0.121354 (* 0.6 = 0.0728122 loss)
I0818 17:59:14.462494  2522 sgd_solver.cpp:106] Iteration 5080, lr = 0.0001
I0818 17:59:17.446462  2522 solver.cpp:228] Iteration 5100, loss = 0.0848995
I0818 17:59:17.446516  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0614198 (* 0.4 = 0.0245679 loss)
I0818 17:59:17.446532  2522 solver.cpp:244]     Train net output #1: loss2 = 0.100553 (* 0.6 = 0.0603316 loss)
I0818 17:59:17.446544  2522 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0818 17:59:20.429106  2522 solver.cpp:228] Iteration 5120, loss = 0.0874022
I0818 17:59:20.429160  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0393229 (* 0.4 = 0.0157292 loss)
I0818 17:59:20.429175  2522 solver.cpp:244]     Train net output #1: loss2 = 0.119455 (* 0.6 = 0.0716731 loss)
I0818 17:59:20.429188  2522 sgd_solver.cpp:106] Iteration 5120, lr = 0.0001
I0818 17:59:23.411800  2522 solver.cpp:228] Iteration 5140, loss = 0.150532
I0818 17:59:23.411854  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0660643 (* 0.4 = 0.0264257 loss)
I0818 17:59:23.411870  2522 solver.cpp:244]     Train net output #1: loss2 = 0.206844 (* 0.6 = 0.124106 loss)
I0818 17:59:23.411882  2522 sgd_solver.cpp:106] Iteration 5140, lr = 0.0001
I0818 17:59:26.394579  2522 solver.cpp:228] Iteration 5160, loss = 0.075772
I0818 17:59:26.394631  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0273272 (* 0.4 = 0.0109309 loss)
I0818 17:59:26.394647  2522 solver.cpp:244]     Train net output #1: loss2 = 0.108069 (* 0.6 = 0.0648412 loss)
I0818 17:59:26.394660  2522 sgd_solver.cpp:106] Iteration 5160, lr = 0.0001
I0818 17:59:29.378089  2522 solver.cpp:228] Iteration 5180, loss = 0.0971581
I0818 17:59:29.378145  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0233131 (* 0.4 = 0.00932522 loss)
I0818 17:59:29.378161  2522 solver.cpp:244]     Train net output #1: loss2 = 0.146388 (* 0.6 = 0.087833 loss)
I0818 17:59:29.378175  2522 sgd_solver.cpp:106] Iteration 5180, lr = 0.0001
I0818 17:59:32.359665  2522 solver.cpp:228] Iteration 5200, loss = 0.130939
I0818 17:59:32.359740  2522 solver.cpp:244]     Train net output #0: loss1 = 0.115448 (* 0.4 = 0.0461793 loss)
I0818 17:59:32.359758  2522 solver.cpp:244]     Train net output #1: loss2 = 0.141266 (* 0.6 = 0.0847598 loss)
I0818 17:59:32.359771  2522 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0818 17:59:35.341411  2522 solver.cpp:228] Iteration 5220, loss = 0.130702
I0818 17:59:35.341498  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0617864 (* 0.4 = 0.0247146 loss)
I0818 17:59:35.341514  2522 solver.cpp:244]     Train net output #1: loss2 = 0.176646 (* 0.6 = 0.105988 loss)
I0818 17:59:35.341528  2522 sgd_solver.cpp:106] Iteration 5220, lr = 0.0001
I0818 17:59:38.324347  2522 solver.cpp:228] Iteration 5240, loss = 0.124836
I0818 17:59:38.324406  2522 solver.cpp:244]     Train net output #0: loss1 = 0.147814 (* 0.4 = 0.0591256 loss)
I0818 17:59:38.324422  2522 solver.cpp:244]     Train net output #1: loss2 = 0.109518 (* 0.6 = 0.0657105 loss)
I0818 17:59:38.324435  2522 sgd_solver.cpp:106] Iteration 5240, lr = 0.0001
I0818 17:59:41.306738  2522 solver.cpp:228] Iteration 5260, loss = 0.101978
I0818 17:59:41.306790  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0272777 (* 0.4 = 0.0109111 loss)
I0818 17:59:41.306807  2522 solver.cpp:244]     Train net output #1: loss2 = 0.151778 (* 0.6 = 0.0910667 loss)
I0818 17:59:41.306819  2522 sgd_solver.cpp:106] Iteration 5260, lr = 0.0001
I0818 17:59:44.295706  2522 solver.cpp:228] Iteration 5280, loss = 0.0925584
I0818 17:59:44.295758  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0295915 (* 0.4 = 0.0118366 loss)
I0818 17:59:44.295773  2522 solver.cpp:244]     Train net output #1: loss2 = 0.134536 (* 0.6 = 0.0807218 loss)
I0818 17:59:44.295785  2522 sgd_solver.cpp:106] Iteration 5280, lr = 0.0001
I0818 17:59:47.282555  2522 solver.cpp:228] Iteration 5300, loss = 0.0920902
I0818 17:59:47.282608  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0617095 (* 0.4 = 0.0246838 loss)
I0818 17:59:47.282624  2522 solver.cpp:244]     Train net output #1: loss2 = 0.112344 (* 0.6 = 0.0674064 loss)
I0818 17:59:47.282637  2522 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0818 17:59:50.265789  2522 solver.cpp:228] Iteration 5320, loss = 0.102688
I0818 17:59:50.265839  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0335731 (* 0.4 = 0.0134293 loss)
I0818 17:59:50.265856  2522 solver.cpp:244]     Train net output #1: loss2 = 0.148765 (* 0.6 = 0.0892588 loss)
I0818 17:59:50.265868  2522 sgd_solver.cpp:106] Iteration 5320, lr = 0.0001
I0818 17:59:53.251529  2522 solver.cpp:228] Iteration 5340, loss = 0.15375
I0818 17:59:53.251580  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0213446 (* 0.4 = 0.00853786 loss)
I0818 17:59:53.251596  2522 solver.cpp:244]     Train net output #1: loss2 = 0.24202 (* 0.6 = 0.145212 loss)
I0818 17:59:53.251610  2522 sgd_solver.cpp:106] Iteration 5340, lr = 0.0001
I0818 17:59:56.233150  2522 solver.cpp:228] Iteration 5360, loss = 0.140923
I0818 17:59:56.233201  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0527128 (* 0.4 = 0.0210851 loss)
I0818 17:59:56.233217  2522 solver.cpp:244]     Train net output #1: loss2 = 0.199729 (* 0.6 = 0.119837 loss)
I0818 17:59:56.233229  2522 sgd_solver.cpp:106] Iteration 5360, lr = 0.0001
I0818 17:59:59.214969  2522 solver.cpp:228] Iteration 5380, loss = 0.0833765
I0818 17:59:59.215023  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0320839 (* 0.4 = 0.0128336 loss)
I0818 17:59:59.215039  2522 solver.cpp:244]     Train net output #1: loss2 = 0.117572 (* 0.6 = 0.070543 loss)
I0818 17:59:59.215050  2522 sgd_solver.cpp:106] Iteration 5380, lr = 0.0001
I0818 18:00:02.198096  2522 solver.cpp:228] Iteration 5400, loss = 0.109728
I0818 18:00:02.198151  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0740318 (* 0.4 = 0.0296127 loss)
I0818 18:00:02.198168  2522 solver.cpp:244]     Train net output #1: loss2 = 0.133525 (* 0.6 = 0.0801149 loss)
I0818 18:00:02.198180  2522 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0818 18:00:05.179545  2522 solver.cpp:228] Iteration 5420, loss = 0.119506
I0818 18:00:05.179597  2522 solver.cpp:244]     Train net output #0: loss1 = 0.156513 (* 0.4 = 0.0626052 loss)
I0818 18:00:05.179612  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0948343 (* 0.6 = 0.0569006 loss)
I0818 18:00:05.179626  2522 sgd_solver.cpp:106] Iteration 5420, lr = 0.0001
I0818 18:00:08.162178  2522 solver.cpp:228] Iteration 5440, loss = 0.158278
I0818 18:00:08.162374  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0425732 (* 0.4 = 0.0170293 loss)
I0818 18:00:08.162391  2522 solver.cpp:244]     Train net output #1: loss2 = 0.235414 (* 0.6 = 0.141248 loss)
I0818 18:00:08.162403  2522 sgd_solver.cpp:106] Iteration 5440, lr = 0.0001
I0818 18:00:11.154873  2522 solver.cpp:228] Iteration 5460, loss = 0.0942422
I0818 18:00:11.154924  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0189241 (* 0.4 = 0.00756964 loss)
I0818 18:00:11.154940  2522 solver.cpp:244]     Train net output #1: loss2 = 0.144454 (* 0.6 = 0.0866726 loss)
I0818 18:00:11.154953  2522 sgd_solver.cpp:106] Iteration 5460, lr = 0.0001
I0818 18:00:14.175101  2522 solver.cpp:228] Iteration 5480, loss = 0.0839756
I0818 18:00:14.175151  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0449067 (* 0.4 = 0.0179627 loss)
I0818 18:00:14.175166  2522 solver.cpp:244]     Train net output #1: loss2 = 0.110022 (* 0.6 = 0.0660129 loss)
I0818 18:00:14.175179  2522 sgd_solver.cpp:106] Iteration 5480, lr = 0.0001
I0818 18:00:17.161280  2522 solver.cpp:228] Iteration 5500, loss = 0.150761
I0818 18:00:17.161331  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0914105 (* 0.4 = 0.0365642 loss)
I0818 18:00:17.161347  2522 solver.cpp:244]     Train net output #1: loss2 = 0.190329 (* 0.6 = 0.114197 loss)
I0818 18:00:17.161360  2522 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0818 18:00:20.147330  2522 solver.cpp:228] Iteration 5520, loss = 0.13439
I0818 18:00:20.147382  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0607221 (* 0.4 = 0.0242888 loss)
I0818 18:00:20.147397  2522 solver.cpp:244]     Train net output #1: loss2 = 0.183502 (* 0.6 = 0.110101 loss)
I0818 18:00:20.147409  2522 sgd_solver.cpp:106] Iteration 5520, lr = 0.0001
I0818 18:00:23.125813  2522 solver.cpp:228] Iteration 5540, loss = 0.185025
I0818 18:00:23.125867  2522 solver.cpp:244]     Train net output #0: loss1 = 0.050439 (* 0.4 = 0.0201756 loss)
I0818 18:00:23.125882  2522 solver.cpp:244]     Train net output #1: loss2 = 0.27475 (* 0.6 = 0.16485 loss)
I0818 18:00:23.125896  2522 sgd_solver.cpp:106] Iteration 5540, lr = 0.0001
I0818 18:00:26.113332  2522 solver.cpp:228] Iteration 5560, loss = 0.15971
I0818 18:00:26.113384  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0735607 (* 0.4 = 0.0294243 loss)
I0818 18:00:26.113399  2522 solver.cpp:244]     Train net output #1: loss2 = 0.217144 (* 0.6 = 0.130286 loss)
I0818 18:00:26.113411  2522 sgd_solver.cpp:106] Iteration 5560, lr = 0.0001
I0818 18:00:29.061599  2522 solver.cpp:228] Iteration 5580, loss = 0.129004
I0818 18:00:29.061650  2522 solver.cpp:244]     Train net output #0: loss1 = 0.132543 (* 0.4 = 0.0530171 loss)
I0818 18:00:29.061666  2522 solver.cpp:244]     Train net output #1: loss2 = 0.126644 (* 0.6 = 0.0759866 loss)
I0818 18:00:29.061679  2522 sgd_solver.cpp:106] Iteration 5580, lr = 0.0001
I0818 18:00:32.020081  2522 solver.cpp:228] Iteration 5600, loss = 0.147133
I0818 18:00:32.020134  2522 solver.cpp:244]     Train net output #0: loss1 = 0.043092 (* 0.4 = 0.0172368 loss)
I0818 18:00:32.020150  2522 solver.cpp:244]     Train net output #1: loss2 = 0.216493 (* 0.6 = 0.129896 loss)
I0818 18:00:32.020162  2522 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0818 18:00:35.021432  2522 solver.cpp:228] Iteration 5620, loss = 0.0885667
I0818 18:00:35.021486  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0723137 (* 0.4 = 0.0289255 loss)
I0818 18:00:35.021502  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0994021 (* 0.6 = 0.0596413 loss)
I0818 18:00:35.021515  2522 sgd_solver.cpp:106] Iteration 5620, lr = 0.0001
I0818 18:00:37.993366  2522 solver.cpp:228] Iteration 5640, loss = 0.0790643
I0818 18:00:37.993418  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0502857 (* 0.4 = 0.0201143 loss)
I0818 18:00:37.993434  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0982501 (* 0.6 = 0.0589501 loss)
I0818 18:00:37.993446  2522 sgd_solver.cpp:106] Iteration 5640, lr = 0.0001
I0818 18:00:40.985528  2522 solver.cpp:228] Iteration 5660, loss = 0.120839
I0818 18:00:40.985669  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0872765 (* 0.4 = 0.0349106 loss)
I0818 18:00:40.985687  2522 solver.cpp:244]     Train net output #1: loss2 = 0.143214 (* 0.6 = 0.0859285 loss)
I0818 18:00:40.985699  2522 sgd_solver.cpp:106] Iteration 5660, lr = 0.0001
I0818 18:00:44.044741  2522 solver.cpp:228] Iteration 5680, loss = 0.127458
I0818 18:00:44.044792  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0459926 (* 0.4 = 0.018397 loss)
I0818 18:00:44.044808  2522 solver.cpp:244]     Train net output #1: loss2 = 0.181769 (* 0.6 = 0.109061 loss)
I0818 18:00:44.044821  2522 sgd_solver.cpp:106] Iteration 5680, lr = 0.0001
I0818 18:00:47.025184  2522 solver.cpp:228] Iteration 5700, loss = 0.115154
I0818 18:00:47.025236  2522 solver.cpp:244]     Train net output #0: loss1 = 0.114761 (* 0.4 = 0.0459045 loss)
I0818 18:00:47.025252  2522 solver.cpp:244]     Train net output #1: loss2 = 0.115415 (* 0.6 = 0.0692491 loss)
I0818 18:00:47.025265  2522 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0818 18:00:49.995025  2522 solver.cpp:228] Iteration 5720, loss = 0.0826095
I0818 18:00:49.995075  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0176149 (* 0.4 = 0.00704598 loss)
I0818 18:00:49.995091  2522 solver.cpp:244]     Train net output #1: loss2 = 0.125939 (* 0.6 = 0.0755636 loss)
I0818 18:00:49.995105  2522 sgd_solver.cpp:106] Iteration 5720, lr = 0.0001
I0818 18:00:52.955101  2522 solver.cpp:228] Iteration 5740, loss = 0.114979
I0818 18:00:52.955152  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0416955 (* 0.4 = 0.0166782 loss)
I0818 18:00:52.955168  2522 solver.cpp:244]     Train net output #1: loss2 = 0.163835 (* 0.6 = 0.0983013 loss)
I0818 18:00:52.955181  2522 sgd_solver.cpp:106] Iteration 5740, lr = 0.0001
I0818 18:00:55.944614  2522 solver.cpp:228] Iteration 5760, loss = 0.102637
I0818 18:00:55.944665  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0496197 (* 0.4 = 0.0198479 loss)
I0818 18:00:55.944680  2522 solver.cpp:244]     Train net output #1: loss2 = 0.137982 (* 0.6 = 0.0827889 loss)
I0818 18:00:55.944694  2522 sgd_solver.cpp:106] Iteration 5760, lr = 0.0001
I0818 18:00:58.908010  2522 solver.cpp:228] Iteration 5780, loss = 0.0783543
I0818 18:00:58.908066  2522 solver.cpp:244]     Train net output #0: loss1 = 0.059022 (* 0.4 = 0.0236088 loss)
I0818 18:00:58.908080  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0912425 (* 0.6 = 0.0547455 loss)
I0818 18:00:58.908093  2522 sgd_solver.cpp:106] Iteration 5780, lr = 0.0001
I0818 18:01:01.883193  2522 solver.cpp:228] Iteration 5800, loss = 0.162771
I0818 18:01:01.883247  2522 solver.cpp:244]     Train net output #0: loss1 = 0.127718 (* 0.4 = 0.0510873 loss)
I0818 18:01:01.883265  2522 solver.cpp:244]     Train net output #1: loss2 = 0.186139 (* 0.6 = 0.111684 loss)
I0818 18:01:01.883277  2522 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0818 18:01:04.831826  2522 solver.cpp:228] Iteration 5820, loss = 0.117486
I0818 18:01:04.831879  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0644545 (* 0.4 = 0.0257818 loss)
I0818 18:01:04.831895  2522 solver.cpp:244]     Train net output #1: loss2 = 0.15284 (* 0.6 = 0.091704 loss)
I0818 18:01:04.831908  2522 sgd_solver.cpp:106] Iteration 5820, lr = 0.0001
I0818 18:01:07.792234  2522 solver.cpp:228] Iteration 5840, loss = 0.100478
I0818 18:01:07.792286  2522 solver.cpp:244]     Train net output #0: loss1 = 0.026794 (* 0.4 = 0.0107176 loss)
I0818 18:01:07.792302  2522 solver.cpp:244]     Train net output #1: loss2 = 0.149601 (* 0.6 = 0.0897605 loss)
I0818 18:01:07.792315  2522 sgd_solver.cpp:106] Iteration 5840, lr = 0.0001
I0818 18:01:10.754415  2522 solver.cpp:228] Iteration 5860, loss = 0.0856905
I0818 18:01:10.754467  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0519897 (* 0.4 = 0.0207959 loss)
I0818 18:01:10.754483  2522 solver.cpp:244]     Train net output #1: loss2 = 0.108158 (* 0.6 = 0.0648947 loss)
I0818 18:01:10.754497  2522 sgd_solver.cpp:106] Iteration 5860, lr = 0.0001
I0818 18:01:13.719331  2522 solver.cpp:228] Iteration 5880, loss = 0.115692
I0818 18:01:13.719439  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0632176 (* 0.4 = 0.025287 loss)
I0818 18:01:13.719455  2522 solver.cpp:244]     Train net output #1: loss2 = 0.150676 (* 0.6 = 0.0904054 loss)
I0818 18:01:13.719468  2522 sgd_solver.cpp:106] Iteration 5880, lr = 0.0001
I0818 18:01:16.694783  2522 solver.cpp:228] Iteration 5900, loss = 0.0481668
I0818 18:01:16.694836  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0249581 (* 0.4 = 0.00998323 loss)
I0818 18:01:16.694854  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0636394 (* 0.6 = 0.0381836 loss)
I0818 18:01:16.694865  2522 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0818 18:01:19.660835  2522 solver.cpp:228] Iteration 5920, loss = 0.095456
I0818 18:01:19.660884  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0509002 (* 0.4 = 0.0203601 loss)
I0818 18:01:19.660900  2522 solver.cpp:244]     Train net output #1: loss2 = 0.12516 (* 0.6 = 0.075096 loss)
I0818 18:01:19.660913  2522 sgd_solver.cpp:106] Iteration 5920, lr = 0.0001
I0818 18:01:22.635443  2522 solver.cpp:228] Iteration 5940, loss = 0.118434
I0818 18:01:22.635493  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0976616 (* 0.4 = 0.0390646 loss)
I0818 18:01:22.635509  2522 solver.cpp:244]     Train net output #1: loss2 = 0.132282 (* 0.6 = 0.0793694 loss)
I0818 18:01:22.635521  2522 sgd_solver.cpp:106] Iteration 5940, lr = 0.0001
I0818 18:01:25.629497  2522 solver.cpp:228] Iteration 5960, loss = 0.100992
I0818 18:01:25.629576  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0659862 (* 0.4 = 0.0263945 loss)
I0818 18:01:25.629606  2522 solver.cpp:244]     Train net output #1: loss2 = 0.124329 (* 0.6 = 0.0745975 loss)
I0818 18:01:25.629628  2522 sgd_solver.cpp:106] Iteration 5960, lr = 0.0001
I0818 18:01:28.622326  2522 solver.cpp:228] Iteration 5980, loss = 0.125781
I0818 18:01:28.622378  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0843797 (* 0.4 = 0.0337519 loss)
I0818 18:01:28.622395  2522 solver.cpp:244]     Train net output #1: loss2 = 0.153382 (* 0.6 = 0.0920291 loss)
I0818 18:01:28.622407  2522 sgd_solver.cpp:106] Iteration 5980, lr = 0.0001
I0818 18:01:31.444735  2522 solver.cpp:337] Iteration 6000, Testing net (#0)
I0818 18:02:06.438665  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.887328
I0818 18:02:06.438767  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.961156
I0818 18:02:06.438786  2522 solver.cpp:404]     Test net output #2: loss1 = 0.106919 (* 0.4 = 0.0427674 loss)
I0818 18:02:06.438799  2522 solver.cpp:404]     Test net output #3: loss2 = 0.280141 (* 0.6 = 0.168085 loss)
I0818 18:02:06.484186  2522 solver.cpp:228] Iteration 6000, loss = 0.149785
I0818 18:02:06.484232  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0786434 (* 0.4 = 0.0314573 loss)
I0818 18:02:06.484247  2522 solver.cpp:244]     Train net output #1: loss2 = 0.197213 (* 0.6 = 0.118328 loss)
I0818 18:02:06.484261  2522 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0818 18:02:09.456080  2522 solver.cpp:228] Iteration 6020, loss = 0.115518
I0818 18:02:09.456130  2522 solver.cpp:244]     Train net output #0: loss1 = 0.066653 (* 0.4 = 0.0266612 loss)
I0818 18:02:09.456146  2522 solver.cpp:244]     Train net output #1: loss2 = 0.148095 (* 0.6 = 0.0888567 loss)
I0818 18:02:09.456159  2522 sgd_solver.cpp:106] Iteration 6020, lr = 1e-05
I0818 18:02:12.425973  2522 solver.cpp:228] Iteration 6040, loss = 0.110478
I0818 18:02:12.426028  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0378107 (* 0.4 = 0.0151243 loss)
I0818 18:02:12.426043  2522 solver.cpp:244]     Train net output #1: loss2 = 0.158923 (* 0.6 = 0.095354 loss)
I0818 18:02:12.426056  2522 sgd_solver.cpp:106] Iteration 6040, lr = 1e-05
I0818 18:02:15.384675  2522 solver.cpp:228] Iteration 6060, loss = 0.109083
I0818 18:02:15.384729  2522 solver.cpp:244]     Train net output #0: loss1 = 0.106504 (* 0.4 = 0.0426014 loss)
I0818 18:02:15.384745  2522 solver.cpp:244]     Train net output #1: loss2 = 0.110803 (* 0.6 = 0.0664816 loss)
I0818 18:02:15.384759  2522 sgd_solver.cpp:106] Iteration 6060, lr = 1e-05
I0818 18:02:18.343016  2522 solver.cpp:228] Iteration 6080, loss = 0.080415
I0818 18:02:18.343067  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0636886 (* 0.4 = 0.0254754 loss)
I0818 18:02:18.343083  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0915659 (* 0.6 = 0.0549395 loss)
I0818 18:02:18.343097  2522 sgd_solver.cpp:106] Iteration 6080, lr = 1e-05
I0818 18:02:21.319133  2522 solver.cpp:228] Iteration 6100, loss = 0.0909939
I0818 18:02:21.319183  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0643216 (* 0.4 = 0.0257287 loss)
I0818 18:02:21.319200  2522 solver.cpp:244]     Train net output #1: loss2 = 0.108776 (* 0.6 = 0.0652653 loss)
I0818 18:02:21.319212  2522 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0818 18:02:24.276399  2522 solver.cpp:228] Iteration 6120, loss = 0.129726
I0818 18:02:24.276453  2522 solver.cpp:244]     Train net output #0: loss1 = 0.013416 (* 0.4 = 0.00536638 loss)
I0818 18:02:24.276468  2522 solver.cpp:244]     Train net output #1: loss2 = 0.207266 (* 0.6 = 0.12436 loss)
I0818 18:02:24.276481  2522 sgd_solver.cpp:106] Iteration 6120, lr = 1e-05
I0818 18:02:27.341116  2522 solver.cpp:228] Iteration 6140, loss = 0.0786881
I0818 18:02:27.341171  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0586406 (* 0.4 = 0.0234563 loss)
I0818 18:02:27.341187  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0920532 (* 0.6 = 0.0552319 loss)
I0818 18:02:27.341202  2522 sgd_solver.cpp:106] Iteration 6140, lr = 1e-05
I0818 18:02:30.373668  2522 solver.cpp:228] Iteration 6160, loss = 0.141586
I0818 18:02:30.373721  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0863083 (* 0.4 = 0.0345233 loss)
I0818 18:02:30.373738  2522 solver.cpp:244]     Train net output #1: loss2 = 0.178437 (* 0.6 = 0.107062 loss)
I0818 18:02:30.373751  2522 sgd_solver.cpp:106] Iteration 6160, lr = 1e-05
I0818 18:02:33.364486  2522 solver.cpp:228] Iteration 6180, loss = 0.125119
I0818 18:02:33.364547  2522 solver.cpp:244]     Train net output #0: loss1 = 0.122104 (* 0.4 = 0.0488415 loss)
I0818 18:02:33.364562  2522 solver.cpp:244]     Train net output #1: loss2 = 0.127129 (* 0.6 = 0.0762773 loss)
I0818 18:02:33.364576  2522 sgd_solver.cpp:106] Iteration 6180, lr = 1e-05
I0818 18:02:36.339730  2522 solver.cpp:228] Iteration 6200, loss = 0.122347
I0818 18:02:36.339808  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0480906 (* 0.4 = 0.0192362 loss)
I0818 18:02:36.339824  2522 solver.cpp:244]     Train net output #1: loss2 = 0.171852 (* 0.6 = 0.103111 loss)
I0818 18:02:36.339838  2522 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0818 18:02:39.311827  2522 solver.cpp:228] Iteration 6220, loss = 0.166411
I0818 18:02:39.312067  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0607411 (* 0.4 = 0.0242964 loss)
I0818 18:02:39.312086  2522 solver.cpp:244]     Train net output #1: loss2 = 0.236858 (* 0.6 = 0.142115 loss)
I0818 18:02:39.312099  2522 sgd_solver.cpp:106] Iteration 6220, lr = 1e-05
I0818 18:02:42.278810  2522 solver.cpp:228] Iteration 6240, loss = 0.144648
I0818 18:02:42.278858  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0159835 (* 0.4 = 0.00639342 loss)
I0818 18:02:42.278873  2522 solver.cpp:244]     Train net output #1: loss2 = 0.230424 (* 0.6 = 0.138255 loss)
I0818 18:02:42.278887  2522 sgd_solver.cpp:106] Iteration 6240, lr = 1e-05
I0818 18:02:45.243312  2522 solver.cpp:228] Iteration 6260, loss = 0.132047
I0818 18:02:45.243363  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0309185 (* 0.4 = 0.0123674 loss)
I0818 18:02:45.243379  2522 solver.cpp:244]     Train net output #1: loss2 = 0.199467 (* 0.6 = 0.11968 loss)
I0818 18:02:45.243393  2522 sgd_solver.cpp:106] Iteration 6260, lr = 1e-05
I0818 18:02:48.211488  2522 solver.cpp:228] Iteration 6280, loss = 0.153198
I0818 18:02:48.211541  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0611312 (* 0.4 = 0.0244525 loss)
I0818 18:02:48.211557  2522 solver.cpp:244]     Train net output #1: loss2 = 0.214576 (* 0.6 = 0.128746 loss)
I0818 18:02:48.211570  2522 sgd_solver.cpp:106] Iteration 6280, lr = 1e-05
I0818 18:02:51.195886  2522 solver.cpp:228] Iteration 6300, loss = 0.121599
I0818 18:02:51.195940  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0979695 (* 0.4 = 0.0391878 loss)
I0818 18:02:51.195956  2522 solver.cpp:244]     Train net output #1: loss2 = 0.137352 (* 0.6 = 0.0824111 loss)
I0818 18:02:51.195971  2522 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0818 18:02:54.169050  2522 solver.cpp:228] Iteration 6320, loss = 0.134737
I0818 18:02:54.169100  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0367486 (* 0.4 = 0.0146994 loss)
I0818 18:02:54.169116  2522 solver.cpp:244]     Train net output #1: loss2 = 0.200063 (* 0.6 = 0.120038 loss)
I0818 18:02:54.169131  2522 sgd_solver.cpp:106] Iteration 6320, lr = 1e-05
I0818 18:02:57.137594  2522 solver.cpp:228] Iteration 6340, loss = 0.0934696
I0818 18:02:57.137647  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0340495 (* 0.4 = 0.0136198 loss)
I0818 18:02:57.137663  2522 solver.cpp:244]     Train net output #1: loss2 = 0.133083 (* 0.6 = 0.0798498 loss)
I0818 18:02:57.137677  2522 sgd_solver.cpp:106] Iteration 6340, lr = 1e-05
I0818 18:03:00.103340  2522 solver.cpp:228] Iteration 6360, loss = 0.0772879
I0818 18:03:00.103395  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0340074 (* 0.4 = 0.013603 loss)
I0818 18:03:00.103411  2522 solver.cpp:244]     Train net output #1: loss2 = 0.106142 (* 0.6 = 0.063685 loss)
I0818 18:03:00.103425  2522 sgd_solver.cpp:106] Iteration 6360, lr = 1e-05
I0818 18:03:03.062012  2522 solver.cpp:228] Iteration 6380, loss = 0.127746
I0818 18:03:03.062065  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0455906 (* 0.4 = 0.0182363 loss)
I0818 18:03:03.062083  2522 solver.cpp:244]     Train net output #1: loss2 = 0.182517 (* 0.6 = 0.10951 loss)
I0818 18:03:03.062095  2522 sgd_solver.cpp:106] Iteration 6380, lr = 1e-05
I0818 18:03:06.032542  2522 solver.cpp:228] Iteration 6400, loss = 0.12912
I0818 18:03:06.032593  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0707115 (* 0.4 = 0.0282846 loss)
I0818 18:03:06.032609  2522 solver.cpp:244]     Train net output #1: loss2 = 0.168058 (* 0.6 = 0.100835 loss)
I0818 18:03:06.032624  2522 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0818 18:03:08.988615  2522 solver.cpp:228] Iteration 6420, loss = 0.105577
I0818 18:03:08.988668  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0494789 (* 0.4 = 0.0197915 loss)
I0818 18:03:08.988684  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142976 (* 0.6 = 0.0857858 loss)
I0818 18:03:08.988698  2522 sgd_solver.cpp:106] Iteration 6420, lr = 1e-05
I0818 18:03:11.944718  2522 solver.cpp:228] Iteration 6440, loss = 0.209617
I0818 18:03:11.944861  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0616535 (* 0.4 = 0.0246614 loss)
I0818 18:03:11.944878  2522 solver.cpp:244]     Train net output #1: loss2 = 0.308259 (* 0.6 = 0.184955 loss)
I0818 18:03:11.944892  2522 sgd_solver.cpp:106] Iteration 6440, lr = 1e-05
I0818 18:03:14.896539  2522 solver.cpp:228] Iteration 6460, loss = 0.132866
I0818 18:03:14.896594  2522 solver.cpp:244]     Train net output #0: loss1 = 0.114708 (* 0.4 = 0.0458832 loss)
I0818 18:03:14.896610  2522 solver.cpp:244]     Train net output #1: loss2 = 0.144971 (* 0.6 = 0.0869828 loss)
I0818 18:03:14.896623  2522 sgd_solver.cpp:106] Iteration 6460, lr = 1e-05
I0818 18:03:17.840378  2522 solver.cpp:228] Iteration 6480, loss = 0.205981
I0818 18:03:17.840428  2522 solver.cpp:244]     Train net output #0: loss1 = 0.156241 (* 0.4 = 0.0624965 loss)
I0818 18:03:17.840445  2522 solver.cpp:244]     Train net output #1: loss2 = 0.239141 (* 0.6 = 0.143485 loss)
I0818 18:03:17.840457  2522 sgd_solver.cpp:106] Iteration 6480, lr = 1e-05
I0818 18:03:20.794024  2522 solver.cpp:228] Iteration 6500, loss = 0.105786
I0818 18:03:20.794073  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0236361 (* 0.4 = 0.00945446 loss)
I0818 18:03:20.794090  2522 solver.cpp:244]     Train net output #1: loss2 = 0.160553 (* 0.6 = 0.0963315 loss)
I0818 18:03:20.794103  2522 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0818 18:03:23.750396  2522 solver.cpp:228] Iteration 6520, loss = 0.111399
I0818 18:03:23.750452  2522 solver.cpp:244]     Train net output #0: loss1 = 0.047434 (* 0.4 = 0.0189736 loss)
I0818 18:03:23.750468  2522 solver.cpp:244]     Train net output #1: loss2 = 0.154042 (* 0.6 = 0.0924251 loss)
I0818 18:03:23.750481  2522 sgd_solver.cpp:106] Iteration 6520, lr = 1e-05
I0818 18:03:26.706311  2522 solver.cpp:228] Iteration 6540, loss = 0.0640182
I0818 18:03:26.706363  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0369317 (* 0.4 = 0.0147727 loss)
I0818 18:03:26.706379  2522 solver.cpp:244]     Train net output #1: loss2 = 0.082076 (* 0.6 = 0.0492456 loss)
I0818 18:03:26.706393  2522 sgd_solver.cpp:106] Iteration 6540, lr = 1e-05
I0818 18:03:29.668661  2522 solver.cpp:228] Iteration 6560, loss = 0.114402
I0818 18:03:29.668711  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0579155 (* 0.4 = 0.0231662 loss)
I0818 18:03:29.668727  2522 solver.cpp:244]     Train net output #1: loss2 = 0.152059 (* 0.6 = 0.0912357 loss)
I0818 18:03:29.668740  2522 sgd_solver.cpp:106] Iteration 6560, lr = 1e-05
I0818 18:03:32.646713  2522 solver.cpp:228] Iteration 6580, loss = 0.124004
I0818 18:03:32.646762  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0378897 (* 0.4 = 0.0151559 loss)
I0818 18:03:32.646778  2522 solver.cpp:244]     Train net output #1: loss2 = 0.181414 (* 0.6 = 0.108848 loss)
I0818 18:03:32.646792  2522 sgd_solver.cpp:106] Iteration 6580, lr = 1e-05
I0818 18:03:35.635758  2522 solver.cpp:228] Iteration 6600, loss = 0.108823
I0818 18:03:35.635812  2522 solver.cpp:244]     Train net output #0: loss1 = 0.059421 (* 0.4 = 0.0237684 loss)
I0818 18:03:35.635829  2522 solver.cpp:244]     Train net output #1: loss2 = 0.141759 (* 0.6 = 0.0850551 loss)
I0818 18:03:35.635843  2522 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0818 18:03:38.595005  2522 solver.cpp:228] Iteration 6620, loss = 0.165949
I0818 18:03:38.595057  2522 solver.cpp:244]     Train net output #0: loss1 = 0.105497 (* 0.4 = 0.0421989 loss)
I0818 18:03:38.595073  2522 solver.cpp:244]     Train net output #1: loss2 = 0.20625 (* 0.6 = 0.12375 loss)
I0818 18:03:38.595088  2522 sgd_solver.cpp:106] Iteration 6620, lr = 1e-05
I0818 18:03:41.554044  2522 solver.cpp:228] Iteration 6640, loss = 0.0798135
I0818 18:03:41.554093  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0601612 (* 0.4 = 0.0240645 loss)
I0818 18:03:41.554110  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0929152 (* 0.6 = 0.0557491 loss)
I0818 18:03:41.554122  2522 sgd_solver.cpp:106] Iteration 6640, lr = 1e-05
I0818 18:03:44.510707  2522 solver.cpp:228] Iteration 6660, loss = 0.08084
I0818 18:03:44.510849  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0517325 (* 0.4 = 0.020693 loss)
I0818 18:03:44.510867  2522 solver.cpp:244]     Train net output #1: loss2 = 0.100245 (* 0.6 = 0.0601471 loss)
I0818 18:03:44.510881  2522 sgd_solver.cpp:106] Iteration 6660, lr = 1e-05
I0818 18:03:47.471298  2522 solver.cpp:228] Iteration 6680, loss = 0.0874105
I0818 18:03:47.471352  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0195685 (* 0.4 = 0.00782741 loss)
I0818 18:03:47.471369  2522 solver.cpp:244]     Train net output #1: loss2 = 0.132639 (* 0.6 = 0.0795832 loss)
I0818 18:03:47.471381  2522 sgd_solver.cpp:106] Iteration 6680, lr = 1e-05
I0818 18:03:50.428081  2522 solver.cpp:228] Iteration 6700, loss = 0.150786
I0818 18:03:50.428134  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0671606 (* 0.4 = 0.0268642 loss)
I0818 18:03:50.428150  2522 solver.cpp:244]     Train net output #1: loss2 = 0.206536 (* 0.6 = 0.123922 loss)
I0818 18:03:50.428164  2522 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0818 18:03:53.390820  2522 solver.cpp:228] Iteration 6720, loss = 0.120734
I0818 18:03:53.390869  2522 solver.cpp:244]     Train net output #0: loss1 = 0.125181 (* 0.4 = 0.0500725 loss)
I0818 18:03:53.390885  2522 solver.cpp:244]     Train net output #1: loss2 = 0.117769 (* 0.6 = 0.0706613 loss)
I0818 18:03:53.390899  2522 sgd_solver.cpp:106] Iteration 6720, lr = 1e-05
I0818 18:03:56.413302  2522 solver.cpp:228] Iteration 6740, loss = 0.117307
I0818 18:03:56.413354  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0421485 (* 0.4 = 0.0168594 loss)
I0818 18:03:56.413370  2522 solver.cpp:244]     Train net output #1: loss2 = 0.167412 (* 0.6 = 0.100447 loss)
I0818 18:03:56.413384  2522 sgd_solver.cpp:106] Iteration 6740, lr = 1e-05
I0818 18:03:59.398816  2522 solver.cpp:228] Iteration 6760, loss = 0.130197
I0818 18:03:59.398869  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0670447 (* 0.4 = 0.0268179 loss)
I0818 18:03:59.398883  2522 solver.cpp:244]     Train net output #1: loss2 = 0.172299 (* 0.6 = 0.103379 loss)
I0818 18:03:59.398897  2522 sgd_solver.cpp:106] Iteration 6760, lr = 1e-05
I0818 18:04:02.386406  2522 solver.cpp:228] Iteration 6780, loss = 0.153721
I0818 18:04:02.386456  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0926562 (* 0.4 = 0.0370625 loss)
I0818 18:04:02.386472  2522 solver.cpp:244]     Train net output #1: loss2 = 0.194431 (* 0.6 = 0.116658 loss)
I0818 18:04:02.386485  2522 sgd_solver.cpp:106] Iteration 6780, lr = 1e-05
I0818 18:04:05.356266  2522 solver.cpp:228] Iteration 6800, loss = 0.109788
I0818 18:04:05.356318  2522 solver.cpp:244]     Train net output #0: loss1 = 0.10141 (* 0.4 = 0.0405641 loss)
I0818 18:04:05.356335  2522 solver.cpp:244]     Train net output #1: loss2 = 0.115373 (* 0.6 = 0.0692239 loss)
I0818 18:04:05.356349  2522 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0818 18:04:08.322218  2522 solver.cpp:228] Iteration 6820, loss = 0.100203
I0818 18:04:08.322268  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0554997 (* 0.4 = 0.0221999 loss)
I0818 18:04:08.322283  2522 solver.cpp:244]     Train net output #1: loss2 = 0.130005 (* 0.6 = 0.0780029 loss)
I0818 18:04:08.322298  2522 sgd_solver.cpp:106] Iteration 6820, lr = 1e-05
I0818 18:04:11.285598  2522 solver.cpp:228] Iteration 6840, loss = 0.0756694
I0818 18:04:11.285650  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0288941 (* 0.4 = 0.0115576 loss)
I0818 18:04:11.285665  2522 solver.cpp:244]     Train net output #1: loss2 = 0.106853 (* 0.6 = 0.0641119 loss)
I0818 18:04:11.285678  2522 sgd_solver.cpp:106] Iteration 6840, lr = 1e-05
I0818 18:04:14.278492  2522 solver.cpp:228] Iteration 6860, loss = 0.0800287
I0818 18:04:14.278542  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0469832 (* 0.4 = 0.0187933 loss)
I0818 18:04:14.278558  2522 solver.cpp:244]     Train net output #1: loss2 = 0.102059 (* 0.6 = 0.0612355 loss)
I0818 18:04:14.278571  2522 sgd_solver.cpp:106] Iteration 6860, lr = 1e-05
I0818 18:04:17.244796  2522 solver.cpp:228] Iteration 6880, loss = 0.0878084
I0818 18:04:17.244938  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0451949 (* 0.4 = 0.018078 loss)
I0818 18:04:17.244956  2522 solver.cpp:244]     Train net output #1: loss2 = 0.116218 (* 0.6 = 0.0697305 loss)
I0818 18:04:17.244969  2522 sgd_solver.cpp:106] Iteration 6880, lr = 1e-05
I0818 18:04:20.194506  2522 solver.cpp:228] Iteration 6900, loss = 0.10996
I0818 18:04:20.194561  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0462458 (* 0.4 = 0.0184983 loss)
I0818 18:04:20.194576  2522 solver.cpp:244]     Train net output #1: loss2 = 0.152436 (* 0.6 = 0.0914618 loss)
I0818 18:04:20.194591  2522 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0818 18:04:23.186945  2522 solver.cpp:228] Iteration 6920, loss = 0.11575
I0818 18:04:23.187000  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0706313 (* 0.4 = 0.0282525 loss)
I0818 18:04:23.187016  2522 solver.cpp:244]     Train net output #1: loss2 = 0.14583 (* 0.6 = 0.0874979 loss)
I0818 18:04:23.187029  2522 sgd_solver.cpp:106] Iteration 6920, lr = 1e-05
I0818 18:04:26.159689  2522 solver.cpp:228] Iteration 6940, loss = 0.0938856
I0818 18:04:26.159741  2522 solver.cpp:244]     Train net output #0: loss1 = 0.029413 (* 0.4 = 0.0117652 loss)
I0818 18:04:26.159757  2522 solver.cpp:244]     Train net output #1: loss2 = 0.136867 (* 0.6 = 0.0821205 loss)
I0818 18:04:26.159770  2522 sgd_solver.cpp:106] Iteration 6940, lr = 1e-05
I0818 18:04:29.122896  2522 solver.cpp:228] Iteration 6960, loss = 0.0918616
I0818 18:04:29.122948  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0567015 (* 0.4 = 0.0226806 loss)
I0818 18:04:29.122966  2522 solver.cpp:244]     Train net output #1: loss2 = 0.115302 (* 0.6 = 0.0691811 loss)
I0818 18:04:29.122979  2522 sgd_solver.cpp:106] Iteration 6960, lr = 1e-05
I0818 18:04:32.113948  2522 solver.cpp:228] Iteration 6980, loss = 0.114255
I0818 18:04:32.114003  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0235381 (* 0.4 = 0.00941525 loss)
I0818 18:04:32.114019  2522 solver.cpp:244]     Train net output #1: loss2 = 0.174733 (* 0.6 = 0.10484 loss)
I0818 18:04:32.114033  2522 sgd_solver.cpp:106] Iteration 6980, lr = 1e-05
I0818 18:04:34.926882  2522 solver.cpp:337] Iteration 7000, Testing net (#0)
I0818 18:05:10.160910  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.888266
I0818 18:05:10.161017  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.962109
I0818 18:05:10.161036  2522 solver.cpp:404]     Test net output #2: loss1 = 0.107194 (* 0.4 = 0.0428778 loss)
I0818 18:05:10.161049  2522 solver.cpp:404]     Test net output #3: loss2 = 0.279252 (* 0.6 = 0.167551 loss)
I0818 18:05:10.209056  2522 solver.cpp:228] Iteration 7000, loss = 0.121138
I0818 18:05:10.209105  2522 solver.cpp:244]     Train net output #0: loss1 = 0.060823 (* 0.4 = 0.0243292 loss)
I0818 18:05:10.209127  2522 solver.cpp:244]     Train net output #1: loss2 = 0.161347 (* 0.6 = 0.0968084 loss)
I0818 18:05:10.209142  2522 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0818 18:05:13.164120  2522 solver.cpp:228] Iteration 7020, loss = 0.0637823
I0818 18:05:13.164170  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0319252 (* 0.4 = 0.0127701 loss)
I0818 18:05:13.164186  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0850205 (* 0.6 = 0.0510123 loss)
I0818 18:05:13.164199  2522 sgd_solver.cpp:106] Iteration 7020, lr = 1e-05
I0818 18:05:16.130786  2522 solver.cpp:228] Iteration 7040, loss = 0.191281
I0818 18:05:16.130836  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0716873 (* 0.4 = 0.0286749 loss)
I0818 18:05:16.130851  2522 solver.cpp:244]     Train net output #1: loss2 = 0.271011 (* 0.6 = 0.162606 loss)
I0818 18:05:16.130866  2522 sgd_solver.cpp:106] Iteration 7040, lr = 1e-05
I0818 18:05:19.173316  2522 solver.cpp:228] Iteration 7060, loss = 0.106828
I0818 18:05:19.173367  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0284548 (* 0.4 = 0.0113819 loss)
I0818 18:05:19.173382  2522 solver.cpp:244]     Train net output #1: loss2 = 0.159077 (* 0.6 = 0.0954461 loss)
I0818 18:05:19.173396  2522 sgd_solver.cpp:106] Iteration 7060, lr = 1e-05
I0818 18:05:22.198772  2522 solver.cpp:228] Iteration 7080, loss = 0.148607
I0818 18:05:22.198823  2522 solver.cpp:244]     Train net output #0: loss1 = 0.10034 (* 0.4 = 0.0401361 loss)
I0818 18:05:22.198839  2522 solver.cpp:244]     Train net output #1: loss2 = 0.180786 (* 0.6 = 0.108471 loss)
I0818 18:05:22.198853  2522 sgd_solver.cpp:106] Iteration 7080, lr = 1e-05
I0818 18:05:25.146211  2522 solver.cpp:228] Iteration 7100, loss = 0.166624
I0818 18:05:25.146265  2522 solver.cpp:244]     Train net output #0: loss1 = 0.121594 (* 0.4 = 0.0486375 loss)
I0818 18:05:25.146281  2522 solver.cpp:244]     Train net output #1: loss2 = 0.196645 (* 0.6 = 0.117987 loss)
I0818 18:05:25.146296  2522 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0818 18:05:28.098623  2522 solver.cpp:228] Iteration 7120, loss = 0.0998856
I0818 18:05:28.098676  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0365944 (* 0.4 = 0.0146378 loss)
I0818 18:05:28.098692  2522 solver.cpp:244]     Train net output #1: loss2 = 0.14208 (* 0.6 = 0.0852479 loss)
I0818 18:05:28.098706  2522 sgd_solver.cpp:106] Iteration 7120, lr = 1e-05
I0818 18:05:31.083153  2522 solver.cpp:228] Iteration 7140, loss = 0.157149
I0818 18:05:31.083199  2522 solver.cpp:244]     Train net output #0: loss1 = 0.118195 (* 0.4 = 0.0472779 loss)
I0818 18:05:31.083215  2522 solver.cpp:244]     Train net output #1: loss2 = 0.183119 (* 0.6 = 0.109871 loss)
I0818 18:05:31.083228  2522 sgd_solver.cpp:106] Iteration 7140, lr = 1e-05
I0818 18:05:34.067059  2522 solver.cpp:228] Iteration 7160, loss = 0.0830554
I0818 18:05:34.067107  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0286639 (* 0.4 = 0.0114656 loss)
I0818 18:05:34.067123  2522 solver.cpp:244]     Train net output #1: loss2 = 0.119317 (* 0.6 = 0.0715899 loss)
I0818 18:05:34.067137  2522 sgd_solver.cpp:106] Iteration 7160, lr = 1e-05
I0818 18:05:37.022964  2522 solver.cpp:228] Iteration 7180, loss = 0.155846
I0818 18:05:37.023016  2522 solver.cpp:244]     Train net output #0: loss1 = 0.034977 (* 0.4 = 0.0139908 loss)
I0818 18:05:37.023032  2522 solver.cpp:244]     Train net output #1: loss2 = 0.236425 (* 0.6 = 0.141855 loss)
I0818 18:05:37.023046  2522 sgd_solver.cpp:106] Iteration 7180, lr = 1e-05
I0818 18:05:39.981570  2522 solver.cpp:228] Iteration 7200, loss = 0.11175
I0818 18:05:39.981650  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0113609 (* 0.4 = 0.00454436 loss)
I0818 18:05:39.981667  2522 solver.cpp:244]     Train net output #1: loss2 = 0.178676 (* 0.6 = 0.107206 loss)
I0818 18:05:39.981681  2522 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0818 18:05:42.932085  2522 solver.cpp:228] Iteration 7220, loss = 0.130407
I0818 18:05:42.932209  2522 solver.cpp:244]     Train net output #0: loss1 = 0.15287 (* 0.4 = 0.0611481 loss)
I0818 18:05:42.932225  2522 solver.cpp:244]     Train net output #1: loss2 = 0.115431 (* 0.6 = 0.0692585 loss)
I0818 18:05:42.932240  2522 sgd_solver.cpp:106] Iteration 7220, lr = 1e-05
I0818 18:05:45.882642  2522 solver.cpp:228] Iteration 7240, loss = 0.107256
I0818 18:05:45.882694  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0568839 (* 0.4 = 0.0227536 loss)
I0818 18:05:45.882710  2522 solver.cpp:244]     Train net output #1: loss2 = 0.140837 (* 0.6 = 0.0845025 loss)
I0818 18:05:45.882724  2522 sgd_solver.cpp:106] Iteration 7240, lr = 1e-05
I0818 18:05:48.836091  2522 solver.cpp:228] Iteration 7260, loss = 0.118547
I0818 18:05:48.836143  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0272751 (* 0.4 = 0.0109101 loss)
I0818 18:05:48.836158  2522 solver.cpp:244]     Train net output #1: loss2 = 0.179395 (* 0.6 = 0.107637 loss)
I0818 18:05:48.836170  2522 sgd_solver.cpp:106] Iteration 7260, lr = 1e-05
I0818 18:05:51.782541  2522 solver.cpp:228] Iteration 7280, loss = 0.102599
I0818 18:05:51.782595  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0215183 (* 0.4 = 0.00860733 loss)
I0818 18:05:51.782611  2522 solver.cpp:244]     Train net output #1: loss2 = 0.156653 (* 0.6 = 0.0939915 loss)
I0818 18:05:51.782625  2522 sgd_solver.cpp:106] Iteration 7280, lr = 1e-05
I0818 18:05:54.728929  2522 solver.cpp:228] Iteration 7300, loss = 0.0879983
I0818 18:05:54.728981  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0142111 (* 0.4 = 0.00568445 loss)
I0818 18:05:54.728997  2522 solver.cpp:244]     Train net output #1: loss2 = 0.13719 (* 0.6 = 0.0823139 loss)
I0818 18:05:54.729012  2522 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0818 18:05:57.680464  2522 solver.cpp:228] Iteration 7320, loss = 0.0775142
I0818 18:05:57.680516  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0497904 (* 0.4 = 0.0199162 loss)
I0818 18:05:57.680531  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0959969 (* 0.6 = 0.0575982 loss)
I0818 18:05:57.680546  2522 sgd_solver.cpp:106] Iteration 7320, lr = 1e-05
I0818 18:06:00.627928  2522 solver.cpp:228] Iteration 7340, loss = 0.141735
I0818 18:06:00.627982  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0292532 (* 0.4 = 0.0117013 loss)
I0818 18:06:00.627998  2522 solver.cpp:244]     Train net output #1: loss2 = 0.216722 (* 0.6 = 0.130033 loss)
I0818 18:06:00.628011  2522 sgd_solver.cpp:106] Iteration 7340, lr = 1e-05
I0818 18:06:03.574348  2522 solver.cpp:228] Iteration 7360, loss = 0.174831
I0818 18:06:03.574403  2522 solver.cpp:244]     Train net output #0: loss1 = 0.148491 (* 0.4 = 0.0593966 loss)
I0818 18:06:03.574419  2522 solver.cpp:244]     Train net output #1: loss2 = 0.192391 (* 0.6 = 0.115434 loss)
I0818 18:06:03.574431  2522 sgd_solver.cpp:106] Iteration 7360, lr = 1e-05
I0818 18:06:06.521335  2522 solver.cpp:228] Iteration 7380, loss = 0.127826
I0818 18:06:06.521401  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0867365 (* 0.4 = 0.0346946 loss)
I0818 18:06:06.521425  2522 solver.cpp:244]     Train net output #1: loss2 = 0.155219 (* 0.6 = 0.0931317 loss)
I0818 18:06:06.521445  2522 sgd_solver.cpp:106] Iteration 7380, lr = 1e-05
I0818 18:06:09.470273  2522 solver.cpp:228] Iteration 7400, loss = 0.0879792
I0818 18:06:09.470329  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0252689 (* 0.4 = 0.0101076 loss)
I0818 18:06:09.470345  2522 solver.cpp:244]     Train net output #1: loss2 = 0.129786 (* 0.6 = 0.0778717 loss)
I0818 18:06:09.470358  2522 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0818 18:06:12.417774  2522 solver.cpp:228] Iteration 7420, loss = 0.130145
I0818 18:06:12.417829  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0152393 (* 0.4 = 0.00609573 loss)
I0818 18:06:12.417845  2522 solver.cpp:244]     Train net output #1: loss2 = 0.206748 (* 0.6 = 0.124049 loss)
I0818 18:06:12.417858  2522 sgd_solver.cpp:106] Iteration 7420, lr = 1e-05
I0818 18:06:15.363394  2522 solver.cpp:228] Iteration 7440, loss = 0.121719
I0818 18:06:15.363541  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0309718 (* 0.4 = 0.0123887 loss)
I0818 18:06:15.363559  2522 solver.cpp:244]     Train net output #1: loss2 = 0.182218 (* 0.6 = 0.109331 loss)
I0818 18:06:15.363572  2522 sgd_solver.cpp:106] Iteration 7440, lr = 1e-05
I0818 18:06:18.310940  2522 solver.cpp:228] Iteration 7460, loss = 0.142954
I0818 18:06:18.310994  2522 solver.cpp:244]     Train net output #0: loss1 = 0.102082 (* 0.4 = 0.0408327 loss)
I0818 18:06:18.311010  2522 solver.cpp:244]     Train net output #1: loss2 = 0.170201 (* 0.6 = 0.102121 loss)
I0818 18:06:18.311023  2522 sgd_solver.cpp:106] Iteration 7460, lr = 1e-05
I0818 18:06:21.257685  2522 solver.cpp:228] Iteration 7480, loss = 0.166506
I0818 18:06:21.257738  2522 solver.cpp:244]     Train net output #0: loss1 = 0.125875 (* 0.4 = 0.0503501 loss)
I0818 18:06:21.257755  2522 solver.cpp:244]     Train net output #1: loss2 = 0.193593 (* 0.6 = 0.116156 loss)
I0818 18:06:21.257768  2522 sgd_solver.cpp:106] Iteration 7480, lr = 1e-05
I0818 18:06:24.205272  2522 solver.cpp:228] Iteration 7500, loss = 0.0830017
I0818 18:06:24.205327  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0683837 (* 0.4 = 0.0273535 loss)
I0818 18:06:24.205343  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0927471 (* 0.6 = 0.0556482 loss)
I0818 18:06:24.205356  2522 sgd_solver.cpp:106] Iteration 7500, lr = 1e-05
I0818 18:06:27.151559  2522 solver.cpp:228] Iteration 7520, loss = 0.0621971
I0818 18:06:27.151613  2522 solver.cpp:244]     Train net output #0: loss1 = 0.045923 (* 0.4 = 0.0183692 loss)
I0818 18:06:27.151628  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0730466 (* 0.6 = 0.0438279 loss)
I0818 18:06:27.151641  2522 sgd_solver.cpp:106] Iteration 7520, lr = 1e-05
I0818 18:06:30.098978  2522 solver.cpp:228] Iteration 7540, loss = 0.103841
I0818 18:06:30.099031  2522 solver.cpp:244]     Train net output #0: loss1 = 0.041275 (* 0.4 = 0.01651 loss)
I0818 18:06:30.099046  2522 solver.cpp:244]     Train net output #1: loss2 = 0.145552 (* 0.6 = 0.087331 loss)
I0818 18:06:30.099061  2522 sgd_solver.cpp:106] Iteration 7540, lr = 1e-05
I0818 18:06:33.049706  2522 solver.cpp:228] Iteration 7560, loss = 0.122962
I0818 18:06:33.049762  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0149996 (* 0.4 = 0.00599985 loss)
I0818 18:06:33.049777  2522 solver.cpp:244]     Train net output #1: loss2 = 0.194937 (* 0.6 = 0.116962 loss)
I0818 18:06:33.049792  2522 sgd_solver.cpp:106] Iteration 7560, lr = 1e-05
I0818 18:06:35.996662  2522 solver.cpp:228] Iteration 7580, loss = 0.100298
I0818 18:06:35.996716  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0673315 (* 0.4 = 0.0269326 loss)
I0818 18:06:35.996732  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122276 (* 0.6 = 0.0733655 loss)
I0818 18:06:35.996747  2522 sgd_solver.cpp:106] Iteration 7580, lr = 1e-05
I0818 18:06:38.945523  2522 solver.cpp:228] Iteration 7600, loss = 0.139684
I0818 18:06:38.945586  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0304707 (* 0.4 = 0.0121883 loss)
I0818 18:06:38.945602  2522 solver.cpp:244]     Train net output #1: loss2 = 0.212493 (* 0.6 = 0.127496 loss)
I0818 18:06:38.945616  2522 sgd_solver.cpp:106] Iteration 7600, lr = 1e-05
I0818 18:06:41.892886  2522 solver.cpp:228] Iteration 7620, loss = 0.0628274
I0818 18:06:41.892940  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0371565 (* 0.4 = 0.0148626 loss)
I0818 18:06:41.892954  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0799414 (* 0.6 = 0.0479648 loss)
I0818 18:06:41.892968  2522 sgd_solver.cpp:106] Iteration 7620, lr = 1e-05
I0818 18:06:44.838974  2522 solver.cpp:228] Iteration 7640, loss = 0.154934
I0818 18:06:44.839026  2522 solver.cpp:244]     Train net output #0: loss1 = 0.178473 (* 0.4 = 0.0713894 loss)
I0818 18:06:44.839041  2522 solver.cpp:244]     Train net output #1: loss2 = 0.13924 (* 0.6 = 0.0835442 loss)
I0818 18:06:44.839056  2522 sgd_solver.cpp:106] Iteration 7640, lr = 1e-05
I0818 18:06:47.788033  2522 solver.cpp:228] Iteration 7660, loss = 0.174672
I0818 18:06:47.788151  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0400696 (* 0.4 = 0.0160278 loss)
I0818 18:06:47.788167  2522 solver.cpp:244]     Train net output #1: loss2 = 0.264407 (* 0.6 = 0.158644 loss)
I0818 18:06:47.788182  2522 sgd_solver.cpp:106] Iteration 7660, lr = 1e-05
I0818 18:06:50.735102  2522 solver.cpp:228] Iteration 7680, loss = 0.101665
I0818 18:06:50.735157  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0598972 (* 0.4 = 0.0239589 loss)
I0818 18:06:50.735174  2522 solver.cpp:244]     Train net output #1: loss2 = 0.129511 (* 0.6 = 0.0777066 loss)
I0818 18:06:50.735188  2522 sgd_solver.cpp:106] Iteration 7680, lr = 1e-05
I0818 18:06:53.682117  2522 solver.cpp:228] Iteration 7700, loss = 0.0977095
I0818 18:06:53.682169  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0675487 (* 0.4 = 0.0270195 loss)
I0818 18:06:53.682185  2522 solver.cpp:244]     Train net output #1: loss2 = 0.117817 (* 0.6 = 0.0706901 loss)
I0818 18:06:53.682199  2522 sgd_solver.cpp:106] Iteration 7700, lr = 1e-05
I0818 18:06:56.633002  2522 solver.cpp:228] Iteration 7720, loss = 0.143921
I0818 18:06:56.633057  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0866486 (* 0.4 = 0.0346595 loss)
I0818 18:06:56.633074  2522 solver.cpp:244]     Train net output #1: loss2 = 0.182102 (* 0.6 = 0.109261 loss)
I0818 18:06:56.633086  2522 sgd_solver.cpp:106] Iteration 7720, lr = 1e-05
I0818 18:06:59.579139  2522 solver.cpp:228] Iteration 7740, loss = 0.151309
I0818 18:06:59.579193  2522 solver.cpp:244]     Train net output #0: loss1 = 0.168472 (* 0.4 = 0.0673888 loss)
I0818 18:06:59.579210  2522 solver.cpp:244]     Train net output #1: loss2 = 0.139867 (* 0.6 = 0.0839205 loss)
I0818 18:06:59.579222  2522 sgd_solver.cpp:106] Iteration 7740, lr = 1e-05
I0818 18:07:02.527354  2522 solver.cpp:228] Iteration 7760, loss = 0.101892
I0818 18:07:02.527407  2522 solver.cpp:244]     Train net output #0: loss1 = 0.108579 (* 0.4 = 0.0434316 loss)
I0818 18:07:02.527423  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0974338 (* 0.6 = 0.0584603 loss)
I0818 18:07:02.527436  2522 sgd_solver.cpp:106] Iteration 7760, lr = 1e-05
I0818 18:07:05.473935  2522 solver.cpp:228] Iteration 7780, loss = 0.11144
I0818 18:07:05.473984  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0370465 (* 0.4 = 0.0148186 loss)
I0818 18:07:05.474000  2522 solver.cpp:244]     Train net output #1: loss2 = 0.161035 (* 0.6 = 0.0966211 loss)
I0818 18:07:05.474014  2522 sgd_solver.cpp:106] Iteration 7780, lr = 1e-05
I0818 18:07:08.421159  2522 solver.cpp:228] Iteration 7800, loss = 0.140976
I0818 18:07:08.421214  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0728044 (* 0.4 = 0.0291218 loss)
I0818 18:07:08.421231  2522 solver.cpp:244]     Train net output #1: loss2 = 0.186424 (* 0.6 = 0.111854 loss)
I0818 18:07:08.421244  2522 sgd_solver.cpp:106] Iteration 7800, lr = 1e-05
I0818 18:07:11.370473  2522 solver.cpp:228] Iteration 7820, loss = 0.133149
I0818 18:07:11.370523  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0509276 (* 0.4 = 0.020371 loss)
I0818 18:07:11.370539  2522 solver.cpp:244]     Train net output #1: loss2 = 0.187964 (* 0.6 = 0.112778 loss)
I0818 18:07:11.370553  2522 sgd_solver.cpp:106] Iteration 7820, lr = 1e-05
I0818 18:07:14.317678  2522 solver.cpp:228] Iteration 7840, loss = 0.0812728
I0818 18:07:14.317734  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0615284 (* 0.4 = 0.0246114 loss)
I0818 18:07:14.317749  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0944358 (* 0.6 = 0.0566615 loss)
I0818 18:07:14.317762  2522 sgd_solver.cpp:106] Iteration 7840, lr = 1e-05
I0818 18:07:17.266225  2522 solver.cpp:228] Iteration 7860, loss = 0.141192
I0818 18:07:17.266278  2522 solver.cpp:244]     Train net output #0: loss1 = 0.074354 (* 0.4 = 0.0297416 loss)
I0818 18:07:17.266294  2522 solver.cpp:244]     Train net output #1: loss2 = 0.185751 (* 0.6 = 0.11145 loss)
I0818 18:07:17.266307  2522 sgd_solver.cpp:106] Iteration 7860, lr = 1e-05
I0818 18:07:20.213621  2522 solver.cpp:228] Iteration 7880, loss = 0.148598
I0818 18:07:20.213785  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0477467 (* 0.4 = 0.0190987 loss)
I0818 18:07:20.213802  2522 solver.cpp:244]     Train net output #1: loss2 = 0.215832 (* 0.6 = 0.129499 loss)
I0818 18:07:20.213816  2522 sgd_solver.cpp:106] Iteration 7880, lr = 1e-05
I0818 18:07:23.160289  2522 solver.cpp:228] Iteration 7900, loss = 0.130245
I0818 18:07:23.160344  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0890249 (* 0.4 = 0.03561 loss)
I0818 18:07:23.160361  2522 solver.cpp:244]     Train net output #1: loss2 = 0.157726 (* 0.6 = 0.0946355 loss)
I0818 18:07:23.160378  2522 sgd_solver.cpp:106] Iteration 7900, lr = 1e-05
I0818 18:07:26.106446  2522 solver.cpp:228] Iteration 7920, loss = 0.0815949
I0818 18:07:26.106499  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0188736 (* 0.4 = 0.00754945 loss)
I0818 18:07:26.106515  2522 solver.cpp:244]     Train net output #1: loss2 = 0.123409 (* 0.6 = 0.0740455 loss)
I0818 18:07:26.106529  2522 sgd_solver.cpp:106] Iteration 7920, lr = 1e-05
I0818 18:07:29.052059  2522 solver.cpp:228] Iteration 7940, loss = 0.0984604
I0818 18:07:29.052122  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0517688 (* 0.4 = 0.0207075 loss)
I0818 18:07:29.052139  2522 solver.cpp:244]     Train net output #1: loss2 = 0.129588 (* 0.6 = 0.0777529 loss)
I0818 18:07:29.052152  2522 sgd_solver.cpp:106] Iteration 7940, lr = 1e-05
I0818 18:07:31.998862  2522 solver.cpp:228] Iteration 7960, loss = 0.114367
I0818 18:07:31.998915  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0520683 (* 0.4 = 0.0208273 loss)
I0818 18:07:31.998931  2522 solver.cpp:244]     Train net output #1: loss2 = 0.155899 (* 0.6 = 0.0935392 loss)
I0818 18:07:31.998945  2522 sgd_solver.cpp:106] Iteration 7960, lr = 1e-05
I0818 18:07:34.944759  2522 solver.cpp:228] Iteration 7980, loss = 0.129564
I0818 18:07:34.944813  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0672858 (* 0.4 = 0.0269143 loss)
I0818 18:07:34.944828  2522 solver.cpp:244]     Train net output #1: loss2 = 0.171083 (* 0.6 = 0.10265 loss)
I0818 18:07:34.944841  2522 sgd_solver.cpp:106] Iteration 7980, lr = 1e-05
I0818 18:07:37.745165  2522 solver.cpp:337] Iteration 8000, Testing net (#0)
I0818 18:08:12.679527  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.887203
I0818 18:08:12.679657  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.962094
I0818 18:08:12.679680  2522 solver.cpp:404]     Test net output #2: loss1 = 0.107077 (* 0.4 = 0.0428309 loss)
I0818 18:08:12.679694  2522 solver.cpp:404]     Test net output #3: loss2 = 0.279306 (* 0.6 = 0.167584 loss)
I0818 18:08:12.727524  2522 solver.cpp:228] Iteration 8000, loss = 0.0969148
I0818 18:08:12.727581  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0676359 (* 0.4 = 0.0270544 loss)
I0818 18:08:12.727598  2522 solver.cpp:244]     Train net output #1: loss2 = 0.116434 (* 0.6 = 0.0698605 loss)
I0818 18:08:12.727614  2522 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0818 18:08:15.674208  2522 solver.cpp:228] Iteration 8020, loss = 0.0912712
I0818 18:08:15.674263  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0368962 (* 0.4 = 0.0147585 loss)
I0818 18:08:15.674278  2522 solver.cpp:244]     Train net output #1: loss2 = 0.127521 (* 0.6 = 0.0765128 loss)
I0818 18:08:15.674291  2522 sgd_solver.cpp:106] Iteration 8020, lr = 1e-06
I0818 18:08:18.620573  2522 solver.cpp:228] Iteration 8040, loss = 0.131891
I0818 18:08:18.620630  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0450377 (* 0.4 = 0.0180151 loss)
I0818 18:08:18.620645  2522 solver.cpp:244]     Train net output #1: loss2 = 0.189794 (* 0.6 = 0.113876 loss)
I0818 18:08:18.620658  2522 sgd_solver.cpp:106] Iteration 8040, lr = 1e-06
I0818 18:08:21.566627  2522 solver.cpp:228] Iteration 8060, loss = 0.0983175
I0818 18:08:21.566680  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0376045 (* 0.4 = 0.0150418 loss)
I0818 18:08:21.566696  2522 solver.cpp:244]     Train net output #1: loss2 = 0.138793 (* 0.6 = 0.0832758 loss)
I0818 18:08:21.566709  2522 sgd_solver.cpp:106] Iteration 8060, lr = 1e-06
I0818 18:08:24.513317  2522 solver.cpp:228] Iteration 8080, loss = 0.189173
I0818 18:08:24.513370  2522 solver.cpp:244]     Train net output #0: loss1 = 0.161562 (* 0.4 = 0.0646249 loss)
I0818 18:08:24.513386  2522 solver.cpp:244]     Train net output #1: loss2 = 0.207581 (* 0.6 = 0.124549 loss)
I0818 18:08:24.513399  2522 sgd_solver.cpp:106] Iteration 8080, lr = 1e-06
I0818 18:08:27.459269  2522 solver.cpp:228] Iteration 8100, loss = 0.155713
I0818 18:08:27.459322  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0417582 (* 0.4 = 0.0167033 loss)
I0818 18:08:27.459339  2522 solver.cpp:244]     Train net output #1: loss2 = 0.231683 (* 0.6 = 0.13901 loss)
I0818 18:08:27.459352  2522 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0818 18:08:30.406553  2522 solver.cpp:228] Iteration 8120, loss = 0.0875019
I0818 18:08:30.406608  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0527302 (* 0.4 = 0.0210921 loss)
I0818 18:08:30.406625  2522 solver.cpp:244]     Train net output #1: loss2 = 0.110683 (* 0.6 = 0.0664099 loss)
I0818 18:08:30.406638  2522 sgd_solver.cpp:106] Iteration 8120, lr = 1e-06
I0818 18:08:33.353044  2522 solver.cpp:228] Iteration 8140, loss = 0.072548
I0818 18:08:33.353099  2522 solver.cpp:244]     Train net output #0: loss1 = 0.016591 (* 0.4 = 0.0066364 loss)
I0818 18:08:33.353116  2522 solver.cpp:244]     Train net output #1: loss2 = 0.109853 (* 0.6 = 0.0659116 loss)
I0818 18:08:33.353129  2522 sgd_solver.cpp:106] Iteration 8140, lr = 1e-06
I0818 18:08:36.301192  2522 solver.cpp:228] Iteration 8160, loss = 0.0568508
I0818 18:08:36.301242  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0279377 (* 0.4 = 0.0111751 loss)
I0818 18:08:36.301259  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0761263 (* 0.6 = 0.0456758 loss)
I0818 18:08:36.301272  2522 sgd_solver.cpp:106] Iteration 8160, lr = 1e-06
I0818 18:08:39.248301  2522 solver.cpp:228] Iteration 8180, loss = 0.0692246
I0818 18:08:39.248353  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0333596 (* 0.4 = 0.0133438 loss)
I0818 18:08:39.248368  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0931347 (* 0.6 = 0.0558808 loss)
I0818 18:08:39.248385  2522 sgd_solver.cpp:106] Iteration 8180, lr = 1e-06
I0818 18:08:42.195376  2522 solver.cpp:228] Iteration 8200, loss = 0.167824
I0818 18:08:42.195457  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0408256 (* 0.4 = 0.0163302 loss)
I0818 18:08:42.195475  2522 solver.cpp:244]     Train net output #1: loss2 = 0.25249 (* 0.6 = 0.151494 loss)
I0818 18:08:42.195488  2522 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0818 18:08:45.143256  2522 solver.cpp:228] Iteration 8220, loss = 0.149392
I0818 18:08:45.143379  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0363911 (* 0.4 = 0.0145564 loss)
I0818 18:08:45.143396  2522 solver.cpp:244]     Train net output #1: loss2 = 0.224726 (* 0.6 = 0.134836 loss)
I0818 18:08:45.143410  2522 sgd_solver.cpp:106] Iteration 8220, lr = 1e-06
I0818 18:08:48.090690  2522 solver.cpp:228] Iteration 8240, loss = 0.121875
I0818 18:08:48.090744  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0461174 (* 0.4 = 0.018447 loss)
I0818 18:08:48.090760  2522 solver.cpp:244]     Train net output #1: loss2 = 0.17238 (* 0.6 = 0.103428 loss)
I0818 18:08:48.090775  2522 sgd_solver.cpp:106] Iteration 8240, lr = 1e-06
I0818 18:08:51.037849  2522 solver.cpp:228] Iteration 8260, loss = 0.0674775
I0818 18:08:51.037904  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0255607 (* 0.4 = 0.0102243 loss)
I0818 18:08:51.037920  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0954221 (* 0.6 = 0.0572533 loss)
I0818 18:08:51.037935  2522 sgd_solver.cpp:106] Iteration 8260, lr = 1e-06
I0818 18:08:53.985380  2522 solver.cpp:228] Iteration 8280, loss = 0.112053
I0818 18:08:53.985435  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0381156 (* 0.4 = 0.0152462 loss)
I0818 18:08:53.985451  2522 solver.cpp:244]     Train net output #1: loss2 = 0.161345 (* 0.6 = 0.0968071 loss)
I0818 18:08:53.985465  2522 sgd_solver.cpp:106] Iteration 8280, lr = 1e-06
I0818 18:08:56.934190  2522 solver.cpp:228] Iteration 8300, loss = 0.107034
I0818 18:08:56.934243  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0676807 (* 0.4 = 0.0270723 loss)
I0818 18:08:56.934259  2522 solver.cpp:244]     Train net output #1: loss2 = 0.133269 (* 0.6 = 0.0799614 loss)
I0818 18:08:56.934273  2522 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0818 18:08:59.880767  2522 solver.cpp:228] Iteration 8320, loss = 0.120682
I0818 18:08:59.880820  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0664542 (* 0.4 = 0.0265817 loss)
I0818 18:08:59.880834  2522 solver.cpp:244]     Train net output #1: loss2 = 0.156833 (* 0.6 = 0.0941 loss)
I0818 18:08:59.880848  2522 sgd_solver.cpp:106] Iteration 8320, lr = 1e-06
I0818 18:09:02.828284  2522 solver.cpp:228] Iteration 8340, loss = 0.124926
I0818 18:09:02.828335  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0520221 (* 0.4 = 0.0208088 loss)
I0818 18:09:02.828351  2522 solver.cpp:244]     Train net output #1: loss2 = 0.173529 (* 0.6 = 0.104118 loss)
I0818 18:09:02.828364  2522 sgd_solver.cpp:106] Iteration 8340, lr = 1e-06
I0818 18:09:05.778861  2522 solver.cpp:228] Iteration 8360, loss = 0.145416
I0818 18:09:05.778914  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0309011 (* 0.4 = 0.0123604 loss)
I0818 18:09:05.778931  2522 solver.cpp:244]     Train net output #1: loss2 = 0.22176 (* 0.6 = 0.133056 loss)
I0818 18:09:05.778944  2522 sgd_solver.cpp:106] Iteration 8360, lr = 1e-06
I0818 18:09:08.726137  2522 solver.cpp:228] Iteration 8380, loss = 0.0856939
I0818 18:09:08.726191  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0292013 (* 0.4 = 0.0116805 loss)
I0818 18:09:08.726207  2522 solver.cpp:244]     Train net output #1: loss2 = 0.123356 (* 0.6 = 0.0740135 loss)
I0818 18:09:08.726222  2522 sgd_solver.cpp:106] Iteration 8380, lr = 1e-06
I0818 18:09:11.673945  2522 solver.cpp:228] Iteration 8400, loss = 0.174021
I0818 18:09:11.674000  2522 solver.cpp:244]     Train net output #0: loss1 = 0.175251 (* 0.4 = 0.0701006 loss)
I0818 18:09:11.674016  2522 solver.cpp:244]     Train net output #1: loss2 = 0.1732 (* 0.6 = 0.10392 loss)
I0818 18:09:11.674031  2522 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0818 18:09:14.620188  2522 solver.cpp:228] Iteration 8420, loss = 0.14182
I0818 18:09:14.620241  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0547262 (* 0.4 = 0.0218905 loss)
I0818 18:09:14.620257  2522 solver.cpp:244]     Train net output #1: loss2 = 0.199882 (* 0.6 = 0.119929 loss)
I0818 18:09:14.620271  2522 sgd_solver.cpp:106] Iteration 8420, lr = 1e-06
I0818 18:09:17.567252  2522 solver.cpp:228] Iteration 8440, loss = 0.17002
I0818 18:09:17.567380  2522 solver.cpp:244]     Train net output #0: loss1 = 0.176411 (* 0.4 = 0.0705646 loss)
I0818 18:09:17.567397  2522 solver.cpp:244]     Train net output #1: loss2 = 0.165758 (* 0.6 = 0.0994551 loss)
I0818 18:09:17.567411  2522 sgd_solver.cpp:106] Iteration 8440, lr = 1e-06
I0818 18:09:20.517468  2522 solver.cpp:228] Iteration 8460, loss = 0.11379
I0818 18:09:20.517523  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0729371 (* 0.4 = 0.0291748 loss)
I0818 18:09:20.517539  2522 solver.cpp:244]     Train net output #1: loss2 = 0.141025 (* 0.6 = 0.084615 loss)
I0818 18:09:20.517552  2522 sgd_solver.cpp:106] Iteration 8460, lr = 1e-06
I0818 18:09:23.463215  2522 solver.cpp:228] Iteration 8480, loss = 0.0897812
I0818 18:09:23.463269  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0413125 (* 0.4 = 0.016525 loss)
I0818 18:09:23.463286  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122094 (* 0.6 = 0.0732563 loss)
I0818 18:09:23.463299  2522 sgd_solver.cpp:106] Iteration 8480, lr = 1e-06
I0818 18:09:26.410290  2522 solver.cpp:228] Iteration 8500, loss = 0.167497
I0818 18:09:26.410346  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0205072 (* 0.4 = 0.00820286 loss)
I0818 18:09:26.410362  2522 solver.cpp:244]     Train net output #1: loss2 = 0.26549 (* 0.6 = 0.159294 loss)
I0818 18:09:26.410375  2522 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0818 18:09:29.357105  2522 solver.cpp:228] Iteration 8520, loss = 0.0620264
I0818 18:09:29.357159  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0398561 (* 0.4 = 0.0159424 loss)
I0818 18:09:29.357175  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0768067 (* 0.6 = 0.046084 loss)
I0818 18:09:29.357189  2522 sgd_solver.cpp:106] Iteration 8520, lr = 1e-06
I0818 18:09:32.304813  2522 solver.cpp:228] Iteration 8540, loss = 0.086982
I0818 18:09:32.304867  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0408754 (* 0.4 = 0.0163502 loss)
I0818 18:09:32.304883  2522 solver.cpp:244]     Train net output #1: loss2 = 0.11772 (* 0.6 = 0.0706319 loss)
I0818 18:09:32.304896  2522 sgd_solver.cpp:106] Iteration 8540, lr = 1e-06
I0818 18:09:35.251068  2522 solver.cpp:228] Iteration 8560, loss = 0.0825429
I0818 18:09:35.251121  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0318328 (* 0.4 = 0.0127331 loss)
I0818 18:09:35.251137  2522 solver.cpp:244]     Train net output #1: loss2 = 0.11635 (* 0.6 = 0.0698099 loss)
I0818 18:09:35.251152  2522 sgd_solver.cpp:106] Iteration 8560, lr = 1e-06
I0818 18:09:38.198628  2522 solver.cpp:228] Iteration 8580, loss = 0.126258
I0818 18:09:38.198681  2522 solver.cpp:244]     Train net output #0: loss1 = 0.14809 (* 0.4 = 0.0592362 loss)
I0818 18:09:38.198698  2522 solver.cpp:244]     Train net output #1: loss2 = 0.111704 (* 0.6 = 0.0670222 loss)
I0818 18:09:38.198710  2522 sgd_solver.cpp:106] Iteration 8580, lr = 1e-06
I0818 18:09:41.145613  2522 solver.cpp:228] Iteration 8600, loss = 0.146914
I0818 18:09:41.145666  2522 solver.cpp:244]     Train net output #0: loss1 = 0.160332 (* 0.4 = 0.0641328 loss)
I0818 18:09:41.145683  2522 solver.cpp:244]     Train net output #1: loss2 = 0.137969 (* 0.6 = 0.0827816 loss)
I0818 18:09:41.145696  2522 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0818 18:09:44.092824  2522 solver.cpp:228] Iteration 8620, loss = 0.0849419
I0818 18:09:44.092876  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0877739 (* 0.4 = 0.0351096 loss)
I0818 18:09:44.092893  2522 solver.cpp:244]     Train net output #1: loss2 = 0.083054 (* 0.6 = 0.0498324 loss)
I0818 18:09:44.092906  2522 sgd_solver.cpp:106] Iteration 8620, lr = 1e-06
I0818 18:09:47.039119  2522 solver.cpp:228] Iteration 8640, loss = 0.0659589
I0818 18:09:47.039170  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0213001 (* 0.4 = 0.00852005 loss)
I0818 18:09:47.039186  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0957315 (* 0.6 = 0.0574389 loss)
I0818 18:09:47.039199  2522 sgd_solver.cpp:106] Iteration 8640, lr = 1e-06
I0818 18:09:49.986184  2522 solver.cpp:228] Iteration 8660, loss = 0.144143
I0818 18:09:49.986343  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0427817 (* 0.4 = 0.0171127 loss)
I0818 18:09:49.986361  2522 solver.cpp:244]     Train net output #1: loss2 = 0.211717 (* 0.6 = 0.12703 loss)
I0818 18:09:49.986376  2522 sgd_solver.cpp:106] Iteration 8660, lr = 1e-06
I0818 18:09:52.932236  2522 solver.cpp:228] Iteration 8680, loss = 0.0919689
I0818 18:09:52.932286  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0248879 (* 0.4 = 0.00995517 loss)
I0818 18:09:52.932302  2522 solver.cpp:244]     Train net output #1: loss2 = 0.13669 (* 0.6 = 0.0820138 loss)
I0818 18:09:52.932315  2522 sgd_solver.cpp:106] Iteration 8680, lr = 1e-06
I0818 18:09:55.879931  2522 solver.cpp:228] Iteration 8700, loss = 0.130357
I0818 18:09:55.879986  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0421892 (* 0.4 = 0.0168757 loss)
I0818 18:09:55.880002  2522 solver.cpp:244]     Train net output #1: loss2 = 0.189136 (* 0.6 = 0.113482 loss)
I0818 18:09:55.880014  2522 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0818 18:09:58.829416  2522 solver.cpp:228] Iteration 8720, loss = 0.133073
I0818 18:09:58.829468  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0431326 (* 0.4 = 0.017253 loss)
I0818 18:09:58.829483  2522 solver.cpp:244]     Train net output #1: loss2 = 0.193033 (* 0.6 = 0.11582 loss)
I0818 18:09:58.829499  2522 sgd_solver.cpp:106] Iteration 8720, lr = 1e-06
I0818 18:10:01.777865  2522 solver.cpp:228] Iteration 8740, loss = 0.116
I0818 18:10:01.777918  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0941083 (* 0.4 = 0.0376433 loss)
I0818 18:10:01.777935  2522 solver.cpp:244]     Train net output #1: loss2 = 0.130595 (* 0.6 = 0.0783568 loss)
I0818 18:10:01.777947  2522 sgd_solver.cpp:106] Iteration 8740, lr = 1e-06
I0818 18:10:04.723882  2522 solver.cpp:228] Iteration 8760, loss = 0.113035
I0818 18:10:04.723937  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0753542 (* 0.4 = 0.0301417 loss)
I0818 18:10:04.723953  2522 solver.cpp:244]     Train net output #1: loss2 = 0.138155 (* 0.6 = 0.0828929 loss)
I0818 18:10:04.723966  2522 sgd_solver.cpp:106] Iteration 8760, lr = 1e-06
I0818 18:10:07.676009  2522 solver.cpp:228] Iteration 8780, loss = 0.2177
I0818 18:10:07.676060  2522 solver.cpp:244]     Train net output #0: loss1 = 0.172817 (* 0.4 = 0.0691268 loss)
I0818 18:10:07.676076  2522 solver.cpp:244]     Train net output #1: loss2 = 0.247621 (* 0.6 = 0.148573 loss)
I0818 18:10:07.676090  2522 sgd_solver.cpp:106] Iteration 8780, lr = 1e-06
I0818 18:10:10.624125  2522 solver.cpp:228] Iteration 8800, loss = 0.127033
I0818 18:10:10.624181  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0521155 (* 0.4 = 0.0208462 loss)
I0818 18:10:10.624197  2522 solver.cpp:244]     Train net output #1: loss2 = 0.176979 (* 0.6 = 0.106187 loss)
I0818 18:10:10.624212  2522 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0818 18:10:13.571547  2522 solver.cpp:228] Iteration 8820, loss = 0.117464
I0818 18:10:13.571600  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0483655 (* 0.4 = 0.0193462 loss)
I0818 18:10:13.571616  2522 solver.cpp:244]     Train net output #1: loss2 = 0.16353 (* 0.6 = 0.0981179 loss)
I0818 18:10:13.571630  2522 sgd_solver.cpp:106] Iteration 8820, lr = 1e-06
I0818 18:10:16.519243  2522 solver.cpp:228] Iteration 8840, loss = 0.0945043
I0818 18:10:16.519294  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0837667 (* 0.4 = 0.0335067 loss)
I0818 18:10:16.519311  2522 solver.cpp:244]     Train net output #1: loss2 = 0.101663 (* 0.6 = 0.0609977 loss)
I0818 18:10:16.519325  2522 sgd_solver.cpp:106] Iteration 8840, lr = 1e-06
I0818 18:10:19.465908  2522 solver.cpp:228] Iteration 8860, loss = 0.0842217
I0818 18:10:19.465961  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0269053 (* 0.4 = 0.0107621 loss)
I0818 18:10:19.465977  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122433 (* 0.6 = 0.0734596 loss)
I0818 18:10:19.465991  2522 sgd_solver.cpp:106] Iteration 8860, lr = 1e-06
I0818 18:10:22.413419  2522 solver.cpp:228] Iteration 8880, loss = 0.0842404
I0818 18:10:22.413563  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0315521 (* 0.4 = 0.0126209 loss)
I0818 18:10:22.413580  2522 solver.cpp:244]     Train net output #1: loss2 = 0.119366 (* 0.6 = 0.0716196 loss)
I0818 18:10:22.413594  2522 sgd_solver.cpp:106] Iteration 8880, lr = 1e-06
I0818 18:10:25.360499  2522 solver.cpp:228] Iteration 8900, loss = 0.135622
I0818 18:10:25.360553  2522 solver.cpp:244]     Train net output #0: loss1 = 0.125768 (* 0.4 = 0.050307 loss)
I0818 18:10:25.360569  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142192 (* 0.6 = 0.0853149 loss)
I0818 18:10:25.360582  2522 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0818 18:10:28.308198  2522 solver.cpp:228] Iteration 8920, loss = 0.131662
I0818 18:10:28.308250  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0627939 (* 0.4 = 0.0251176 loss)
I0818 18:10:28.308266  2522 solver.cpp:244]     Train net output #1: loss2 = 0.177575 (* 0.6 = 0.106545 loss)
I0818 18:10:28.308280  2522 sgd_solver.cpp:106] Iteration 8920, lr = 1e-06
I0818 18:10:31.254920  2522 solver.cpp:228] Iteration 8940, loss = 0.137257
I0818 18:10:31.254971  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0450322 (* 0.4 = 0.0180129 loss)
I0818 18:10:31.254987  2522 solver.cpp:244]     Train net output #1: loss2 = 0.19874 (* 0.6 = 0.119244 loss)
I0818 18:10:31.255000  2522 sgd_solver.cpp:106] Iteration 8940, lr = 1e-06
I0818 18:10:34.281690  2522 solver.cpp:228] Iteration 8960, loss = 0.0809622
I0818 18:10:34.281741  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0646968 (* 0.4 = 0.0258787 loss)
I0818 18:10:34.281756  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0918059 (* 0.6 = 0.0550835 loss)
I0818 18:10:34.281770  2522 sgd_solver.cpp:106] Iteration 8960, lr = 1e-06
I0818 18:10:37.384558  2522 solver.cpp:228] Iteration 8980, loss = 0.100625
I0818 18:10:37.384609  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0615565 (* 0.4 = 0.0246226 loss)
I0818 18:10:37.384625  2522 solver.cpp:244]     Train net output #1: loss2 = 0.126671 (* 0.6 = 0.0760028 loss)
I0818 18:10:37.384639  2522 sgd_solver.cpp:106] Iteration 8980, lr = 1e-06
I0818 18:10:40.335114  2522 solver.cpp:337] Iteration 9000, Testing net (#0)
I0818 18:11:15.403337  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.889219
I0818 18:11:15.403431  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.962031
I0818 18:11:15.403461  2522 solver.cpp:404]     Test net output #2: loss1 = 0.10736 (* 0.4 = 0.0429439 loss)
I0818 18:11:15.403475  2522 solver.cpp:404]     Test net output #3: loss2 = 0.279432 (* 0.6 = 0.167659 loss)
I0818 18:11:15.453217  2522 solver.cpp:228] Iteration 9000, loss = 0.0590895
I0818 18:11:15.453274  2522 solver.cpp:244]     Train net output #0: loss1 = 0.034978 (* 0.4 = 0.0139912 loss)
I0818 18:11:15.453292  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0751639 (* 0.6 = 0.0450984 loss)
I0818 18:11:15.453308  2522 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0818 18:11:18.412174  2522 solver.cpp:228] Iteration 9020, loss = 0.0923983
I0818 18:11:18.412230  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0460094 (* 0.4 = 0.0184038 loss)
I0818 18:11:18.412245  2522 solver.cpp:244]     Train net output #1: loss2 = 0.123324 (* 0.6 = 0.0739946 loss)
I0818 18:11:18.412258  2522 sgd_solver.cpp:106] Iteration 9020, lr = 1e-06
I0818 18:11:21.369935  2522 solver.cpp:228] Iteration 9040, loss = 0.105247
I0818 18:11:21.369988  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0743137 (* 0.4 = 0.0297255 loss)
I0818 18:11:21.370004  2522 solver.cpp:244]     Train net output #1: loss2 = 0.125869 (* 0.6 = 0.0755216 loss)
I0818 18:11:21.370018  2522 sgd_solver.cpp:106] Iteration 9040, lr = 1e-06
I0818 18:11:24.327730  2522 solver.cpp:228] Iteration 9060, loss = 0.139787
I0818 18:11:24.327780  2522 solver.cpp:244]     Train net output #0: loss1 = 0.108688 (* 0.4 = 0.0434751 loss)
I0818 18:11:24.327796  2522 solver.cpp:244]     Train net output #1: loss2 = 0.16052 (* 0.6 = 0.096312 loss)
I0818 18:11:24.327811  2522 sgd_solver.cpp:106] Iteration 9060, lr = 1e-06
I0818 18:11:27.289918  2522 solver.cpp:228] Iteration 9080, loss = 0.0897681
I0818 18:11:27.289973  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0368706 (* 0.4 = 0.0147482 loss)
I0818 18:11:27.289989  2522 solver.cpp:244]     Train net output #1: loss2 = 0.125033 (* 0.6 = 0.0750199 loss)
I0818 18:11:27.290002  2522 sgd_solver.cpp:106] Iteration 9080, lr = 1e-06
I0818 18:11:30.247805  2522 solver.cpp:228] Iteration 9100, loss = 0.0482746
I0818 18:11:30.247860  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0108519 (* 0.4 = 0.00434077 loss)
I0818 18:11:30.247876  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0732232 (* 0.6 = 0.0439339 loss)
I0818 18:11:30.247889  2522 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0818 18:11:33.210414  2522 solver.cpp:228] Iteration 9120, loss = 0.114819
I0818 18:11:33.210533  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0617468 (* 0.4 = 0.0246987 loss)
I0818 18:11:33.210553  2522 solver.cpp:244]     Train net output #1: loss2 = 0.1502 (* 0.6 = 0.09012 loss)
I0818 18:11:33.210577  2522 sgd_solver.cpp:106] Iteration 9120, lr = 1e-06
I0818 18:11:36.170860  2522 solver.cpp:228] Iteration 9140, loss = 0.11573
I0818 18:11:36.170910  2522 solver.cpp:244]     Train net output #0: loss1 = 0.027667 (* 0.4 = 0.0110668 loss)
I0818 18:11:36.170927  2522 solver.cpp:244]     Train net output #1: loss2 = 0.174439 (* 0.6 = 0.104663 loss)
I0818 18:11:36.170940  2522 sgd_solver.cpp:106] Iteration 9140, lr = 1e-06
I0818 18:11:39.132647  2522 solver.cpp:228] Iteration 9160, loss = 0.0906636
I0818 18:11:39.132699  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0352185 (* 0.4 = 0.0140874 loss)
I0818 18:11:39.132715  2522 solver.cpp:244]     Train net output #1: loss2 = 0.127627 (* 0.6 = 0.0765762 loss)
I0818 18:11:39.132730  2522 sgd_solver.cpp:106] Iteration 9160, lr = 1e-06
I0818 18:11:42.090984  2522 solver.cpp:228] Iteration 9180, loss = 0.118328
I0818 18:11:42.091037  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0237416 (* 0.4 = 0.00949663 loss)
I0818 18:11:42.091053  2522 solver.cpp:244]     Train net output #1: loss2 = 0.181385 (* 0.6 = 0.108831 loss)
I0818 18:11:42.091065  2522 sgd_solver.cpp:106] Iteration 9180, lr = 1e-06
I0818 18:11:45.050447  2522 solver.cpp:228] Iteration 9200, loss = 0.141556
I0818 18:11:45.050520  2522 solver.cpp:244]     Train net output #0: loss1 = 0.123181 (* 0.4 = 0.0492724 loss)
I0818 18:11:45.050537  2522 solver.cpp:244]     Train net output #1: loss2 = 0.153807 (* 0.6 = 0.092284 loss)
I0818 18:11:45.050551  2522 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0818 18:11:48.013396  2522 solver.cpp:228] Iteration 9220, loss = 0.159582
I0818 18:11:48.013536  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0846791 (* 0.4 = 0.0338717 loss)
I0818 18:11:48.013555  2522 solver.cpp:244]     Train net output #1: loss2 = 0.209517 (* 0.6 = 0.12571 loss)
I0818 18:11:48.013568  2522 sgd_solver.cpp:106] Iteration 9220, lr = 1e-06
I0818 18:11:50.974895  2522 solver.cpp:228] Iteration 9240, loss = 0.116445
I0818 18:11:50.974949  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0779999 (* 0.4 = 0.0312 loss)
I0818 18:11:50.974966  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142076 (* 0.6 = 0.0852456 loss)
I0818 18:11:50.974979  2522 sgd_solver.cpp:106] Iteration 9240, lr = 1e-06
I0818 18:11:53.935271  2522 solver.cpp:228] Iteration 9260, loss = 0.115284
I0818 18:11:53.935322  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0535962 (* 0.4 = 0.0214385 loss)
I0818 18:11:53.935338  2522 solver.cpp:244]     Train net output #1: loss2 = 0.156409 (* 0.6 = 0.0938457 loss)
I0818 18:11:53.935350  2522 sgd_solver.cpp:106] Iteration 9260, lr = 1e-06
I0818 18:11:56.895730  2522 solver.cpp:228] Iteration 9280, loss = 0.109651
I0818 18:11:56.895783  2522 solver.cpp:244]     Train net output #0: loss1 = 0.116097 (* 0.4 = 0.0464386 loss)
I0818 18:11:56.895799  2522 solver.cpp:244]     Train net output #1: loss2 = 0.105354 (* 0.6 = 0.0632127 loss)
I0818 18:11:56.895812  2522 sgd_solver.cpp:106] Iteration 9280, lr = 1e-06
I0818 18:11:59.854480  2522 solver.cpp:228] Iteration 9300, loss = 0.173979
I0818 18:11:59.854532  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0336022 (* 0.4 = 0.0134409 loss)
I0818 18:11:59.854548  2522 solver.cpp:244]     Train net output #1: loss2 = 0.267564 (* 0.6 = 0.160538 loss)
I0818 18:11:59.854562  2522 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0818 18:12:02.815309  2522 solver.cpp:228] Iteration 9320, loss = 0.139016
I0818 18:12:02.815359  2522 solver.cpp:244]     Train net output #0: loss1 = 0.147388 (* 0.4 = 0.0589554 loss)
I0818 18:12:02.815376  2522 solver.cpp:244]     Train net output #1: loss2 = 0.133435 (* 0.6 = 0.0800611 loss)
I0818 18:12:02.815389  2522 sgd_solver.cpp:106] Iteration 9320, lr = 1e-06
I0818 18:12:05.776722  2522 solver.cpp:228] Iteration 9340, loss = 0.0830276
I0818 18:12:05.776773  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0241689 (* 0.4 = 0.00966755 loss)
I0818 18:12:05.776789  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122267 (* 0.6 = 0.0733601 loss)
I0818 18:12:05.776803  2522 sgd_solver.cpp:106] Iteration 9340, lr = 1e-06
I0818 18:12:08.733955  2522 solver.cpp:228] Iteration 9360, loss = 0.140404
I0818 18:12:08.734006  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0642813 (* 0.4 = 0.0257125 loss)
I0818 18:12:08.734021  2522 solver.cpp:244]     Train net output #1: loss2 = 0.191153 (* 0.6 = 0.114692 loss)
I0818 18:12:08.734035  2522 sgd_solver.cpp:106] Iteration 9360, lr = 1e-06
I0818 18:12:11.695433  2522 solver.cpp:228] Iteration 9380, loss = 0.179761
I0818 18:12:11.695488  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0889445 (* 0.4 = 0.0355778 loss)
I0818 18:12:11.695504  2522 solver.cpp:244]     Train net output #1: loss2 = 0.240306 (* 0.6 = 0.144184 loss)
I0818 18:12:11.695518  2522 sgd_solver.cpp:106] Iteration 9380, lr = 1e-06
I0818 18:12:14.654315  2522 solver.cpp:228] Iteration 9400, loss = 0.123223
I0818 18:12:14.654367  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0580621 (* 0.4 = 0.0232248 loss)
I0818 18:12:14.654383  2522 solver.cpp:244]     Train net output #1: loss2 = 0.166664 (* 0.6 = 0.0999985 loss)
I0818 18:12:14.654397  2522 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0818 18:12:17.616600  2522 solver.cpp:228] Iteration 9420, loss = 0.068371
I0818 18:12:17.616654  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0320455 (* 0.4 = 0.0128182 loss)
I0818 18:12:17.616669  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0925881 (* 0.6 = 0.0555529 loss)
I0818 18:12:17.616683  2522 sgd_solver.cpp:106] Iteration 9420, lr = 1e-06
I0818 18:12:20.576843  2522 solver.cpp:228] Iteration 9440, loss = 0.0830529
I0818 18:12:20.576987  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0185391 (* 0.4 = 0.00741564 loss)
I0818 18:12:20.577004  2522 solver.cpp:244]     Train net output #1: loss2 = 0.126062 (* 0.6 = 0.0756374 loss)
I0818 18:12:20.577018  2522 sgd_solver.cpp:106] Iteration 9440, lr = 1e-06
I0818 18:12:23.538290  2522 solver.cpp:228] Iteration 9460, loss = 0.149185
I0818 18:12:23.538342  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0561442 (* 0.4 = 0.0224577 loss)
I0818 18:12:23.538358  2522 solver.cpp:244]     Train net output #1: loss2 = 0.211212 (* 0.6 = 0.126727 loss)
I0818 18:12:23.538372  2522 sgd_solver.cpp:106] Iteration 9460, lr = 1e-06
I0818 18:12:26.500077  2522 solver.cpp:228] Iteration 9480, loss = 0.103582
I0818 18:12:26.500128  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0223518 (* 0.4 = 0.00894072 loss)
I0818 18:12:26.500144  2522 solver.cpp:244]     Train net output #1: loss2 = 0.157735 (* 0.6 = 0.094641 loss)
I0818 18:12:26.500159  2522 sgd_solver.cpp:106] Iteration 9480, lr = 1e-06
I0818 18:12:29.459228  2522 solver.cpp:228] Iteration 9500, loss = 0.0953018
I0818 18:12:29.459280  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0541404 (* 0.4 = 0.0216562 loss)
I0818 18:12:29.459297  2522 solver.cpp:244]     Train net output #1: loss2 = 0.122743 (* 0.6 = 0.0736457 loss)
I0818 18:12:29.459311  2522 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0818 18:12:32.418534  2522 solver.cpp:228] Iteration 9520, loss = 0.0712099
I0818 18:12:32.418584  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0370779 (* 0.4 = 0.0148311 loss)
I0818 18:12:32.418601  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0939647 (* 0.6 = 0.0563788 loss)
I0818 18:12:32.418614  2522 sgd_solver.cpp:106] Iteration 9520, lr = 1e-06
I0818 18:12:35.379166  2522 solver.cpp:228] Iteration 9540, loss = 0.0879524
I0818 18:12:35.379220  2522 solver.cpp:244]     Train net output #0: loss1 = 0.059588 (* 0.4 = 0.0238352 loss)
I0818 18:12:35.379236  2522 solver.cpp:244]     Train net output #1: loss2 = 0.106862 (* 0.6 = 0.0641173 loss)
I0818 18:12:35.379250  2522 sgd_solver.cpp:106] Iteration 9540, lr = 1e-06
I0818 18:12:38.338773  2522 solver.cpp:228] Iteration 9560, loss = 0.0774169
I0818 18:12:38.338827  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0324866 (* 0.4 = 0.0129946 loss)
I0818 18:12:38.338843  2522 solver.cpp:244]     Train net output #1: loss2 = 0.107371 (* 0.6 = 0.0644224 loss)
I0818 18:12:38.338856  2522 sgd_solver.cpp:106] Iteration 9560, lr = 1e-06
I0818 18:12:41.295316  2522 solver.cpp:228] Iteration 9580, loss = 0.141844
I0818 18:12:41.295369  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0578943 (* 0.4 = 0.0231577 loss)
I0818 18:12:41.295385  2522 solver.cpp:244]     Train net output #1: loss2 = 0.197811 (* 0.6 = 0.118687 loss)
I0818 18:12:41.295399  2522 sgd_solver.cpp:106] Iteration 9580, lr = 1e-06
I0818 18:12:44.256245  2522 solver.cpp:228] Iteration 9600, loss = 0.0655039
I0818 18:12:44.256299  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0277869 (* 0.4 = 0.0111148 loss)
I0818 18:12:44.256315  2522 solver.cpp:244]     Train net output #1: loss2 = 0.0906487 (* 0.6 = 0.0543892 loss)
I0818 18:12:44.256328  2522 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0818 18:12:47.215859  2522 solver.cpp:228] Iteration 9620, loss = 0.0822678
I0818 18:12:47.215914  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0404223 (* 0.4 = 0.0161689 loss)
I0818 18:12:47.215929  2522 solver.cpp:244]     Train net output #1: loss2 = 0.110165 (* 0.6 = 0.066099 loss)
I0818 18:12:47.215945  2522 sgd_solver.cpp:106] Iteration 9620, lr = 1e-06
I0818 18:12:50.176604  2522 solver.cpp:228] Iteration 9640, loss = 0.137556
I0818 18:12:50.176656  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0301705 (* 0.4 = 0.0120682 loss)
I0818 18:12:50.176671  2522 solver.cpp:244]     Train net output #1: loss2 = 0.209146 (* 0.6 = 0.125488 loss)
I0818 18:12:50.176684  2522 sgd_solver.cpp:106] Iteration 9640, lr = 1e-06
I0818 18:12:53.139058  2522 solver.cpp:228] Iteration 9660, loss = 0.128049
I0818 18:12:53.139175  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0315635 (* 0.4 = 0.0126254 loss)
I0818 18:12:53.139194  2522 solver.cpp:244]     Train net output #1: loss2 = 0.192373 (* 0.6 = 0.115424 loss)
I0818 18:12:53.139207  2522 sgd_solver.cpp:106] Iteration 9660, lr = 1e-06
I0818 18:12:56.098985  2522 solver.cpp:228] Iteration 9680, loss = 0.117382
I0818 18:12:56.099040  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0761437 (* 0.4 = 0.0304575 loss)
I0818 18:12:56.099056  2522 solver.cpp:244]     Train net output #1: loss2 = 0.144874 (* 0.6 = 0.0869246 loss)
I0818 18:12:56.099068  2522 sgd_solver.cpp:106] Iteration 9680, lr = 1e-06
I0818 18:12:59.057237  2522 solver.cpp:228] Iteration 9700, loss = 0.117031
I0818 18:12:59.057291  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0403122 (* 0.4 = 0.0161249 loss)
I0818 18:12:59.057307  2522 solver.cpp:244]     Train net output #1: loss2 = 0.168178 (* 0.6 = 0.100907 loss)
I0818 18:12:59.057319  2522 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0818 18:13:02.023488  2522 solver.cpp:228] Iteration 9720, loss = 0.0865369
I0818 18:13:02.023541  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0374819 (* 0.4 = 0.0149928 loss)
I0818 18:13:02.023557  2522 solver.cpp:244]     Train net output #1: loss2 = 0.11924 (* 0.6 = 0.0715443 loss)
I0818 18:13:02.023571  2522 sgd_solver.cpp:106] Iteration 9720, lr = 1e-06
I0818 18:13:04.982144  2522 solver.cpp:228] Iteration 9740, loss = 0.10881
I0818 18:13:04.982198  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0386409 (* 0.4 = 0.0154564 loss)
I0818 18:13:04.982214  2522 solver.cpp:244]     Train net output #1: loss2 = 0.155589 (* 0.6 = 0.0933533 loss)
I0818 18:13:04.982228  2522 sgd_solver.cpp:106] Iteration 9740, lr = 1e-06
I0818 18:13:07.943753  2522 solver.cpp:228] Iteration 9760, loss = 0.136578
I0818 18:13:07.943804  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0846094 (* 0.4 = 0.0338438 loss)
I0818 18:13:07.943819  2522 solver.cpp:244]     Train net output #1: loss2 = 0.171224 (* 0.6 = 0.102734 loss)
I0818 18:13:07.943833  2522 sgd_solver.cpp:106] Iteration 9760, lr = 1e-06
I0818 18:13:10.904978  2522 solver.cpp:228] Iteration 9780, loss = 0.135782
I0818 18:13:10.905032  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0962883 (* 0.4 = 0.0385153 loss)
I0818 18:13:10.905048  2522 solver.cpp:244]     Train net output #1: loss2 = 0.162112 (* 0.6 = 0.0972671 loss)
I0818 18:13:10.905062  2522 sgd_solver.cpp:106] Iteration 9780, lr = 1e-06
I0818 18:13:13.862000  2522 solver.cpp:228] Iteration 9800, loss = 0.137033
I0818 18:13:13.862053  2522 solver.cpp:244]     Train net output #0: loss1 = 0.128132 (* 0.4 = 0.0512528 loss)
I0818 18:13:13.862069  2522 solver.cpp:244]     Train net output #1: loss2 = 0.142967 (* 0.6 = 0.0857804 loss)
I0818 18:13:13.862083  2522 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0818 18:13:16.821863  2522 solver.cpp:228] Iteration 9820, loss = 0.148046
I0818 18:13:16.821914  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0621578 (* 0.4 = 0.0248631 loss)
I0818 18:13:16.821929  2522 solver.cpp:244]     Train net output #1: loss2 = 0.205304 (* 0.6 = 0.123183 loss)
I0818 18:13:16.821943  2522 sgd_solver.cpp:106] Iteration 9820, lr = 1e-06
I0818 18:13:19.784556  2522 solver.cpp:228] Iteration 9840, loss = 0.176223
I0818 18:13:19.784606  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0413193 (* 0.4 = 0.0165277 loss)
I0818 18:13:19.784622  2522 solver.cpp:244]     Train net output #1: loss2 = 0.266158 (* 0.6 = 0.159695 loss)
I0818 18:13:19.784636  2522 sgd_solver.cpp:106] Iteration 9840, lr = 1e-06
I0818 18:13:22.745296  2522 solver.cpp:228] Iteration 9860, loss = 0.112289
I0818 18:13:22.745348  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0630749 (* 0.4 = 0.02523 loss)
I0818 18:13:22.745364  2522 solver.cpp:244]     Train net output #1: loss2 = 0.145098 (* 0.6 = 0.0870587 loss)
I0818 18:13:22.745378  2522 sgd_solver.cpp:106] Iteration 9860, lr = 1e-06
I0818 18:13:25.706290  2522 solver.cpp:228] Iteration 9880, loss = 0.110938
I0818 18:13:25.706454  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0695586 (* 0.4 = 0.0278234 loss)
I0818 18:13:25.706471  2522 solver.cpp:244]     Train net output #1: loss2 = 0.138524 (* 0.6 = 0.0831145 loss)
I0818 18:13:25.706485  2522 sgd_solver.cpp:106] Iteration 9880, lr = 1e-06
I0818 18:13:28.667579  2522 solver.cpp:228] Iteration 9900, loss = 0.113716
I0818 18:13:28.667644  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0587756 (* 0.4 = 0.0235102 loss)
I0818 18:13:28.667665  2522 solver.cpp:244]     Train net output #1: loss2 = 0.150343 (* 0.6 = 0.0902059 loss)
I0818 18:13:28.667687  2522 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0818 18:13:31.625488  2522 solver.cpp:228] Iteration 9920, loss = 0.11642
I0818 18:13:31.625541  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0700112 (* 0.4 = 0.0280045 loss)
I0818 18:13:31.625557  2522 solver.cpp:244]     Train net output #1: loss2 = 0.147359 (* 0.6 = 0.0884155 loss)
I0818 18:13:31.625571  2522 sgd_solver.cpp:106] Iteration 9920, lr = 1e-06
I0818 18:13:34.584669  2522 solver.cpp:228] Iteration 9940, loss = 0.117213
I0818 18:13:34.584745  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0395157 (* 0.4 = 0.0158063 loss)
I0818 18:13:34.584772  2522 solver.cpp:244]     Train net output #1: loss2 = 0.169011 (* 0.6 = 0.101407 loss)
I0818 18:13:34.584794  2522 sgd_solver.cpp:106] Iteration 9940, lr = 1e-06
I0818 18:13:37.542119  2522 solver.cpp:228] Iteration 9960, loss = 0.119061
I0818 18:13:37.542172  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0288215 (* 0.4 = 0.0115286 loss)
I0818 18:13:37.542187  2522 solver.cpp:244]     Train net output #1: loss2 = 0.17922 (* 0.6 = 0.107532 loss)
I0818 18:13:37.542201  2522 sgd_solver.cpp:106] Iteration 9960, lr = 1e-06
I0818 18:13:40.500434  2522 solver.cpp:228] Iteration 9980, loss = 0.147246
I0818 18:13:40.500486  2522 solver.cpp:244]     Train net output #0: loss1 = 0.0568837 (* 0.4 = 0.0227535 loss)
I0818 18:13:40.500502  2522 solver.cpp:244]     Train net output #1: loss2 = 0.207488 (* 0.6 = 0.124493 loss)
I0818 18:13:40.500515  2522 sgd_solver.cpp:106] Iteration 9980, lr = 1e-06
I0818 18:13:43.312722  2522 solver.cpp:454] Snapshotting to binary proto file models/gender_glasses/gg_net_train_iter_10000.caffemodel
I0818 18:13:43.640858  2522 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/gender_glasses/gg_net_train_iter_10000.solverstate
I0818 18:13:43.816144  2522 solver.cpp:317] Iteration 10000, loss = 0.0842734
I0818 18:13:43.816210  2522 solver.cpp:337] Iteration 10000, Testing net (#0)
I0818 18:14:18.626905  2522 solver.cpp:404]     Test net output #0: accuracy_gender = 0.889156
I0818 18:14:18.627002  2522 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.962125
I0818 18:14:18.627024  2522 solver.cpp:404]     Test net output #2: loss1 = 0.10732 (* 0.4 = 0.0429282 loss)
I0818 18:14:18.627040  2522 solver.cpp:404]     Test net output #3: loss2 = 0.279697 (* 0.6 = 0.167818 loss)
I0818 18:14:18.627051  2522 solver.cpp:322] Optimization Done.
I0818 18:14:18.627061  2522 caffe.cpp:254] Optimization Done.
