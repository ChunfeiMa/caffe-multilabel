Log file created at: 2016/08/15 09:16:52
Running on machine: jaychou-OptiPlex-9010
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0815 09:16:52.127411   668 caffe.cpp:217] Using GPUs 0
I0815 09:16:52.173882   668 caffe.cpp:222] GPU 0: GeForce GTX 650 Ti
I0815 09:16:52.306943   668 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 10000
snapshot_prefix: "models/gender_glasses/gg_net_train"
solver_mode: GPU
device_id: 0
net: "models/gender_glasses/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0815 09:16:52.307128   668 solver.cpp:91] Creating training net from net file: models/gender_glasses/train_val.prototxt
I0815 09:16:52.307644   668 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0815 09:16:52.307662   668 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer labels
I0815 09:16:52.307684   668 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_glasses
I0815 09:16:52.307695   668 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_gender
I0815 09:16:52.307816   668 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.5
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.5
}
I0815 09:16:52.308405   668 layer_factory.hpp:77] Creating layer data
I0815 09:16:52.308771   668 net.cpp:100] Creating Layer data
I0815 09:16:52.308789   668 net.cpp:408] data -> data
I0815 09:16:52.309695   672 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb
I0815 09:16:52.321036   668 data_layer.cpp:41] output data size: 100,3,100,100
I0815 09:16:52.339205   668 net.cpp:150] Setting up data
I0815 09:16:52.339251   668 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0815 09:16:52.339263   668 net.cpp:165] Memory required for data: 12000000
I0815 09:16:52.339280   668 layer_factory.hpp:77] Creating layer labels
I0815 09:16:52.339385   668 net.cpp:100] Creating Layer labels
I0815 09:16:52.339401   668 net.cpp:408] labels -> labels
I0815 09:16:52.341153   674 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb
I0815 09:16:52.342054   668 data_layer.cpp:41] output data size: 100,2,1,1
I0815 09:16:52.342397   668 net.cpp:150] Setting up labels
I0815 09:16:52.342411   668 net.cpp:157] Top shape: 100 2 1 1 (200)
I0815 09:16:52.342417   668 net.cpp:165] Memory required for data: 12000800
I0815 09:16:52.342422   668 layer_factory.hpp:77] Creating layer slice1
I0815 09:16:52.342435   668 net.cpp:100] Creating Layer slice1
I0815 09:16:52.342444   668 net.cpp:434] slice1 <- labels
I0815 09:16:52.342458   668 net.cpp:408] slice1 -> glasses
I0815 09:16:52.342471   668 net.cpp:408] slice1 -> gender
I0815 09:16:52.342509   668 net.cpp:150] Setting up slice1
I0815 09:16:52.342520   668 net.cpp:157] Top shape: 100 1 1 1 (100)
I0815 09:16:52.342527   668 net.cpp:157] Top shape: 100 1 1 1 (100)
I0815 09:16:52.342532   668 net.cpp:165] Memory required for data: 12001600
I0815 09:16:52.342537   668 layer_factory.hpp:77] Creating layer conv1
I0815 09:16:52.342555   668 net.cpp:100] Creating Layer conv1
I0815 09:16:52.342571   668 net.cpp:434] conv1 <- data
I0815 09:16:52.342581   668 net.cpp:408] conv1 -> conv1
I0815 09:16:52.508131   668 net.cpp:150] Setting up conv1
I0815 09:16:52.508182   668 net.cpp:157] Top shape: 100 20 96 96 (18432000)
I0815 09:16:52.508191   668 net.cpp:165] Memory required for data: 85729600
I0815 09:16:52.508219   668 layer_factory.hpp:77] Creating layer relu1
I0815 09:16:52.508236   668 net.cpp:100] Creating Layer relu1
I0815 09:16:52.508247   668 net.cpp:434] relu1 <- conv1
I0815 09:16:52.508258   668 net.cpp:395] relu1 -> conv1 (in-place)
I0815 09:16:52.508795   668 net.cpp:150] Setting up relu1
I0815 09:16:52.508815   668 net.cpp:157] Top shape: 100 20 96 96 (18432000)
I0815 09:16:52.508823   668 net.cpp:165] Memory required for data: 159457600
I0815 09:16:52.508837   668 layer_factory.hpp:77] Creating layer pool1
I0815 09:16:52.508851   668 net.cpp:100] Creating Layer pool1
I0815 09:16:52.508860   668 net.cpp:434] pool1 <- conv1
I0815 09:16:52.508872   668 net.cpp:408] pool1 -> pool1
I0815 09:16:52.508918   668 net.cpp:150] Setting up pool1
I0815 09:16:52.508931   668 net.cpp:157] Top shape: 100 20 48 48 (4608000)
I0815 09:16:52.508940   668 net.cpp:165] Memory required for data: 177889600
I0815 09:16:52.508949   668 layer_factory.hpp:77] Creating layer conv2
I0815 09:16:52.508965   668 net.cpp:100] Creating Layer conv2
I0815 09:16:52.508975   668 net.cpp:434] conv2 <- pool1
I0815 09:16:52.508985   668 net.cpp:408] conv2 -> conv2
I0815 09:16:52.510293   668 net.cpp:150] Setting up conv2
I0815 09:16:52.510315   668 net.cpp:157] Top shape: 100 48 44 44 (9292800)
I0815 09:16:52.510347   668 net.cpp:165] Memory required for data: 215060800
I0815 09:16:52.510363   668 layer_factory.hpp:77] Creating layer relu2
I0815 09:16:52.510380   668 net.cpp:100] Creating Layer relu2
I0815 09:16:52.510390   668 net.cpp:434] relu2 <- conv2
I0815 09:16:52.510399   668 net.cpp:395] relu2 -> conv2 (in-place)
I0815 09:16:52.510869   668 net.cpp:150] Setting up relu2
I0815 09:16:52.510887   668 net.cpp:157] Top shape: 100 48 44 44 (9292800)
I0815 09:16:52.510896   668 net.cpp:165] Memory required for data: 252232000
I0815 09:16:52.510907   668 layer_factory.hpp:77] Creating layer pool2
I0815 09:16:52.510921   668 net.cpp:100] Creating Layer pool2
I0815 09:16:52.510931   668 net.cpp:434] pool2 <- conv2
I0815 09:16:52.510941   668 net.cpp:408] pool2 -> pool2
I0815 09:16:52.510978   668 net.cpp:150] Setting up pool2
I0815 09:16:52.510992   668 net.cpp:157] Top shape: 100 48 22 22 (2323200)
I0815 09:16:52.511000   668 net.cpp:165] Memory required for data: 261524800
I0815 09:16:52.511008   668 layer_factory.hpp:77] Creating layer conv3
I0815 09:16:52.511023   668 net.cpp:100] Creating Layer conv3
I0815 09:16:52.511032   668 net.cpp:434] conv3 <- pool2
I0815 09:16:52.511044   668 net.cpp:408] conv3 -> conv3
I0815 09:16:52.512213   668 net.cpp:150] Setting up conv3
I0815 09:16:52.512234   668 net.cpp:157] Top shape: 100 64 20 20 (2560000)
I0815 09:16:52.512243   668 net.cpp:165] Memory required for data: 271764800
I0815 09:16:52.512256   668 layer_factory.hpp:77] Creating layer relu3
I0815 09:16:52.512267   668 net.cpp:100] Creating Layer relu3
I0815 09:16:52.512276   668 net.cpp:434] relu3 <- conv3
I0815 09:16:52.512287   668 net.cpp:395] relu3 -> conv3 (in-place)
I0815 09:16:52.512377   668 net.cpp:150] Setting up relu3
I0815 09:16:52.512392   668 net.cpp:157] Top shape: 100 64 20 20 (2560000)
I0815 09:16:52.512401   668 net.cpp:165] Memory required for data: 282004800
I0815 09:16:52.512414   668 layer_factory.hpp:77] Creating layer ip1
I0815 09:16:52.512430   668 net.cpp:100] Creating Layer ip1
I0815 09:16:52.512440   668 net.cpp:434] ip1 <- conv3
I0815 09:16:52.512450   668 net.cpp:408] ip1 -> ip1
I0815 09:16:52.612051   668 net.cpp:150] Setting up ip1
I0815 09:16:52.612098   668 net.cpp:157] Top shape: 100 512 (51200)
I0815 09:16:52.612110   668 net.cpp:165] Memory required for data: 282209600
I0815 09:16:52.612128   668 layer_factory.hpp:77] Creating layer relu5
I0815 09:16:52.612145   668 net.cpp:100] Creating Layer relu5
I0815 09:16:52.612156   668 net.cpp:434] relu5 <- ip1
I0815 09:16:52.612169   668 net.cpp:395] relu5 -> ip1 (in-place)
I0815 09:16:52.612257   668 net.cpp:150] Setting up relu5
I0815 09:16:52.612273   668 net.cpp:157] Top shape: 100 512 (51200)
I0815 09:16:52.612282   668 net.cpp:165] Memory required for data: 282414400
I0815 09:16:52.612293   668 layer_factory.hpp:77] Creating layer drop1
I0815 09:16:52.612313   668 net.cpp:100] Creating Layer drop1
I0815 09:16:52.612323   668 net.cpp:434] drop1 <- ip1
I0815 09:16:52.612334   668 net.cpp:395] drop1 -> ip1 (in-place)
I0815 09:16:52.612367   668 net.cpp:150] Setting up drop1
I0815 09:16:52.612381   668 net.cpp:157] Top shape: 100 512 (51200)
I0815 09:16:52.612390   668 net.cpp:165] Memory required for data: 282619200
I0815 09:16:52.612398   668 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0815 09:16:52.612412   668 net.cpp:100] Creating Layer ip1_drop1_0_split
I0815 09:16:52.612421   668 net.cpp:434] ip1_drop1_0_split <- ip1
I0815 09:16:52.612432   668 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0815 09:16:52.612444   668 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0815 09:16:52.612481   668 net.cpp:150] Setting up ip1_drop1_0_split
I0815 09:16:52.612495   668 net.cpp:157] Top shape: 100 512 (51200)
I0815 09:16:52.612504   668 net.cpp:157] Top shape: 100 512 (51200)
I0815 09:16:52.612512   668 net.cpp:165] Memory required for data: 283028800
I0815 09:16:52.612521   668 layer_factory.hpp:77] Creating layer ip2
I0815 09:16:52.612534   668 net.cpp:100] Creating Layer ip2
I0815 09:16:52.612542   668 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0815 09:16:52.612581   668 net.cpp:408] ip2 -> ip2
I0815 09:16:52.612675   668 net.cpp:150] Setting up ip2
I0815 09:16:52.612689   668 net.cpp:157] Top shape: 100 2 (200)
I0815 09:16:52.612697   668 net.cpp:165] Memory required for data: 283029600
I0815 09:16:52.612709   668 layer_factory.hpp:77] Creating layer loss1
I0815 09:16:52.612725   668 net.cpp:100] Creating Layer loss1
I0815 09:16:52.612733   668 net.cpp:434] loss1 <- ip2
I0815 09:16:52.612742   668 net.cpp:434] loss1 <- glasses
I0815 09:16:52.612753   668 net.cpp:408] loss1 -> loss1
I0815 09:16:52.612768   668 layer_factory.hpp:77] Creating layer loss1
I0815 09:16:52.613237   668 net.cpp:150] Setting up loss1
I0815 09:16:52.613255   668 net.cpp:157] Top shape: (1)
I0815 09:16:52.613265   668 net.cpp:160]     with loss weight 0.5
I0815 09:16:52.613289   668 net.cpp:165] Memory required for data: 283029604
I0815 09:16:52.613298   668 layer_factory.hpp:77] Creating layer ip3
I0815 09:16:52.613311   668 net.cpp:100] Creating Layer ip3
I0815 09:16:52.613320   668 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0815 09:16:52.613332   668 net.cpp:408] ip3 -> ip3
I0815 09:16:52.615494   668 net.cpp:150] Setting up ip3
I0815 09:16:52.615514   668 net.cpp:157] Top shape: 100 512 (51200)
I0815 09:16:52.615522   668 net.cpp:165] Memory required for data: 283234404
I0815 09:16:52.615535   668 layer_factory.hpp:77] Creating layer loss2
I0815 09:16:52.615545   668 net.cpp:100] Creating Layer loss2
I0815 09:16:52.615558   668 net.cpp:434] loss2 <- ip3
I0815 09:16:52.615568   668 net.cpp:434] loss2 <- gender
I0815 09:16:52.615579   668 net.cpp:408] loss2 -> loss2
I0815 09:16:52.615593   668 layer_factory.hpp:77] Creating layer loss2
I0815 09:16:52.615838   668 net.cpp:150] Setting up loss2
I0815 09:16:52.615854   668 net.cpp:157] Top shape: (1)
I0815 09:16:52.615862   668 net.cpp:160]     with loss weight 0.5
I0815 09:16:52.615875   668 net.cpp:165] Memory required for data: 283234408
I0815 09:16:52.615883   668 net.cpp:226] loss2 needs backward computation.
I0815 09:16:52.615892   668 net.cpp:226] ip3 needs backward computation.
I0815 09:16:52.615901   668 net.cpp:226] loss1 needs backward computation.
I0815 09:16:52.615911   668 net.cpp:226] ip2 needs backward computation.
I0815 09:16:52.615918   668 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0815 09:16:52.615927   668 net.cpp:226] drop1 needs backward computation.
I0815 09:16:52.615936   668 net.cpp:226] relu5 needs backward computation.
I0815 09:16:52.615943   668 net.cpp:226] ip1 needs backward computation.
I0815 09:16:52.615952   668 net.cpp:226] relu3 needs backward computation.
I0815 09:16:52.615962   668 net.cpp:226] conv3 needs backward computation.
I0815 09:16:52.615969   668 net.cpp:226] pool2 needs backward computation.
I0815 09:16:52.615978   668 net.cpp:226] relu2 needs backward computation.
I0815 09:16:52.615986   668 net.cpp:226] conv2 needs backward computation.
I0815 09:16:52.615995   668 net.cpp:226] pool1 needs backward computation.
I0815 09:16:52.616004   668 net.cpp:226] relu1 needs backward computation.
I0815 09:16:52.616013   668 net.cpp:226] conv1 needs backward computation.
I0815 09:16:52.616021   668 net.cpp:228] slice1 does not need backward computation.
I0815 09:16:52.616030   668 net.cpp:228] labels does not need backward computation.
I0815 09:16:52.616039   668 net.cpp:228] data does not need backward computation.
I0815 09:16:52.616047   668 net.cpp:270] This network produces output loss1
I0815 09:16:52.616055   668 net.cpp:270] This network produces output loss2
I0815 09:16:52.616075   668 net.cpp:283] Network initialization done.
I0815 09:16:52.616581   668 solver.cpp:181] Creating test net (#0) specified by net file: models/gender_glasses/train_val.prototxt
I0815 09:16:52.616623   668 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0815 09:16:52.616634   668 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer labels
I0815 09:16:52.616858   668 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.5
}
layer {
  name: "accuracy_glasses"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "glasses"
  top: "accuracy_glasses"
  include {
    phase: TEST
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.5
}
layer {
  name: "accuracy_gender"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "gender"
  top: "accuracy_gender"
  include {
    phase: TEST
  }
}
I0815 09:16:52.617439   668 layer_factory.hpp:77] Creating layer data
I0815 09:16:52.617529   668 net.cpp:100] Creating Layer data
I0815 09:16:52.617543   668 net.cpp:408] data -> data
I0815 09:16:52.618916   676 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb
I0815 09:16:52.619148   668 data_layer.cpp:41] output data size: 64,3,100,100
I0815 09:16:52.634630   668 net.cpp:150] Setting up data
I0815 09:16:52.634672   668 net.cpp:157] Top shape: 64 3 100 100 (1920000)
I0815 09:16:52.634682   668 net.cpp:165] Memory required for data: 7680000
I0815 09:16:52.634694   668 layer_factory.hpp:77] Creating layer labels
I0815 09:16:52.634778   668 net.cpp:100] Creating Layer labels
I0815 09:16:52.634793   668 net.cpp:408] labels -> labels
I0815 09:16:52.656724   678 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb
I0815 09:16:52.656880   668 data_layer.cpp:41] output data size: 64,2,1,1
I0815 09:16:52.657217   668 net.cpp:150] Setting up labels
I0815 09:16:52.657238   668 net.cpp:157] Top shape: 64 2 1 1 (128)
I0815 09:16:52.657248   668 net.cpp:165] Memory required for data: 7680512
I0815 09:16:52.657258   668 layer_factory.hpp:77] Creating layer slice1
I0815 09:16:52.657276   668 net.cpp:100] Creating Layer slice1
I0815 09:16:52.657287   668 net.cpp:434] slice1 <- labels
I0815 09:16:52.657299   668 net.cpp:408] slice1 -> glasses
I0815 09:16:52.657318   668 net.cpp:408] slice1 -> gender
I0815 09:16:52.657357   668 net.cpp:150] Setting up slice1
I0815 09:16:52.657371   668 net.cpp:157] Top shape: 64 1 1 1 (64)
I0815 09:16:52.657380   668 net.cpp:157] Top shape: 64 1 1 1 (64)
I0815 09:16:52.657389   668 net.cpp:165] Memory required for data: 7681024
I0815 09:16:52.657397   668 layer_factory.hpp:77] Creating layer glasses_slice1_0_split
I0815 09:16:52.657408   668 net.cpp:100] Creating Layer glasses_slice1_0_split
I0815 09:16:52.657418   668 net.cpp:434] glasses_slice1_0_split <- glasses
I0815 09:16:52.657428   668 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_0
I0815 09:16:52.657440   668 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_1
I0815 09:16:52.657475   668 net.cpp:150] Setting up glasses_slice1_0_split
I0815 09:16:52.657490   668 net.cpp:157] Top shape: 64 1 1 1 (64)
I0815 09:16:52.657498   668 net.cpp:157] Top shape: 64 1 1 1 (64)
I0815 09:16:52.657507   668 net.cpp:165] Memory required for data: 7681536
I0815 09:16:52.657516   668 layer_factory.hpp:77] Creating layer gender_slice1_1_split
I0815 09:16:52.657526   668 net.cpp:100] Creating Layer gender_slice1_1_split
I0815 09:16:52.657536   668 net.cpp:434] gender_slice1_1_split <- gender
I0815 09:16:52.657546   668 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_0
I0815 09:16:52.657557   668 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_1
I0815 09:16:52.657590   668 net.cpp:150] Setting up gender_slice1_1_split
I0815 09:16:52.657603   668 net.cpp:157] Top shape: 64 1 1 1 (64)
I0815 09:16:52.657613   668 net.cpp:157] Top shape: 64 1 1 1 (64)
I0815 09:16:52.657621   668 net.cpp:165] Memory required for data: 7682048
I0815 09:16:52.657629   668 layer_factory.hpp:77] Creating layer conv1
I0815 09:16:52.657649   668 net.cpp:100] Creating Layer conv1
I0815 09:16:52.657660   668 net.cpp:434] conv1 <- data
I0815 09:16:52.657672   668 net.cpp:408] conv1 -> conv1
I0815 09:16:52.659023   668 net.cpp:150] Setting up conv1
I0815 09:16:52.659042   668 net.cpp:157] Top shape: 64 20 96 96 (11796480)
I0815 09:16:52.659054   668 net.cpp:165] Memory required for data: 54867968
I0815 09:16:52.659071   668 layer_factory.hpp:77] Creating layer relu1
I0815 09:16:52.659086   668 net.cpp:100] Creating Layer relu1
I0815 09:16:52.659103   668 net.cpp:434] relu1 <- conv1
I0815 09:16:52.659116   668 net.cpp:395] relu1 -> conv1 (in-place)
I0815 09:16:52.659797   668 net.cpp:150] Setting up relu1
I0815 09:16:52.659819   668 net.cpp:157] Top shape: 64 20 96 96 (11796480)
I0815 09:16:52.659832   668 net.cpp:165] Memory required for data: 102053888
I0815 09:16:52.659847   668 layer_factory.hpp:77] Creating layer pool1
I0815 09:16:52.659865   668 net.cpp:100] Creating Layer pool1
I0815 09:16:52.659875   668 net.cpp:434] pool1 <- conv1
I0815 09:16:52.659888   668 net.cpp:408] pool1 -> pool1
I0815 09:16:52.659934   668 net.cpp:150] Setting up pool1
I0815 09:16:52.659948   668 net.cpp:157] Top shape: 64 20 48 48 (2949120)
I0815 09:16:52.659975   668 net.cpp:165] Memory required for data: 113850368
I0815 09:16:52.659983   668 layer_factory.hpp:77] Creating layer conv2
I0815 09:16:52.660001   668 net.cpp:100] Creating Layer conv2
I0815 09:16:52.660012   668 net.cpp:434] conv2 <- pool1
I0815 09:16:52.660022   668 net.cpp:408] conv2 -> conv2
I0815 09:16:52.661063   668 net.cpp:150] Setting up conv2
I0815 09:16:52.661085   668 net.cpp:157] Top shape: 64 48 44 44 (5947392)
I0815 09:16:52.661095   668 net.cpp:165] Memory required for data: 137639936
I0815 09:16:52.661109   668 layer_factory.hpp:77] Creating layer relu2
I0815 09:16:52.661120   668 net.cpp:100] Creating Layer relu2
I0815 09:16:52.661129   668 net.cpp:434] relu2 <- conv2
I0815 09:16:52.661140   668 net.cpp:395] relu2 -> conv2 (in-place)
I0815 09:16:52.661309   668 net.cpp:150] Setting up relu2
I0815 09:16:52.661324   668 net.cpp:157] Top shape: 64 48 44 44 (5947392)
I0815 09:16:52.661331   668 net.cpp:165] Memory required for data: 161429504
I0815 09:16:52.661342   668 layer_factory.hpp:77] Creating layer pool2
I0815 09:16:52.661355   668 net.cpp:100] Creating Layer pool2
I0815 09:16:52.661363   668 net.cpp:434] pool2 <- conv2
I0815 09:16:52.661375   668 net.cpp:408] pool2 -> pool2
I0815 09:16:52.661413   668 net.cpp:150] Setting up pool2
I0815 09:16:52.661427   668 net.cpp:157] Top shape: 64 48 22 22 (1486848)
I0815 09:16:52.661434   668 net.cpp:165] Memory required for data: 167376896
I0815 09:16:52.661442   668 layer_factory.hpp:77] Creating layer conv3
I0815 09:16:52.661456   668 net.cpp:100] Creating Layer conv3
I0815 09:16:52.661466   668 net.cpp:434] conv3 <- pool2
I0815 09:16:52.661478   668 net.cpp:408] conv3 -> conv3
I0815 09:16:52.662634   668 net.cpp:150] Setting up conv3
I0815 09:16:52.662653   668 net.cpp:157] Top shape: 64 64 20 20 (1638400)
I0815 09:16:52.662662   668 net.cpp:165] Memory required for data: 173930496
I0815 09:16:52.662674   668 layer_factory.hpp:77] Creating layer relu3
I0815 09:16:52.662686   668 net.cpp:100] Creating Layer relu3
I0815 09:16:52.662696   668 net.cpp:434] relu3 <- conv3
I0815 09:16:52.662706   668 net.cpp:395] relu3 -> conv3 (in-place)
I0815 09:16:52.662816   668 net.cpp:150] Setting up relu3
I0815 09:16:52.662829   668 net.cpp:157] Top shape: 64 64 20 20 (1638400)
I0815 09:16:52.662837   668 net.cpp:165] Memory required for data: 180484096
I0815 09:16:52.662850   668 layer_factory.hpp:77] Creating layer ip1
I0815 09:16:52.662865   668 net.cpp:100] Creating Layer ip1
I0815 09:16:52.662874   668 net.cpp:434] ip1 <- conv3
I0815 09:16:52.662884   668 net.cpp:408] ip1 -> ip1
I0815 09:16:52.759454   668 net.cpp:150] Setting up ip1
I0815 09:16:52.759500   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.759510   668 net.cpp:165] Memory required for data: 180615168
I0815 09:16:52.759526   668 layer_factory.hpp:77] Creating layer relu5
I0815 09:16:52.759542   668 net.cpp:100] Creating Layer relu5
I0815 09:16:52.759552   668 net.cpp:434] relu5 <- ip1
I0815 09:16:52.759567   668 net.cpp:395] relu5 -> ip1 (in-place)
I0815 09:16:52.759650   668 net.cpp:150] Setting up relu5
I0815 09:16:52.759665   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.759672   668 net.cpp:165] Memory required for data: 180746240
I0815 09:16:52.759682   668 layer_factory.hpp:77] Creating layer drop1
I0815 09:16:52.759694   668 net.cpp:100] Creating Layer drop1
I0815 09:16:52.759703   668 net.cpp:434] drop1 <- ip1
I0815 09:16:52.759713   668 net.cpp:395] drop1 -> ip1 (in-place)
I0815 09:16:52.759742   668 net.cpp:150] Setting up drop1
I0815 09:16:52.759755   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.759764   668 net.cpp:165] Memory required for data: 180877312
I0815 09:16:52.759773   668 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0815 09:16:52.759785   668 net.cpp:100] Creating Layer ip1_drop1_0_split
I0815 09:16:52.759799   668 net.cpp:434] ip1_drop1_0_split <- ip1
I0815 09:16:52.759809   668 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0815 09:16:52.759821   668 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0815 09:16:52.759886   668 net.cpp:150] Setting up ip1_drop1_0_split
I0815 09:16:52.759898   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.759907   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.759917   668 net.cpp:165] Memory required for data: 181139456
I0815 09:16:52.759924   668 layer_factory.hpp:77] Creating layer ip2
I0815 09:16:52.759937   668 net.cpp:100] Creating Layer ip2
I0815 09:16:52.759945   668 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0815 09:16:52.759958   668 net.cpp:408] ip2 -> ip2
I0815 09:16:52.760062   668 net.cpp:150] Setting up ip2
I0815 09:16:52.760077   668 net.cpp:157] Top shape: 64 2 (128)
I0815 09:16:52.760085   668 net.cpp:165] Memory required for data: 181139968
I0815 09:16:52.760097   668 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0815 09:16:52.760108   668 net.cpp:100] Creating Layer ip2_ip2_0_split
I0815 09:16:52.760116   668 net.cpp:434] ip2_ip2_0_split <- ip2
I0815 09:16:52.760129   668 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0815 09:16:52.760141   668 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0815 09:16:52.760179   668 net.cpp:150] Setting up ip2_ip2_0_split
I0815 09:16:52.760192   668 net.cpp:157] Top shape: 64 2 (128)
I0815 09:16:52.760201   668 net.cpp:157] Top shape: 64 2 (128)
I0815 09:16:52.760210   668 net.cpp:165] Memory required for data: 181140992
I0815 09:16:52.760217   668 layer_factory.hpp:77] Creating layer loss1
I0815 09:16:52.760228   668 net.cpp:100] Creating Layer loss1
I0815 09:16:52.760237   668 net.cpp:434] loss1 <- ip2_ip2_0_split_0
I0815 09:16:52.760247   668 net.cpp:434] loss1 <- glasses_slice1_0_split_0
I0815 09:16:52.760257   668 net.cpp:408] loss1 -> loss1
I0815 09:16:52.760270   668 layer_factory.hpp:77] Creating layer loss1
I0815 09:16:52.760509   668 net.cpp:150] Setting up loss1
I0815 09:16:52.760524   668 net.cpp:157] Top shape: (1)
I0815 09:16:52.760535   668 net.cpp:160]     with loss weight 0.5
I0815 09:16:52.760551   668 net.cpp:165] Memory required for data: 181140996
I0815 09:16:52.760560   668 layer_factory.hpp:77] Creating layer accuracy_glasses
I0815 09:16:52.760571   668 net.cpp:100] Creating Layer accuracy_glasses
I0815 09:16:52.760579   668 net.cpp:434] accuracy_glasses <- ip2_ip2_0_split_1
I0815 09:16:52.760589   668 net.cpp:434] accuracy_glasses <- glasses_slice1_0_split_1
I0815 09:16:52.760602   668 net.cpp:408] accuracy_glasses -> accuracy_glasses
I0815 09:16:52.760617   668 net.cpp:150] Setting up accuracy_glasses
I0815 09:16:52.760627   668 net.cpp:157] Top shape: (1)
I0815 09:16:52.760635   668 net.cpp:165] Memory required for data: 181141000
I0815 09:16:52.760643   668 layer_factory.hpp:77] Creating layer ip3
I0815 09:16:52.760654   668 net.cpp:100] Creating Layer ip3
I0815 09:16:52.760663   668 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0815 09:16:52.760675   668 net.cpp:408] ip3 -> ip3
I0815 09:16:52.762894   668 net.cpp:150] Setting up ip3
I0815 09:16:52.762910   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.762919   668 net.cpp:165] Memory required for data: 181272072
I0815 09:16:52.762930   668 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0815 09:16:52.762941   668 net.cpp:100] Creating Layer ip3_ip3_0_split
I0815 09:16:52.762949   668 net.cpp:434] ip3_ip3_0_split <- ip3
I0815 09:16:52.762961   668 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0815 09:16:52.762974   668 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0815 09:16:52.763015   668 net.cpp:150] Setting up ip3_ip3_0_split
I0815 09:16:52.763030   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.763038   668 net.cpp:157] Top shape: 64 512 (32768)
I0815 09:16:52.763046   668 net.cpp:165] Memory required for data: 181534216
I0815 09:16:52.763054   668 layer_factory.hpp:77] Creating layer loss2
I0815 09:16:52.763065   668 net.cpp:100] Creating Layer loss2
I0815 09:16:52.763073   668 net.cpp:434] loss2 <- ip3_ip3_0_split_0
I0815 09:16:52.763083   668 net.cpp:434] loss2 <- gender_slice1_1_split_0
I0815 09:16:52.763093   668 net.cpp:408] loss2 -> loss2
I0815 09:16:52.763105   668 layer_factory.hpp:77] Creating layer loss2
I0815 09:16:52.763532   668 net.cpp:150] Setting up loss2
I0815 09:16:52.763548   668 net.cpp:157] Top shape: (1)
I0815 09:16:52.763557   668 net.cpp:160]     with loss weight 0.5
I0815 09:16:52.763568   668 net.cpp:165] Memory required for data: 181534220
I0815 09:16:52.763577   668 layer_factory.hpp:77] Creating layer accuracy_gender
I0815 09:16:52.763587   668 net.cpp:100] Creating Layer accuracy_gender
I0815 09:16:52.763597   668 net.cpp:434] accuracy_gender <- ip3_ip3_0_split_1
I0815 09:16:52.763607   668 net.cpp:434] accuracy_gender <- gender_slice1_1_split_1
I0815 09:16:52.763618   668 net.cpp:408] accuracy_gender -> accuracy_gender
I0815 09:16:52.763633   668 net.cpp:150] Setting up accuracy_gender
I0815 09:16:52.763643   668 net.cpp:157] Top shape: (1)
I0815 09:16:52.763651   668 net.cpp:165] Memory required for data: 181534224
I0815 09:16:52.763660   668 net.cpp:228] accuracy_gender does not need backward computation.
I0815 09:16:52.763669   668 net.cpp:226] loss2 needs backward computation.
I0815 09:16:52.763677   668 net.cpp:226] ip3_ip3_0_split needs backward computation.
I0815 09:16:52.763686   668 net.cpp:226] ip3 needs backward computation.
I0815 09:16:52.763695   668 net.cpp:228] accuracy_glasses does not need backward computation.
I0815 09:16:52.763703   668 net.cpp:226] loss1 needs backward computation.
I0815 09:16:52.763712   668 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0815 09:16:52.763721   668 net.cpp:226] ip2 needs backward computation.
I0815 09:16:52.763730   668 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0815 09:16:52.763738   668 net.cpp:226] drop1 needs backward computation.
I0815 09:16:52.763746   668 net.cpp:226] relu5 needs backward computation.
I0815 09:16:52.763754   668 net.cpp:226] ip1 needs backward computation.
I0815 09:16:52.763762   668 net.cpp:226] relu3 needs backward computation.
I0815 09:16:52.763772   668 net.cpp:226] conv3 needs backward computation.
I0815 09:16:52.763779   668 net.cpp:226] pool2 needs backward computation.
I0815 09:16:52.763787   668 net.cpp:226] relu2 needs backward computation.
I0815 09:16:52.763795   668 net.cpp:226] conv2 needs backward computation.
I0815 09:16:52.763803   668 net.cpp:226] pool1 needs backward computation.
I0815 09:16:52.763813   668 net.cpp:226] relu1 needs backward computation.
I0815 09:16:52.763820   668 net.cpp:226] conv1 needs backward computation.
I0815 09:16:52.763829   668 net.cpp:228] gender_slice1_1_split does not need backward computation.
I0815 09:16:52.763839   668 net.cpp:228] glasses_slice1_0_split does not need backward computation.
I0815 09:16:52.763847   668 net.cpp:228] slice1 does not need backward computation.
I0815 09:16:52.763856   668 net.cpp:228] labels does not need backward computation.
I0815 09:16:52.763864   668 net.cpp:228] data does not need backward computation.
I0815 09:16:52.763871   668 net.cpp:270] This network produces output accuracy_gender
I0815 09:16:52.763880   668 net.cpp:270] This network produces output accuracy_glasses
I0815 09:16:52.763888   668 net.cpp:270] This network produces output loss1
I0815 09:16:52.763896   668 net.cpp:270] This network produces output loss2
I0815 09:16:52.763918   668 net.cpp:283] Network initialization done.
I0815 09:16:52.764013   668 solver.cpp:60] Solver scaffolding done.
I0815 09:16:52.764502   668 caffe.cpp:251] Starting Optimization
I0815 09:16:52.764513   668 solver.cpp:279] Solving multi_task
I0815 09:16:52.764521   668 solver.cpp:280] Learning Rate Policy: step
I0815 09:16:52.765591   668 solver.cpp:337] Iteration 0, Testing net (#0)
I0815 09:17:18.804852   668 blocking_queue.cpp:50] Data layer prefetch queue empty
I0815 09:17:49.276741   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0
I0815 09:17:49.276829   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.242109
I0815 09:17:49.276847   668 solver.cpp:404]     Test net output #2: loss1 = 0.808356 (* 0.5 = 0.404178 loss)
I0815 09:17:49.276860   668 solver.cpp:404]     Test net output #3: loss2 = 6.18257 (* 0.5 = 3.09129 loss)
I0815 09:17:49.533632   668 solver.cpp:228] Iteration 0, loss = 3.48673
I0815 09:17:49.533687   668 solver.cpp:244]     Train net output #0: loss1 = 0.78033 (* 0.5 = 0.390165 loss)
I0815 09:17:49.533702   668 solver.cpp:244]     Train net output #1: loss2 = 6.19313 (* 0.5 = 3.09657 loss)
I0815 09:17:49.533722   668 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0815 09:17:54.290297   668 solver.cpp:228] Iteration 20, loss = 0.900212
I0815 09:17:54.290361   668 solver.cpp:244]     Train net output #0: loss1 = 0.610901 (* 0.5 = 0.30545 loss)
I0815 09:17:54.290377   668 solver.cpp:244]     Train net output #1: loss2 = 1.18952 (* 0.5 = 0.594761 loss)
I0815 09:17:54.290391   668 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0815 09:17:59.186234   668 solver.cpp:228] Iteration 40, loss = 0.645821
I0815 09:17:59.186285   668 solver.cpp:244]     Train net output #0: loss1 = 0.592359 (* 0.5 = 0.296179 loss)
I0815 09:17:59.186300   668 solver.cpp:244]     Train net output #1: loss2 = 0.699284 (* 0.5 = 0.349642 loss)
I0815 09:17:59.186312   668 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0815 09:18:04.081389   668 solver.cpp:228] Iteration 60, loss = 0.723264
I0815 09:18:04.081447   668 solver.cpp:244]     Train net output #0: loss1 = 0.754404 (* 0.5 = 0.377202 loss)
I0815 09:18:04.081464   668 solver.cpp:244]     Train net output #1: loss2 = 0.692124 (* 0.5 = 0.346062 loss)
I0815 09:18:04.081475   668 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0815 09:18:09.004310   668 solver.cpp:228] Iteration 80, loss = 0.596689
I0815 09:18:09.004370   668 solver.cpp:244]     Train net output #0: loss1 = 0.551728 (* 0.5 = 0.275864 loss)
I0815 09:18:09.004389   668 solver.cpp:244]     Train net output #1: loss2 = 0.641649 (* 0.5 = 0.320824 loss)
I0815 09:18:09.004402   668 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0815 09:18:13.900332   668 solver.cpp:228] Iteration 100, loss = 0.498878
I0815 09:18:13.900393   668 solver.cpp:244]     Train net output #0: loss1 = 0.397341 (* 0.5 = 0.19867 loss)
I0815 09:18:13.900408   668 solver.cpp:244]     Train net output #1: loss2 = 0.600415 (* 0.5 = 0.300207 loss)
I0815 09:18:13.900420   668 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0815 09:18:18.789258   668 solver.cpp:228] Iteration 120, loss = 0.488737
I0815 09:18:18.789314   668 solver.cpp:244]     Train net output #0: loss1 = 0.463746 (* 0.5 = 0.231873 loss)
I0815 09:18:18.789330   668 solver.cpp:244]     Train net output #1: loss2 = 0.513728 (* 0.5 = 0.256864 loss)
I0815 09:18:18.789343   668 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0815 09:18:23.701542   668 solver.cpp:228] Iteration 140, loss = 0.556761
I0815 09:18:23.701670   668 solver.cpp:244]     Train net output #0: loss1 = 0.564423 (* 0.5 = 0.282211 loss)
I0815 09:18:23.701683   668 solver.cpp:244]     Train net output #1: loss2 = 0.5491 (* 0.5 = 0.27455 loss)
I0815 09:18:23.701692   668 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0815 09:18:28.622611   668 solver.cpp:228] Iteration 160, loss = 0.461415
I0815 09:18:28.622668   668 solver.cpp:244]     Train net output #0: loss1 = 0.369889 (* 0.5 = 0.184944 loss)
I0815 09:18:28.622684   668 solver.cpp:244]     Train net output #1: loss2 = 0.55294 (* 0.5 = 0.27647 loss)
I0815 09:18:28.622696   668 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0815 09:18:33.594969   668 solver.cpp:228] Iteration 180, loss = 0.384385
I0815 09:18:33.595027   668 solver.cpp:244]     Train net output #0: loss1 = 0.255372 (* 0.5 = 0.127686 loss)
I0815 09:18:33.595042   668 solver.cpp:244]     Train net output #1: loss2 = 0.513399 (* 0.5 = 0.256699 loss)
I0815 09:18:33.595055   668 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0815 09:18:38.495056   668 solver.cpp:228] Iteration 200, loss = 0.369952
I0815 09:18:38.495111   668 solver.cpp:244]     Train net output #0: loss1 = 0.243916 (* 0.5 = 0.121958 loss)
I0815 09:18:38.495127   668 solver.cpp:244]     Train net output #1: loss2 = 0.495989 (* 0.5 = 0.247994 loss)
I0815 09:18:38.495139   668 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0815 09:18:43.395921   668 solver.cpp:228] Iteration 220, loss = 0.382738
I0815 09:18:43.395979   668 solver.cpp:244]     Train net output #0: loss1 = 0.21708 (* 0.5 = 0.10854 loss)
I0815 09:18:43.395995   668 solver.cpp:244]     Train net output #1: loss2 = 0.548395 (* 0.5 = 0.274198 loss)
I0815 09:18:43.396008   668 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0815 09:18:48.293092   668 solver.cpp:228] Iteration 240, loss = 0.402513
I0815 09:18:48.293149   668 solver.cpp:244]     Train net output #0: loss1 = 0.294933 (* 0.5 = 0.147466 loss)
I0815 09:18:48.293164   668 solver.cpp:244]     Train net output #1: loss2 = 0.510092 (* 0.5 = 0.255046 loss)
I0815 09:18:48.293177   668 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0815 09:18:53.243485   668 solver.cpp:228] Iteration 260, loss = 0.411765
I0815 09:18:53.243541   668 solver.cpp:244]     Train net output #0: loss1 = 0.260969 (* 0.5 = 0.130484 loss)
I0815 09:18:53.243556   668 solver.cpp:244]     Train net output #1: loss2 = 0.562561 (* 0.5 = 0.28128 loss)
I0815 09:18:53.243568   668 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0815 09:18:58.188704   668 solver.cpp:228] Iteration 280, loss = 0.402921
I0815 09:18:58.188885   668 solver.cpp:244]     Train net output #0: loss1 = 0.286189 (* 0.5 = 0.143094 loss)
I0815 09:18:58.188908   668 solver.cpp:244]     Train net output #1: loss2 = 0.519653 (* 0.5 = 0.259827 loss)
I0815 09:18:58.188925   668 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0815 09:19:03.132485   668 solver.cpp:228] Iteration 300, loss = 0.41799
I0815 09:19:03.132542   668 solver.cpp:244]     Train net output #0: loss1 = 0.321879 (* 0.5 = 0.16094 loss)
I0815 09:19:03.132558   668 solver.cpp:244]     Train net output #1: loss2 = 0.5141 (* 0.5 = 0.25705 loss)
I0815 09:19:03.132571   668 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0815 09:19:08.047631   668 solver.cpp:228] Iteration 320, loss = 0.365549
I0815 09:19:08.047688   668 solver.cpp:244]     Train net output #0: loss1 = 0.19204 (* 0.5 = 0.0960199 loss)
I0815 09:19:08.047704   668 solver.cpp:244]     Train net output #1: loss2 = 0.539058 (* 0.5 = 0.269529 loss)
I0815 09:19:08.047718   668 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0815 09:19:12.940475   668 solver.cpp:228] Iteration 340, loss = 0.308279
I0815 09:19:12.940533   668 solver.cpp:244]     Train net output #0: loss1 = 0.220046 (* 0.5 = 0.110023 loss)
I0815 09:19:12.940549   668 solver.cpp:244]     Train net output #1: loss2 = 0.396512 (* 0.5 = 0.198256 loss)
I0815 09:19:12.940562   668 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0815 09:19:17.858136   668 solver.cpp:228] Iteration 360, loss = 0.369195
I0815 09:19:17.858191   668 solver.cpp:244]     Train net output #0: loss1 = 0.234878 (* 0.5 = 0.117439 loss)
I0815 09:19:17.858206   668 solver.cpp:244]     Train net output #1: loss2 = 0.503513 (* 0.5 = 0.251756 loss)
I0815 09:19:17.858218   668 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0815 09:19:22.839653   668 solver.cpp:228] Iteration 380, loss = 0.399211
I0815 09:19:22.839709   668 solver.cpp:244]     Train net output #0: loss1 = 0.331622 (* 0.5 = 0.165811 loss)
I0815 09:19:22.839723   668 solver.cpp:244]     Train net output #1: loss2 = 0.4668 (* 0.5 = 0.2334 loss)
I0815 09:19:22.839735   668 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0815 09:19:27.852963   668 solver.cpp:228] Iteration 400, loss = 0.364987
I0815 09:19:27.853021   668 solver.cpp:244]     Train net output #0: loss1 = 0.266212 (* 0.5 = 0.133106 loss)
I0815 09:19:27.853036   668 solver.cpp:244]     Train net output #1: loss2 = 0.463762 (* 0.5 = 0.231881 loss)
I0815 09:19:27.853049   668 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0815 09:19:32.754911   668 solver.cpp:228] Iteration 420, loss = 0.312449
I0815 09:19:32.755080   668 solver.cpp:244]     Train net output #0: loss1 = 0.209694 (* 0.5 = 0.104847 loss)
I0815 09:19:32.755105   668 solver.cpp:244]     Train net output #1: loss2 = 0.415204 (* 0.5 = 0.207602 loss)
I0815 09:19:32.755120   668 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0815 09:19:37.664371   668 solver.cpp:228] Iteration 440, loss = 0.288832
I0815 09:19:37.664427   668 solver.cpp:244]     Train net output #0: loss1 = 0.126146 (* 0.5 = 0.0630732 loss)
I0815 09:19:37.664443   668 solver.cpp:244]     Train net output #1: loss2 = 0.451517 (* 0.5 = 0.225758 loss)
I0815 09:19:37.664455   668 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0815 09:19:42.596859   668 solver.cpp:228] Iteration 460, loss = 0.309566
I0815 09:19:42.596916   668 solver.cpp:244]     Train net output #0: loss1 = 0.1421 (* 0.5 = 0.0710499 loss)
I0815 09:19:42.596931   668 solver.cpp:244]     Train net output #1: loss2 = 0.477032 (* 0.5 = 0.238516 loss)
I0815 09:19:42.596943   668 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0815 09:19:47.557813   668 solver.cpp:228] Iteration 480, loss = 0.280917
I0815 09:19:47.557934   668 solver.cpp:244]     Train net output #0: loss1 = 0.119043 (* 0.5 = 0.0595216 loss)
I0815 09:19:47.557952   668 solver.cpp:244]     Train net output #1: loss2 = 0.442791 (* 0.5 = 0.221395 loss)
I0815 09:19:47.557965   668 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0815 09:19:52.509554   668 solver.cpp:228] Iteration 500, loss = 0.322234
I0815 09:19:52.509610   668 solver.cpp:244]     Train net output #0: loss1 = 0.149626 (* 0.5 = 0.0748128 loss)
I0815 09:19:52.509626   668 solver.cpp:244]     Train net output #1: loss2 = 0.494842 (* 0.5 = 0.247421 loss)
I0815 09:19:52.509639   668 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0815 09:19:57.464130   668 solver.cpp:228] Iteration 520, loss = 0.319888
I0815 09:19:57.464189   668 solver.cpp:244]     Train net output #0: loss1 = 0.187069 (* 0.5 = 0.0935347 loss)
I0815 09:19:57.464205   668 solver.cpp:244]     Train net output #1: loss2 = 0.452706 (* 0.5 = 0.226353 loss)
I0815 09:19:57.464216   668 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0815 09:20:02.510830   668 solver.cpp:228] Iteration 540, loss = 0.303103
I0815 09:20:02.510887   668 solver.cpp:244]     Train net output #0: loss1 = 0.227061 (* 0.5 = 0.11353 loss)
I0815 09:20:02.510902   668 solver.cpp:244]     Train net output #1: loss2 = 0.379145 (* 0.5 = 0.189573 loss)
I0815 09:20:02.510915   668 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0815 09:20:07.411192   668 solver.cpp:228] Iteration 560, loss = 0.325941
I0815 09:20:07.411340   668 solver.cpp:244]     Train net output #0: loss1 = 0.171889 (* 0.5 = 0.0859444 loss)
I0815 09:20:07.411357   668 solver.cpp:244]     Train net output #1: loss2 = 0.479994 (* 0.5 = 0.239997 loss)
I0815 09:20:07.411370   668 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0815 09:20:12.307554   668 solver.cpp:228] Iteration 580, loss = 0.300584
I0815 09:20:12.307613   668 solver.cpp:244]     Train net output #0: loss1 = 0.232635 (* 0.5 = 0.116318 loss)
I0815 09:20:12.307629   668 solver.cpp:244]     Train net output #1: loss2 = 0.368532 (* 0.5 = 0.184266 loss)
I0815 09:20:12.307641   668 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0815 09:20:17.196387   668 solver.cpp:228] Iteration 600, loss = 0.315899
I0815 09:20:17.196444   668 solver.cpp:244]     Train net output #0: loss1 = 0.2437 (* 0.5 = 0.12185 loss)
I0815 09:20:17.196460   668 solver.cpp:244]     Train net output #1: loss2 = 0.388098 (* 0.5 = 0.194049 loss)
I0815 09:20:17.196473   668 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0815 09:20:22.108095   668 solver.cpp:228] Iteration 620, loss = 0.279591
I0815 09:20:22.108155   668 solver.cpp:244]     Train net output #0: loss1 = 0.224039 (* 0.5 = 0.112019 loss)
I0815 09:20:22.108170   668 solver.cpp:244]     Train net output #1: loss2 = 0.335143 (* 0.5 = 0.167572 loss)
I0815 09:20:22.108182   668 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0815 09:20:27.081409   668 solver.cpp:228] Iteration 640, loss = 0.298606
I0815 09:20:27.081467   668 solver.cpp:244]     Train net output #0: loss1 = 0.156379 (* 0.5 = 0.0781896 loss)
I0815 09:20:27.081482   668 solver.cpp:244]     Train net output #1: loss2 = 0.440833 (* 0.5 = 0.220417 loss)
I0815 09:20:27.081496   668 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0815 09:20:32.013244   668 solver.cpp:228] Iteration 660, loss = 0.308534
I0815 09:20:32.013303   668 solver.cpp:244]     Train net output #0: loss1 = 0.221657 (* 0.5 = 0.110829 loss)
I0815 09:20:32.013319   668 solver.cpp:244]     Train net output #1: loss2 = 0.395411 (* 0.5 = 0.197705 loss)
I0815 09:20:32.013330   668 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0815 09:20:36.989745   668 solver.cpp:228] Iteration 680, loss = 0.212794
I0815 09:20:36.989804   668 solver.cpp:244]     Train net output #0: loss1 = 0.106681 (* 0.5 = 0.0533406 loss)
I0815 09:20:36.989820   668 solver.cpp:244]     Train net output #1: loss2 = 0.318907 (* 0.5 = 0.159453 loss)
I0815 09:20:36.989831   668 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0815 09:20:41.900674   668 solver.cpp:228] Iteration 700, loss = 0.26793
I0815 09:20:41.900827   668 solver.cpp:244]     Train net output #0: loss1 = 0.176486 (* 0.5 = 0.0882431 loss)
I0815 09:20:41.900846   668 solver.cpp:244]     Train net output #1: loss2 = 0.359374 (* 0.5 = 0.179687 loss)
I0815 09:20:41.900858   668 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0815 09:20:46.825227   668 solver.cpp:228] Iteration 720, loss = 0.231943
I0815 09:20:46.825289   668 solver.cpp:244]     Train net output #0: loss1 = 0.124111 (* 0.5 = 0.0620555 loss)
I0815 09:20:46.825306   668 solver.cpp:244]     Train net output #1: loss2 = 0.339774 (* 0.5 = 0.169887 loss)
I0815 09:20:46.825320   668 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0815 09:20:51.726461   668 solver.cpp:228] Iteration 740, loss = 0.227267
I0815 09:20:51.726519   668 solver.cpp:244]     Train net output #0: loss1 = 0.181865 (* 0.5 = 0.0909326 loss)
I0815 09:20:51.726536   668 solver.cpp:244]     Train net output #1: loss2 = 0.272668 (* 0.5 = 0.136334 loss)
I0815 09:20:51.726547   668 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0815 09:20:56.663982   668 solver.cpp:228] Iteration 760, loss = 0.266199
I0815 09:20:56.664041   668 solver.cpp:244]     Train net output #0: loss1 = 0.145789 (* 0.5 = 0.0728944 loss)
I0815 09:20:56.664057   668 solver.cpp:244]     Train net output #1: loss2 = 0.386609 (* 0.5 = 0.193305 loss)
I0815 09:20:56.664068   668 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0815 09:21:01.564971   668 solver.cpp:228] Iteration 780, loss = 0.255594
I0815 09:21:01.565032   668 solver.cpp:244]     Train net output #0: loss1 = 0.170403 (* 0.5 = 0.0852015 loss)
I0815 09:21:01.565047   668 solver.cpp:244]     Train net output #1: loss2 = 0.340784 (* 0.5 = 0.170392 loss)
I0815 09:21:01.565060   668 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0815 09:21:06.492506   668 solver.cpp:228] Iteration 800, loss = 0.20471
I0815 09:21:06.492564   668 solver.cpp:244]     Train net output #0: loss1 = 0.0867282 (* 0.5 = 0.0433641 loss)
I0815 09:21:06.492580   668 solver.cpp:244]     Train net output #1: loss2 = 0.322691 (* 0.5 = 0.161345 loss)
I0815 09:21:06.492593   668 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0815 09:21:11.498662   668 solver.cpp:228] Iteration 820, loss = 0.205763
I0815 09:21:11.498719   668 solver.cpp:244]     Train net output #0: loss1 = 0.141062 (* 0.5 = 0.0705309 loss)
I0815 09:21:11.498735   668 solver.cpp:244]     Train net output #1: loss2 = 0.270465 (* 0.5 = 0.135232 loss)
I0815 09:21:11.498747   668 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0815 09:21:16.514467   668 solver.cpp:228] Iteration 840, loss = 0.295143
I0815 09:21:16.514735   668 solver.cpp:244]     Train net output #0: loss1 = 0.0959863 (* 0.5 = 0.0479932 loss)
I0815 09:21:16.514758   668 solver.cpp:244]     Train net output #1: loss2 = 0.494299 (* 0.5 = 0.247149 loss)
I0815 09:21:16.514775   668 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0815 09:21:21.398665   668 solver.cpp:228] Iteration 860, loss = 0.274536
I0815 09:21:21.398721   668 solver.cpp:244]     Train net output #0: loss1 = 0.204472 (* 0.5 = 0.102236 loss)
I0815 09:21:21.398737   668 solver.cpp:244]     Train net output #1: loss2 = 0.3446 (* 0.5 = 0.1723 loss)
I0815 09:21:21.398749   668 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0815 09:21:26.303318   668 solver.cpp:228] Iteration 880, loss = 0.201839
I0815 09:21:26.303376   668 solver.cpp:244]     Train net output #0: loss1 = 0.0827764 (* 0.5 = 0.0413882 loss)
I0815 09:21:26.303392   668 solver.cpp:244]     Train net output #1: loss2 = 0.320901 (* 0.5 = 0.16045 loss)
I0815 09:21:26.303406   668 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0815 09:21:31.283298   668 solver.cpp:228] Iteration 900, loss = 0.182709
I0815 09:21:31.283387   668 solver.cpp:244]     Train net output #0: loss1 = 0.0986761 (* 0.5 = 0.0493381 loss)
I0815 09:21:31.283421   668 solver.cpp:244]     Train net output #1: loss2 = 0.266742 (* 0.5 = 0.133371 loss)
I0815 09:21:31.283450   668 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0815 09:21:36.279609   668 solver.cpp:228] Iteration 920, loss = 0.230695
I0815 09:21:36.279670   668 solver.cpp:244]     Train net output #0: loss1 = 0.0757034 (* 0.5 = 0.0378517 loss)
I0815 09:21:36.279686   668 solver.cpp:244]     Train net output #1: loss2 = 0.385687 (* 0.5 = 0.192844 loss)
I0815 09:21:36.279698   668 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0815 09:21:41.392169   668 solver.cpp:228] Iteration 940, loss = 0.249789
I0815 09:21:41.392227   668 solver.cpp:244]     Train net output #0: loss1 = 0.237463 (* 0.5 = 0.118732 loss)
I0815 09:21:41.392242   668 solver.cpp:244]     Train net output #1: loss2 = 0.262114 (* 0.5 = 0.131057 loss)
I0815 09:21:41.392256   668 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0815 09:21:46.389504   668 solver.cpp:228] Iteration 960, loss = 0.227896
I0815 09:21:46.389566   668 solver.cpp:244]     Train net output #0: loss1 = 0.103238 (* 0.5 = 0.0516192 loss)
I0815 09:21:46.389581   668 solver.cpp:244]     Train net output #1: loss2 = 0.352553 (* 0.5 = 0.176276 loss)
I0815 09:21:46.389595   668 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0815 09:21:51.369245   668 solver.cpp:228] Iteration 980, loss = 0.172312
I0815 09:21:51.369364   668 solver.cpp:244]     Train net output #0: loss1 = 0.156617 (* 0.5 = 0.0783085 loss)
I0815 09:21:51.369381   668 solver.cpp:244]     Train net output #1: loss2 = 0.188006 (* 0.5 = 0.094003 loss)
I0815 09:21:51.369393   668 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0815 09:21:56.054294   668 solver.cpp:337] Iteration 1000, Testing net (#0)
I0815 09:22:53.686511   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.756078
I0815 09:22:53.686614   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.931063
I0815 09:22:53.686632   668 solver.cpp:404]     Test net output #2: loss1 = 0.207381 (* 0.5 = 0.10369 loss)
I0815 09:22:53.686646   668 solver.cpp:404]     Test net output #3: loss2 = 0.529431 (* 0.5 = 0.264716 loss)
I0815 09:22:53.769088   668 solver.cpp:228] Iteration 1000, loss = 0.186753
I0815 09:22:53.769143   668 solver.cpp:244]     Train net output #0: loss1 = 0.119275 (* 0.5 = 0.0596374 loss)
I0815 09:22:53.769160   668 solver.cpp:244]     Train net output #1: loss2 = 0.254231 (* 0.5 = 0.127116 loss)
I0815 09:22:53.769171   668 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0815 09:22:58.693573   668 solver.cpp:228] Iteration 1020, loss = 0.16537
I0815 09:22:58.693630   668 solver.cpp:244]     Train net output #0: loss1 = 0.0768756 (* 0.5 = 0.0384378 loss)
I0815 09:22:58.693645   668 solver.cpp:244]     Train net output #1: loss2 = 0.253864 (* 0.5 = 0.126932 loss)
I0815 09:22:58.693658   668 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0815 09:23:03.646651   668 solver.cpp:228] Iteration 1040, loss = 0.27337
I0815 09:23:03.646711   668 solver.cpp:244]     Train net output #0: loss1 = 0.159955 (* 0.5 = 0.0799773 loss)
I0815 09:23:03.646728   668 solver.cpp:244]     Train net output #1: loss2 = 0.386785 (* 0.5 = 0.193393 loss)
I0815 09:23:03.646739   668 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0815 09:23:08.589665   668 solver.cpp:228] Iteration 1060, loss = 0.192063
I0815 09:23:08.589721   668 solver.cpp:244]     Train net output #0: loss1 = 0.0930831 (* 0.5 = 0.0465416 loss)
I0815 09:23:08.589737   668 solver.cpp:244]     Train net output #1: loss2 = 0.291043 (* 0.5 = 0.145522 loss)
I0815 09:23:08.589750   668 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0815 09:23:13.527892   668 solver.cpp:228] Iteration 1080, loss = 0.267656
I0815 09:23:13.527951   668 solver.cpp:244]     Train net output #0: loss1 = 0.293508 (* 0.5 = 0.146754 loss)
I0815 09:23:13.527966   668 solver.cpp:244]     Train net output #1: loss2 = 0.241804 (* 0.5 = 0.120902 loss)
I0815 09:23:13.527978   668 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0815 09:23:18.436516   668 solver.cpp:228] Iteration 1100, loss = 0.171512
I0815 09:23:18.436574   668 solver.cpp:244]     Train net output #0: loss1 = 0.0754293 (* 0.5 = 0.0377147 loss)
I0815 09:23:18.436590   668 solver.cpp:244]     Train net output #1: loss2 = 0.267594 (* 0.5 = 0.133797 loss)
I0815 09:23:18.436602   668 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0815 09:23:23.340200   668 solver.cpp:228] Iteration 1120, loss = 0.218918
I0815 09:23:23.340250   668 solver.cpp:244]     Train net output #0: loss1 = 0.208997 (* 0.5 = 0.104498 loss)
I0815 09:23:23.340260   668 solver.cpp:244]     Train net output #1: loss2 = 0.228839 (* 0.5 = 0.11442 loss)
I0815 09:23:23.340270   668 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0815 09:23:28.246415   668 solver.cpp:228] Iteration 1140, loss = 0.203616
I0815 09:23:28.246537   668 solver.cpp:244]     Train net output #0: loss1 = 0.073473 (* 0.5 = 0.0367365 loss)
I0815 09:23:28.246554   668 solver.cpp:244]     Train net output #1: loss2 = 0.333758 (* 0.5 = 0.166879 loss)
I0815 09:23:28.246575   668 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0815 09:23:33.144274   668 solver.cpp:228] Iteration 1160, loss = 0.170749
I0815 09:23:33.144331   668 solver.cpp:244]     Train net output #0: loss1 = 0.144056 (* 0.5 = 0.0720279 loss)
I0815 09:23:33.144347   668 solver.cpp:244]     Train net output #1: loss2 = 0.197442 (* 0.5 = 0.0987208 loss)
I0815 09:23:33.144361   668 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0815 09:23:38.044863   668 solver.cpp:228] Iteration 1180, loss = 0.185743
I0815 09:23:38.044924   668 solver.cpp:244]     Train net output #0: loss1 = 0.0753071 (* 0.5 = 0.0376535 loss)
I0815 09:23:38.044939   668 solver.cpp:244]     Train net output #1: loss2 = 0.296178 (* 0.5 = 0.148089 loss)
I0815 09:23:38.044952   668 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0815 09:23:42.958209   668 solver.cpp:228] Iteration 1200, loss = 0.159598
I0815 09:23:42.958264   668 solver.cpp:244]     Train net output #0: loss1 = 0.0413756 (* 0.5 = 0.0206878 loss)
I0815 09:23:42.958281   668 solver.cpp:244]     Train net output #1: loss2 = 0.277821 (* 0.5 = 0.13891 loss)
I0815 09:23:42.958293   668 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0815 09:23:47.857484   668 solver.cpp:228] Iteration 1220, loss = 0.1647
I0815 09:23:47.857542   668 solver.cpp:244]     Train net output #0: loss1 = 0.0598926 (* 0.5 = 0.0299463 loss)
I0815 09:23:47.857556   668 solver.cpp:244]     Train net output #1: loss2 = 0.269507 (* 0.5 = 0.134754 loss)
I0815 09:23:47.857569   668 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0815 09:23:52.752801   668 solver.cpp:228] Iteration 1240, loss = 0.153784
I0815 09:23:52.752861   668 solver.cpp:244]     Train net output #0: loss1 = 0.100015 (* 0.5 = 0.0500075 loss)
I0815 09:23:52.752876   668 solver.cpp:244]     Train net output #1: loss2 = 0.207553 (* 0.5 = 0.103777 loss)
I0815 09:23:52.752889   668 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0815 09:23:57.639394   668 solver.cpp:228] Iteration 1260, loss = 0.134984
I0815 09:23:57.639449   668 solver.cpp:244]     Train net output #0: loss1 = 0.0547576 (* 0.5 = 0.0273788 loss)
I0815 09:23:57.639466   668 solver.cpp:244]     Train net output #1: loss2 = 0.215209 (* 0.5 = 0.107605 loss)
I0815 09:23:57.639478   668 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0815 09:24:02.534440   668 solver.cpp:228] Iteration 1280, loss = 0.181496
I0815 09:24:02.537163   668 solver.cpp:244]     Train net output #0: loss1 = 0.158922 (* 0.5 = 0.0794608 loss)
I0815 09:24:02.537179   668 solver.cpp:244]     Train net output #1: loss2 = 0.204069 (* 0.5 = 0.102035 loss)
I0815 09:24:02.537189   668 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0815 09:24:07.422627   668 solver.cpp:228] Iteration 1300, loss = 0.191049
I0815 09:24:07.422683   668 solver.cpp:244]     Train net output #0: loss1 = 0.184277 (* 0.5 = 0.0921384 loss)
I0815 09:24:07.422699   668 solver.cpp:244]     Train net output #1: loss2 = 0.197821 (* 0.5 = 0.0989105 loss)
I0815 09:24:07.422713   668 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0815 09:24:12.314407   668 solver.cpp:228] Iteration 1320, loss = 0.130004
I0815 09:24:12.314467   668 solver.cpp:244]     Train net output #0: loss1 = 0.055118 (* 0.5 = 0.027559 loss)
I0815 09:24:12.314482   668 solver.cpp:244]     Train net output #1: loss2 = 0.204891 (* 0.5 = 0.102445 loss)
I0815 09:24:12.314496   668 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0815 09:24:17.203938   668 solver.cpp:228] Iteration 1340, loss = 0.151839
I0815 09:24:17.203994   668 solver.cpp:244]     Train net output #0: loss1 = 0.0560344 (* 0.5 = 0.0280172 loss)
I0815 09:24:17.204010   668 solver.cpp:244]     Train net output #1: loss2 = 0.247643 (* 0.5 = 0.123821 loss)
I0815 09:24:17.204021   668 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0815 09:24:22.089931   668 solver.cpp:228] Iteration 1360, loss = 0.170994
I0815 09:24:22.089988   668 solver.cpp:244]     Train net output #0: loss1 = 0.129624 (* 0.5 = 0.0648119 loss)
I0815 09:24:22.090004   668 solver.cpp:244]     Train net output #1: loss2 = 0.212363 (* 0.5 = 0.106182 loss)
I0815 09:24:22.090018   668 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0815 09:24:26.978324   668 solver.cpp:228] Iteration 1380, loss = 0.192846
I0815 09:24:26.978389   668 solver.cpp:244]     Train net output #0: loss1 = 0.132604 (* 0.5 = 0.0663018 loss)
I0815 09:24:26.978405   668 solver.cpp:244]     Train net output #1: loss2 = 0.253089 (* 0.5 = 0.126544 loss)
I0815 09:24:26.978418   668 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0815 09:24:31.874208   668 solver.cpp:228] Iteration 1400, loss = 0.150188
I0815 09:24:31.874264   668 solver.cpp:244]     Train net output #0: loss1 = 0.073302 (* 0.5 = 0.036651 loss)
I0815 09:24:31.874279   668 solver.cpp:244]     Train net output #1: loss2 = 0.227074 (* 0.5 = 0.113537 loss)
I0815 09:24:31.874291   668 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0815 09:24:36.762116   668 solver.cpp:228] Iteration 1420, loss = 0.142948
I0815 09:24:36.762259   668 solver.cpp:244]     Train net output #0: loss1 = 0.0221902 (* 0.5 = 0.0110951 loss)
I0815 09:24:36.762275   668 solver.cpp:244]     Train net output #1: loss2 = 0.263706 (* 0.5 = 0.131853 loss)
I0815 09:24:36.762289   668 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0815 09:24:41.654474   668 solver.cpp:228] Iteration 1440, loss = 0.200306
I0815 09:24:41.654532   668 solver.cpp:244]     Train net output #0: loss1 = 0.17661 (* 0.5 = 0.0883052 loss)
I0815 09:24:41.654548   668 solver.cpp:244]     Train net output #1: loss2 = 0.224 (* 0.5 = 0.112 loss)
I0815 09:24:41.654566   668 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0815 09:24:46.542196   668 solver.cpp:228] Iteration 1460, loss = 0.164889
I0815 09:24:46.542254   668 solver.cpp:244]     Train net output #0: loss1 = 0.129099 (* 0.5 = 0.0645493 loss)
I0815 09:24:46.542270   668 solver.cpp:244]     Train net output #1: loss2 = 0.200679 (* 0.5 = 0.100339 loss)
I0815 09:24:46.542284   668 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0815 09:24:51.435979   668 solver.cpp:228] Iteration 1480, loss = 0.240766
I0815 09:24:51.436038   668 solver.cpp:244]     Train net output #0: loss1 = 0.232936 (* 0.5 = 0.116468 loss)
I0815 09:24:51.436053   668 solver.cpp:244]     Train net output #1: loss2 = 0.248596 (* 0.5 = 0.124298 loss)
I0815 09:24:51.436065   668 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0815 09:24:56.391474   668 solver.cpp:228] Iteration 1500, loss = 0.166849
I0815 09:24:56.391530   668 solver.cpp:244]     Train net output #0: loss1 = 0.100718 (* 0.5 = 0.0503588 loss)
I0815 09:24:56.391546   668 solver.cpp:244]     Train net output #1: loss2 = 0.232979 (* 0.5 = 0.11649 loss)
I0815 09:24:56.391558   668 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0815 09:25:01.318356   668 solver.cpp:228] Iteration 1520, loss = 0.146382
I0815 09:25:01.318413   668 solver.cpp:244]     Train net output #0: loss1 = 0.0762594 (* 0.5 = 0.0381297 loss)
I0815 09:25:01.318429   668 solver.cpp:244]     Train net output #1: loss2 = 0.216504 (* 0.5 = 0.108252 loss)
I0815 09:25:01.318441   668 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0815 09:25:06.259310   668 solver.cpp:228] Iteration 1540, loss = 0.0813277
I0815 09:25:06.259366   668 solver.cpp:244]     Train net output #0: loss1 = 0.0604753 (* 0.5 = 0.0302377 loss)
I0815 09:25:06.259380   668 solver.cpp:244]     Train net output #1: loss2 = 0.10218 (* 0.5 = 0.0510899 loss)
I0815 09:25:06.259393   668 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0815 09:25:11.231555   668 solver.cpp:228] Iteration 1560, loss = 0.121277
I0815 09:25:11.231969   668 solver.cpp:244]     Train net output #0: loss1 = 0.0519568 (* 0.5 = 0.0259784 loss)
I0815 09:25:11.231989   668 solver.cpp:244]     Train net output #1: loss2 = 0.190597 (* 0.5 = 0.0952983 loss)
I0815 09:25:11.232002   668 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0815 09:25:16.131669   668 solver.cpp:228] Iteration 1580, loss = 0.10441
I0815 09:25:16.131727   668 solver.cpp:244]     Train net output #0: loss1 = 0.058909 (* 0.5 = 0.0294545 loss)
I0815 09:25:16.131742   668 solver.cpp:244]     Train net output #1: loss2 = 0.14991 (* 0.5 = 0.074955 loss)
I0815 09:25:16.131755   668 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0815 09:25:21.064962   668 solver.cpp:228] Iteration 1600, loss = 0.134634
I0815 09:25:21.065019   668 solver.cpp:244]     Train net output #0: loss1 = 0.062509 (* 0.5 = 0.0312545 loss)
I0815 09:25:21.065035   668 solver.cpp:244]     Train net output #1: loss2 = 0.206759 (* 0.5 = 0.10338 loss)
I0815 09:25:21.065047   668 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0815 09:25:26.020328   668 solver.cpp:228] Iteration 1620, loss = 0.121511
I0815 09:25:26.020385   668 solver.cpp:244]     Train net output #0: loss1 = 0.0362656 (* 0.5 = 0.0181328 loss)
I0815 09:25:26.020401   668 solver.cpp:244]     Train net output #1: loss2 = 0.206756 (* 0.5 = 0.103378 loss)
I0815 09:25:26.020412   668 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0815 09:25:30.979702   668 solver.cpp:228] Iteration 1640, loss = 0.179275
I0815 09:25:30.979759   668 solver.cpp:244]     Train net output #0: loss1 = 0.160461 (* 0.5 = 0.0802307 loss)
I0815 09:25:30.979774   668 solver.cpp:244]     Train net output #1: loss2 = 0.198089 (* 0.5 = 0.0990446 loss)
I0815 09:25:30.979787   668 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0815 09:25:35.941443   668 solver.cpp:228] Iteration 1660, loss = 0.0995865
I0815 09:25:35.941498   668 solver.cpp:244]     Train net output #0: loss1 = 0.0234295 (* 0.5 = 0.0117147 loss)
I0815 09:25:35.941514   668 solver.cpp:244]     Train net output #1: loss2 = 0.175743 (* 0.5 = 0.0878717 loss)
I0815 09:25:35.941527   668 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0815 09:25:40.903774   668 solver.cpp:228] Iteration 1680, loss = 0.152915
I0815 09:25:40.903834   668 solver.cpp:244]     Train net output #0: loss1 = 0.0787981 (* 0.5 = 0.0393991 loss)
I0815 09:25:40.903846   668 solver.cpp:244]     Train net output #1: loss2 = 0.227031 (* 0.5 = 0.113515 loss)
I0815 09:25:40.903856   668 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0815 09:25:45.796226   668 solver.cpp:228] Iteration 1700, loss = 0.133757
I0815 09:25:45.796350   668 solver.cpp:244]     Train net output #0: loss1 = 0.0485932 (* 0.5 = 0.0242966 loss)
I0815 09:25:45.796366   668 solver.cpp:244]     Train net output #1: loss2 = 0.21892 (* 0.5 = 0.10946 loss)
I0815 09:25:45.796380   668 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0815 09:25:50.697405   668 solver.cpp:228] Iteration 1720, loss = 0.122331
I0815 09:25:50.697461   668 solver.cpp:244]     Train net output #0: loss1 = 0.0521796 (* 0.5 = 0.0260898 loss)
I0815 09:25:50.697477   668 solver.cpp:244]     Train net output #1: loss2 = 0.192481 (* 0.5 = 0.0962406 loss)
I0815 09:25:50.697490   668 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0815 09:25:55.627815   668 solver.cpp:228] Iteration 1740, loss = 0.139947
I0815 09:25:55.627867   668 solver.cpp:244]     Train net output #0: loss1 = 0.0692671 (* 0.5 = 0.0346335 loss)
I0815 09:25:55.627882   668 solver.cpp:244]     Train net output #1: loss2 = 0.210628 (* 0.5 = 0.105314 loss)
I0815 09:25:55.627895   668 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0815 09:26:00.533820   668 solver.cpp:228] Iteration 1760, loss = 0.154621
I0815 09:26:00.533875   668 solver.cpp:244]     Train net output #0: loss1 = 0.063987 (* 0.5 = 0.0319935 loss)
I0815 09:26:00.533890   668 solver.cpp:244]     Train net output #1: loss2 = 0.245254 (* 0.5 = 0.122627 loss)
I0815 09:26:00.533903   668 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0815 09:26:05.423390   668 solver.cpp:228] Iteration 1780, loss = 0.0969446
I0815 09:26:05.423445   668 solver.cpp:244]     Train net output #0: loss1 = 0.0401604 (* 0.5 = 0.0200802 loss)
I0815 09:26:05.423461   668 solver.cpp:244]     Train net output #1: loss2 = 0.153729 (* 0.5 = 0.0768643 loss)
I0815 09:26:05.423473   668 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0815 09:26:10.323642   668 solver.cpp:228] Iteration 1800, loss = 0.169025
I0815 09:26:10.323703   668 solver.cpp:244]     Train net output #0: loss1 = 0.0764057 (* 0.5 = 0.0382028 loss)
I0815 09:26:10.323719   668 solver.cpp:244]     Train net output #1: loss2 = 0.261645 (* 0.5 = 0.130823 loss)
I0815 09:26:10.323731   668 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0815 09:26:15.216261   668 solver.cpp:228] Iteration 1820, loss = 0.146057
I0815 09:26:15.216316   668 solver.cpp:244]     Train net output #0: loss1 = 0.0670127 (* 0.5 = 0.0335064 loss)
I0815 09:26:15.216331   668 solver.cpp:244]     Train net output #1: loss2 = 0.2251 (* 0.5 = 0.11255 loss)
I0815 09:26:15.216344   668 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0815 09:26:20.116109   668 solver.cpp:228] Iteration 1840, loss = 0.118434
I0815 09:26:20.116256   668 solver.cpp:244]     Train net output #0: loss1 = 0.0621478 (* 0.5 = 0.0310739 loss)
I0815 09:26:20.116273   668 solver.cpp:244]     Train net output #1: loss2 = 0.17472 (* 0.5 = 0.0873602 loss)
I0815 09:26:20.116286   668 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0815 09:26:25.001024   668 solver.cpp:228] Iteration 1860, loss = 0.0982331
I0815 09:26:25.001085   668 solver.cpp:244]     Train net output #0: loss1 = 0.0209568 (* 0.5 = 0.0104784 loss)
I0815 09:26:25.001101   668 solver.cpp:244]     Train net output #1: loss2 = 0.175509 (* 0.5 = 0.0877546 loss)
I0815 09:26:25.001113   668 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0815 09:26:29.888419   668 solver.cpp:228] Iteration 1880, loss = 0.150175
I0815 09:26:29.888476   668 solver.cpp:244]     Train net output #0: loss1 = 0.0766447 (* 0.5 = 0.0383224 loss)
I0815 09:26:29.888491   668 solver.cpp:244]     Train net output #1: loss2 = 0.223705 (* 0.5 = 0.111853 loss)
I0815 09:26:29.888504   668 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0815 09:26:34.777457   668 solver.cpp:228] Iteration 1900, loss = 0.13616
I0815 09:26:34.777518   668 solver.cpp:244]     Train net output #0: loss1 = 0.0567322 (* 0.5 = 0.0283661 loss)
I0815 09:26:34.777534   668 solver.cpp:244]     Train net output #1: loss2 = 0.215588 (* 0.5 = 0.107794 loss)
I0815 09:26:34.777545   668 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0815 09:26:39.667248   668 solver.cpp:228] Iteration 1920, loss = 0.0969744
I0815 09:26:39.667306   668 solver.cpp:244]     Train net output #0: loss1 = 0.035161 (* 0.5 = 0.0175805 loss)
I0815 09:26:39.667321   668 solver.cpp:244]     Train net output #1: loss2 = 0.158788 (* 0.5 = 0.0793938 loss)
I0815 09:26:39.667335   668 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0815 09:26:44.574010   668 solver.cpp:228] Iteration 1940, loss = 0.0756568
I0815 09:26:44.574069   668 solver.cpp:244]     Train net output #0: loss1 = 0.023589 (* 0.5 = 0.0117945 loss)
I0815 09:26:44.574085   668 solver.cpp:244]     Train net output #1: loss2 = 0.127724 (* 0.5 = 0.0638621 loss)
I0815 09:26:44.574097   668 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0815 09:26:49.474848   668 solver.cpp:228] Iteration 1960, loss = 0.178405
I0815 09:26:49.474921   668 solver.cpp:244]     Train net output #0: loss1 = 0.213585 (* 0.5 = 0.106792 loss)
I0815 09:26:49.474938   668 solver.cpp:244]     Train net output #1: loss2 = 0.143224 (* 0.5 = 0.071612 loss)
I0815 09:26:49.474951   668 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0815 09:26:54.446311   668 solver.cpp:228] Iteration 1980, loss = 0.109231
I0815 09:26:54.446491   668 solver.cpp:244]     Train net output #0: loss1 = 0.0530682 (* 0.5 = 0.0265341 loss)
I0815 09:26:54.446516   668 solver.cpp:244]     Train net output #1: loss2 = 0.165394 (* 0.5 = 0.0826968 loss)
I0815 09:26:54.446532   668 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0815 09:26:59.099107   668 solver.cpp:337] Iteration 2000, Testing net (#0)
I0815 09:27:56.858233   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.820094
I0815 09:27:56.858350   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.9475
I0815 09:27:56.858369   668 solver.cpp:404]     Test net output #2: loss1 = 0.183359 (* 0.5 = 0.0916793 loss)
I0815 09:27:56.858381   668 solver.cpp:404]     Test net output #3: loss2 = 0.425422 (* 0.5 = 0.212711 loss)
I0815 09:27:56.933081   668 solver.cpp:228] Iteration 2000, loss = 0.093787
I0815 09:27:56.933136   668 solver.cpp:244]     Train net output #0: loss1 = 0.0327434 (* 0.5 = 0.0163717 loss)
I0815 09:27:56.933151   668 solver.cpp:244]     Train net output #1: loss2 = 0.15483 (* 0.5 = 0.0774152 loss)
I0815 09:27:56.933163   668 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0815 09:28:01.832638   668 solver.cpp:228] Iteration 2020, loss = 0.125419
I0815 09:28:01.832691   668 solver.cpp:244]     Train net output #0: loss1 = 0.0751935 (* 0.5 = 0.0375968 loss)
I0815 09:28:01.832707   668 solver.cpp:244]     Train net output #1: loss2 = 0.175645 (* 0.5 = 0.0878224 loss)
I0815 09:28:01.832720   668 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0815 09:28:06.725790   668 solver.cpp:228] Iteration 2040, loss = 0.10359
I0815 09:28:06.725848   668 solver.cpp:244]     Train net output #0: loss1 = 0.0492662 (* 0.5 = 0.0246331 loss)
I0815 09:28:06.725863   668 solver.cpp:244]     Train net output #1: loss2 = 0.157913 (* 0.5 = 0.0789566 loss)
I0815 09:28:06.725875   668 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0815 09:28:11.613812   668 solver.cpp:228] Iteration 2060, loss = 0.171397
I0815 09:28:11.613868   668 solver.cpp:244]     Train net output #0: loss1 = 0.104741 (* 0.5 = 0.0523707 loss)
I0815 09:28:11.613884   668 solver.cpp:244]     Train net output #1: loss2 = 0.238052 (* 0.5 = 0.119026 loss)
I0815 09:28:11.613896   668 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0815 09:28:16.522733   668 solver.cpp:228] Iteration 2080, loss = 0.0742634
I0815 09:28:16.522790   668 solver.cpp:244]     Train net output #0: loss1 = 0.0454251 (* 0.5 = 0.0227125 loss)
I0815 09:28:16.522805   668 solver.cpp:244]     Train net output #1: loss2 = 0.103102 (* 0.5 = 0.0515508 loss)
I0815 09:28:16.522819   668 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0815 09:28:21.419062   668 solver.cpp:228] Iteration 2100, loss = 0.0912191
I0815 09:28:21.419119   668 solver.cpp:244]     Train net output #0: loss1 = 0.0198276 (* 0.5 = 0.00991381 loss)
I0815 09:28:21.419136   668 solver.cpp:244]     Train net output #1: loss2 = 0.16261 (* 0.5 = 0.0813052 loss)
I0815 09:28:21.419147   668 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0815 09:28:26.308926   668 solver.cpp:228] Iteration 2120, loss = 0.149884
I0815 09:28:26.308984   668 solver.cpp:244]     Train net output #0: loss1 = 0.0293209 (* 0.5 = 0.0146604 loss)
I0815 09:28:26.309000   668 solver.cpp:244]     Train net output #1: loss2 = 0.270447 (* 0.5 = 0.135224 loss)
I0815 09:28:26.309011   668 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0815 09:28:31.198336   668 solver.cpp:228] Iteration 2140, loss = 0.11098
I0815 09:28:31.198460   668 solver.cpp:244]     Train net output #0: loss1 = 0.0269345 (* 0.5 = 0.0134672 loss)
I0815 09:28:31.198477   668 solver.cpp:244]     Train net output #1: loss2 = 0.195025 (* 0.5 = 0.0975125 loss)
I0815 09:28:31.198489   668 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0815 09:28:36.097055   668 solver.cpp:228] Iteration 2160, loss = 0.114767
I0815 09:28:36.097117   668 solver.cpp:244]     Train net output #0: loss1 = 0.0127863 (* 0.5 = 0.00639314 loss)
I0815 09:28:36.097133   668 solver.cpp:244]     Train net output #1: loss2 = 0.216747 (* 0.5 = 0.108373 loss)
I0815 09:28:36.097146   668 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0815 09:28:41.002845   668 solver.cpp:228] Iteration 2180, loss = 0.0852877
I0815 09:28:41.002903   668 solver.cpp:244]     Train net output #0: loss1 = 0.0393917 (* 0.5 = 0.0196958 loss)
I0815 09:28:41.002919   668 solver.cpp:244]     Train net output #1: loss2 = 0.131184 (* 0.5 = 0.0655918 loss)
I0815 09:28:41.002931   668 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0815 09:28:45.895628   668 solver.cpp:228] Iteration 2200, loss = 0.0564319
I0815 09:28:45.895684   668 solver.cpp:244]     Train net output #0: loss1 = 0.0494205 (* 0.5 = 0.0247102 loss)
I0815 09:28:45.895700   668 solver.cpp:244]     Train net output #1: loss2 = 0.0634431 (* 0.5 = 0.0317216 loss)
I0815 09:28:45.895712   668 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0815 09:28:50.787982   668 solver.cpp:228] Iteration 2220, loss = 0.169512
I0815 09:28:50.788034   668 solver.cpp:244]     Train net output #0: loss1 = 0.0921447 (* 0.5 = 0.0460724 loss)
I0815 09:28:50.788050   668 solver.cpp:244]     Train net output #1: loss2 = 0.246879 (* 0.5 = 0.123439 loss)
I0815 09:28:50.788063   668 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0815 09:28:55.676550   668 solver.cpp:228] Iteration 2240, loss = 0.0725176
I0815 09:28:55.676609   668 solver.cpp:244]     Train net output #0: loss1 = 0.0343925 (* 0.5 = 0.0171962 loss)
I0815 09:28:55.676625   668 solver.cpp:244]     Train net output #1: loss2 = 0.110643 (* 0.5 = 0.0553213 loss)
I0815 09:28:55.676637   668 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0815 09:29:00.565289   668 solver.cpp:228] Iteration 2260, loss = 0.0620939
I0815 09:29:00.565349   668 solver.cpp:244]     Train net output #0: loss1 = 0.0200802 (* 0.5 = 0.0100401 loss)
I0815 09:29:00.565366   668 solver.cpp:244]     Train net output #1: loss2 = 0.104107 (* 0.5 = 0.0520537 loss)
I0815 09:29:00.565377   668 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0815 09:29:05.450096   668 solver.cpp:228] Iteration 2280, loss = 0.12413
I0815 09:29:05.450238   668 solver.cpp:244]     Train net output #0: loss1 = 0.0992435 (* 0.5 = 0.0496218 loss)
I0815 09:29:05.450255   668 solver.cpp:244]     Train net output #1: loss2 = 0.149016 (* 0.5 = 0.074508 loss)
I0815 09:29:05.450268   668 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0815 09:29:10.340047   668 solver.cpp:228] Iteration 2300, loss = 0.117455
I0815 09:29:10.340102   668 solver.cpp:244]     Train net output #0: loss1 = 0.0780621 (* 0.5 = 0.0390311 loss)
I0815 09:29:10.340117   668 solver.cpp:244]     Train net output #1: loss2 = 0.156848 (* 0.5 = 0.0784241 loss)
I0815 09:29:10.340131   668 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0815 09:29:15.226810   668 solver.cpp:228] Iteration 2320, loss = 0.110696
I0815 09:29:15.226866   668 solver.cpp:244]     Train net output #0: loss1 = 0.0358689 (* 0.5 = 0.0179345 loss)
I0815 09:29:15.226882   668 solver.cpp:244]     Train net output #1: loss2 = 0.185522 (* 0.5 = 0.092761 loss)
I0815 09:29:15.226894   668 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0815 09:29:20.113477   668 solver.cpp:228] Iteration 2340, loss = 0.0912581
I0815 09:29:20.113535   668 solver.cpp:244]     Train net output #0: loss1 = 0.0612333 (* 0.5 = 0.0306166 loss)
I0815 09:29:20.113550   668 solver.cpp:244]     Train net output #1: loss2 = 0.121283 (* 0.5 = 0.0606413 loss)
I0815 09:29:20.113564   668 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0815 09:29:25.000349   668 solver.cpp:228] Iteration 2360, loss = 0.126936
I0815 09:29:25.000404   668 solver.cpp:244]     Train net output #0: loss1 = 0.132633 (* 0.5 = 0.0663167 loss)
I0815 09:29:25.000419   668 solver.cpp:244]     Train net output #1: loss2 = 0.121239 (* 0.5 = 0.0606193 loss)
I0815 09:29:25.000432   668 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0815 09:29:29.889493   668 solver.cpp:228] Iteration 2380, loss = 0.100912
I0815 09:29:29.889551   668 solver.cpp:244]     Train net output #0: loss1 = 0.0111544 (* 0.5 = 0.00557718 loss)
I0815 09:29:29.889567   668 solver.cpp:244]     Train net output #1: loss2 = 0.190669 (* 0.5 = 0.0953346 loss)
I0815 09:29:29.889580   668 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0815 09:29:34.775888   668 solver.cpp:228] Iteration 2400, loss = 0.0915016
I0815 09:29:34.775949   668 solver.cpp:244]     Train net output #0: loss1 = 0.0545306 (* 0.5 = 0.0272653 loss)
I0815 09:29:34.775964   668 solver.cpp:244]     Train net output #1: loss2 = 0.128472 (* 0.5 = 0.0642361 loss)
I0815 09:29:34.775976   668 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0815 09:29:39.663866   668 solver.cpp:228] Iteration 2420, loss = 0.0938521
I0815 09:29:39.664027   668 solver.cpp:244]     Train net output #0: loss1 = 0.0827967 (* 0.5 = 0.0413983 loss)
I0815 09:29:39.664044   668 solver.cpp:244]     Train net output #1: loss2 = 0.104907 (* 0.5 = 0.0524536 loss)
I0815 09:29:39.664057   668 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0815 09:29:44.550619   668 solver.cpp:228] Iteration 2440, loss = 0.111552
I0815 09:29:44.550673   668 solver.cpp:244]     Train net output #0: loss1 = 0.0391928 (* 0.5 = 0.0195964 loss)
I0815 09:29:44.550688   668 solver.cpp:244]     Train net output #1: loss2 = 0.183912 (* 0.5 = 0.0919559 loss)
I0815 09:29:44.550700   668 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0815 09:29:49.438684   668 solver.cpp:228] Iteration 2460, loss = 0.0818475
I0815 09:29:49.438741   668 solver.cpp:244]     Train net output #0: loss1 = 0.0227803 (* 0.5 = 0.0113901 loss)
I0815 09:29:49.438756   668 solver.cpp:244]     Train net output #1: loss2 = 0.140914 (* 0.5 = 0.0704572 loss)
I0815 09:29:49.438769   668 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0815 09:29:54.324714   668 solver.cpp:228] Iteration 2480, loss = 0.0532728
I0815 09:29:54.324774   668 solver.cpp:244]     Train net output #0: loss1 = 0.0215077 (* 0.5 = 0.0107539 loss)
I0815 09:29:54.324789   668 solver.cpp:244]     Train net output #1: loss2 = 0.0850376 (* 0.5 = 0.0425188 loss)
I0815 09:29:54.324801   668 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0815 09:29:59.209651   668 solver.cpp:228] Iteration 2500, loss = 0.091303
I0815 09:29:59.209709   668 solver.cpp:244]     Train net output #0: loss1 = 0.0332465 (* 0.5 = 0.0166233 loss)
I0815 09:29:59.209725   668 solver.cpp:244]     Train net output #1: loss2 = 0.149359 (* 0.5 = 0.0746796 loss)
I0815 09:29:59.209738   668 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0815 09:30:04.101441   668 solver.cpp:228] Iteration 2520, loss = 0.108737
I0815 09:30:04.101506   668 solver.cpp:244]     Train net output #0: loss1 = 0.077738 (* 0.5 = 0.038869 loss)
I0815 09:30:04.101522   668 solver.cpp:244]     Train net output #1: loss2 = 0.139736 (* 0.5 = 0.0698682 loss)
I0815 09:30:04.101536   668 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0815 09:30:08.987208   668 solver.cpp:228] Iteration 2540, loss = 0.0561388
I0815 09:30:08.987264   668 solver.cpp:244]     Train net output #0: loss1 = 0.0135295 (* 0.5 = 0.00676476 loss)
I0815 09:30:08.987280   668 solver.cpp:244]     Train net output #1: loss2 = 0.0987479 (* 0.5 = 0.0493739 loss)
I0815 09:30:08.987293   668 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0815 09:30:13.873862   668 solver.cpp:228] Iteration 2560, loss = 0.0911091
I0815 09:30:13.874018   668 solver.cpp:244]     Train net output #0: loss1 = 0.0569135 (* 0.5 = 0.0284568 loss)
I0815 09:30:13.874042   668 solver.cpp:244]     Train net output #1: loss2 = 0.125305 (* 0.5 = 0.0626523 loss)
I0815 09:30:13.874058   668 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0815 09:30:18.759896   668 solver.cpp:228] Iteration 2580, loss = 0.0795971
I0815 09:30:18.759953   668 solver.cpp:244]     Train net output #0: loss1 = 0.0268573 (* 0.5 = 0.0134286 loss)
I0815 09:30:18.759969   668 solver.cpp:244]     Train net output #1: loss2 = 0.132337 (* 0.5 = 0.0661684 loss)
I0815 09:30:18.759981   668 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0815 09:30:23.648458   668 solver.cpp:228] Iteration 2600, loss = 0.0716386
I0815 09:30:23.648545   668 solver.cpp:244]     Train net output #0: loss1 = 0.0499686 (* 0.5 = 0.0249843 loss)
I0815 09:30:23.648578   668 solver.cpp:244]     Train net output #1: loss2 = 0.0933084 (* 0.5 = 0.0466542 loss)
I0815 09:30:23.648607   668 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0815 09:30:28.532260   668 solver.cpp:228] Iteration 2620, loss = 0.0710185
I0815 09:30:28.532318   668 solver.cpp:244]     Train net output #0: loss1 = 0.0644178 (* 0.5 = 0.0322089 loss)
I0815 09:30:28.532335   668 solver.cpp:244]     Train net output #1: loss2 = 0.077619 (* 0.5 = 0.0388095 loss)
I0815 09:30:28.532346   668 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0815 09:30:33.415634   668 solver.cpp:228] Iteration 2640, loss = 0.128757
I0815 09:30:33.415694   668 solver.cpp:244]     Train net output #0: loss1 = 0.0194745 (* 0.5 = 0.00973723 loss)
I0815 09:30:33.415710   668 solver.cpp:244]     Train net output #1: loss2 = 0.238039 (* 0.5 = 0.119019 loss)
I0815 09:30:33.415724   668 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0815 09:30:38.301048   668 solver.cpp:228] Iteration 2660, loss = 0.0991943
I0815 09:30:38.301106   668 solver.cpp:244]     Train net output #0: loss1 = 0.014466 (* 0.5 = 0.00723298 loss)
I0815 09:30:38.301121   668 solver.cpp:244]     Train net output #1: loss2 = 0.183922 (* 0.5 = 0.0919612 loss)
I0815 09:30:38.301134   668 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0815 09:30:43.188280   668 solver.cpp:228] Iteration 2680, loss = 0.07831
I0815 09:30:43.188338   668 solver.cpp:244]     Train net output #0: loss1 = 0.0563091 (* 0.5 = 0.0281545 loss)
I0815 09:30:43.188354   668 solver.cpp:244]     Train net output #1: loss2 = 0.100311 (* 0.5 = 0.0501554 loss)
I0815 09:30:43.188366   668 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0815 09:30:48.073716   668 solver.cpp:228] Iteration 2700, loss = 0.100625
I0815 09:30:48.073834   668 solver.cpp:244]     Train net output #0: loss1 = 0.0551751 (* 0.5 = 0.0275875 loss)
I0815 09:30:48.073851   668 solver.cpp:244]     Train net output #1: loss2 = 0.146075 (* 0.5 = 0.0730373 loss)
I0815 09:30:48.073863   668 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0815 09:30:52.959270   668 solver.cpp:228] Iteration 2720, loss = 0.134274
I0815 09:30:52.959327   668 solver.cpp:244]     Train net output #0: loss1 = 0.0278978 (* 0.5 = 0.0139489 loss)
I0815 09:30:52.959343   668 solver.cpp:244]     Train net output #1: loss2 = 0.24065 (* 0.5 = 0.120325 loss)
I0815 09:30:52.959357   668 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0815 09:30:57.908983   668 solver.cpp:228] Iteration 2740, loss = 0.069002
I0815 09:30:57.909044   668 solver.cpp:244]     Train net output #0: loss1 = 0.0691229 (* 0.5 = 0.0345615 loss)
I0815 09:30:57.909059   668 solver.cpp:244]     Train net output #1: loss2 = 0.0688808 (* 0.5 = 0.0344404 loss)
I0815 09:30:57.909071   668 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0815 09:31:02.865509   668 solver.cpp:228] Iteration 2760, loss = 0.0963503
I0815 09:31:02.865566   668 solver.cpp:244]     Train net output #0: loss1 = 0.045879 (* 0.5 = 0.0229395 loss)
I0815 09:31:02.865581   668 solver.cpp:244]     Train net output #1: loss2 = 0.146821 (* 0.5 = 0.0734107 loss)
I0815 09:31:02.865593   668 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0815 09:31:07.803537   668 solver.cpp:228] Iteration 2780, loss = 0.0976879
I0815 09:31:07.803596   668 solver.cpp:244]     Train net output #0: loss1 = 0.0226112 (* 0.5 = 0.0113056 loss)
I0815 09:31:07.803612   668 solver.cpp:244]     Train net output #1: loss2 = 0.172764 (* 0.5 = 0.0863821 loss)
I0815 09:31:07.803625   668 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0815 09:31:12.771266   668 solver.cpp:228] Iteration 2800, loss = 0.0635182
I0815 09:31:12.771325   668 solver.cpp:244]     Train net output #0: loss1 = 0.0153327 (* 0.5 = 0.00766633 loss)
I0815 09:31:12.771342   668 solver.cpp:244]     Train net output #1: loss2 = 0.111704 (* 0.5 = 0.0558518 loss)
I0815 09:31:12.771354   668 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0815 09:31:17.717440   668 solver.cpp:228] Iteration 2820, loss = 0.0740347
I0815 09:31:17.717499   668 solver.cpp:244]     Train net output #0: loss1 = 0.0526038 (* 0.5 = 0.0263019 loss)
I0815 09:31:17.717515   668 solver.cpp:244]     Train net output #1: loss2 = 0.0954654 (* 0.5 = 0.0477327 loss)
I0815 09:31:17.717528   668 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0815 09:31:22.654904   668 solver.cpp:228] Iteration 2840, loss = 0.0717762
I0815 09:31:22.654991   668 solver.cpp:244]     Train net output #0: loss1 = 0.0458286 (* 0.5 = 0.0229143 loss)
I0815 09:31:22.655004   668 solver.cpp:244]     Train net output #1: loss2 = 0.0977236 (* 0.5 = 0.0488618 loss)
I0815 09:31:22.655014   668 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0815 09:31:27.639883   668 solver.cpp:228] Iteration 2860, loss = 0.0880302
I0815 09:31:27.639940   668 solver.cpp:244]     Train net output #0: loss1 = 0.0482047 (* 0.5 = 0.0241023 loss)
I0815 09:31:27.639955   668 solver.cpp:244]     Train net output #1: loss2 = 0.127855 (* 0.5 = 0.0639277 loss)
I0815 09:31:27.639967   668 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0815 09:31:32.613361   668 solver.cpp:228] Iteration 2880, loss = 0.115956
I0815 09:31:32.613420   668 solver.cpp:244]     Train net output #0: loss1 = 0.0482776 (* 0.5 = 0.0241388 loss)
I0815 09:31:32.613435   668 solver.cpp:244]     Train net output #1: loss2 = 0.183634 (* 0.5 = 0.0918172 loss)
I0815 09:31:32.613447   668 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0815 09:31:37.573863   668 solver.cpp:228] Iteration 2900, loss = 0.0638368
I0815 09:31:37.573923   668 solver.cpp:244]     Train net output #0: loss1 = 0.0246417 (* 0.5 = 0.0123209 loss)
I0815 09:31:37.573938   668 solver.cpp:244]     Train net output #1: loss2 = 0.103032 (* 0.5 = 0.0515158 loss)
I0815 09:31:37.573951   668 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0815 09:31:42.516856   668 solver.cpp:228] Iteration 2920, loss = 0.131006
I0815 09:31:42.516916   668 solver.cpp:244]     Train net output #0: loss1 = 0.085416 (* 0.5 = 0.042708 loss)
I0815 09:31:42.516930   668 solver.cpp:244]     Train net output #1: loss2 = 0.176596 (* 0.5 = 0.0882982 loss)
I0815 09:31:42.516943   668 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0815 09:31:47.438767   668 solver.cpp:228] Iteration 2940, loss = 0.060524
I0815 09:31:47.438825   668 solver.cpp:244]     Train net output #0: loss1 = 0.0175902 (* 0.5 = 0.00879511 loss)
I0815 09:31:47.438841   668 solver.cpp:244]     Train net output #1: loss2 = 0.103458 (* 0.5 = 0.0517288 loss)
I0815 09:31:47.438853   668 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0815 09:31:52.349427   668 solver.cpp:228] Iteration 2960, loss = 0.104899
I0815 09:31:52.349483   668 solver.cpp:244]     Train net output #0: loss1 = 0.0774642 (* 0.5 = 0.0387321 loss)
I0815 09:31:52.349499   668 solver.cpp:244]     Train net output #1: loss2 = 0.132333 (* 0.5 = 0.0661666 loss)
I0815 09:31:52.349511   668 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0815 09:31:57.335543   668 solver.cpp:228] Iteration 2980, loss = 0.0724944
I0815 09:31:57.335706   668 solver.cpp:244]     Train net output #0: loss1 = 0.0151 (* 0.5 = 0.00755001 loss)
I0815 09:31:57.335731   668 solver.cpp:244]     Train net output #1: loss2 = 0.129888 (* 0.5 = 0.0649442 loss)
I0815 09:31:57.335747   668 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0815 09:32:02.021437   668 solver.cpp:337] Iteration 3000, Testing net (#0)
I0815 09:32:59.635938   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.833859
I0815 09:32:59.636049   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.9515
I0815 09:32:59.636068   668 solver.cpp:404]     Test net output #2: loss1 = 0.170507 (* 0.5 = 0.0852536 loss)
I0815 09:32:59.636081   668 solver.cpp:404]     Test net output #3: loss2 = 0.410484 (* 0.5 = 0.205242 loss)
I0815 09:32:59.710656   668 solver.cpp:228] Iteration 3000, loss = 0.0716645
I0815 09:32:59.710710   668 solver.cpp:244]     Train net output #0: loss1 = 0.0439657 (* 0.5 = 0.0219828 loss)
I0815 09:32:59.710724   668 solver.cpp:244]     Train net output #1: loss2 = 0.0993632 (* 0.5 = 0.0496816 loss)
I0815 09:32:59.710737   668 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0815 09:33:04.603214   668 solver.cpp:228] Iteration 3020, loss = 0.0644104
I0815 09:33:04.603276   668 solver.cpp:244]     Train net output #0: loss1 = 0.0106842 (* 0.5 = 0.0053421 loss)
I0815 09:33:04.603291   668 solver.cpp:244]     Train net output #1: loss2 = 0.118136 (* 0.5 = 0.0590682 loss)
I0815 09:33:04.603303   668 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0815 09:33:09.495225   668 solver.cpp:228] Iteration 3040, loss = 0.0759235
I0815 09:33:09.495285   668 solver.cpp:244]     Train net output #0: loss1 = 0.0306148 (* 0.5 = 0.0153074 loss)
I0815 09:33:09.495301   668 solver.cpp:244]     Train net output #1: loss2 = 0.121232 (* 0.5 = 0.060616 loss)
I0815 09:33:09.495313   668 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0815 09:33:14.397552   668 solver.cpp:228] Iteration 3060, loss = 0.12528
I0815 09:33:14.397604   668 solver.cpp:244]     Train net output #0: loss1 = 0.119533 (* 0.5 = 0.0597665 loss)
I0815 09:33:14.397619   668 solver.cpp:244]     Train net output #1: loss2 = 0.131026 (* 0.5 = 0.0655132 loss)
I0815 09:33:14.397632   668 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0815 09:33:19.297612   668 solver.cpp:228] Iteration 3080, loss = 0.0921424
I0815 09:33:19.297668   668 solver.cpp:244]     Train net output #0: loss1 = 0.0405555 (* 0.5 = 0.0202777 loss)
I0815 09:33:19.297683   668 solver.cpp:244]     Train net output #1: loss2 = 0.143729 (* 0.5 = 0.0718645 loss)
I0815 09:33:19.297695   668 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0815 09:33:24.209856   668 solver.cpp:228] Iteration 3100, loss = 0.0467702
I0815 09:33:24.209909   668 solver.cpp:244]     Train net output #0: loss1 = 0.0200413 (* 0.5 = 0.0100206 loss)
I0815 09:33:24.209925   668 solver.cpp:244]     Train net output #1: loss2 = 0.0734988 (* 0.5 = 0.0367494 loss)
I0815 09:33:24.209938   668 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0815 09:33:29.101426   668 solver.cpp:228] Iteration 3120, loss = 0.109231
I0815 09:33:29.101482   668 solver.cpp:244]     Train net output #0: loss1 = 0.0262881 (* 0.5 = 0.0131441 loss)
I0815 09:33:29.101498   668 solver.cpp:244]     Train net output #1: loss2 = 0.192174 (* 0.5 = 0.0960869 loss)
I0815 09:33:29.101511   668 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0815 09:33:34.006261   668 solver.cpp:228] Iteration 3140, loss = 0.0788241
I0815 09:33:34.006412   668 solver.cpp:244]     Train net output #0: loss1 = 0.0361066 (* 0.5 = 0.0180533 loss)
I0815 09:33:34.006429   668 solver.cpp:244]     Train net output #1: loss2 = 0.121541 (* 0.5 = 0.0607706 loss)
I0815 09:33:34.006443   668 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0815 09:33:38.898648   668 solver.cpp:228] Iteration 3160, loss = 0.0817603
I0815 09:33:38.898699   668 solver.cpp:244]     Train net output #0: loss1 = 0.0365688 (* 0.5 = 0.0182844 loss)
I0815 09:33:38.898713   668 solver.cpp:244]     Train net output #1: loss2 = 0.126952 (* 0.5 = 0.0634758 loss)
I0815 09:33:38.898725   668 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0815 09:33:43.793323   668 solver.cpp:228] Iteration 3180, loss = 0.0786316
I0815 09:33:43.793380   668 solver.cpp:244]     Train net output #0: loss1 = 0.0964384 (* 0.5 = 0.0482192 loss)
I0815 09:33:43.793395   668 solver.cpp:244]     Train net output #1: loss2 = 0.0608246 (* 0.5 = 0.0304123 loss)
I0815 09:33:43.793406   668 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0815 09:33:48.686169   668 solver.cpp:228] Iteration 3200, loss = 0.0742367
I0815 09:33:48.686223   668 solver.cpp:244]     Train net output #0: loss1 = 0.022374 (* 0.5 = 0.011187 loss)
I0815 09:33:48.686238   668 solver.cpp:244]     Train net output #1: loss2 = 0.126099 (* 0.5 = 0.0630496 loss)
I0815 09:33:48.686250   668 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0815 09:33:53.577844   668 solver.cpp:228] Iteration 3220, loss = 0.0754842
I0815 09:33:53.577903   668 solver.cpp:244]     Train net output #0: loss1 = 0.0290902 (* 0.5 = 0.0145451 loss)
I0815 09:33:53.577919   668 solver.cpp:244]     Train net output #1: loss2 = 0.121878 (* 0.5 = 0.060939 loss)
I0815 09:33:53.577931   668 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0815 09:33:58.482622   668 solver.cpp:228] Iteration 3240, loss = 0.0636477
I0815 09:33:58.482676   668 solver.cpp:244]     Train net output #0: loss1 = 0.0265082 (* 0.5 = 0.0132541 loss)
I0815 09:33:58.482692   668 solver.cpp:244]     Train net output #1: loss2 = 0.100787 (* 0.5 = 0.0503935 loss)
I0815 09:33:58.482704   668 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0815 09:34:03.392652   668 solver.cpp:228] Iteration 3260, loss = 0.0748464
I0815 09:34:03.392709   668 solver.cpp:244]     Train net output #0: loss1 = 0.0172419 (* 0.5 = 0.00862096 loss)
I0815 09:34:03.392724   668 solver.cpp:244]     Train net output #1: loss2 = 0.132451 (* 0.5 = 0.0662254 loss)
I0815 09:34:03.392740   668 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0815 09:34:08.295590   668 solver.cpp:228] Iteration 3280, loss = 0.0654599
I0815 09:34:08.295737   668 solver.cpp:244]     Train net output #0: loss1 = 0.0127002 (* 0.5 = 0.0063501 loss)
I0815 09:34:08.295754   668 solver.cpp:244]     Train net output #1: loss2 = 0.118219 (* 0.5 = 0.0591097 loss)
I0815 09:34:08.295766   668 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0815 09:34:13.209756   668 solver.cpp:228] Iteration 3300, loss = 0.0730231
I0815 09:34:13.209815   668 solver.cpp:244]     Train net output #0: loss1 = 0.032045 (* 0.5 = 0.0160225 loss)
I0815 09:34:13.209831   668 solver.cpp:244]     Train net output #1: loss2 = 0.114001 (* 0.5 = 0.0570005 loss)
I0815 09:34:13.209843   668 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0815 09:34:18.107846   668 solver.cpp:228] Iteration 3320, loss = 0.0647723
I0815 09:34:18.107900   668 solver.cpp:244]     Train net output #0: loss1 = 0.0238163 (* 0.5 = 0.0119082 loss)
I0815 09:34:18.107915   668 solver.cpp:244]     Train net output #1: loss2 = 0.105728 (* 0.5 = 0.0528641 loss)
I0815 09:34:18.107928   668 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0815 09:34:23.010489   668 solver.cpp:228] Iteration 3340, loss = 0.0565736
I0815 09:34:23.010545   668 solver.cpp:244]     Train net output #0: loss1 = 0.0326009 (* 0.5 = 0.0163004 loss)
I0815 09:34:23.010565   668 solver.cpp:244]     Train net output #1: loss2 = 0.0805461 (* 0.5 = 0.0402731 loss)
I0815 09:34:23.010579   668 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0815 09:34:27.915294   668 solver.cpp:228] Iteration 3360, loss = 0.124298
I0815 09:34:27.915349   668 solver.cpp:244]     Train net output #0: loss1 = 0.094332 (* 0.5 = 0.047166 loss)
I0815 09:34:27.915364   668 solver.cpp:244]     Train net output #1: loss2 = 0.154264 (* 0.5 = 0.077132 loss)
I0815 09:34:27.915376   668 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0815 09:34:32.821797   668 solver.cpp:228] Iteration 3380, loss = 0.141866
I0815 09:34:32.821858   668 solver.cpp:244]     Train net output #0: loss1 = 0.0630257 (* 0.5 = 0.0315128 loss)
I0815 09:34:32.821874   668 solver.cpp:244]     Train net output #1: loss2 = 0.220706 (* 0.5 = 0.110353 loss)
I0815 09:34:32.821887   668 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0815 09:34:37.724861   668 solver.cpp:228] Iteration 3400, loss = 0.0808793
I0815 09:34:37.724920   668 solver.cpp:244]     Train net output #0: loss1 = 0.0709234 (* 0.5 = 0.0354617 loss)
I0815 09:34:37.724934   668 solver.cpp:244]     Train net output #1: loss2 = 0.0908349 (* 0.5 = 0.0454175 loss)
I0815 09:34:37.724947   668 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0815 09:34:42.631472   668 solver.cpp:228] Iteration 3420, loss = 0.105739
I0815 09:34:42.631590   668 solver.cpp:244]     Train net output #0: loss1 = 0.064024 (* 0.5 = 0.032012 loss)
I0815 09:34:42.631606   668 solver.cpp:244]     Train net output #1: loss2 = 0.147453 (* 0.5 = 0.0737265 loss)
I0815 09:34:42.631619   668 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0815 09:34:47.560108   668 solver.cpp:228] Iteration 3440, loss = 0.138624
I0815 09:34:47.560168   668 solver.cpp:244]     Train net output #0: loss1 = 0.112637 (* 0.5 = 0.0563185 loss)
I0815 09:34:47.560183   668 solver.cpp:244]     Train net output #1: loss2 = 0.164611 (* 0.5 = 0.0823056 loss)
I0815 09:34:47.560195   668 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0815 09:34:52.517361   668 solver.cpp:228] Iteration 3460, loss = 0.0762076
I0815 09:34:52.517421   668 solver.cpp:244]     Train net output #0: loss1 = 0.0236764 (* 0.5 = 0.0118382 loss)
I0815 09:34:52.517436   668 solver.cpp:244]     Train net output #1: loss2 = 0.128739 (* 0.5 = 0.0643693 loss)
I0815 09:34:52.517449   668 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0815 09:34:57.437878   668 solver.cpp:228] Iteration 3480, loss = 0.0939538
I0815 09:34:57.437935   668 solver.cpp:244]     Train net output #0: loss1 = 0.024632 (* 0.5 = 0.012316 loss)
I0815 09:34:57.437952   668 solver.cpp:244]     Train net output #1: loss2 = 0.163275 (* 0.5 = 0.0816376 loss)
I0815 09:34:57.437963   668 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0815 09:35:02.355851   668 solver.cpp:228] Iteration 3500, loss = 0.0839999
I0815 09:35:02.355906   668 solver.cpp:244]     Train net output #0: loss1 = 0.0462495 (* 0.5 = 0.0231248 loss)
I0815 09:35:02.355922   668 solver.cpp:244]     Train net output #1: loss2 = 0.12175 (* 0.5 = 0.060875 loss)
I0815 09:35:02.355936   668 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0815 09:35:07.257513   668 solver.cpp:228] Iteration 3520, loss = 0.0937008
I0815 09:35:07.257570   668 solver.cpp:244]     Train net output #0: loss1 = 0.0532852 (* 0.5 = 0.0266426 loss)
I0815 09:35:07.257586   668 solver.cpp:244]     Train net output #1: loss2 = 0.134116 (* 0.5 = 0.067058 loss)
I0815 09:35:07.257598   668 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0815 09:35:12.157845   668 solver.cpp:228] Iteration 3540, loss = 0.127476
I0815 09:35:12.157901   668 solver.cpp:244]     Train net output #0: loss1 = 0.0510037 (* 0.5 = 0.0255018 loss)
I0815 09:35:12.157917   668 solver.cpp:244]     Train net output #1: loss2 = 0.203949 (* 0.5 = 0.101974 loss)
I0815 09:35:12.157928   668 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0815 09:35:17.060740   668 solver.cpp:228] Iteration 3560, loss = 0.0973486
I0815 09:35:17.060885   668 solver.cpp:244]     Train net output #0: loss1 = 0.07003 (* 0.5 = 0.035015 loss)
I0815 09:35:17.060902   668 solver.cpp:244]     Train net output #1: loss2 = 0.124667 (* 0.5 = 0.0623335 loss)
I0815 09:35:17.060914   668 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0815 09:35:21.954174   668 solver.cpp:228] Iteration 3580, loss = 0.120781
I0815 09:35:21.954233   668 solver.cpp:244]     Train net output #0: loss1 = 0.0714075 (* 0.5 = 0.0357038 loss)
I0815 09:35:21.954248   668 solver.cpp:244]     Train net output #1: loss2 = 0.170154 (* 0.5 = 0.0850772 loss)
I0815 09:35:21.954262   668 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0815 09:35:26.843379   668 solver.cpp:228] Iteration 3600, loss = 0.118779
I0815 09:35:26.843435   668 solver.cpp:244]     Train net output #0: loss1 = 0.0570344 (* 0.5 = 0.0285172 loss)
I0815 09:35:26.843451   668 solver.cpp:244]     Train net output #1: loss2 = 0.180523 (* 0.5 = 0.0902614 loss)
I0815 09:35:26.843463   668 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0815 09:35:31.729497   668 solver.cpp:228] Iteration 3620, loss = 0.106776
I0815 09:35:31.729557   668 solver.cpp:244]     Train net output #0: loss1 = 0.081861 (* 0.5 = 0.0409305 loss)
I0815 09:35:31.729573   668 solver.cpp:244]     Train net output #1: loss2 = 0.131691 (* 0.5 = 0.0658453 loss)
I0815 09:35:31.729584   668 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0815 09:35:36.633502   668 solver.cpp:228] Iteration 3640, loss = 0.0709834
I0815 09:35:36.633560   668 solver.cpp:244]     Train net output #0: loss1 = 0.0673704 (* 0.5 = 0.0336852 loss)
I0815 09:35:36.633576   668 solver.cpp:244]     Train net output #1: loss2 = 0.0745961 (* 0.5 = 0.0372981 loss)
I0815 09:35:36.633589   668 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0815 09:35:41.562872   668 solver.cpp:228] Iteration 3660, loss = 0.0805539
I0815 09:35:41.562928   668 solver.cpp:244]     Train net output #0: loss1 = 0.00901554 (* 0.5 = 0.00450777 loss)
I0815 09:35:41.562943   668 solver.cpp:244]     Train net output #1: loss2 = 0.152092 (* 0.5 = 0.076046 loss)
I0815 09:35:41.562955   668 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0815 09:35:46.475217   668 solver.cpp:228] Iteration 3680, loss = 0.0668583
I0815 09:35:46.475275   668 solver.cpp:244]     Train net output #0: loss1 = 0.0353159 (* 0.5 = 0.017658 loss)
I0815 09:35:46.475289   668 solver.cpp:244]     Train net output #1: loss2 = 0.0984004 (* 0.5 = 0.0492002 loss)
I0815 09:35:46.475302   668 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0815 09:35:51.387050   668 solver.cpp:228] Iteration 3700, loss = 0.153735
I0815 09:35:51.390660   668 solver.cpp:244]     Train net output #0: loss1 = 0.0932694 (* 0.5 = 0.0466347 loss)
I0815 09:35:51.390687   668 solver.cpp:244]     Train net output #1: loss2 = 0.214201 (* 0.5 = 0.107101 loss)
I0815 09:35:51.390702   668 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0815 09:35:56.301729   668 solver.cpp:228] Iteration 3720, loss = 0.0612606
I0815 09:35:56.301784   668 solver.cpp:244]     Train net output #0: loss1 = 0.0434312 (* 0.5 = 0.0217156 loss)
I0815 09:35:56.301800   668 solver.cpp:244]     Train net output #1: loss2 = 0.0790898 (* 0.5 = 0.0395449 loss)
I0815 09:35:56.301812   668 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0815 09:36:01.256497   668 solver.cpp:228] Iteration 3740, loss = 0.0625886
I0815 09:36:01.256557   668 solver.cpp:244]     Train net output #0: loss1 = 0.0237593 (* 0.5 = 0.0118797 loss)
I0815 09:36:01.256573   668 solver.cpp:244]     Train net output #1: loss2 = 0.101418 (* 0.5 = 0.0507089 loss)
I0815 09:36:01.256585   668 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0815 09:36:06.206538   668 solver.cpp:228] Iteration 3760, loss = 0.0976855
I0815 09:36:06.206609   668 solver.cpp:244]     Train net output #0: loss1 = 0.0292582 (* 0.5 = 0.0146291 loss)
I0815 09:36:06.206625   668 solver.cpp:244]     Train net output #1: loss2 = 0.166113 (* 0.5 = 0.0830563 loss)
I0815 09:36:06.206637   668 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0815 09:36:11.155683   668 solver.cpp:228] Iteration 3780, loss = 0.11443
I0815 09:36:11.155741   668 solver.cpp:244]     Train net output #0: loss1 = 0.0629463 (* 0.5 = 0.0314731 loss)
I0815 09:36:11.155757   668 solver.cpp:244]     Train net output #1: loss2 = 0.165914 (* 0.5 = 0.0829568 loss)
I0815 09:36:11.155769   668 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0815 09:36:16.138908   668 solver.cpp:228] Iteration 3800, loss = 0.0877858
I0815 09:36:16.138962   668 solver.cpp:244]     Train net output #0: loss1 = 0.0124127 (* 0.5 = 0.00620634 loss)
I0815 09:36:16.138978   668 solver.cpp:244]     Train net output #1: loss2 = 0.163159 (* 0.5 = 0.0815793 loss)
I0815 09:36:16.138990   668 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0815 09:36:21.121503   668 solver.cpp:228] Iteration 3820, loss = 0.0769894
I0815 09:36:21.121563   668 solver.cpp:244]     Train net output #0: loss1 = 0.0415239 (* 0.5 = 0.020762 loss)
I0815 09:36:21.121579   668 solver.cpp:244]     Train net output #1: loss2 = 0.112455 (* 0.5 = 0.0562273 loss)
I0815 09:36:21.121593   668 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0815 09:36:26.035959   668 solver.cpp:228] Iteration 3840, loss = 0.0729603
I0815 09:36:26.036140   668 solver.cpp:244]     Train net output #0: loss1 = 0.0456339 (* 0.5 = 0.022817 loss)
I0815 09:36:26.036187   668 solver.cpp:244]     Train net output #1: loss2 = 0.100286 (* 0.5 = 0.0501432 loss)
I0815 09:36:26.036208   668 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0815 09:36:30.936425   668 solver.cpp:228] Iteration 3860, loss = 0.0867329
I0815 09:36:30.936476   668 solver.cpp:244]     Train net output #0: loss1 = 0.0333068 (* 0.5 = 0.0166534 loss)
I0815 09:36:30.936491   668 solver.cpp:244]     Train net output #1: loss2 = 0.140159 (* 0.5 = 0.0700793 loss)
I0815 09:36:30.936504   668 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0815 09:36:35.861645   668 solver.cpp:228] Iteration 3880, loss = 0.154833
I0815 09:36:35.861697   668 solver.cpp:244]     Train net output #0: loss1 = 0.157043 (* 0.5 = 0.0785217 loss)
I0815 09:36:35.861713   668 solver.cpp:244]     Train net output #1: loss2 = 0.152623 (* 0.5 = 0.0763114 loss)
I0815 09:36:35.861726   668 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0815 09:36:40.775571   668 solver.cpp:228] Iteration 3900, loss = 0.0637268
I0815 09:36:40.775629   668 solver.cpp:244]     Train net output #0: loss1 = 0.022046 (* 0.5 = 0.011023 loss)
I0815 09:36:40.775645   668 solver.cpp:244]     Train net output #1: loss2 = 0.105407 (* 0.5 = 0.0527037 loss)
I0815 09:36:40.775657   668 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0815 09:36:45.672014   668 solver.cpp:228] Iteration 3920, loss = 0.0986864
I0815 09:36:45.672073   668 solver.cpp:244]     Train net output #0: loss1 = 0.0447862 (* 0.5 = 0.0223931 loss)
I0815 09:36:45.672088   668 solver.cpp:244]     Train net output #1: loss2 = 0.152586 (* 0.5 = 0.0762932 loss)
I0815 09:36:45.672101   668 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0815 09:36:50.590405   668 solver.cpp:228] Iteration 3940, loss = 0.0773226
I0815 09:36:50.590463   668 solver.cpp:244]     Train net output #0: loss1 = 0.0401171 (* 0.5 = 0.0200585 loss)
I0815 09:36:50.590479   668 solver.cpp:244]     Train net output #1: loss2 = 0.114528 (* 0.5 = 0.057264 loss)
I0815 09:36:50.590492   668 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0815 09:36:55.505182   668 solver.cpp:228] Iteration 3960, loss = 0.112027
I0815 09:36:55.505239   668 solver.cpp:244]     Train net output #0: loss1 = 0.0225178 (* 0.5 = 0.0112589 loss)
I0815 09:36:55.505254   668 solver.cpp:244]     Train net output #1: loss2 = 0.201535 (* 0.5 = 0.100768 loss)
I0815 09:36:55.505267   668 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0815 09:37:00.462843   668 solver.cpp:228] Iteration 3980, loss = 0.0737234
I0815 09:37:00.462983   668 solver.cpp:244]     Train net output #0: loss1 = 0.0401325 (* 0.5 = 0.0200662 loss)
I0815 09:37:00.463001   668 solver.cpp:244]     Train net output #1: loss2 = 0.107314 (* 0.5 = 0.053657 loss)
I0815 09:37:00.463013   668 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0815 09:37:05.116118   668 solver.cpp:337] Iteration 4000, Testing net (#0)
I0815 09:38:02.862285   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.834828
I0815 09:38:02.862397   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.952375
I0815 09:38:02.862416   668 solver.cpp:404]     Test net output #2: loss1 = 0.158807 (* 0.5 = 0.0794033 loss)
I0815 09:38:02.862429   668 solver.cpp:404]     Test net output #3: loss2 = 0.411068 (* 0.5 = 0.205534 loss)
I0815 09:38:02.936254   668 solver.cpp:228] Iteration 4000, loss = 0.0927323
I0815 09:38:02.936305   668 solver.cpp:244]     Train net output #0: loss1 = 0.0936922 (* 0.5 = 0.0468461 loss)
I0815 09:38:02.936319   668 solver.cpp:244]     Train net output #1: loss2 = 0.0917722 (* 0.5 = 0.0458861 loss)
I0815 09:38:02.936332   668 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0815 09:38:07.878336   668 solver.cpp:228] Iteration 4020, loss = 0.122866
I0815 09:38:07.878392   668 solver.cpp:244]     Train net output #0: loss1 = 0.106264 (* 0.5 = 0.0531322 loss)
I0815 09:38:07.878407   668 solver.cpp:244]     Train net output #1: loss2 = 0.139468 (* 0.5 = 0.0697338 loss)
I0815 09:38:07.878420   668 sgd_solver.cpp:106] Iteration 4020, lr = 0.0001
I0815 09:38:12.783509   668 solver.cpp:228] Iteration 4040, loss = 0.104788
I0815 09:38:12.783565   668 solver.cpp:244]     Train net output #0: loss1 = 0.0504119 (* 0.5 = 0.025206 loss)
I0815 09:38:12.783581   668 solver.cpp:244]     Train net output #1: loss2 = 0.159163 (* 0.5 = 0.0795816 loss)
I0815 09:38:12.783593   668 sgd_solver.cpp:106] Iteration 4040, lr = 0.0001
I0815 09:38:17.708240   668 solver.cpp:228] Iteration 4060, loss = 0.0461474
I0815 09:38:17.708297   668 solver.cpp:244]     Train net output #0: loss1 = 0.0161067 (* 0.5 = 0.00805333 loss)
I0815 09:38:17.708313   668 solver.cpp:244]     Train net output #1: loss2 = 0.076188 (* 0.5 = 0.038094 loss)
I0815 09:38:17.708325   668 sgd_solver.cpp:106] Iteration 4060, lr = 0.0001
I0815 09:38:22.681499   668 solver.cpp:228] Iteration 4080, loss = 0.0736017
I0815 09:38:22.681566   668 solver.cpp:244]     Train net output #0: loss1 = 0.0188459 (* 0.5 = 0.00942294 loss)
I0815 09:38:22.681581   668 solver.cpp:244]     Train net output #1: loss2 = 0.128357 (* 0.5 = 0.0641787 loss)
I0815 09:38:22.681594   668 sgd_solver.cpp:106] Iteration 4080, lr = 0.0001
I0815 09:38:27.614626   668 solver.cpp:228] Iteration 4100, loss = 0.0449022
I0815 09:38:27.614686   668 solver.cpp:244]     Train net output #0: loss1 = 0.0205988 (* 0.5 = 0.0102994 loss)
I0815 09:38:27.614701   668 solver.cpp:244]     Train net output #1: loss2 = 0.0692054 (* 0.5 = 0.0346027 loss)
I0815 09:38:27.614713   668 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0815 09:38:32.504060   668 solver.cpp:228] Iteration 4120, loss = 0.0713745
I0815 09:38:32.504115   668 solver.cpp:244]     Train net output #0: loss1 = 0.024218 (* 0.5 = 0.012109 loss)
I0815 09:38:32.504130   668 solver.cpp:244]     Train net output #1: loss2 = 0.118531 (* 0.5 = 0.0592654 loss)
I0815 09:38:32.504143   668 sgd_solver.cpp:106] Iteration 4120, lr = 0.0001
I0815 09:38:37.427453   668 solver.cpp:228] Iteration 4140, loss = 0.080914
I0815 09:38:37.430649   668 solver.cpp:244]     Train net output #0: loss1 = 0.052905 (* 0.5 = 0.0264525 loss)
I0815 09:38:37.430675   668 solver.cpp:244]     Train net output #1: loss2 = 0.108923 (* 0.5 = 0.0544614 loss)
I0815 09:38:37.430691   668 sgd_solver.cpp:106] Iteration 4140, lr = 0.0001
I0815 09:38:42.323398   668 solver.cpp:228] Iteration 4160, loss = 0.0524441
I0815 09:38:42.323457   668 solver.cpp:244]     Train net output #0: loss1 = 0.0151643 (* 0.5 = 0.00758216 loss)
I0815 09:38:42.323472   668 solver.cpp:244]     Train net output #1: loss2 = 0.0897237 (* 0.5 = 0.0448618 loss)
I0815 09:38:42.323487   668 sgd_solver.cpp:106] Iteration 4160, lr = 0.0001
I0815 09:38:47.227814   668 solver.cpp:228] Iteration 4180, loss = 0.0830901
I0815 09:38:47.227870   668 solver.cpp:244]     Train net output #0: loss1 = 0.0626603 (* 0.5 = 0.0313302 loss)
I0815 09:38:47.227886   668 solver.cpp:244]     Train net output #1: loss2 = 0.10352 (* 0.5 = 0.0517598 loss)
I0815 09:38:47.227900   668 sgd_solver.cpp:106] Iteration 4180, lr = 0.0001
I0815 09:38:52.132956   668 solver.cpp:228] Iteration 4200, loss = 0.0873067
I0815 09:38:52.132999   668 solver.cpp:244]     Train net output #0: loss1 = 0.0233595 (* 0.5 = 0.0116797 loss)
I0815 09:38:52.133010   668 solver.cpp:244]     Train net output #1: loss2 = 0.151254 (* 0.5 = 0.0756268 loss)
I0815 09:38:52.133019   668 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0815 09:38:57.070916   668 solver.cpp:228] Iteration 4220, loss = 0.0620854
I0815 09:38:57.070971   668 solver.cpp:244]     Train net output #0: loss1 = 0.0481017 (* 0.5 = 0.0240509 loss)
I0815 09:38:57.070986   668 solver.cpp:244]     Train net output #1: loss2 = 0.0760689 (* 0.5 = 0.0380345 loss)
I0815 09:38:57.070999   668 sgd_solver.cpp:106] Iteration 4220, lr = 0.0001
I0815 09:39:01.972131   668 solver.cpp:228] Iteration 4240, loss = 0.0800919
I0815 09:39:01.972187   668 solver.cpp:244]     Train net output #0: loss1 = 0.015667 (* 0.5 = 0.00783352 loss)
I0815 09:39:01.972203   668 solver.cpp:244]     Train net output #1: loss2 = 0.144516 (* 0.5 = 0.0722582 loss)
I0815 09:39:01.972215   668 sgd_solver.cpp:106] Iteration 4240, lr = 0.0001
I0815 09:39:06.864006   668 solver.cpp:228] Iteration 4260, loss = 0.0671517
I0815 09:39:06.864068   668 solver.cpp:244]     Train net output #0: loss1 = 0.0163833 (* 0.5 = 0.00819164 loss)
I0815 09:39:06.864084   668 solver.cpp:244]     Train net output #1: loss2 = 0.11792 (* 0.5 = 0.0589599 loss)
I0815 09:39:06.864097   668 sgd_solver.cpp:106] Iteration 4260, lr = 0.0001
I0815 09:39:11.766261   668 solver.cpp:228] Iteration 4280, loss = 0.158905
I0815 09:39:11.766374   668 solver.cpp:244]     Train net output #0: loss1 = 0.0481637 (* 0.5 = 0.0240819 loss)
I0815 09:39:11.766391   668 solver.cpp:244]     Train net output #1: loss2 = 0.269646 (* 0.5 = 0.134823 loss)
I0815 09:39:11.766407   668 sgd_solver.cpp:106] Iteration 4280, lr = 0.0001
I0815 09:39:16.677029   668 solver.cpp:228] Iteration 4300, loss = 0.113991
I0815 09:39:16.677084   668 solver.cpp:244]     Train net output #0: loss1 = 0.0344435 (* 0.5 = 0.0172218 loss)
I0815 09:39:16.677099   668 solver.cpp:244]     Train net output #1: loss2 = 0.193538 (* 0.5 = 0.0967689 loss)
I0815 09:39:16.677114   668 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0815 09:39:21.606994   668 solver.cpp:228] Iteration 4320, loss = 0.0730964
I0815 09:39:21.607051   668 solver.cpp:244]     Train net output #0: loss1 = 0.0378013 (* 0.5 = 0.0189006 loss)
I0815 09:39:21.607066   668 solver.cpp:244]     Train net output #1: loss2 = 0.108391 (* 0.5 = 0.0541957 loss)
I0815 09:39:21.607079   668 sgd_solver.cpp:106] Iteration 4320, lr = 0.0001
I0815 09:39:26.564484   668 solver.cpp:228] Iteration 4340, loss = 0.128646
I0815 09:39:26.564543   668 solver.cpp:244]     Train net output #0: loss1 = 0.0441461 (* 0.5 = 0.0220731 loss)
I0815 09:39:26.564559   668 solver.cpp:244]     Train net output #1: loss2 = 0.213145 (* 0.5 = 0.106573 loss)
I0815 09:39:26.564574   668 sgd_solver.cpp:106] Iteration 4340, lr = 0.0001
I0815 09:39:31.504554   668 solver.cpp:228] Iteration 4360, loss = 0.101243
I0815 09:39:31.504611   668 solver.cpp:244]     Train net output #0: loss1 = 0.0371473 (* 0.5 = 0.0185736 loss)
I0815 09:39:31.504627   668 solver.cpp:244]     Train net output #1: loss2 = 0.165338 (* 0.5 = 0.0826688 loss)
I0815 09:39:31.504640   668 sgd_solver.cpp:106] Iteration 4360, lr = 0.0001
I0815 09:39:36.410552   668 solver.cpp:228] Iteration 4380, loss = 0.0936454
I0815 09:39:36.410619   668 solver.cpp:244]     Train net output #0: loss1 = 0.0143875 (* 0.5 = 0.00719374 loss)
I0815 09:39:36.410634   668 solver.cpp:244]     Train net output #1: loss2 = 0.172903 (* 0.5 = 0.0864516 loss)
I0815 09:39:36.410647   668 sgd_solver.cpp:106] Iteration 4380, lr = 0.0001
I0815 09:39:41.316269   668 solver.cpp:228] Iteration 4400, loss = 0.0936796
I0815 09:39:41.316324   668 solver.cpp:244]     Train net output #0: loss1 = 0.0477244 (* 0.5 = 0.0238622 loss)
I0815 09:39:41.316340   668 solver.cpp:244]     Train net output #1: loss2 = 0.139635 (* 0.5 = 0.0698173 loss)
I0815 09:39:41.316352   668 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0815 09:39:46.212083   668 solver.cpp:228] Iteration 4420, loss = 0.0503152
I0815 09:39:46.214622   668 solver.cpp:244]     Train net output #0: loss1 = 0.0255991 (* 0.5 = 0.0127995 loss)
I0815 09:39:46.214642   668 solver.cpp:244]     Train net output #1: loss2 = 0.0750311 (* 0.5 = 0.0375155 loss)
I0815 09:39:46.214656   668 sgd_solver.cpp:106] Iteration 4420, lr = 0.0001
I0815 09:39:51.136047   668 solver.cpp:228] Iteration 4440, loss = 0.0657483
I0815 09:39:51.136103   668 solver.cpp:244]     Train net output #0: loss1 = 0.0429716 (* 0.5 = 0.0214858 loss)
I0815 09:39:51.136119   668 solver.cpp:244]     Train net output #1: loss2 = 0.0885247 (* 0.5 = 0.0442623 loss)
I0815 09:39:51.136132   668 sgd_solver.cpp:106] Iteration 4440, lr = 0.0001
I0815 09:39:56.035209   668 solver.cpp:228] Iteration 4460, loss = 0.0661505
I0815 09:39:56.035261   668 solver.cpp:244]     Train net output #0: loss1 = 0.0177077 (* 0.5 = 0.00885386 loss)
I0815 09:39:56.035277   668 solver.cpp:244]     Train net output #1: loss2 = 0.114593 (* 0.5 = 0.0572965 loss)
I0815 09:39:56.035303   668 sgd_solver.cpp:106] Iteration 4460, lr = 0.0001
I0815 09:40:00.935582   668 solver.cpp:228] Iteration 4480, loss = 0.0908647
I0815 09:40:00.935636   668 solver.cpp:244]     Train net output #0: loss1 = 0.0565564 (* 0.5 = 0.0282782 loss)
I0815 09:40:00.935652   668 solver.cpp:244]     Train net output #1: loss2 = 0.125173 (* 0.5 = 0.0625864 loss)
I0815 09:40:00.935663   668 sgd_solver.cpp:106] Iteration 4480, lr = 0.0001
I0815 09:40:05.837430   668 solver.cpp:228] Iteration 4500, loss = 0.0777685
I0815 09:40:05.837486   668 solver.cpp:244]     Train net output #0: loss1 = 0.050286 (* 0.5 = 0.025143 loss)
I0815 09:40:05.837502   668 solver.cpp:244]     Train net output #1: loss2 = 0.105251 (* 0.5 = 0.0526254 loss)
I0815 09:40:05.837514   668 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0815 09:40:10.729100   668 solver.cpp:228] Iteration 4520, loss = 0.096624
I0815 09:40:10.729161   668 solver.cpp:244]     Train net output #0: loss1 = 0.0420136 (* 0.5 = 0.0210068 loss)
I0815 09:40:10.729176   668 solver.cpp:244]     Train net output #1: loss2 = 0.151234 (* 0.5 = 0.0756172 loss)
I0815 09:40:10.729192   668 sgd_solver.cpp:106] Iteration 4520, lr = 0.0001
I0815 09:40:15.634810   668 solver.cpp:228] Iteration 4540, loss = 0.0704921
I0815 09:40:15.634867   668 solver.cpp:244]     Train net output #0: loss1 = 0.0350256 (* 0.5 = 0.0175128 loss)
I0815 09:40:15.634883   668 solver.cpp:244]     Train net output #1: loss2 = 0.105958 (* 0.5 = 0.0529791 loss)
I0815 09:40:15.634896   668 sgd_solver.cpp:106] Iteration 4540, lr = 0.0001
I0815 09:40:20.531270   668 solver.cpp:228] Iteration 4560, loss = 0.0911374
I0815 09:40:20.535022   668 solver.cpp:244]     Train net output #0: loss1 = 0.0435324 (* 0.5 = 0.0217662 loss)
I0815 09:40:20.535056   668 solver.cpp:244]     Train net output #1: loss2 = 0.138742 (* 0.5 = 0.0693711 loss)
I0815 09:40:20.535079   668 sgd_solver.cpp:106] Iteration 4560, lr = 0.0001
I0815 09:40:25.450186   668 solver.cpp:228] Iteration 4580, loss = 0.0424955
I0815 09:40:25.450245   668 solver.cpp:244]     Train net output #0: loss1 = 0.0215518 (* 0.5 = 0.0107759 loss)
I0815 09:40:25.450261   668 solver.cpp:244]     Train net output #1: loss2 = 0.063439 (* 0.5 = 0.0317195 loss)
I0815 09:40:25.450273   668 sgd_solver.cpp:106] Iteration 4580, lr = 0.0001
I0815 09:40:30.362661   668 solver.cpp:228] Iteration 4600, loss = 0.065566
I0815 09:40:30.362714   668 solver.cpp:244]     Train net output #0: loss1 = 0.018735 (* 0.5 = 0.00936752 loss)
I0815 09:40:30.362728   668 solver.cpp:244]     Train net output #1: loss2 = 0.112397 (* 0.5 = 0.0561984 loss)
I0815 09:40:30.362740   668 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0815 09:40:35.258378   668 solver.cpp:228] Iteration 4620, loss = 0.077605
I0815 09:40:35.258441   668 solver.cpp:244]     Train net output #0: loss1 = 0.0380811 (* 0.5 = 0.0190405 loss)
I0815 09:40:35.258456   668 solver.cpp:244]     Train net output #1: loss2 = 0.117129 (* 0.5 = 0.0585644 loss)
I0815 09:40:35.258471   668 sgd_solver.cpp:106] Iteration 4620, lr = 0.0001
I0815 09:40:40.152139   668 solver.cpp:228] Iteration 4640, loss = 0.0822947
I0815 09:40:40.152199   668 solver.cpp:244]     Train net output #0: loss1 = 0.0294719 (* 0.5 = 0.014736 loss)
I0815 09:40:40.152215   668 solver.cpp:244]     Train net output #1: loss2 = 0.135117 (* 0.5 = 0.0675586 loss)
I0815 09:40:40.152226   668 sgd_solver.cpp:106] Iteration 4640, lr = 0.0001
I0815 09:40:45.049540   668 solver.cpp:228] Iteration 4660, loss = 0.0730107
I0815 09:40:45.049597   668 solver.cpp:244]     Train net output #0: loss1 = 0.016631 (* 0.5 = 0.0083155 loss)
I0815 09:40:45.049612   668 solver.cpp:244]     Train net output #1: loss2 = 0.12939 (* 0.5 = 0.0646951 loss)
I0815 09:40:45.049625   668 sgd_solver.cpp:106] Iteration 4660, lr = 0.0001
I0815 09:40:49.960943   668 solver.cpp:228] Iteration 4680, loss = 0.0881559
I0815 09:40:49.961001   668 solver.cpp:244]     Train net output #0: loss1 = 0.0267485 (* 0.5 = 0.0133743 loss)
I0815 09:40:49.961019   668 solver.cpp:244]     Train net output #1: loss2 = 0.149563 (* 0.5 = 0.0747816 loss)
I0815 09:40:49.961031   668 sgd_solver.cpp:106] Iteration 4680, lr = 0.0001
I0815 09:40:54.866293   668 solver.cpp:228] Iteration 4700, loss = 0.0840643
I0815 09:40:54.866415   668 solver.cpp:244]     Train net output #0: loss1 = 0.0343673 (* 0.5 = 0.0171836 loss)
I0815 09:40:54.866432   668 solver.cpp:244]     Train net output #1: loss2 = 0.133761 (* 0.5 = 0.0668806 loss)
I0815 09:40:54.866446   668 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0815 09:40:59.763696   668 solver.cpp:228] Iteration 4720, loss = 0.0912462
I0815 09:40:59.763787   668 solver.cpp:244]     Train net output #0: loss1 = 0.0399543 (* 0.5 = 0.0199772 loss)
I0815 09:40:59.763819   668 solver.cpp:244]     Train net output #1: loss2 = 0.142538 (* 0.5 = 0.0712689 loss)
I0815 09:40:59.763849   668 sgd_solver.cpp:106] Iteration 4720, lr = 0.0001
I0815 09:41:04.673765   668 solver.cpp:228] Iteration 4740, loss = 0.0849581
I0815 09:41:04.673822   668 solver.cpp:244]     Train net output #0: loss1 = 0.0163531 (* 0.5 = 0.00817657 loss)
I0815 09:41:04.673837   668 solver.cpp:244]     Train net output #1: loss2 = 0.153563 (* 0.5 = 0.0767814 loss)
I0815 09:41:04.673851   668 sgd_solver.cpp:106] Iteration 4740, lr = 0.0001
I0815 09:41:09.568332   668 solver.cpp:228] Iteration 4760, loss = 0.0682742
I0815 09:41:09.568392   668 solver.cpp:244]     Train net output #0: loss1 = 0.053392 (* 0.5 = 0.026696 loss)
I0815 09:41:09.568406   668 solver.cpp:244]     Train net output #1: loss2 = 0.0831562 (* 0.5 = 0.0415781 loss)
I0815 09:41:09.568419   668 sgd_solver.cpp:106] Iteration 4760, lr = 0.0001
I0815 09:41:14.453054   668 solver.cpp:228] Iteration 4780, loss = 0.0664501
I0815 09:41:14.453107   668 solver.cpp:244]     Train net output #0: loss1 = 0.0384987 (* 0.5 = 0.0192494 loss)
I0815 09:41:14.453124   668 solver.cpp:244]     Train net output #1: loss2 = 0.0944012 (* 0.5 = 0.0472006 loss)
I0815 09:41:14.453135   668 sgd_solver.cpp:106] Iteration 4780, lr = 0.0001
I0815 09:41:19.338724   668 solver.cpp:228] Iteration 4800, loss = 0.0655449
I0815 09:41:19.338783   668 solver.cpp:244]     Train net output #0: loss1 = 0.0161018 (* 0.5 = 0.00805092 loss)
I0815 09:41:19.338798   668 solver.cpp:244]     Train net output #1: loss2 = 0.114988 (* 0.5 = 0.0574939 loss)
I0815 09:41:19.338811   668 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0815 09:41:24.259529   668 solver.cpp:228] Iteration 4820, loss = 0.0582347
I0815 09:41:24.259589   668 solver.cpp:244]     Train net output #0: loss1 = 0.0169647 (* 0.5 = 0.00848234 loss)
I0815 09:41:24.259605   668 solver.cpp:244]     Train net output #1: loss2 = 0.0995046 (* 0.5 = 0.0497523 loss)
I0815 09:41:24.259618   668 sgd_solver.cpp:106] Iteration 4820, lr = 0.0001
I0815 09:41:29.148788   668 solver.cpp:228] Iteration 4840, loss = 0.0562624
I0815 09:41:29.148967   668 solver.cpp:244]     Train net output #0: loss1 = 0.0408656 (* 0.5 = 0.0204328 loss)
I0815 09:41:29.148990   668 solver.cpp:244]     Train net output #1: loss2 = 0.071659 (* 0.5 = 0.0358295 loss)
I0815 09:41:29.149005   668 sgd_solver.cpp:106] Iteration 4840, lr = 0.0001
I0815 09:41:34.066987   668 solver.cpp:228] Iteration 4860, loss = 0.087349
I0815 09:41:34.067044   668 solver.cpp:244]     Train net output #0: loss1 = 0.0977659 (* 0.5 = 0.048883 loss)
I0815 09:41:34.067060   668 solver.cpp:244]     Train net output #1: loss2 = 0.0769318 (* 0.5 = 0.0384659 loss)
I0815 09:41:34.067072   668 sgd_solver.cpp:106] Iteration 4860, lr = 0.0001
I0815 09:41:38.949589   668 solver.cpp:228] Iteration 4880, loss = 0.0660312
I0815 09:41:38.949647   668 solver.cpp:244]     Train net output #0: loss1 = 0.0255639 (* 0.5 = 0.012782 loss)
I0815 09:41:38.949662   668 solver.cpp:244]     Train net output #1: loss2 = 0.106498 (* 0.5 = 0.0532491 loss)
I0815 09:41:38.949676   668 sgd_solver.cpp:106] Iteration 4880, lr = 0.0001
I0815 09:41:43.842911   668 solver.cpp:228] Iteration 4900, loss = 0.0539486
I0815 09:41:43.842969   668 solver.cpp:244]     Train net output #0: loss1 = 0.0108175 (* 0.5 = 0.00540874 loss)
I0815 09:41:43.842985   668 solver.cpp:244]     Train net output #1: loss2 = 0.0970795 (* 0.5 = 0.0485398 loss)
I0815 09:41:43.842998   668 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0815 09:41:48.753620   668 solver.cpp:228] Iteration 4920, loss = 0.11423
I0815 09:41:48.753705   668 solver.cpp:244]     Train net output #0: loss1 = 0.149981 (* 0.5 = 0.0749904 loss)
I0815 09:41:48.753742   668 solver.cpp:244]     Train net output #1: loss2 = 0.0784795 (* 0.5 = 0.0392397 loss)
I0815 09:41:48.753763   668 sgd_solver.cpp:106] Iteration 4920, lr = 0.0001
I0815 09:41:53.637609   668 solver.cpp:228] Iteration 4940, loss = 0.119952
I0815 09:41:53.637665   668 solver.cpp:244]     Train net output #0: loss1 = 0.0924933 (* 0.5 = 0.0462467 loss)
I0815 09:41:53.637681   668 solver.cpp:244]     Train net output #1: loss2 = 0.14741 (* 0.5 = 0.0737048 loss)
I0815 09:41:53.637693   668 sgd_solver.cpp:106] Iteration 4940, lr = 0.0001
I0815 09:41:58.552225   668 solver.cpp:228] Iteration 4960, loss = 0.0775159
I0815 09:41:58.552280   668 solver.cpp:244]     Train net output #0: loss1 = 0.0214738 (* 0.5 = 0.0107369 loss)
I0815 09:41:58.552295   668 solver.cpp:244]     Train net output #1: loss2 = 0.133558 (* 0.5 = 0.0667789 loss)
I0815 09:41:58.552309   668 sgd_solver.cpp:106] Iteration 4960, lr = 0.0001
I0815 09:42:03.461696   668 solver.cpp:228] Iteration 4980, loss = 0.0756903
I0815 09:42:03.461843   668 solver.cpp:244]     Train net output #0: loss1 = 0.0164908 (* 0.5 = 0.00824539 loss)
I0815 09:42:03.461861   668 solver.cpp:244]     Train net output #1: loss2 = 0.13489 (* 0.5 = 0.0674448 loss)
I0815 09:42:03.461874   668 sgd_solver.cpp:106] Iteration 4980, lr = 0.0001
I0815 09:42:08.113929   668 solver.cpp:337] Iteration 5000, Testing net (#0)
I0815 09:43:05.511638   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.83575
I0815 09:43:05.511741   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.95425
I0815 09:43:05.511760   668 solver.cpp:404]     Test net output #2: loss1 = 0.163725 (* 0.5 = 0.0818624 loss)
I0815 09:43:05.511772   668 solver.cpp:404]     Test net output #3: loss2 = 0.416368 (* 0.5 = 0.208184 loss)
I0815 09:43:05.585919   668 solver.cpp:228] Iteration 5000, loss = 0.083873
I0815 09:43:05.585973   668 solver.cpp:244]     Train net output #0: loss1 = 0.0301706 (* 0.5 = 0.0150853 loss)
I0815 09:43:05.585988   668 solver.cpp:244]     Train net output #1: loss2 = 0.137575 (* 0.5 = 0.0687876 loss)
I0815 09:43:05.586000   668 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0815 09:43:10.477890   668 solver.cpp:228] Iteration 5020, loss = 0.117361
I0815 09:43:10.477946   668 solver.cpp:244]     Train net output #0: loss1 = 0.0861761 (* 0.5 = 0.0430881 loss)
I0815 09:43:10.477962   668 solver.cpp:244]     Train net output #1: loss2 = 0.148545 (* 0.5 = 0.0742724 loss)
I0815 09:43:10.477974   668 sgd_solver.cpp:106] Iteration 5020, lr = 0.0001
I0815 09:43:15.455076   668 solver.cpp:228] Iteration 5040, loss = 0.103912
I0815 09:43:15.455135   668 solver.cpp:244]     Train net output #0: loss1 = 0.0808189 (* 0.5 = 0.0404094 loss)
I0815 09:43:15.455152   668 solver.cpp:244]     Train net output #1: loss2 = 0.127006 (* 0.5 = 0.0635028 loss)
I0815 09:43:15.455164   668 sgd_solver.cpp:106] Iteration 5040, lr = 0.0001
I0815 09:43:20.350814   668 solver.cpp:228] Iteration 5060, loss = 0.0843359
I0815 09:43:20.350870   668 solver.cpp:244]     Train net output #0: loss1 = 0.0183922 (* 0.5 = 0.00919609 loss)
I0815 09:43:20.350886   668 solver.cpp:244]     Train net output #1: loss2 = 0.150279 (* 0.5 = 0.0751397 loss)
I0815 09:43:20.350898   668 sgd_solver.cpp:106] Iteration 5060, lr = 0.0001
I0815 09:43:25.259966   668 solver.cpp:228] Iteration 5080, loss = 0.0457958
I0815 09:43:25.260025   668 solver.cpp:244]     Train net output #0: loss1 = 0.0176993 (* 0.5 = 0.00884967 loss)
I0815 09:43:25.260040   668 solver.cpp:244]     Train net output #1: loss2 = 0.073892 (* 0.5 = 0.036946 loss)
I0815 09:43:25.260052   668 sgd_solver.cpp:106] Iteration 5080, lr = 0.0001
I0815 09:43:30.152912   668 solver.cpp:228] Iteration 5100, loss = 0.040059
I0815 09:43:30.152972   668 solver.cpp:244]     Train net output #0: loss1 = 0.0129725 (* 0.5 = 0.00648626 loss)
I0815 09:43:30.152987   668 solver.cpp:244]     Train net output #1: loss2 = 0.0671453 (* 0.5 = 0.0335727 loss)
I0815 09:43:30.153000   668 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0815 09:43:35.049566   668 solver.cpp:228] Iteration 5120, loss = 0.0689788
I0815 09:43:35.049618   668 solver.cpp:244]     Train net output #0: loss1 = 0.0222268 (* 0.5 = 0.0111134 loss)
I0815 09:43:35.049633   668 solver.cpp:244]     Train net output #1: loss2 = 0.115731 (* 0.5 = 0.0578653 loss)
I0815 09:43:35.049648   668 sgd_solver.cpp:106] Iteration 5120, lr = 0.0001
I0815 09:43:39.948936   668 solver.cpp:228] Iteration 5140, loss = 0.0644338
I0815 09:43:39.949158   668 solver.cpp:244]     Train net output #0: loss1 = 0.0172578 (* 0.5 = 0.00862889 loss)
I0815 09:43:39.949179   668 solver.cpp:244]     Train net output #1: loss2 = 0.11161 (* 0.5 = 0.0558049 loss)
I0815 09:43:39.949193   668 sgd_solver.cpp:106] Iteration 5140, lr = 0.0001
I0815 09:43:44.846330   668 solver.cpp:228] Iteration 5160, loss = 0.0711729
I0815 09:43:44.846388   668 solver.cpp:244]     Train net output #0: loss1 = 0.0286658 (* 0.5 = 0.0143329 loss)
I0815 09:43:44.846403   668 solver.cpp:244]     Train net output #1: loss2 = 0.11368 (* 0.5 = 0.0568399 loss)
I0815 09:43:44.846416   668 sgd_solver.cpp:106] Iteration 5160, lr = 0.0001
I0815 09:43:49.736429   668 solver.cpp:228] Iteration 5180, loss = 0.111355
I0815 09:43:49.736487   668 solver.cpp:244]     Train net output #0: loss1 = 0.0446094 (* 0.5 = 0.0223047 loss)
I0815 09:43:49.736502   668 solver.cpp:244]     Train net output #1: loss2 = 0.1781 (* 0.5 = 0.0890498 loss)
I0815 09:43:49.736515   668 sgd_solver.cpp:106] Iteration 5180, lr = 0.0001
I0815 09:43:54.628562   668 solver.cpp:228] Iteration 5200, loss = 0.0629521
I0815 09:43:54.628620   668 solver.cpp:244]     Train net output #0: loss1 = 0.013521 (* 0.5 = 0.00676048 loss)
I0815 09:43:54.628636   668 solver.cpp:244]     Train net output #1: loss2 = 0.112383 (* 0.5 = 0.0561915 loss)
I0815 09:43:54.628649   668 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0815 09:43:59.561954   668 solver.cpp:228] Iteration 5220, loss = 0.111563
I0815 09:43:59.562012   668 solver.cpp:244]     Train net output #0: loss1 = 0.0718116 (* 0.5 = 0.0359058 loss)
I0815 09:43:59.562027   668 solver.cpp:244]     Train net output #1: loss2 = 0.151315 (* 0.5 = 0.0756573 loss)
I0815 09:43:59.562041   668 sgd_solver.cpp:106] Iteration 5220, lr = 0.0001
I0815 09:44:04.454341   668 solver.cpp:228] Iteration 5240, loss = 0.109269
I0815 09:44:04.454399   668 solver.cpp:244]     Train net output #0: loss1 = 0.0612857 (* 0.5 = 0.0306429 loss)
I0815 09:44:04.454416   668 solver.cpp:244]     Train net output #1: loss2 = 0.157252 (* 0.5 = 0.0786262 loss)
I0815 09:44:04.454428   668 sgd_solver.cpp:106] Iteration 5240, lr = 0.0001
I0815 09:44:09.358907   668 solver.cpp:228] Iteration 5260, loss = 0.0849714
I0815 09:44:09.358963   668 solver.cpp:244]     Train net output #0: loss1 = 0.0262134 (* 0.5 = 0.0131067 loss)
I0815 09:44:09.358979   668 solver.cpp:244]     Train net output #1: loss2 = 0.143729 (* 0.5 = 0.0718646 loss)
I0815 09:44:09.358992   668 sgd_solver.cpp:106] Iteration 5260, lr = 0.0001
I0815 09:44:14.253948   668 solver.cpp:228] Iteration 5280, loss = 0.0919907
I0815 09:44:14.254070   668 solver.cpp:244]     Train net output #0: loss1 = 0.0340856 (* 0.5 = 0.0170428 loss)
I0815 09:44:14.254086   668 solver.cpp:244]     Train net output #1: loss2 = 0.149896 (* 0.5 = 0.0749478 loss)
I0815 09:44:14.254099   668 sgd_solver.cpp:106] Iteration 5280, lr = 0.0001
I0815 09:44:19.142731   668 solver.cpp:228] Iteration 5300, loss = 0.0702177
I0815 09:44:19.142791   668 solver.cpp:244]     Train net output #0: loss1 = 0.0495625 (* 0.5 = 0.0247813 loss)
I0815 09:44:19.142807   668 solver.cpp:244]     Train net output #1: loss2 = 0.0908727 (* 0.5 = 0.0454364 loss)
I0815 09:44:19.142820   668 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0815 09:44:24.030992   668 solver.cpp:228] Iteration 5320, loss = 0.0752317
I0815 09:44:24.031050   668 solver.cpp:244]     Train net output #0: loss1 = 0.0391525 (* 0.5 = 0.0195762 loss)
I0815 09:44:24.031065   668 solver.cpp:244]     Train net output #1: loss2 = 0.111311 (* 0.5 = 0.0556554 loss)
I0815 09:44:24.031078   668 sgd_solver.cpp:106] Iteration 5320, lr = 0.0001
I0815 09:44:28.922983   668 solver.cpp:228] Iteration 5340, loss = 0.0660357
I0815 09:44:28.923039   668 solver.cpp:244]     Train net output #0: loss1 = 0.0132271 (* 0.5 = 0.00661354 loss)
I0815 09:44:28.923054   668 solver.cpp:244]     Train net output #1: loss2 = 0.118844 (* 0.5 = 0.0594221 loss)
I0815 09:44:28.923068   668 sgd_solver.cpp:106] Iteration 5340, lr = 0.0001
I0815 09:44:33.840576   668 solver.cpp:228] Iteration 5360, loss = 0.126468
I0815 09:44:33.840634   668 solver.cpp:244]     Train net output #0: loss1 = 0.124655 (* 0.5 = 0.0623274 loss)
I0815 09:44:33.840651   668 solver.cpp:244]     Train net output #1: loss2 = 0.128282 (* 0.5 = 0.0641409 loss)
I0815 09:44:33.840663   668 sgd_solver.cpp:106] Iteration 5360, lr = 0.0001
I0815 09:44:38.724570   668 solver.cpp:228] Iteration 5380, loss = 0.0985968
I0815 09:44:38.724628   668 solver.cpp:244]     Train net output #0: loss1 = 0.0274705 (* 0.5 = 0.0137353 loss)
I0815 09:44:38.724643   668 solver.cpp:244]     Train net output #1: loss2 = 0.169723 (* 0.5 = 0.0848614 loss)
I0815 09:44:38.724656   668 sgd_solver.cpp:106] Iteration 5380, lr = 0.0001
I0815 09:44:43.615900   668 solver.cpp:228] Iteration 5400, loss = 0.0973707
I0815 09:44:43.615991   668 solver.cpp:244]     Train net output #0: loss1 = 0.0298966 (* 0.5 = 0.0149483 loss)
I0815 09:44:43.616024   668 solver.cpp:244]     Train net output #1: loss2 = 0.164845 (* 0.5 = 0.0824223 loss)
I0815 09:44:43.616055   668 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0815 09:44:48.511888   668 solver.cpp:228] Iteration 5420, loss = 0.105088
I0815 09:44:48.512042   668 solver.cpp:244]     Train net output #0: loss1 = 0.111435 (* 0.5 = 0.0557175 loss)
I0815 09:44:48.512059   668 solver.cpp:244]     Train net output #1: loss2 = 0.09874 (* 0.5 = 0.04937 loss)
I0815 09:44:48.512073   668 sgd_solver.cpp:106] Iteration 5420, lr = 0.0001
I0815 09:44:53.405283   668 solver.cpp:228] Iteration 5440, loss = 0.0629636
I0815 09:44:53.405341   668 solver.cpp:244]     Train net output #0: loss1 = 0.0379808 (* 0.5 = 0.0189904 loss)
I0815 09:44:53.405356   668 solver.cpp:244]     Train net output #1: loss2 = 0.0879463 (* 0.5 = 0.0439731 loss)
I0815 09:44:53.405369   668 sgd_solver.cpp:106] Iteration 5440, lr = 0.0001
I0815 09:44:58.292980   668 solver.cpp:228] Iteration 5460, loss = 0.092125
I0815 09:44:58.293038   668 solver.cpp:244]     Train net output #0: loss1 = 0.109256 (* 0.5 = 0.054628 loss)
I0815 09:44:58.293054   668 solver.cpp:244]     Train net output #1: loss2 = 0.0749939 (* 0.5 = 0.0374969 loss)
I0815 09:44:58.293066   668 sgd_solver.cpp:106] Iteration 5460, lr = 0.0001
I0815 09:45:03.180308   668 solver.cpp:228] Iteration 5480, loss = 0.105099
I0815 09:45:03.180366   668 solver.cpp:244]     Train net output #0: loss1 = 0.0943815 (* 0.5 = 0.0471907 loss)
I0815 09:45:03.180380   668 solver.cpp:244]     Train net output #1: loss2 = 0.115816 (* 0.5 = 0.0579078 loss)
I0815 09:45:03.180393   668 sgd_solver.cpp:106] Iteration 5480, lr = 0.0001
I0815 09:45:08.061547   668 solver.cpp:228] Iteration 5500, loss = 0.091275
I0815 09:45:08.061606   668 solver.cpp:244]     Train net output #0: loss1 = 0.0229541 (* 0.5 = 0.011477 loss)
I0815 09:45:08.061622   668 solver.cpp:244]     Train net output #1: loss2 = 0.159596 (* 0.5 = 0.0797979 loss)
I0815 09:45:08.061635   668 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0815 09:45:12.945320   668 solver.cpp:228] Iteration 5520, loss = 0.0687872
I0815 09:45:12.945379   668 solver.cpp:244]     Train net output #0: loss1 = 0.0445592 (* 0.5 = 0.0222796 loss)
I0815 09:45:12.945394   668 solver.cpp:244]     Train net output #1: loss2 = 0.0930151 (* 0.5 = 0.0465075 loss)
I0815 09:45:12.945407   668 sgd_solver.cpp:106] Iteration 5520, lr = 0.0001
I0815 09:45:17.827494   668 solver.cpp:228] Iteration 5540, loss = 0.0834905
I0815 09:45:17.827554   668 solver.cpp:244]     Train net output #0: loss1 = 0.0332248 (* 0.5 = 0.0166124 loss)
I0815 09:45:17.827570   668 solver.cpp:244]     Train net output #1: loss2 = 0.133756 (* 0.5 = 0.066878 loss)
I0815 09:45:17.827584   668 sgd_solver.cpp:106] Iteration 5540, lr = 0.0001
I0815 09:45:22.716135   668 solver.cpp:228] Iteration 5560, loss = 0.107659
I0815 09:45:22.716259   668 solver.cpp:244]     Train net output #0: loss1 = 0.0444409 (* 0.5 = 0.0222205 loss)
I0815 09:45:22.716275   668 solver.cpp:244]     Train net output #1: loss2 = 0.170877 (* 0.5 = 0.0854385 loss)
I0815 09:45:22.716287   668 sgd_solver.cpp:106] Iteration 5560, lr = 0.0001
I0815 09:45:27.614078   668 solver.cpp:228] Iteration 5580, loss = 0.0727898
I0815 09:45:27.614136   668 solver.cpp:244]     Train net output #0: loss1 = 0.0150284 (* 0.5 = 0.00751419 loss)
I0815 09:45:27.614151   668 solver.cpp:244]     Train net output #1: loss2 = 0.130551 (* 0.5 = 0.0652755 loss)
I0815 09:45:27.614164   668 sgd_solver.cpp:106] Iteration 5580, lr = 0.0001
I0815 09:45:32.524458   668 solver.cpp:228] Iteration 5600, loss = 0.0650342
I0815 09:45:32.524518   668 solver.cpp:244]     Train net output #0: loss1 = 0.0270394 (* 0.5 = 0.0135197 loss)
I0815 09:45:32.524533   668 solver.cpp:244]     Train net output #1: loss2 = 0.103029 (* 0.5 = 0.0515144 loss)
I0815 09:45:32.524546   668 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0815 09:45:37.446579   668 solver.cpp:228] Iteration 5620, loss = 0.0910287
I0815 09:45:37.446636   668 solver.cpp:244]     Train net output #0: loss1 = 0.046851 (* 0.5 = 0.0234255 loss)
I0815 09:45:37.446652   668 solver.cpp:244]     Train net output #1: loss2 = 0.135206 (* 0.5 = 0.0676032 loss)
I0815 09:45:37.446666   668 sgd_solver.cpp:106] Iteration 5620, lr = 0.0001
I0815 09:45:42.353632   668 solver.cpp:228] Iteration 5640, loss = 0.0485954
I0815 09:45:42.353708   668 solver.cpp:244]     Train net output #0: loss1 = 0.00939049 (* 0.5 = 0.00469525 loss)
I0815 09:45:42.353727   668 solver.cpp:244]     Train net output #1: loss2 = 0.0878001 (* 0.5 = 0.0439 loss)
I0815 09:45:42.353745   668 sgd_solver.cpp:106] Iteration 5640, lr = 0.0001
I0815 09:45:47.301388   668 solver.cpp:228] Iteration 5660, loss = 0.0544076
I0815 09:45:47.301440   668 solver.cpp:244]     Train net output #0: loss1 = 0.0267328 (* 0.5 = 0.0133664 loss)
I0815 09:45:47.301456   668 solver.cpp:244]     Train net output #1: loss2 = 0.0820822 (* 0.5 = 0.0410411 loss)
I0815 09:45:47.301470   668 sgd_solver.cpp:106] Iteration 5660, lr = 0.0001
I0815 09:45:52.236146   668 solver.cpp:228] Iteration 5680, loss = 0.0482172
I0815 09:45:52.236204   668 solver.cpp:244]     Train net output #0: loss1 = 0.0277711 (* 0.5 = 0.0138856 loss)
I0815 09:45:52.236220   668 solver.cpp:244]     Train net output #1: loss2 = 0.0686632 (* 0.5 = 0.0343316 loss)
I0815 09:45:52.236233   668 sgd_solver.cpp:106] Iteration 5680, lr = 0.0001
I0815 09:45:57.168741   668 solver.cpp:228] Iteration 5700, loss = 0.068022
I0815 09:45:57.168943   668 solver.cpp:244]     Train net output #0: loss1 = 0.0231781 (* 0.5 = 0.011589 loss)
I0815 09:45:57.168965   668 solver.cpp:244]     Train net output #1: loss2 = 0.112866 (* 0.5 = 0.0564329 loss)
I0815 09:45:57.168979   668 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0815 09:46:02.068598   668 solver.cpp:228] Iteration 5720, loss = 0.0336709
I0815 09:46:02.068655   668 solver.cpp:244]     Train net output #0: loss1 = 0.0174415 (* 0.5 = 0.00872077 loss)
I0815 09:46:02.068670   668 solver.cpp:244]     Train net output #1: loss2 = 0.0499 (* 0.5 = 0.02495 loss)
I0815 09:46:02.068683   668 sgd_solver.cpp:106] Iteration 5720, lr = 0.0001
I0815 09:46:06.961936   668 solver.cpp:228] Iteration 5740, loss = 0.110695
I0815 09:46:06.961990   668 solver.cpp:244]     Train net output #0: loss1 = 0.106571 (* 0.5 = 0.0532855 loss)
I0815 09:46:06.962007   668 solver.cpp:244]     Train net output #1: loss2 = 0.114819 (* 0.5 = 0.0574094 loss)
I0815 09:46:06.962018   668 sgd_solver.cpp:106] Iteration 5740, lr = 0.0001
I0815 09:46:11.852329   668 solver.cpp:228] Iteration 5760, loss = 0.0727938
I0815 09:46:11.852382   668 solver.cpp:244]     Train net output #0: loss1 = 0.0192477 (* 0.5 = 0.00962385 loss)
I0815 09:46:11.852398   668 solver.cpp:244]     Train net output #1: loss2 = 0.12634 (* 0.5 = 0.0631699 loss)
I0815 09:46:11.852411   668 sgd_solver.cpp:106] Iteration 5760, lr = 0.0001
I0815 09:46:16.753772   668 solver.cpp:228] Iteration 5780, loss = 0.088167
I0815 09:46:16.753830   668 solver.cpp:244]     Train net output #0: loss1 = 0.0548267 (* 0.5 = 0.0274134 loss)
I0815 09:46:16.753846   668 solver.cpp:244]     Train net output #1: loss2 = 0.121507 (* 0.5 = 0.0607536 loss)
I0815 09:46:16.753859   668 sgd_solver.cpp:106] Iteration 5780, lr = 0.0001
I0815 09:46:21.652148   668 solver.cpp:228] Iteration 5800, loss = 0.115151
I0815 09:46:21.652204   668 solver.cpp:244]     Train net output #0: loss1 = 0.069226 (* 0.5 = 0.034613 loss)
I0815 09:46:21.652220   668 solver.cpp:244]     Train net output #1: loss2 = 0.161076 (* 0.5 = 0.0805379 loss)
I0815 09:46:21.652232   668 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0815 09:46:26.544996   668 solver.cpp:228] Iteration 5820, loss = 0.0327557
I0815 09:46:26.545050   668 solver.cpp:244]     Train net output #0: loss1 = 0.0208041 (* 0.5 = 0.010402 loss)
I0815 09:46:26.545065   668 solver.cpp:244]     Train net output #1: loss2 = 0.0447072 (* 0.5 = 0.0223536 loss)
I0815 09:46:26.545078   668 sgd_solver.cpp:106] Iteration 5820, lr = 0.0001
I0815 09:46:31.438670   668 solver.cpp:228] Iteration 5840, loss = 0.0599153
I0815 09:46:31.438851   668 solver.cpp:244]     Train net output #0: loss1 = 0.0218095 (* 0.5 = 0.0109048 loss)
I0815 09:46:31.438876   668 solver.cpp:244]     Train net output #1: loss2 = 0.0980209 (* 0.5 = 0.0490104 loss)
I0815 09:46:31.438899   668 sgd_solver.cpp:106] Iteration 5840, lr = 0.0001
I0815 09:46:36.360064   668 solver.cpp:228] Iteration 5860, loss = 0.0807337
I0815 09:46:36.360118   668 solver.cpp:244]     Train net output #0: loss1 = 0.018027 (* 0.5 = 0.00901349 loss)
I0815 09:46:36.360134   668 solver.cpp:244]     Train net output #1: loss2 = 0.14344 (* 0.5 = 0.0717201 loss)
I0815 09:46:36.360146   668 sgd_solver.cpp:106] Iteration 5860, lr = 0.0001
I0815 09:46:41.272343   668 solver.cpp:228] Iteration 5880, loss = 0.112255
I0815 09:46:41.272399   668 solver.cpp:244]     Train net output #0: loss1 = 0.0552527 (* 0.5 = 0.0276263 loss)
I0815 09:46:41.272415   668 solver.cpp:244]     Train net output #1: loss2 = 0.169257 (* 0.5 = 0.0846284 loss)
I0815 09:46:41.272428   668 sgd_solver.cpp:106] Iteration 5880, lr = 0.0001
I0815 09:46:46.166534   668 solver.cpp:228] Iteration 5900, loss = 0.20276
I0815 09:46:46.166633   668 solver.cpp:244]     Train net output #0: loss1 = 0.242944 (* 0.5 = 0.121472 loss)
I0815 09:46:46.166671   668 solver.cpp:244]     Train net output #1: loss2 = 0.162576 (* 0.5 = 0.0812878 loss)
I0815 09:46:46.166692   668 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0815 09:46:51.068974   668 solver.cpp:228] Iteration 5920, loss = 0.0656016
I0815 09:46:51.069031   668 solver.cpp:244]     Train net output #0: loss1 = 0.0152794 (* 0.5 = 0.00763972 loss)
I0815 09:46:51.069047   668 solver.cpp:244]     Train net output #1: loss2 = 0.115924 (* 0.5 = 0.0579618 loss)
I0815 09:46:51.069061   668 sgd_solver.cpp:106] Iteration 5920, lr = 0.0001
I0815 09:46:55.960479   668 solver.cpp:228] Iteration 5940, loss = 0.0486191
I0815 09:46:55.960536   668 solver.cpp:244]     Train net output #0: loss1 = 0.0170581 (* 0.5 = 0.00852904 loss)
I0815 09:46:55.960551   668 solver.cpp:244]     Train net output #1: loss2 = 0.08018 (* 0.5 = 0.04009 loss)
I0815 09:46:55.960563   668 sgd_solver.cpp:106] Iteration 5940, lr = 0.0001
I0815 09:47:00.876386   668 solver.cpp:228] Iteration 5960, loss = 0.0664347
I0815 09:47:00.876446   668 solver.cpp:244]     Train net output #0: loss1 = 0.0513726 (* 0.5 = 0.0256863 loss)
I0815 09:47:00.876461   668 solver.cpp:244]     Train net output #1: loss2 = 0.0814966 (* 0.5 = 0.0407483 loss)
I0815 09:47:00.876474   668 sgd_solver.cpp:106] Iteration 5960, lr = 0.0001
I0815 09:47:05.802825   668 solver.cpp:228] Iteration 5980, loss = 0.0492042
I0815 09:47:05.802971   668 solver.cpp:244]     Train net output #0: loss1 = 0.0264316 (* 0.5 = 0.0132158 loss)
I0815 09:47:05.802996   668 solver.cpp:244]     Train net output #1: loss2 = 0.0719765 (* 0.5 = 0.0359883 loss)
I0815 09:47:05.803011   668 sgd_solver.cpp:106] Iteration 5980, lr = 0.0001
I0815 09:47:10.477108   668 solver.cpp:337] Iteration 6000, Testing net (#0)
I0815 09:48:07.731922   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.834891
I0815 09:48:07.732069   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.955312
I0815 09:48:07.732089   668 solver.cpp:404]     Test net output #2: loss1 = 0.163399 (* 0.5 = 0.0816993 loss)
I0815 09:48:07.732101   668 solver.cpp:404]     Test net output #3: loss2 = 0.418322 (* 0.5 = 0.209161 loss)
I0815 09:48:07.805960   668 solver.cpp:228] Iteration 6000, loss = 0.0489737
I0815 09:48:07.806017   668 solver.cpp:244]     Train net output #0: loss1 = 0.0207484 (* 0.5 = 0.0103742 loss)
I0815 09:48:07.806033   668 solver.cpp:244]     Train net output #1: loss2 = 0.0771988 (* 0.5 = 0.0385994 loss)
I0815 09:48:07.806048   668 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0815 09:48:12.689594   668 solver.cpp:228] Iteration 6020, loss = 0.0789287
I0815 09:48:12.689651   668 solver.cpp:244]     Train net output #0: loss1 = 0.0392062 (* 0.5 = 0.0196031 loss)
I0815 09:48:12.689667   668 solver.cpp:244]     Train net output #1: loss2 = 0.118651 (* 0.5 = 0.0593255 loss)
I0815 09:48:12.689682   668 sgd_solver.cpp:106] Iteration 6020, lr = 1e-05
I0815 09:48:17.573786   668 solver.cpp:228] Iteration 6040, loss = 0.124051
I0815 09:48:17.573838   668 solver.cpp:244]     Train net output #0: loss1 = 0.129194 (* 0.5 = 0.0645968 loss)
I0815 09:48:17.573853   668 solver.cpp:244]     Train net output #1: loss2 = 0.118909 (* 0.5 = 0.0594544 loss)
I0815 09:48:17.573868   668 sgd_solver.cpp:106] Iteration 6040, lr = 1e-05
I0815 09:48:22.457315   668 solver.cpp:228] Iteration 6060, loss = 0.104772
I0815 09:48:22.457375   668 solver.cpp:244]     Train net output #0: loss1 = 0.0341577 (* 0.5 = 0.0170789 loss)
I0815 09:48:22.457391   668 solver.cpp:244]     Train net output #1: loss2 = 0.175387 (* 0.5 = 0.0876935 loss)
I0815 09:48:22.457403   668 sgd_solver.cpp:106] Iteration 6060, lr = 1e-05
I0815 09:48:27.368350   668 solver.cpp:228] Iteration 6080, loss = 0.11111
I0815 09:48:27.368393   668 solver.cpp:244]     Train net output #0: loss1 = 0.0601884 (* 0.5 = 0.0300942 loss)
I0815 09:48:27.368404   668 solver.cpp:244]     Train net output #1: loss2 = 0.162031 (* 0.5 = 0.0810155 loss)
I0815 09:48:27.368418   668 sgd_solver.cpp:106] Iteration 6080, lr = 1e-05
I0815 09:48:32.289819   668 solver.cpp:228] Iteration 6100, loss = 0.0439605
I0815 09:48:32.289878   668 solver.cpp:244]     Train net output #0: loss1 = 0.0172878 (* 0.5 = 0.0086439 loss)
I0815 09:48:32.289894   668 solver.cpp:244]     Train net output #1: loss2 = 0.0706329 (* 0.5 = 0.0353165 loss)
I0815 09:48:32.289907   668 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0815 09:48:37.205582   668 solver.cpp:228] Iteration 6120, loss = 0.0775371
I0815 09:48:37.205639   668 solver.cpp:244]     Train net output #0: loss1 = 0.0230088 (* 0.5 = 0.0115044 loss)
I0815 09:48:37.205656   668 solver.cpp:244]     Train net output #1: loss2 = 0.132065 (* 0.5 = 0.0660326 loss)
I0815 09:48:37.205668   668 sgd_solver.cpp:106] Iteration 6120, lr = 1e-05
I0815 09:48:42.094666   668 solver.cpp:228] Iteration 6140, loss = 0.0428119
I0815 09:48:42.094863   668 solver.cpp:244]     Train net output #0: loss1 = 0.0236369 (* 0.5 = 0.0118185 loss)
I0815 09:48:42.094892   668 solver.cpp:244]     Train net output #1: loss2 = 0.0619868 (* 0.5 = 0.0309934 loss)
I0815 09:48:42.094918   668 sgd_solver.cpp:106] Iteration 6140, lr = 1e-05
I0815 09:48:46.987030   668 solver.cpp:228] Iteration 6160, loss = 0.0876382
I0815 09:48:46.987082   668 solver.cpp:244]     Train net output #0: loss1 = 0.016187 (* 0.5 = 0.00809349 loss)
I0815 09:48:46.987097   668 solver.cpp:244]     Train net output #1: loss2 = 0.159089 (* 0.5 = 0.0795446 loss)
I0815 09:48:46.987112   668 sgd_solver.cpp:106] Iteration 6160, lr = 1e-05
I0815 09:48:51.899399   668 solver.cpp:228] Iteration 6180, loss = 0.0783722
I0815 09:48:51.899458   668 solver.cpp:244]     Train net output #0: loss1 = 0.0163361 (* 0.5 = 0.00816805 loss)
I0815 09:48:51.899474   668 solver.cpp:244]     Train net output #1: loss2 = 0.140408 (* 0.5 = 0.070204 loss)
I0815 09:48:51.899488   668 sgd_solver.cpp:106] Iteration 6180, lr = 1e-05
I0815 09:48:56.802426   668 solver.cpp:228] Iteration 6200, loss = 0.0460037
I0815 09:48:56.802481   668 solver.cpp:244]     Train net output #0: loss1 = 0.0214469 (* 0.5 = 0.0107234 loss)
I0815 09:48:56.802497   668 solver.cpp:244]     Train net output #1: loss2 = 0.0705603 (* 0.5 = 0.0352801 loss)
I0815 09:48:56.802511   668 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0815 09:49:01.692718   668 solver.cpp:228] Iteration 6220, loss = 0.081182
I0815 09:49:01.692775   668 solver.cpp:244]     Train net output #0: loss1 = 0.0184901 (* 0.5 = 0.00924507 loss)
I0815 09:49:01.692790   668 solver.cpp:244]     Train net output #1: loss2 = 0.143874 (* 0.5 = 0.0719369 loss)
I0815 09:49:01.692803   668 sgd_solver.cpp:106] Iteration 6220, lr = 1e-05
I0815 09:49:06.587632   668 solver.cpp:228] Iteration 6240, loss = 0.0688457
I0815 09:49:06.587687   668 solver.cpp:244]     Train net output #0: loss1 = 0.0211247 (* 0.5 = 0.0105623 loss)
I0815 09:49:06.587702   668 solver.cpp:244]     Train net output #1: loss2 = 0.116567 (* 0.5 = 0.0582833 loss)
I0815 09:49:06.587715   668 sgd_solver.cpp:106] Iteration 6240, lr = 1e-05
I0815 09:49:11.472807   668 solver.cpp:228] Iteration 6260, loss = 0.104342
I0815 09:49:11.472865   668 solver.cpp:244]     Train net output #0: loss1 = 0.032814 (* 0.5 = 0.016407 loss)
I0815 09:49:11.472882   668 solver.cpp:244]     Train net output #1: loss2 = 0.175869 (* 0.5 = 0.0879345 loss)
I0815 09:49:11.472894   668 sgd_solver.cpp:106] Iteration 6260, lr = 1e-05
I0815 09:49:16.356745   668 solver.cpp:228] Iteration 6280, loss = 0.0589191
I0815 09:49:16.356890   668 solver.cpp:244]     Train net output #0: loss1 = 0.0263332 (* 0.5 = 0.0131666 loss)
I0815 09:49:16.356907   668 solver.cpp:244]     Train net output #1: loss2 = 0.0915047 (* 0.5 = 0.0457524 loss)
I0815 09:49:16.356921   668 sgd_solver.cpp:106] Iteration 6280, lr = 1e-05
I0815 09:49:21.243358   668 solver.cpp:228] Iteration 6300, loss = 0.0786249
I0815 09:49:21.243415   668 solver.cpp:244]     Train net output #0: loss1 = 0.0174695 (* 0.5 = 0.00873473 loss)
I0815 09:49:21.243432   668 solver.cpp:244]     Train net output #1: loss2 = 0.13978 (* 0.5 = 0.0698901 loss)
I0815 09:49:21.243444   668 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0815 09:49:26.125808   668 solver.cpp:228] Iteration 6320, loss = 0.0872495
I0815 09:49:26.125867   668 solver.cpp:244]     Train net output #0: loss1 = 0.0233491 (* 0.5 = 0.0116745 loss)
I0815 09:49:26.125882   668 solver.cpp:244]     Train net output #1: loss2 = 0.15115 (* 0.5 = 0.0755748 loss)
I0815 09:49:26.125896   668 sgd_solver.cpp:106] Iteration 6320, lr = 1e-05
I0815 09:49:31.009871   668 solver.cpp:228] Iteration 6340, loss = 0.107378
I0815 09:49:31.009925   668 solver.cpp:244]     Train net output #0: loss1 = 0.123218 (* 0.5 = 0.0616092 loss)
I0815 09:49:31.009941   668 solver.cpp:244]     Train net output #1: loss2 = 0.0915367 (* 0.5 = 0.0457684 loss)
I0815 09:49:31.009954   668 sgd_solver.cpp:106] Iteration 6340, lr = 1e-05
I0815 09:49:35.898504   668 solver.cpp:228] Iteration 6360, loss = 0.0607343
I0815 09:49:35.898556   668 solver.cpp:244]     Train net output #0: loss1 = 0.0435009 (* 0.5 = 0.0217504 loss)
I0815 09:49:35.898579   668 solver.cpp:244]     Train net output #1: loss2 = 0.0779676 (* 0.5 = 0.0389838 loss)
I0815 09:49:35.898592   668 sgd_solver.cpp:106] Iteration 6360, lr = 1e-05
I0815 09:49:40.782862   668 solver.cpp:228] Iteration 6380, loss = 0.0486783
I0815 09:49:40.782918   668 solver.cpp:244]     Train net output #0: loss1 = 0.0355275 (* 0.5 = 0.0177638 loss)
I0815 09:49:40.782934   668 solver.cpp:244]     Train net output #1: loss2 = 0.061829 (* 0.5 = 0.0309145 loss)
I0815 09:49:40.782948   668 sgd_solver.cpp:106] Iteration 6380, lr = 1e-05
I0815 09:49:45.666055   668 solver.cpp:228] Iteration 6400, loss = 0.0782423
I0815 09:49:45.666111   668 solver.cpp:244]     Train net output #0: loss1 = 0.0357171 (* 0.5 = 0.0178586 loss)
I0815 09:49:45.666127   668 solver.cpp:244]     Train net output #1: loss2 = 0.120767 (* 0.5 = 0.0603837 loss)
I0815 09:49:45.666141   668 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0815 09:49:50.552744   668 solver.cpp:228] Iteration 6420, loss = 0.0913202
I0815 09:49:50.552902   668 solver.cpp:244]     Train net output #0: loss1 = 0.0606409 (* 0.5 = 0.0303205 loss)
I0815 09:49:50.552924   668 solver.cpp:244]     Train net output #1: loss2 = 0.121999 (* 0.5 = 0.0609997 loss)
I0815 09:49:50.552942   668 sgd_solver.cpp:106] Iteration 6420, lr = 1e-05
I0815 09:49:55.446511   668 solver.cpp:228] Iteration 6440, loss = 0.0652038
I0815 09:49:55.446579   668 solver.cpp:244]     Train net output #0: loss1 = 0.0333113 (* 0.5 = 0.0166556 loss)
I0815 09:49:55.446596   668 solver.cpp:244]     Train net output #1: loss2 = 0.0970962 (* 0.5 = 0.0485481 loss)
I0815 09:49:55.446610   668 sgd_solver.cpp:106] Iteration 6440, lr = 1e-05
I0815 09:50:00.336640   668 solver.cpp:228] Iteration 6460, loss = 0.0906392
I0815 09:50:00.336688   668 solver.cpp:244]     Train net output #0: loss1 = 0.0180577 (* 0.5 = 0.00902886 loss)
I0815 09:50:00.336699   668 solver.cpp:244]     Train net output #1: loss2 = 0.163221 (* 0.5 = 0.0816103 loss)
I0815 09:50:00.336709   668 sgd_solver.cpp:106] Iteration 6460, lr = 1e-05
I0815 09:50:05.250569   668 solver.cpp:228] Iteration 6480, loss = 0.0516989
I0815 09:50:05.250624   668 solver.cpp:244]     Train net output #0: loss1 = 0.0298695 (* 0.5 = 0.0149347 loss)
I0815 09:50:05.250639   668 solver.cpp:244]     Train net output #1: loss2 = 0.0735281 (* 0.5 = 0.0367641 loss)
I0815 09:50:05.250653   668 sgd_solver.cpp:106] Iteration 6480, lr = 1e-05
I0815 09:50:10.149220   668 solver.cpp:228] Iteration 6500, loss = 0.0551722
I0815 09:50:10.149279   668 solver.cpp:244]     Train net output #0: loss1 = 0.0149065 (* 0.5 = 0.00745327 loss)
I0815 09:50:10.149296   668 solver.cpp:244]     Train net output #1: loss2 = 0.0954376 (* 0.5 = 0.0477188 loss)
I0815 09:50:10.149308   668 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0815 09:50:15.038899   668 solver.cpp:228] Iteration 6520, loss = 0.0771407
I0815 09:50:15.038959   668 solver.cpp:244]     Train net output #0: loss1 = 0.0385912 (* 0.5 = 0.0192956 loss)
I0815 09:50:15.038975   668 solver.cpp:244]     Train net output #1: loss2 = 0.11569 (* 0.5 = 0.057845 loss)
I0815 09:50:15.038990   668 sgd_solver.cpp:106] Iteration 6520, lr = 1e-05
I0815 09:50:19.929482   668 solver.cpp:228] Iteration 6540, loss = 0.101511
I0815 09:50:19.929543   668 solver.cpp:244]     Train net output #0: loss1 = 0.0872847 (* 0.5 = 0.0436423 loss)
I0815 09:50:19.929558   668 solver.cpp:244]     Train net output #1: loss2 = 0.115736 (* 0.5 = 0.0578682 loss)
I0815 09:50:19.929574   668 sgd_solver.cpp:106] Iteration 6540, lr = 1e-05
I0815 09:50:24.827622   668 solver.cpp:228] Iteration 6560, loss = 0.0663681
I0815 09:50:24.827721   668 solver.cpp:244]     Train net output #0: loss1 = 0.0238124 (* 0.5 = 0.0119062 loss)
I0815 09:50:24.827738   668 solver.cpp:244]     Train net output #1: loss2 = 0.108924 (* 0.5 = 0.0544619 loss)
I0815 09:50:24.827757   668 sgd_solver.cpp:106] Iteration 6560, lr = 1e-05
I0815 09:50:29.774416   668 solver.cpp:228] Iteration 6580, loss = 0.127825
I0815 09:50:29.774466   668 solver.cpp:244]     Train net output #0: loss1 = 0.0796985 (* 0.5 = 0.0398493 loss)
I0815 09:50:29.774477   668 solver.cpp:244]     Train net output #1: loss2 = 0.175952 (* 0.5 = 0.0879759 loss)
I0815 09:50:29.774487   668 sgd_solver.cpp:106] Iteration 6580, lr = 1e-05
I0815 09:50:34.710010   668 solver.cpp:228] Iteration 6600, loss = 0.0823221
I0815 09:50:34.710068   668 solver.cpp:244]     Train net output #0: loss1 = 0.0728283 (* 0.5 = 0.0364142 loss)
I0815 09:50:34.710084   668 solver.cpp:244]     Train net output #1: loss2 = 0.0918157 (* 0.5 = 0.0459079 loss)
I0815 09:50:34.710099   668 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0815 09:50:39.620131   668 solver.cpp:228] Iteration 6620, loss = 0.0677429
I0815 09:50:39.620192   668 solver.cpp:244]     Train net output #0: loss1 = 0.0199382 (* 0.5 = 0.00996911 loss)
I0815 09:50:39.620208   668 solver.cpp:244]     Train net output #1: loss2 = 0.115547 (* 0.5 = 0.0577737 loss)
I0815 09:50:39.620220   668 sgd_solver.cpp:106] Iteration 6620, lr = 1e-05
I0815 09:50:44.530004   668 solver.cpp:228] Iteration 6640, loss = 0.0983253
I0815 09:50:44.530064   668 solver.cpp:244]     Train net output #0: loss1 = 0.0207411 (* 0.5 = 0.0103706 loss)
I0815 09:50:44.530081   668 solver.cpp:244]     Train net output #1: loss2 = 0.175909 (* 0.5 = 0.0879547 loss)
I0815 09:50:44.530093   668 sgd_solver.cpp:106] Iteration 6640, lr = 1e-05
I0815 09:50:49.435010   668 solver.cpp:228] Iteration 6660, loss = 0.0588329
I0815 09:50:49.435068   668 solver.cpp:244]     Train net output #0: loss1 = 0.0107779 (* 0.5 = 0.00538893 loss)
I0815 09:50:49.435084   668 solver.cpp:244]     Train net output #1: loss2 = 0.106888 (* 0.5 = 0.0534438 loss)
I0815 09:50:49.435097   668 sgd_solver.cpp:106] Iteration 6660, lr = 1e-05
I0815 09:50:54.329733   668 solver.cpp:228] Iteration 6680, loss = 0.0583678
I0815 09:50:54.329788   668 solver.cpp:244]     Train net output #0: loss1 = 0.0233927 (* 0.5 = 0.0116964 loss)
I0815 09:50:54.329803   668 solver.cpp:244]     Train net output #1: loss2 = 0.0933428 (* 0.5 = 0.0466714 loss)
I0815 09:50:54.329818   668 sgd_solver.cpp:106] Iteration 6680, lr = 1e-05
I0815 09:50:59.259413   668 solver.cpp:228] Iteration 6700, loss = 0.110816
I0815 09:50:59.259563   668 solver.cpp:244]     Train net output #0: loss1 = 0.0159791 (* 0.5 = 0.00798953 loss)
I0815 09:50:59.259582   668 solver.cpp:244]     Train net output #1: loss2 = 0.205653 (* 0.5 = 0.102826 loss)
I0815 09:50:59.259594   668 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0815 09:51:04.150202   668 solver.cpp:228] Iteration 6720, loss = 0.0697164
I0815 09:51:04.150260   668 solver.cpp:244]     Train net output #0: loss1 = 0.021107 (* 0.5 = 0.0105535 loss)
I0815 09:51:04.150276   668 solver.cpp:244]     Train net output #1: loss2 = 0.118326 (* 0.5 = 0.0591628 loss)
I0815 09:51:04.150290   668 sgd_solver.cpp:106] Iteration 6720, lr = 1e-05
I0815 09:51:09.063463   668 solver.cpp:228] Iteration 6740, loss = 0.054431
I0815 09:51:09.063524   668 solver.cpp:244]     Train net output #0: loss1 = 0.0281814 (* 0.5 = 0.0140907 loss)
I0815 09:51:09.063539   668 solver.cpp:244]     Train net output #1: loss2 = 0.0806805 (* 0.5 = 0.0403403 loss)
I0815 09:51:09.063552   668 sgd_solver.cpp:106] Iteration 6740, lr = 1e-05
I0815 09:51:13.973548   668 solver.cpp:228] Iteration 6760, loss = 0.091831
I0815 09:51:13.973608   668 solver.cpp:244]     Train net output #0: loss1 = 0.0880948 (* 0.5 = 0.0440474 loss)
I0815 09:51:13.973623   668 solver.cpp:244]     Train net output #1: loss2 = 0.095567 (* 0.5 = 0.0477835 loss)
I0815 09:51:13.973636   668 sgd_solver.cpp:106] Iteration 6760, lr = 1e-05
I0815 09:51:18.895112   668 solver.cpp:228] Iteration 6780, loss = 0.0533522
I0815 09:51:18.895174   668 solver.cpp:244]     Train net output #0: loss1 = 0.0154382 (* 0.5 = 0.00771912 loss)
I0815 09:51:18.895190   668 solver.cpp:244]     Train net output #1: loss2 = 0.0912659 (* 0.5 = 0.045633 loss)
I0815 09:51:18.895203   668 sgd_solver.cpp:106] Iteration 6780, lr = 1e-05
I0815 09:51:23.812484   668 solver.cpp:228] Iteration 6800, loss = 0.0475885
I0815 09:51:23.812543   668 solver.cpp:244]     Train net output #0: loss1 = 0.0157676 (* 0.5 = 0.00788382 loss)
I0815 09:51:23.812559   668 solver.cpp:244]     Train net output #1: loss2 = 0.0794091 (* 0.5 = 0.0397046 loss)
I0815 09:51:23.812573   668 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0815 09:51:28.732977   668 solver.cpp:228] Iteration 6820, loss = 0.0382366
I0815 09:51:28.733042   668 solver.cpp:244]     Train net output #0: loss1 = 0.0104627 (* 0.5 = 0.00523137 loss)
I0815 09:51:28.733057   668 solver.cpp:244]     Train net output #1: loss2 = 0.0660103 (* 0.5 = 0.0330051 loss)
I0815 09:51:28.733072   668 sgd_solver.cpp:106] Iteration 6820, lr = 1e-05
I0815 09:51:33.631032   668 solver.cpp:228] Iteration 6840, loss = 0.0919643
I0815 09:51:33.631153   668 solver.cpp:244]     Train net output #0: loss1 = 0.0305675 (* 0.5 = 0.0152838 loss)
I0815 09:51:33.631170   668 solver.cpp:244]     Train net output #1: loss2 = 0.153361 (* 0.5 = 0.0766804 loss)
I0815 09:51:33.631183   668 sgd_solver.cpp:106] Iteration 6840, lr = 1e-05
I0815 09:51:38.524463   668 solver.cpp:228] Iteration 6860, loss = 0.0911801
I0815 09:51:38.524520   668 solver.cpp:244]     Train net output #0: loss1 = 0.0284472 (* 0.5 = 0.0142236 loss)
I0815 09:51:38.524536   668 solver.cpp:244]     Train net output #1: loss2 = 0.153913 (* 0.5 = 0.0769564 loss)
I0815 09:51:38.524549   668 sgd_solver.cpp:106] Iteration 6860, lr = 1e-05
I0815 09:51:43.448209   668 solver.cpp:228] Iteration 6880, loss = 0.0541681
I0815 09:51:43.448264   668 solver.cpp:244]     Train net output #0: loss1 = 0.00675045 (* 0.5 = 0.00337522 loss)
I0815 09:51:43.448281   668 solver.cpp:244]     Train net output #1: loss2 = 0.101586 (* 0.5 = 0.0507928 loss)
I0815 09:51:43.448293   668 sgd_solver.cpp:106] Iteration 6880, lr = 1e-05
I0815 09:51:48.338037   668 solver.cpp:228] Iteration 6900, loss = 0.0663441
I0815 09:51:48.338099   668 solver.cpp:244]     Train net output #0: loss1 = 0.0284045 (* 0.5 = 0.0142022 loss)
I0815 09:51:48.338114   668 solver.cpp:244]     Train net output #1: loss2 = 0.104284 (* 0.5 = 0.0521418 loss)
I0815 09:51:48.338129   668 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0815 09:51:53.225903   668 solver.cpp:228] Iteration 6920, loss = 0.0557359
I0815 09:51:53.226176   668 solver.cpp:244]     Train net output #0: loss1 = 0.03553 (* 0.5 = 0.017765 loss)
I0815 09:51:53.226243   668 solver.cpp:244]     Train net output #1: loss2 = 0.0759416 (* 0.5 = 0.0379708 loss)
I0815 09:51:53.226306   668 sgd_solver.cpp:106] Iteration 6920, lr = 1e-05
I0815 09:51:58.135923   668 solver.cpp:228] Iteration 6940, loss = 0.130921
I0815 09:51:58.135978   668 solver.cpp:244]     Train net output #0: loss1 = 0.0585876 (* 0.5 = 0.0292938 loss)
I0815 09:51:58.135994   668 solver.cpp:244]     Train net output #1: loss2 = 0.203254 (* 0.5 = 0.101627 loss)
I0815 09:51:58.136006   668 sgd_solver.cpp:106] Iteration 6940, lr = 1e-05
I0815 09:52:03.056890   668 solver.cpp:228] Iteration 6960, loss = 0.0834436
I0815 09:52:03.056946   668 solver.cpp:244]     Train net output #0: loss1 = 0.0288889 (* 0.5 = 0.0144444 loss)
I0815 09:52:03.056960   668 solver.cpp:244]     Train net output #1: loss2 = 0.137998 (* 0.5 = 0.0689991 loss)
I0815 09:52:03.056974   668 sgd_solver.cpp:106] Iteration 6960, lr = 1e-05
I0815 09:52:07.991034   668 solver.cpp:228] Iteration 6980, loss = 0.0809411
I0815 09:52:07.991176   668 solver.cpp:244]     Train net output #0: loss1 = 0.0437081 (* 0.5 = 0.021854 loss)
I0815 09:52:07.991194   668 solver.cpp:244]     Train net output #1: loss2 = 0.118174 (* 0.5 = 0.059087 loss)
I0815 09:52:07.991206   668 sgd_solver.cpp:106] Iteration 6980, lr = 1e-05
I0815 09:52:12.634331   668 solver.cpp:337] Iteration 7000, Testing net (#0)
I0815 09:53:09.991369   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.834656
I0815 09:53:09.991480   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.953328
I0815 09:53:09.991499   668 solver.cpp:404]     Test net output #2: loss1 = 0.163502 (* 0.5 = 0.0817508 loss)
I0815 09:53:09.991511   668 solver.cpp:404]     Test net output #3: loss2 = 0.417781 (* 0.5 = 0.20889 loss)
I0815 09:53:10.065374   668 solver.cpp:228] Iteration 7000, loss = 0.113729
I0815 09:53:10.065433   668 solver.cpp:244]     Train net output #0: loss1 = 0.0392945 (* 0.5 = 0.0196473 loss)
I0815 09:53:10.065449   668 solver.cpp:244]     Train net output #1: loss2 = 0.188164 (* 0.5 = 0.094082 loss)
I0815 09:53:10.065464   668 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0815 09:53:14.956593   668 solver.cpp:228] Iteration 7020, loss = 0.0959588
I0815 09:53:14.956645   668 solver.cpp:244]     Train net output #0: loss1 = 0.0585935 (* 0.5 = 0.0292967 loss)
I0815 09:53:14.956661   668 solver.cpp:244]     Train net output #1: loss2 = 0.133324 (* 0.5 = 0.066662 loss)
I0815 09:53:14.956676   668 sgd_solver.cpp:106] Iteration 7020, lr = 1e-05
I0815 09:53:19.844243   668 solver.cpp:228] Iteration 7040, loss = 0.105464
I0815 09:53:19.844300   668 solver.cpp:244]     Train net output #0: loss1 = 0.0742179 (* 0.5 = 0.037109 loss)
I0815 09:53:19.844316   668 solver.cpp:244]     Train net output #1: loss2 = 0.136709 (* 0.5 = 0.0683545 loss)
I0815 09:53:19.844329   668 sgd_solver.cpp:106] Iteration 7040, lr = 1e-05
I0815 09:53:24.744343   668 solver.cpp:228] Iteration 7060, loss = 0.0889402
I0815 09:53:24.744396   668 solver.cpp:244]     Train net output #0: loss1 = 0.0867342 (* 0.5 = 0.0433671 loss)
I0815 09:53:24.744412   668 solver.cpp:244]     Train net output #1: loss2 = 0.091146 (* 0.5 = 0.045573 loss)
I0815 09:53:24.744426   668 sgd_solver.cpp:106] Iteration 7060, lr = 1e-05
I0815 09:53:29.635001   668 solver.cpp:228] Iteration 7080, loss = 0.0678357
I0815 09:53:29.635056   668 solver.cpp:244]     Train net output #0: loss1 = 0.0199444 (* 0.5 = 0.00997221 loss)
I0815 09:53:29.635072   668 solver.cpp:244]     Train net output #1: loss2 = 0.115727 (* 0.5 = 0.0578634 loss)
I0815 09:53:29.635087   668 sgd_solver.cpp:106] Iteration 7080, lr = 1e-05
I0815 09:53:34.527565   668 solver.cpp:228] Iteration 7100, loss = 0.0499666
I0815 09:53:34.527624   668 solver.cpp:244]     Train net output #0: loss1 = 0.0167076 (* 0.5 = 0.00835381 loss)
I0815 09:53:34.527640   668 solver.cpp:244]     Train net output #1: loss2 = 0.0832254 (* 0.5 = 0.0416127 loss)
I0815 09:53:34.527653   668 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0815 09:53:39.422394   668 solver.cpp:228] Iteration 7120, loss = 0.0685453
I0815 09:53:39.422451   668 solver.cpp:244]     Train net output #0: loss1 = 0.0595006 (* 0.5 = 0.0297503 loss)
I0815 09:53:39.422467   668 solver.cpp:244]     Train net output #1: loss2 = 0.0775898 (* 0.5 = 0.0387949 loss)
I0815 09:53:39.422480   668 sgd_solver.cpp:106] Iteration 7120, lr = 1e-05
I0815 09:53:44.313530   668 solver.cpp:228] Iteration 7140, loss = 0.0876082
I0815 09:53:44.313684   668 solver.cpp:244]     Train net output #0: loss1 = 0.037582 (* 0.5 = 0.018791 loss)
I0815 09:53:44.313701   668 solver.cpp:244]     Train net output #1: loss2 = 0.137634 (* 0.5 = 0.0688171 loss)
I0815 09:53:44.313715   668 sgd_solver.cpp:106] Iteration 7140, lr = 1e-05
I0815 09:53:49.206512   668 solver.cpp:228] Iteration 7160, loss = 0.0635989
I0815 09:53:49.206569   668 solver.cpp:244]     Train net output #0: loss1 = 0.0369132 (* 0.5 = 0.0184566 loss)
I0815 09:53:49.206586   668 solver.cpp:244]     Train net output #1: loss2 = 0.0902844 (* 0.5 = 0.0451422 loss)
I0815 09:53:49.206603   668 sgd_solver.cpp:106] Iteration 7160, lr = 1e-05
I0815 09:53:54.100802   668 solver.cpp:228] Iteration 7180, loss = 0.120644
I0815 09:53:54.100862   668 solver.cpp:244]     Train net output #0: loss1 = 0.0842046 (* 0.5 = 0.0421023 loss)
I0815 09:53:54.100878   668 solver.cpp:244]     Train net output #1: loss2 = 0.157083 (* 0.5 = 0.0785416 loss)
I0815 09:53:54.100890   668 sgd_solver.cpp:106] Iteration 7180, lr = 1e-05
I0815 09:53:58.992707   668 solver.cpp:228] Iteration 7200, loss = 0.0739034
I0815 09:53:58.992765   668 solver.cpp:244]     Train net output #0: loss1 = 0.0148579 (* 0.5 = 0.00742895 loss)
I0815 09:53:58.992781   668 solver.cpp:244]     Train net output #1: loss2 = 0.132949 (* 0.5 = 0.0664743 loss)
I0815 09:53:58.992795   668 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0815 09:54:03.890416   668 solver.cpp:228] Iteration 7220, loss = 0.0833945
I0815 09:54:03.890475   668 solver.cpp:244]     Train net output #0: loss1 = 0.0197364 (* 0.5 = 0.00986822 loss)
I0815 09:54:03.890489   668 solver.cpp:244]     Train net output #1: loss2 = 0.147052 (* 0.5 = 0.0735262 loss)
I0815 09:54:03.890503   668 sgd_solver.cpp:106] Iteration 7220, lr = 1e-05
I0815 09:54:08.783174   668 solver.cpp:228] Iteration 7240, loss = 0.0880469
I0815 09:54:08.783231   668 solver.cpp:244]     Train net output #0: loss1 = 0.0291612 (* 0.5 = 0.0145806 loss)
I0815 09:54:08.783246   668 solver.cpp:244]     Train net output #1: loss2 = 0.146933 (* 0.5 = 0.0734663 loss)
I0815 09:54:08.783259   668 sgd_solver.cpp:106] Iteration 7240, lr = 1e-05
I0815 09:54:13.672799   668 solver.cpp:228] Iteration 7260, loss = 0.123776
I0815 09:54:13.672859   668 solver.cpp:244]     Train net output #0: loss1 = 0.0464019 (* 0.5 = 0.0232009 loss)
I0815 09:54:13.672874   668 solver.cpp:244]     Train net output #1: loss2 = 0.201149 (* 0.5 = 0.100575 loss)
I0815 09:54:13.672888   668 sgd_solver.cpp:106] Iteration 7260, lr = 1e-05
I0815 09:54:18.573534   668 solver.cpp:228] Iteration 7280, loss = 0.0608178
I0815 09:54:18.573717   668 solver.cpp:244]     Train net output #0: loss1 = 0.0628982 (* 0.5 = 0.0314491 loss)
I0815 09:54:18.573741   668 solver.cpp:244]     Train net output #1: loss2 = 0.0587373 (* 0.5 = 0.0293686 loss)
I0815 09:54:18.573757   668 sgd_solver.cpp:106] Iteration 7280, lr = 1e-05
I0815 09:54:23.465831   668 solver.cpp:228] Iteration 7300, loss = 0.0976677
I0815 09:54:23.465889   668 solver.cpp:244]     Train net output #0: loss1 = 0.0386079 (* 0.5 = 0.0193039 loss)
I0815 09:54:23.465905   668 solver.cpp:244]     Train net output #1: loss2 = 0.156727 (* 0.5 = 0.0783637 loss)
I0815 09:54:23.465919   668 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0815 09:54:28.357220   668 solver.cpp:228] Iteration 7320, loss = 0.0599277
I0815 09:54:28.357278   668 solver.cpp:244]     Train net output #0: loss1 = 0.0193269 (* 0.5 = 0.00966347 loss)
I0815 09:54:28.357295   668 solver.cpp:244]     Train net output #1: loss2 = 0.100528 (* 0.5 = 0.0502642 loss)
I0815 09:54:28.357308   668 sgd_solver.cpp:106] Iteration 7320, lr = 1e-05
I0815 09:54:33.327121   668 solver.cpp:228] Iteration 7340, loss = 0.101238
I0815 09:54:33.327180   668 solver.cpp:244]     Train net output #0: loss1 = 0.0257599 (* 0.5 = 0.01288 loss)
I0815 09:54:33.327196   668 solver.cpp:244]     Train net output #1: loss2 = 0.176716 (* 0.5 = 0.0883581 loss)
I0815 09:54:33.327209   668 sgd_solver.cpp:106] Iteration 7340, lr = 1e-05
I0815 09:54:38.228832   668 solver.cpp:228] Iteration 7360, loss = 0.0641762
I0815 09:54:38.228890   668 solver.cpp:244]     Train net output #0: loss1 = 0.0585158 (* 0.5 = 0.0292579 loss)
I0815 09:54:38.228905   668 solver.cpp:244]     Train net output #1: loss2 = 0.0698364 (* 0.5 = 0.0349182 loss)
I0815 09:54:38.228919   668 sgd_solver.cpp:106] Iteration 7360, lr = 1e-05
I0815 09:54:43.147635   668 solver.cpp:228] Iteration 7380, loss = 0.0690701
I0815 09:54:43.147693   668 solver.cpp:244]     Train net output #0: loss1 = 0.0148924 (* 0.5 = 0.00744622 loss)
I0815 09:54:43.147708   668 solver.cpp:244]     Train net output #1: loss2 = 0.123248 (* 0.5 = 0.0616238 loss)
I0815 09:54:43.147722   668 sgd_solver.cpp:106] Iteration 7380, lr = 1e-05
I0815 09:54:48.077504   668 solver.cpp:228] Iteration 7400, loss = 0.0648856
I0815 09:54:48.077657   668 solver.cpp:244]     Train net output #0: loss1 = 0.0216348 (* 0.5 = 0.0108174 loss)
I0815 09:54:48.077674   668 solver.cpp:244]     Train net output #1: loss2 = 0.108136 (* 0.5 = 0.0540682 loss)
I0815 09:54:48.077688   668 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0815 09:54:52.977535   668 solver.cpp:228] Iteration 7420, loss = 0.097531
I0815 09:54:52.977653   668 solver.cpp:244]     Train net output #0: loss1 = 0.0799519 (* 0.5 = 0.039976 loss)
I0815 09:54:52.977669   668 solver.cpp:244]     Train net output #1: loss2 = 0.11511 (* 0.5 = 0.057555 loss)
I0815 09:54:52.977684   668 sgd_solver.cpp:106] Iteration 7420, lr = 1e-05
I0815 09:54:57.872697   668 solver.cpp:228] Iteration 7440, loss = 0.0595882
I0815 09:54:57.872759   668 solver.cpp:244]     Train net output #0: loss1 = 0.0544165 (* 0.5 = 0.0272083 loss)
I0815 09:54:57.872776   668 solver.cpp:244]     Train net output #1: loss2 = 0.0647598 (* 0.5 = 0.0323799 loss)
I0815 09:54:57.872787   668 sgd_solver.cpp:106] Iteration 7440, lr = 1e-05
I0815 09:55:02.787648   668 solver.cpp:228] Iteration 7460, loss = 0.0268326
I0815 09:55:02.787889   668 solver.cpp:244]     Train net output #0: loss1 = 0.0116912 (* 0.5 = 0.00584559 loss)
I0815 09:55:02.787905   668 solver.cpp:244]     Train net output #1: loss2 = 0.0419737 (* 0.5 = 0.0209869 loss)
I0815 09:55:02.787926   668 sgd_solver.cpp:106] Iteration 7460, lr = 1e-05
I0815 09:55:07.689491   668 solver.cpp:228] Iteration 7480, loss = 0.0565587
I0815 09:55:07.689550   668 solver.cpp:244]     Train net output #0: loss1 = 0.030506 (* 0.5 = 0.015253 loss)
I0815 09:55:07.689566   668 solver.cpp:244]     Train net output #1: loss2 = 0.0826112 (* 0.5 = 0.0413056 loss)
I0815 09:55:07.689579   668 sgd_solver.cpp:106] Iteration 7480, lr = 1e-05
I0815 09:55:12.602761   668 solver.cpp:228] Iteration 7500, loss = 0.0798038
I0815 09:55:12.602818   668 solver.cpp:244]     Train net output #0: loss1 = 0.0281546 (* 0.5 = 0.0140773 loss)
I0815 09:55:12.602833   668 solver.cpp:244]     Train net output #1: loss2 = 0.131453 (* 0.5 = 0.0657264 loss)
I0815 09:55:12.602846   668 sgd_solver.cpp:106] Iteration 7500, lr = 1e-05
I0815 09:55:17.533897   668 solver.cpp:228] Iteration 7520, loss = 0.123343
I0815 09:55:17.533956   668 solver.cpp:244]     Train net output #0: loss1 = 0.0451178 (* 0.5 = 0.0225589 loss)
I0815 09:55:17.533972   668 solver.cpp:244]     Train net output #1: loss2 = 0.201569 (* 0.5 = 0.100784 loss)
I0815 09:55:17.533984   668 sgd_solver.cpp:106] Iteration 7520, lr = 1e-05
I0815 09:55:22.465435   668 solver.cpp:228] Iteration 7540, loss = 0.168191
I0815 09:55:22.465497   668 solver.cpp:244]     Train net output #0: loss1 = 0.168584 (* 0.5 = 0.0842918 loss)
I0815 09:55:22.465512   668 solver.cpp:244]     Train net output #1: loss2 = 0.167797 (* 0.5 = 0.0838987 loss)
I0815 09:55:22.465525   668 sgd_solver.cpp:106] Iteration 7540, lr = 1e-05
I0815 09:55:27.376627   668 solver.cpp:228] Iteration 7560, loss = 0.0691556
I0815 09:55:27.376770   668 solver.cpp:244]     Train net output #0: loss1 = 0.0377994 (* 0.5 = 0.0188997 loss)
I0815 09:55:27.376786   668 solver.cpp:244]     Train net output #1: loss2 = 0.100512 (* 0.5 = 0.0502558 loss)
I0815 09:55:27.376801   668 sgd_solver.cpp:106] Iteration 7560, lr = 1e-05
I0815 09:55:32.295068   668 solver.cpp:228] Iteration 7580, loss = 0.0648603
I0815 09:55:32.295122   668 solver.cpp:244]     Train net output #0: loss1 = 0.0157346 (* 0.5 = 0.00786729 loss)
I0815 09:55:32.295138   668 solver.cpp:244]     Train net output #1: loss2 = 0.113986 (* 0.5 = 0.0569929 loss)
I0815 09:55:32.295151   668 sgd_solver.cpp:106] Iteration 7580, lr = 1e-05
I0815 09:55:37.240806   668 solver.cpp:228] Iteration 7600, loss = 0.0950143
I0815 09:55:37.240885   668 solver.cpp:244]     Train net output #0: loss1 = 0.0289742 (* 0.5 = 0.0144871 loss)
I0815 09:55:37.240921   668 solver.cpp:244]     Train net output #1: loss2 = 0.161054 (* 0.5 = 0.0805271 loss)
I0815 09:55:37.240942   668 sgd_solver.cpp:106] Iteration 7600, lr = 1e-05
I0815 09:55:42.167444   668 solver.cpp:228] Iteration 7620, loss = 0.128211
I0815 09:55:42.167500   668 solver.cpp:244]     Train net output #0: loss1 = 0.110015 (* 0.5 = 0.0550073 loss)
I0815 09:55:42.167515   668 solver.cpp:244]     Train net output #1: loss2 = 0.146407 (* 0.5 = 0.0732033 loss)
I0815 09:55:42.167528   668 sgd_solver.cpp:106] Iteration 7620, lr = 1e-05
I0815 09:55:47.065065   668 solver.cpp:228] Iteration 7640, loss = 0.084734
I0815 09:55:47.065125   668 solver.cpp:244]     Train net output #0: loss1 = 0.0231601 (* 0.5 = 0.0115801 loss)
I0815 09:55:47.065140   668 solver.cpp:244]     Train net output #1: loss2 = 0.146308 (* 0.5 = 0.0731539 loss)
I0815 09:55:47.065155   668 sgd_solver.cpp:106] Iteration 7640, lr = 1e-05
I0815 09:55:51.971226   668 solver.cpp:228] Iteration 7660, loss = 0.0829541
I0815 09:55:51.971279   668 solver.cpp:244]     Train net output #0: loss1 = 0.0639333 (* 0.5 = 0.0319666 loss)
I0815 09:55:51.971295   668 solver.cpp:244]     Train net output #1: loss2 = 0.101975 (* 0.5 = 0.0509873 loss)
I0815 09:55:51.971308   668 sgd_solver.cpp:106] Iteration 7660, lr = 1e-05
I0815 09:55:56.889004   668 solver.cpp:228] Iteration 7680, loss = 0.118873
I0815 09:55:56.889061   668 solver.cpp:244]     Train net output #0: loss1 = 0.0553068 (* 0.5 = 0.0276534 loss)
I0815 09:55:56.889077   668 solver.cpp:244]     Train net output #1: loss2 = 0.18244 (* 0.5 = 0.0912199 loss)
I0815 09:55:56.889091   668 sgd_solver.cpp:106] Iteration 7680, lr = 1e-05
I0815 09:56:01.848424   668 solver.cpp:228] Iteration 7700, loss = 0.0558605
I0815 09:56:01.848587   668 solver.cpp:244]     Train net output #0: loss1 = 0.0248993 (* 0.5 = 0.0124497 loss)
I0815 09:56:01.848605   668 solver.cpp:244]     Train net output #1: loss2 = 0.0868216 (* 0.5 = 0.0434108 loss)
I0815 09:56:01.848619   668 sgd_solver.cpp:106] Iteration 7700, lr = 1e-05
I0815 09:56:06.757314   668 solver.cpp:228] Iteration 7720, loss = 0.0731576
I0815 09:56:06.757372   668 solver.cpp:244]     Train net output #0: loss1 = 0.0260993 (* 0.5 = 0.0130496 loss)
I0815 09:56:06.757388   668 solver.cpp:244]     Train net output #1: loss2 = 0.120216 (* 0.5 = 0.0601078 loss)
I0815 09:56:06.757401   668 sgd_solver.cpp:106] Iteration 7720, lr = 1e-05
I0815 09:56:11.665567   668 solver.cpp:228] Iteration 7740, loss = 0.0687251
I0815 09:56:11.665627   668 solver.cpp:244]     Train net output #0: loss1 = 0.0280296 (* 0.5 = 0.0140148 loss)
I0815 09:56:11.665642   668 solver.cpp:244]     Train net output #1: loss2 = 0.10942 (* 0.5 = 0.0547102 loss)
I0815 09:56:11.665655   668 sgd_solver.cpp:106] Iteration 7740, lr = 1e-05
I0815 09:56:16.578372   668 solver.cpp:228] Iteration 7760, loss = 0.0503035
I0815 09:56:16.578431   668 solver.cpp:244]     Train net output #0: loss1 = 0.0215621 (* 0.5 = 0.0107811 loss)
I0815 09:56:16.578446   668 solver.cpp:244]     Train net output #1: loss2 = 0.0790448 (* 0.5 = 0.0395224 loss)
I0815 09:56:16.578460   668 sgd_solver.cpp:106] Iteration 7760, lr = 1e-05
I0815 09:56:21.497663   668 solver.cpp:228] Iteration 7780, loss = 0.0697206
I0815 09:56:21.497721   668 solver.cpp:244]     Train net output #0: loss1 = 0.0361558 (* 0.5 = 0.0180779 loss)
I0815 09:56:21.497737   668 solver.cpp:244]     Train net output #1: loss2 = 0.103285 (* 0.5 = 0.0516426 loss)
I0815 09:56:21.497750   668 sgd_solver.cpp:106] Iteration 7780, lr = 1e-05
I0815 09:56:26.407521   668 solver.cpp:228] Iteration 7800, loss = 0.0816743
I0815 09:56:26.407582   668 solver.cpp:244]     Train net output #0: loss1 = 0.0705169 (* 0.5 = 0.0352584 loss)
I0815 09:56:26.407598   668 solver.cpp:244]     Train net output #1: loss2 = 0.0928315 (* 0.5 = 0.0464157 loss)
I0815 09:56:26.407611   668 sgd_solver.cpp:106] Iteration 7800, lr = 1e-05
I0815 09:56:31.314347   668 solver.cpp:228] Iteration 7820, loss = 0.0815585
I0815 09:56:31.314405   668 solver.cpp:244]     Train net output #0: loss1 = 0.0496693 (* 0.5 = 0.0248347 loss)
I0815 09:56:31.314420   668 solver.cpp:244]     Train net output #1: loss2 = 0.113448 (* 0.5 = 0.0567238 loss)
I0815 09:56:31.314435   668 sgd_solver.cpp:106] Iteration 7820, lr = 1e-05
I0815 09:56:36.209448   668 solver.cpp:228] Iteration 7840, loss = 0.0667537
I0815 09:56:36.209611   668 solver.cpp:244]     Train net output #0: loss1 = 0.0213087 (* 0.5 = 0.0106543 loss)
I0815 09:56:36.209635   668 solver.cpp:244]     Train net output #1: loss2 = 0.112199 (* 0.5 = 0.0560993 loss)
I0815 09:56:36.209651   668 sgd_solver.cpp:106] Iteration 7840, lr = 1e-05
I0815 09:56:41.131744   668 solver.cpp:228] Iteration 7860, loss = 0.045737
I0815 09:56:41.131803   668 solver.cpp:244]     Train net output #0: loss1 = 0.0112926 (* 0.5 = 0.00564631 loss)
I0815 09:56:41.131817   668 solver.cpp:244]     Train net output #1: loss2 = 0.0801813 (* 0.5 = 0.0400906 loss)
I0815 09:56:41.131831   668 sgd_solver.cpp:106] Iteration 7860, lr = 1e-05
I0815 09:56:46.028156   668 solver.cpp:228] Iteration 7880, loss = 0.0718117
I0815 09:56:46.028215   668 solver.cpp:244]     Train net output #0: loss1 = 0.0618315 (* 0.5 = 0.0309157 loss)
I0815 09:56:46.028230   668 solver.cpp:244]     Train net output #1: loss2 = 0.0817918 (* 0.5 = 0.0408959 loss)
I0815 09:56:46.028244   668 sgd_solver.cpp:106] Iteration 7880, lr = 1e-05
I0815 09:56:50.947000   668 solver.cpp:228] Iteration 7900, loss = 0.0902411
I0815 09:56:50.947057   668 solver.cpp:244]     Train net output #0: loss1 = 0.0791934 (* 0.5 = 0.0395967 loss)
I0815 09:56:50.947073   668 solver.cpp:244]     Train net output #1: loss2 = 0.101289 (* 0.5 = 0.0506443 loss)
I0815 09:56:50.947087   668 sgd_solver.cpp:106] Iteration 7900, lr = 1e-05
I0815 09:56:55.860110   668 solver.cpp:228] Iteration 7920, loss = 0.054581
I0815 09:56:55.860165   668 solver.cpp:244]     Train net output #0: loss1 = 0.0227657 (* 0.5 = 0.0113829 loss)
I0815 09:56:55.860180   668 solver.cpp:244]     Train net output #1: loss2 = 0.0863962 (* 0.5 = 0.0431981 loss)
I0815 09:56:55.860203   668 sgd_solver.cpp:106] Iteration 7920, lr = 1e-05
I0815 09:57:00.752254   668 solver.cpp:228] Iteration 7940, loss = 0.0728335
I0815 09:57:00.752312   668 solver.cpp:244]     Train net output #0: loss1 = 0.0199992 (* 0.5 = 0.0099996 loss)
I0815 09:57:00.752327   668 solver.cpp:244]     Train net output #1: loss2 = 0.125668 (* 0.5 = 0.0628338 loss)
I0815 09:57:00.752341   668 sgd_solver.cpp:106] Iteration 7940, lr = 1e-05
I0815 09:57:05.647187   668 solver.cpp:228] Iteration 7960, loss = 0.0917064
I0815 09:57:05.647243   668 solver.cpp:244]     Train net output #0: loss1 = 0.0365792 (* 0.5 = 0.0182896 loss)
I0815 09:57:05.647259   668 solver.cpp:244]     Train net output #1: loss2 = 0.146833 (* 0.5 = 0.0734167 loss)
I0815 09:57:05.647272   668 sgd_solver.cpp:106] Iteration 7960, lr = 1e-05
I0815 09:57:10.566102   668 solver.cpp:228] Iteration 7980, loss = 0.106037
I0815 09:57:10.566300   668 solver.cpp:244]     Train net output #0: loss1 = 0.0289653 (* 0.5 = 0.0144826 loss)
I0815 09:57:10.566323   668 solver.cpp:244]     Train net output #1: loss2 = 0.183108 (* 0.5 = 0.091554 loss)
I0815 09:57:10.566336   668 sgd_solver.cpp:106] Iteration 7980, lr = 1e-05
I0815 09:57:15.269510   668 solver.cpp:337] Iteration 8000, Testing net (#0)
I0815 09:58:12.685174   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.836719
I0815 09:58:12.685267   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.951469
I0815 09:58:12.685291   668 solver.cpp:404]     Test net output #2: loss1 = 0.16321 (* 0.5 = 0.081605 loss)
I0815 09:58:12.685303   668 solver.cpp:404]     Test net output #3: loss2 = 0.417568 (* 0.5 = 0.208784 loss)
I0815 09:58:12.760833   668 solver.cpp:228] Iteration 8000, loss = 0.0955519
I0815 09:58:12.760895   668 solver.cpp:244]     Train net output #0: loss1 = 0.0881964 (* 0.5 = 0.0440982 loss)
I0815 09:58:12.760911   668 solver.cpp:244]     Train net output #1: loss2 = 0.102907 (* 0.5 = 0.0514536 loss)
I0815 09:58:12.760926   668 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0815 09:58:17.672377   668 solver.cpp:228] Iteration 8020, loss = 0.0877921
I0815 09:58:17.672442   668 solver.cpp:244]     Train net output #0: loss1 = 0.066473 (* 0.5 = 0.0332365 loss)
I0815 09:58:17.672458   668 solver.cpp:244]     Train net output #1: loss2 = 0.109111 (* 0.5 = 0.0545555 loss)
I0815 09:58:17.672472   668 sgd_solver.cpp:106] Iteration 8020, lr = 1e-06
I0815 09:58:22.576848   668 solver.cpp:228] Iteration 8040, loss = 0.106791
I0815 09:58:22.576905   668 solver.cpp:244]     Train net output #0: loss1 = 0.0152681 (* 0.5 = 0.00763403 loss)
I0815 09:58:22.576920   668 solver.cpp:244]     Train net output #1: loss2 = 0.198313 (* 0.5 = 0.0991567 loss)
I0815 09:58:22.576933   668 sgd_solver.cpp:106] Iteration 8040, lr = 1e-06
I0815 09:58:27.487694   668 solver.cpp:228] Iteration 8060, loss = 0.106699
I0815 09:58:27.487741   668 solver.cpp:244]     Train net output #0: loss1 = 0.0529566 (* 0.5 = 0.0264783 loss)
I0815 09:58:27.487752   668 solver.cpp:244]     Train net output #1: loss2 = 0.160441 (* 0.5 = 0.0802205 loss)
I0815 09:58:27.487762   668 sgd_solver.cpp:106] Iteration 8060, lr = 1e-06
I0815 09:58:32.412063   668 solver.cpp:228] Iteration 8080, loss = 0.0628827
I0815 09:58:32.412117   668 solver.cpp:244]     Train net output #0: loss1 = 0.0166504 (* 0.5 = 0.00832521 loss)
I0815 09:58:32.412134   668 solver.cpp:244]     Train net output #1: loss2 = 0.109115 (* 0.5 = 0.0545574 loss)
I0815 09:58:32.412152   668 sgd_solver.cpp:106] Iteration 8080, lr = 1e-06
I0815 09:58:37.307128   668 solver.cpp:228] Iteration 8100, loss = 0.0697027
I0815 09:58:37.307188   668 solver.cpp:244]     Train net output #0: loss1 = 0.019941 (* 0.5 = 0.00997048 loss)
I0815 09:58:37.307204   668 solver.cpp:244]     Train net output #1: loss2 = 0.119464 (* 0.5 = 0.0597321 loss)
I0815 09:58:37.307216   668 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0815 09:58:42.199861   668 solver.cpp:228] Iteration 8120, loss = 0.10775
I0815 09:58:42.199918   668 solver.cpp:244]     Train net output #0: loss1 = 0.0535322 (* 0.5 = 0.0267661 loss)
I0815 09:58:42.199934   668 solver.cpp:244]     Train net output #1: loss2 = 0.161968 (* 0.5 = 0.0809841 loss)
I0815 09:58:42.199947   668 sgd_solver.cpp:106] Iteration 8120, lr = 1e-06
I0815 09:58:47.087745   668 solver.cpp:228] Iteration 8140, loss = 0.0942467
I0815 09:58:47.087918   668 solver.cpp:244]     Train net output #0: loss1 = 0.0323999 (* 0.5 = 0.0161999 loss)
I0815 09:58:47.087944   668 solver.cpp:244]     Train net output #1: loss2 = 0.156093 (* 0.5 = 0.0780467 loss)
I0815 09:58:47.087960   668 sgd_solver.cpp:106] Iteration 8140, lr = 1e-06
I0815 09:58:51.971838   668 solver.cpp:228] Iteration 8160, loss = 0.0712802
I0815 09:58:51.971923   668 solver.cpp:244]     Train net output #0: loss1 = 0.0271959 (* 0.5 = 0.0135979 loss)
I0815 09:58:51.971940   668 solver.cpp:244]     Train net output #1: loss2 = 0.115364 (* 0.5 = 0.0576822 loss)
I0815 09:58:51.971953   668 sgd_solver.cpp:106] Iteration 8160, lr = 1e-06
I0815 09:58:56.853646   668 solver.cpp:228] Iteration 8180, loss = 0.0994779
I0815 09:58:56.853705   668 solver.cpp:244]     Train net output #0: loss1 = 0.00991883 (* 0.5 = 0.00495941 loss)
I0815 09:58:56.853721   668 solver.cpp:244]     Train net output #1: loss2 = 0.189037 (* 0.5 = 0.0945184 loss)
I0815 09:58:56.853735   668 sgd_solver.cpp:106] Iteration 8180, lr = 1e-06
I0815 09:59:01.738162   668 solver.cpp:228] Iteration 8200, loss = 0.112084
I0815 09:59:01.738219   668 solver.cpp:244]     Train net output #0: loss1 = 0.111105 (* 0.5 = 0.0555527 loss)
I0815 09:59:01.738235   668 solver.cpp:244]     Train net output #1: loss2 = 0.113063 (* 0.5 = 0.0565313 loss)
I0815 09:59:01.738250   668 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0815 09:59:06.620726   668 solver.cpp:228] Iteration 8220, loss = 0.081358
I0815 09:59:06.620784   668 solver.cpp:244]     Train net output #0: loss1 = 0.0216812 (* 0.5 = 0.0108406 loss)
I0815 09:59:06.620807   668 solver.cpp:244]     Train net output #1: loss2 = 0.141035 (* 0.5 = 0.0705173 loss)
I0815 09:59:06.620822   668 sgd_solver.cpp:106] Iteration 8220, lr = 1e-06
I0815 09:59:11.505915   668 solver.cpp:228] Iteration 8240, loss = 0.0486596
I0815 09:59:11.505975   668 solver.cpp:244]     Train net output #0: loss1 = 0.0213287 (* 0.5 = 0.0106643 loss)
I0815 09:59:11.505990   668 solver.cpp:244]     Train net output #1: loss2 = 0.0759904 (* 0.5 = 0.0379952 loss)
I0815 09:59:11.506003   668 sgd_solver.cpp:106] Iteration 8240, lr = 1e-06
I0815 09:59:16.394420   668 solver.cpp:228] Iteration 8260, loss = 0.0573061
I0815 09:59:16.394479   668 solver.cpp:244]     Train net output #0: loss1 = 0.025322 (* 0.5 = 0.012661 loss)
I0815 09:59:16.394493   668 solver.cpp:244]     Train net output #1: loss2 = 0.0892899 (* 0.5 = 0.044645 loss)
I0815 09:59:16.394507   668 sgd_solver.cpp:106] Iteration 8260, lr = 1e-06
I0815 09:59:21.279309   668 solver.cpp:228] Iteration 8280, loss = 0.0476781
I0815 09:59:21.279458   668 solver.cpp:244]     Train net output #0: loss1 = 0.0226319 (* 0.5 = 0.0113159 loss)
I0815 09:59:21.279482   668 solver.cpp:244]     Train net output #1: loss2 = 0.0727241 (* 0.5 = 0.036362 loss)
I0815 09:59:21.279500   668 sgd_solver.cpp:106] Iteration 8280, lr = 1e-06
I0815 09:59:26.222702   668 solver.cpp:228] Iteration 8300, loss = 0.052727
I0815 09:59:26.222757   668 solver.cpp:244]     Train net output #0: loss1 = 0.0333506 (* 0.5 = 0.0166753 loss)
I0815 09:59:26.222772   668 solver.cpp:244]     Train net output #1: loss2 = 0.0721033 (* 0.5 = 0.0360517 loss)
I0815 09:59:26.222786   668 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0815 09:59:31.174183   668 solver.cpp:228] Iteration 8320, loss = 0.107462
I0815 09:59:31.174263   668 solver.cpp:244]     Train net output #0: loss1 = 0.0577367 (* 0.5 = 0.0288684 loss)
I0815 09:59:31.174290   668 solver.cpp:244]     Train net output #1: loss2 = 0.157186 (* 0.5 = 0.0785932 loss)
I0815 09:59:31.174311   668 sgd_solver.cpp:106] Iteration 8320, lr = 1e-06
I0815 09:59:36.163874   668 solver.cpp:228] Iteration 8340, loss = 0.0516013
I0815 09:59:36.163933   668 solver.cpp:244]     Train net output #0: loss1 = 0.0226667 (* 0.5 = 0.0113334 loss)
I0815 09:59:36.163947   668 solver.cpp:244]     Train net output #1: loss2 = 0.0805356 (* 0.5 = 0.0402678 loss)
I0815 09:59:36.163960   668 sgd_solver.cpp:106] Iteration 8340, lr = 1e-06
I0815 09:59:41.123739   668 solver.cpp:228] Iteration 8360, loss = 0.0743901
I0815 09:59:41.123795   668 solver.cpp:244]     Train net output #0: loss1 = 0.00459603 (* 0.5 = 0.00229801 loss)
I0815 09:59:41.123811   668 solver.cpp:244]     Train net output #1: loss2 = 0.144184 (* 0.5 = 0.072092 loss)
I0815 09:59:41.123826   668 sgd_solver.cpp:106] Iteration 8360, lr = 1e-06
I0815 09:59:46.036447   668 solver.cpp:228] Iteration 8380, loss = 0.091235
I0815 09:59:46.036505   668 solver.cpp:244]     Train net output #0: loss1 = 0.0822023 (* 0.5 = 0.0411012 loss)
I0815 09:59:46.036520   668 solver.cpp:244]     Train net output #1: loss2 = 0.100268 (* 0.5 = 0.0501338 loss)
I0815 09:59:46.036536   668 sgd_solver.cpp:106] Iteration 8380, lr = 1e-06
I0815 09:59:50.967754   668 solver.cpp:228] Iteration 8400, loss = 0.0717022
I0815 09:59:50.967826   668 solver.cpp:244]     Train net output #0: loss1 = 0.0331411 (* 0.5 = 0.0165705 loss)
I0815 09:59:50.967841   668 solver.cpp:244]     Train net output #1: loss2 = 0.110263 (* 0.5 = 0.0551316 loss)
I0815 09:59:50.967859   668 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0815 09:59:55.887688   668 solver.cpp:228] Iteration 8420, loss = 0.0468287
I0815 09:59:55.887814   668 solver.cpp:244]     Train net output #0: loss1 = 0.0310292 (* 0.5 = 0.0155146 loss)
I0815 09:59:55.887830   668 solver.cpp:244]     Train net output #1: loss2 = 0.0626281 (* 0.5 = 0.031314 loss)
I0815 09:59:55.887845   668 sgd_solver.cpp:106] Iteration 8420, lr = 1e-06
I0815 10:00:00.794445   668 solver.cpp:228] Iteration 8440, loss = 0.0546626
I0815 10:00:00.794502   668 solver.cpp:244]     Train net output #0: loss1 = 0.0386242 (* 0.5 = 0.0193121 loss)
I0815 10:00:00.794517   668 solver.cpp:244]     Train net output #1: loss2 = 0.0707008 (* 0.5 = 0.0353504 loss)
I0815 10:00:00.794530   668 sgd_solver.cpp:106] Iteration 8440, lr = 1e-06
I0815 10:00:05.711889   668 solver.cpp:228] Iteration 8460, loss = 0.075205
I0815 10:00:05.711947   668 solver.cpp:244]     Train net output #0: loss1 = 0.024064 (* 0.5 = 0.012032 loss)
I0815 10:00:05.711963   668 solver.cpp:244]     Train net output #1: loss2 = 0.126346 (* 0.5 = 0.0631729 loss)
I0815 10:00:05.711977   668 sgd_solver.cpp:106] Iteration 8460, lr = 1e-06
I0815 10:00:10.644628   668 solver.cpp:228] Iteration 8480, loss = 0.0472612
I0815 10:00:10.644691   668 solver.cpp:244]     Train net output #0: loss1 = 0.0206757 (* 0.5 = 0.0103378 loss)
I0815 10:00:10.644706   668 solver.cpp:244]     Train net output #1: loss2 = 0.0738466 (* 0.5 = 0.0369233 loss)
I0815 10:00:10.644721   668 sgd_solver.cpp:106] Iteration 8480, lr = 1e-06
I0815 10:00:15.538310   668 solver.cpp:228] Iteration 8500, loss = 0.0941261
I0815 10:00:15.538372   668 solver.cpp:244]     Train net output #0: loss1 = 0.0250725 (* 0.5 = 0.0125363 loss)
I0815 10:00:15.538388   668 solver.cpp:244]     Train net output #1: loss2 = 0.16318 (* 0.5 = 0.0815898 loss)
I0815 10:00:15.538401   668 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0815 10:00:20.427590   668 solver.cpp:228] Iteration 8520, loss = 0.0865035
I0815 10:00:20.427650   668 solver.cpp:244]     Train net output #0: loss1 = 0.0398038 (* 0.5 = 0.0199019 loss)
I0815 10:00:20.427666   668 solver.cpp:244]     Train net output #1: loss2 = 0.133203 (* 0.5 = 0.0666015 loss)
I0815 10:00:20.427680   668 sgd_solver.cpp:106] Iteration 8520, lr = 1e-06
I0815 10:00:25.311934   668 solver.cpp:228] Iteration 8540, loss = 0.0614143
I0815 10:00:25.311993   668 solver.cpp:244]     Train net output #0: loss1 = 0.0159663 (* 0.5 = 0.00798313 loss)
I0815 10:00:25.312010   668 solver.cpp:244]     Train net output #1: loss2 = 0.106862 (* 0.5 = 0.0534311 loss)
I0815 10:00:25.312022   668 sgd_solver.cpp:106] Iteration 8540, lr = 1e-06
I0815 10:00:30.220238   668 solver.cpp:228] Iteration 8560, loss = 0.108818
I0815 10:00:30.220405   668 solver.cpp:244]     Train net output #0: loss1 = 0.0536379 (* 0.5 = 0.0268189 loss)
I0815 10:00:30.220422   668 solver.cpp:244]     Train net output #1: loss2 = 0.163998 (* 0.5 = 0.0819991 loss)
I0815 10:00:30.220437   668 sgd_solver.cpp:106] Iteration 8560, lr = 1e-06
I0815 10:00:35.120198   668 solver.cpp:228] Iteration 8580, loss = 0.0685118
I0815 10:00:35.120256   668 solver.cpp:244]     Train net output #0: loss1 = 0.010835 (* 0.5 = 0.00541752 loss)
I0815 10:00:35.120272   668 solver.cpp:244]     Train net output #1: loss2 = 0.126188 (* 0.5 = 0.0630942 loss)
I0815 10:00:35.120286   668 sgd_solver.cpp:106] Iteration 8580, lr = 1e-06
I0815 10:00:40.014389   668 solver.cpp:228] Iteration 8600, loss = 0.0629548
I0815 10:00:40.014446   668 solver.cpp:244]     Train net output #0: loss1 = 0.0614964 (* 0.5 = 0.0307482 loss)
I0815 10:00:40.014461   668 solver.cpp:244]     Train net output #1: loss2 = 0.064413 (* 0.5 = 0.0322065 loss)
I0815 10:00:40.014474   668 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0815 10:00:44.906234   668 solver.cpp:228] Iteration 8620, loss = 0.0676281
I0815 10:00:44.906291   668 solver.cpp:244]     Train net output #0: loss1 = 0.0138337 (* 0.5 = 0.00691684 loss)
I0815 10:00:44.906306   668 solver.cpp:244]     Train net output #1: loss2 = 0.121422 (* 0.5 = 0.0607112 loss)
I0815 10:00:44.906319   668 sgd_solver.cpp:106] Iteration 8620, lr = 1e-06
I0815 10:00:49.836537   668 solver.cpp:228] Iteration 8640, loss = 0.0445518
I0815 10:00:49.836597   668 solver.cpp:244]     Train net output #0: loss1 = 0.0198501 (* 0.5 = 0.00992505 loss)
I0815 10:00:49.836612   668 solver.cpp:244]     Train net output #1: loss2 = 0.0692532 (* 0.5 = 0.0346266 loss)
I0815 10:00:49.836627   668 sgd_solver.cpp:106] Iteration 8640, lr = 1e-06
I0815 10:00:54.736889   668 solver.cpp:228] Iteration 8660, loss = 0.121781
I0815 10:00:54.736950   668 solver.cpp:244]     Train net output #0: loss1 = 0.144082 (* 0.5 = 0.072041 loss)
I0815 10:00:54.736965   668 solver.cpp:244]     Train net output #1: loss2 = 0.0994795 (* 0.5 = 0.0497397 loss)
I0815 10:00:54.736982   668 sgd_solver.cpp:106] Iteration 8660, lr = 1e-06
I0815 10:00:59.634238   668 solver.cpp:228] Iteration 8680, loss = 0.0920056
I0815 10:00:59.634295   668 solver.cpp:244]     Train net output #0: loss1 = 0.0690711 (* 0.5 = 0.0345355 loss)
I0815 10:00:59.634310   668 solver.cpp:244]     Train net output #1: loss2 = 0.11494 (* 0.5 = 0.0574699 loss)
I0815 10:00:59.634323   668 sgd_solver.cpp:106] Iteration 8680, lr = 1e-06
I0815 10:01:04.546496   668 solver.cpp:228] Iteration 8700, loss = 0.0475646
I0815 10:01:04.546712   668 solver.cpp:244]     Train net output #0: loss1 = 0.0115153 (* 0.5 = 0.00575763 loss)
I0815 10:01:04.546737   668 solver.cpp:244]     Train net output #1: loss2 = 0.0836137 (* 0.5 = 0.0418068 loss)
I0815 10:01:04.546753   668 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0815 10:01:09.438100   668 solver.cpp:228] Iteration 8720, loss = 0.0918195
I0815 10:01:09.438158   668 solver.cpp:244]     Train net output #0: loss1 = 0.0687262 (* 0.5 = 0.0343631 loss)
I0815 10:01:09.438174   668 solver.cpp:244]     Train net output #1: loss2 = 0.114912 (* 0.5 = 0.0574562 loss)
I0815 10:01:09.438189   668 sgd_solver.cpp:106] Iteration 8720, lr = 1e-06
I0815 10:01:14.330138   668 solver.cpp:228] Iteration 8740, loss = 0.0603709
I0815 10:01:14.330199   668 solver.cpp:244]     Train net output #0: loss1 = 0.028744 (* 0.5 = 0.014372 loss)
I0815 10:01:14.330215   668 solver.cpp:244]     Train net output #1: loss2 = 0.0919975 (* 0.5 = 0.0459987 loss)
I0815 10:01:14.330229   668 sgd_solver.cpp:106] Iteration 8740, lr = 1e-06
I0815 10:01:19.213013   668 solver.cpp:228] Iteration 8760, loss = 0.0565004
I0815 10:01:19.213073   668 solver.cpp:244]     Train net output #0: loss1 = 0.0219109 (* 0.5 = 0.0109555 loss)
I0815 10:01:19.213088   668 solver.cpp:244]     Train net output #1: loss2 = 0.0910896 (* 0.5 = 0.0455448 loss)
I0815 10:01:19.213102   668 sgd_solver.cpp:106] Iteration 8760, lr = 1e-06
I0815 10:01:24.101083   668 solver.cpp:228] Iteration 8780, loss = 0.0908198
I0815 10:01:24.101143   668 solver.cpp:244]     Train net output #0: loss1 = 0.0595268 (* 0.5 = 0.0297634 loss)
I0815 10:01:24.101160   668 solver.cpp:244]     Train net output #1: loss2 = 0.122113 (* 0.5 = 0.0610563 loss)
I0815 10:01:24.101172   668 sgd_solver.cpp:106] Iteration 8780, lr = 1e-06
I0815 10:01:28.988406   668 solver.cpp:228] Iteration 8800, loss = 0.059346
I0815 10:01:28.988466   668 solver.cpp:244]     Train net output #0: loss1 = 0.0110837 (* 0.5 = 0.00554185 loss)
I0815 10:01:28.988481   668 solver.cpp:244]     Train net output #1: loss2 = 0.107608 (* 0.5 = 0.053804 loss)
I0815 10:01:28.988495   668 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0815 10:01:33.872005   668 solver.cpp:228] Iteration 8820, loss = 0.124299
I0815 10:01:33.872061   668 solver.cpp:244]     Train net output #0: loss1 = 0.0994231 (* 0.5 = 0.0497115 loss)
I0815 10:01:33.872076   668 solver.cpp:244]     Train net output #1: loss2 = 0.149175 (* 0.5 = 0.0745874 loss)
I0815 10:01:33.872090   668 sgd_solver.cpp:106] Iteration 8820, lr = 1e-06
I0815 10:01:38.757390   668 solver.cpp:228] Iteration 8840, loss = 0.123819
I0815 10:01:38.757540   668 solver.cpp:244]     Train net output #0: loss1 = 0.143348 (* 0.5 = 0.0716742 loss)
I0815 10:01:38.757557   668 solver.cpp:244]     Train net output #1: loss2 = 0.104289 (* 0.5 = 0.0521444 loss)
I0815 10:01:38.757571   668 sgd_solver.cpp:106] Iteration 8840, lr = 1e-06
I0815 10:01:43.645910   668 solver.cpp:228] Iteration 8860, loss = 0.0977196
I0815 10:01:43.645968   668 solver.cpp:244]     Train net output #0: loss1 = 0.0293253 (* 0.5 = 0.0146627 loss)
I0815 10:01:43.645984   668 solver.cpp:244]     Train net output #1: loss2 = 0.166114 (* 0.5 = 0.0830569 loss)
I0815 10:01:43.645998   668 sgd_solver.cpp:106] Iteration 8860, lr = 1e-06
I0815 10:01:48.529057   668 solver.cpp:228] Iteration 8880, loss = 0.08418
I0815 10:01:48.529114   668 solver.cpp:244]     Train net output #0: loss1 = 0.07634 (* 0.5 = 0.03817 loss)
I0815 10:01:48.529130   668 solver.cpp:244]     Train net output #1: loss2 = 0.0920198 (* 0.5 = 0.0460099 loss)
I0815 10:01:48.529144   668 sgd_solver.cpp:106] Iteration 8880, lr = 1e-06
I0815 10:01:53.414223   668 solver.cpp:228] Iteration 8900, loss = 0.122039
I0815 10:01:53.414280   668 solver.cpp:244]     Train net output #0: loss1 = 0.100607 (* 0.5 = 0.0503036 loss)
I0815 10:01:53.414297   668 solver.cpp:244]     Train net output #1: loss2 = 0.14347 (* 0.5 = 0.0717352 loss)
I0815 10:01:53.414310   668 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0815 10:01:58.296542   668 solver.cpp:228] Iteration 8920, loss = 0.0665766
I0815 10:01:58.296602   668 solver.cpp:244]     Train net output #0: loss1 = 0.0304477 (* 0.5 = 0.0152239 loss)
I0815 10:01:58.296617   668 solver.cpp:244]     Train net output #1: loss2 = 0.102705 (* 0.5 = 0.0513526 loss)
I0815 10:01:58.296632   668 sgd_solver.cpp:106] Iteration 8920, lr = 1e-06
I0815 10:02:03.183406   668 solver.cpp:228] Iteration 8940, loss = 0.0773951
I0815 10:02:03.183470   668 solver.cpp:244]     Train net output #0: loss1 = 0.026287 (* 0.5 = 0.0131435 loss)
I0815 10:02:03.183485   668 solver.cpp:244]     Train net output #1: loss2 = 0.128503 (* 0.5 = 0.0642514 loss)
I0815 10:02:03.183501   668 sgd_solver.cpp:106] Iteration 8940, lr = 1e-06
I0815 10:02:08.067595   668 solver.cpp:228] Iteration 8960, loss = 0.0753811
I0815 10:02:08.067651   668 solver.cpp:244]     Train net output #0: loss1 = 0.0264629 (* 0.5 = 0.0132315 loss)
I0815 10:02:08.067667   668 solver.cpp:244]     Train net output #1: loss2 = 0.124299 (* 0.5 = 0.0621495 loss)
I0815 10:02:08.067682   668 sgd_solver.cpp:106] Iteration 8960, lr = 1e-06
I0815 10:02:12.954612   668 solver.cpp:228] Iteration 8980, loss = 0.0539935
I0815 10:02:12.954749   668 solver.cpp:244]     Train net output #0: loss1 = 0.0166817 (* 0.5 = 0.00834085 loss)
I0815 10:02:12.954797   668 solver.cpp:244]     Train net output #1: loss2 = 0.0913051 (* 0.5 = 0.0456525 loss)
I0815 10:02:12.954810   668 sgd_solver.cpp:106] Iteration 8980, lr = 1e-06
I0815 10:02:17.594884   668 solver.cpp:337] Iteration 9000, Testing net (#0)
I0815 10:03:15.144942   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.835859
I0815 10:03:15.145083   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.952391
I0815 10:03:15.145103   668 solver.cpp:404]     Test net output #2: loss1 = 0.163569 (* 0.5 = 0.0817845 loss)
I0815 10:03:15.145117   668 solver.cpp:404]     Test net output #3: loss2 = 0.417323 (* 0.5 = 0.208661 loss)
I0815 10:03:15.219208   668 solver.cpp:228] Iteration 9000, loss = 0.0575552
I0815 10:03:15.219293   668 solver.cpp:244]     Train net output #0: loss1 = 0.0132152 (* 0.5 = 0.00660761 loss)
I0815 10:03:15.219310   668 solver.cpp:244]     Train net output #1: loss2 = 0.101895 (* 0.5 = 0.0509475 loss)
I0815 10:03:15.219323   668 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0815 10:03:20.104051   668 solver.cpp:228] Iteration 9020, loss = 0.05654
I0815 10:03:20.104110   668 solver.cpp:244]     Train net output #0: loss1 = 0.0179848 (* 0.5 = 0.0089924 loss)
I0815 10:03:20.104125   668 solver.cpp:244]     Train net output #1: loss2 = 0.095095 (* 0.5 = 0.0475475 loss)
I0815 10:03:20.104140   668 sgd_solver.cpp:106] Iteration 9020, lr = 1e-06
I0815 10:03:24.988239   668 solver.cpp:228] Iteration 9040, loss = 0.0645124
I0815 10:03:24.988298   668 solver.cpp:244]     Train net output #0: loss1 = 0.0224507 (* 0.5 = 0.0112254 loss)
I0815 10:03:24.988314   668 solver.cpp:244]     Train net output #1: loss2 = 0.106574 (* 0.5 = 0.053287 loss)
I0815 10:03:24.988327   668 sgd_solver.cpp:106] Iteration 9040, lr = 1e-06
I0815 10:03:29.879760   668 solver.cpp:228] Iteration 9060, loss = 0.0411346
I0815 10:03:29.879815   668 solver.cpp:244]     Train net output #0: loss1 = 0.0268855 (* 0.5 = 0.0134428 loss)
I0815 10:03:29.879830   668 solver.cpp:244]     Train net output #1: loss2 = 0.0553835 (* 0.5 = 0.0276917 loss)
I0815 10:03:29.879843   668 sgd_solver.cpp:106] Iteration 9060, lr = 1e-06
I0815 10:03:34.798483   668 solver.cpp:228] Iteration 9080, loss = 0.0951548
I0815 10:03:34.798542   668 solver.cpp:244]     Train net output #0: loss1 = 0.0442101 (* 0.5 = 0.022105 loss)
I0815 10:03:34.798557   668 solver.cpp:244]     Train net output #1: loss2 = 0.146099 (* 0.5 = 0.0730497 loss)
I0815 10:03:34.798578   668 sgd_solver.cpp:106] Iteration 9080, lr = 1e-06
I0815 10:03:39.717133   668 solver.cpp:228] Iteration 9100, loss = 0.0317101
I0815 10:03:39.717191   668 solver.cpp:244]     Train net output #0: loss1 = 0.0209395 (* 0.5 = 0.0104697 loss)
I0815 10:03:39.717207   668 solver.cpp:244]     Train net output #1: loss2 = 0.0424805 (* 0.5 = 0.0212402 loss)
I0815 10:03:39.717221   668 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0815 10:03:44.626441   668 solver.cpp:228] Iteration 9120, loss = 0.0922582
I0815 10:03:44.626500   668 solver.cpp:244]     Train net output #0: loss1 = 0.120756 (* 0.5 = 0.0603779 loss)
I0815 10:03:44.626515   668 solver.cpp:244]     Train net output #1: loss2 = 0.0637603 (* 0.5 = 0.0318802 loss)
I0815 10:03:44.626529   668 sgd_solver.cpp:106] Iteration 9120, lr = 1e-06
I0815 10:03:49.537237   668 solver.cpp:228] Iteration 9140, loss = 0.0704793
I0815 10:03:49.537361   668 solver.cpp:244]     Train net output #0: loss1 = 0.0493031 (* 0.5 = 0.0246516 loss)
I0815 10:03:49.537379   668 solver.cpp:244]     Train net output #1: loss2 = 0.0916554 (* 0.5 = 0.0458277 loss)
I0815 10:03:49.537391   668 sgd_solver.cpp:106] Iteration 9140, lr = 1e-06
I0815 10:03:54.443332   668 solver.cpp:228] Iteration 9160, loss = 0.0671463
I0815 10:03:54.443389   668 solver.cpp:244]     Train net output #0: loss1 = 0.0344133 (* 0.5 = 0.0172067 loss)
I0815 10:03:54.443404   668 solver.cpp:244]     Train net output #1: loss2 = 0.099879 (* 0.5 = 0.0499395 loss)
I0815 10:03:54.443418   668 sgd_solver.cpp:106] Iteration 9160, lr = 1e-06
I0815 10:03:59.327879   668 solver.cpp:228] Iteration 9180, loss = 0.0560423
I0815 10:03:59.327939   668 solver.cpp:244]     Train net output #0: loss1 = 0.0302393 (* 0.5 = 0.0151197 loss)
I0815 10:03:59.327955   668 solver.cpp:244]     Train net output #1: loss2 = 0.0818451 (* 0.5 = 0.0409226 loss)
I0815 10:03:59.327967   668 sgd_solver.cpp:106] Iteration 9180, lr = 1e-06
I0815 10:04:04.235890   668 solver.cpp:228] Iteration 9200, loss = 0.120277
I0815 10:04:04.235950   668 solver.cpp:244]     Train net output #0: loss1 = 0.0639322 (* 0.5 = 0.0319661 loss)
I0815 10:04:04.235966   668 solver.cpp:244]     Train net output #1: loss2 = 0.176623 (* 0.5 = 0.0883113 loss)
I0815 10:04:04.235980   668 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0815 10:04:09.140847   668 solver.cpp:228] Iteration 9220, loss = 0.0965457
I0815 10:04:09.140905   668 solver.cpp:244]     Train net output #0: loss1 = 0.0236923 (* 0.5 = 0.0118462 loss)
I0815 10:04:09.140921   668 solver.cpp:244]     Train net output #1: loss2 = 0.169399 (* 0.5 = 0.0846995 loss)
I0815 10:04:09.140934   668 sgd_solver.cpp:106] Iteration 9220, lr = 1e-06
I0815 10:04:14.048138   668 solver.cpp:228] Iteration 9240, loss = 0.104353
I0815 10:04:14.048197   668 solver.cpp:244]     Train net output #0: loss1 = 0.0763715 (* 0.5 = 0.0381858 loss)
I0815 10:04:14.048212   668 solver.cpp:244]     Train net output #1: loss2 = 0.132334 (* 0.5 = 0.066167 loss)
I0815 10:04:14.048225   668 sgd_solver.cpp:106] Iteration 9240, lr = 1e-06
I0815 10:04:18.939092   668 solver.cpp:228] Iteration 9260, loss = 0.0576845
I0815 10:04:18.939151   668 solver.cpp:244]     Train net output #0: loss1 = 0.0477402 (* 0.5 = 0.0238701 loss)
I0815 10:04:18.939167   668 solver.cpp:244]     Train net output #1: loss2 = 0.0676285 (* 0.5 = 0.0338143 loss)
I0815 10:04:18.939179   668 sgd_solver.cpp:106] Iteration 9260, lr = 1e-06
I0815 10:04:23.826109   668 solver.cpp:228] Iteration 9280, loss = 0.0638985
I0815 10:04:23.826298   668 solver.cpp:244]     Train net output #0: loss1 = 0.0139599 (* 0.5 = 0.00697995 loss)
I0815 10:04:23.826323   668 solver.cpp:244]     Train net output #1: loss2 = 0.113837 (* 0.5 = 0.0569185 loss)
I0815 10:04:23.826339   668 sgd_solver.cpp:106] Iteration 9280, lr = 1e-06
I0815 10:04:28.711369   668 solver.cpp:228] Iteration 9300, loss = 0.08318
I0815 10:04:28.711429   668 solver.cpp:244]     Train net output #0: loss1 = 0.017578 (* 0.5 = 0.00878898 loss)
I0815 10:04:28.711446   668 solver.cpp:244]     Train net output #1: loss2 = 0.148782 (* 0.5 = 0.0743909 loss)
I0815 10:04:28.711459   668 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0815 10:04:33.594210   668 solver.cpp:228] Iteration 9320, loss = 0.0878819
I0815 10:04:33.594269   668 solver.cpp:244]     Train net output #0: loss1 = 0.0322961 (* 0.5 = 0.0161481 loss)
I0815 10:04:33.594285   668 solver.cpp:244]     Train net output #1: loss2 = 0.143468 (* 0.5 = 0.0717338 loss)
I0815 10:04:33.594298   668 sgd_solver.cpp:106] Iteration 9320, lr = 1e-06
I0815 10:04:38.488829   668 solver.cpp:228] Iteration 9340, loss = 0.114309
I0815 10:04:38.488883   668 solver.cpp:244]     Train net output #0: loss1 = 0.0745437 (* 0.5 = 0.0372719 loss)
I0815 10:04:38.488898   668 solver.cpp:244]     Train net output #1: loss2 = 0.154074 (* 0.5 = 0.077037 loss)
I0815 10:04:38.488911   668 sgd_solver.cpp:106] Iteration 9340, lr = 1e-06
I0815 10:04:43.406046   668 solver.cpp:228] Iteration 9360, loss = 0.128227
I0815 10:04:43.406102   668 solver.cpp:244]     Train net output #0: loss1 = 0.0325932 (* 0.5 = 0.0162966 loss)
I0815 10:04:43.406118   668 solver.cpp:244]     Train net output #1: loss2 = 0.22386 (* 0.5 = 0.11193 loss)
I0815 10:04:43.406131   668 sgd_solver.cpp:106] Iteration 9360, lr = 1e-06
I0815 10:04:48.328346   668 solver.cpp:228] Iteration 9380, loss = 0.0738269
I0815 10:04:48.328402   668 solver.cpp:244]     Train net output #0: loss1 = 0.0631412 (* 0.5 = 0.0315706 loss)
I0815 10:04:48.328418   668 solver.cpp:244]     Train net output #1: loss2 = 0.0845124 (* 0.5 = 0.0422562 loss)
I0815 10:04:48.328431   668 sgd_solver.cpp:106] Iteration 9380, lr = 1e-06
I0815 10:04:53.216697   668 solver.cpp:228] Iteration 9400, loss = 0.0910888
I0815 10:04:53.216754   668 solver.cpp:244]     Train net output #0: loss1 = 0.0279731 (* 0.5 = 0.0139866 loss)
I0815 10:04:53.216770   668 solver.cpp:244]     Train net output #1: loss2 = 0.154204 (* 0.5 = 0.0771021 loss)
I0815 10:04:53.216784   668 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0815 10:04:58.111948   668 solver.cpp:228] Iteration 9420, loss = 0.0736345
I0815 10:04:58.112123   668 solver.cpp:244]     Train net output #0: loss1 = 0.0174602 (* 0.5 = 0.0087301 loss)
I0815 10:04:58.112141   668 solver.cpp:244]     Train net output #1: loss2 = 0.129809 (* 0.5 = 0.0649043 loss)
I0815 10:04:58.112154   668 sgd_solver.cpp:106] Iteration 9420, lr = 1e-06
I0815 10:05:03.003226   668 solver.cpp:228] Iteration 9440, loss = 0.0969679
I0815 10:05:03.003289   668 solver.cpp:244]     Train net output #0: loss1 = 0.0118744 (* 0.5 = 0.00593719 loss)
I0815 10:05:03.003305   668 solver.cpp:244]     Train net output #1: loss2 = 0.182061 (* 0.5 = 0.0910306 loss)
I0815 10:05:03.003319   668 sgd_solver.cpp:106] Iteration 9440, lr = 1e-06
I0815 10:05:07.894565   668 solver.cpp:228] Iteration 9460, loss = 0.0544368
I0815 10:05:07.894616   668 solver.cpp:244]     Train net output #0: loss1 = 0.0188284 (* 0.5 = 0.00941419 loss)
I0815 10:05:07.894631   668 solver.cpp:244]     Train net output #1: loss2 = 0.0900451 (* 0.5 = 0.0450226 loss)
I0815 10:05:07.894644   668 sgd_solver.cpp:106] Iteration 9460, lr = 1e-06
I0815 10:05:12.786095   668 solver.cpp:228] Iteration 9480, loss = 0.0927253
I0815 10:05:12.786152   668 solver.cpp:244]     Train net output #0: loss1 = 0.0501432 (* 0.5 = 0.0250716 loss)
I0815 10:05:12.786167   668 solver.cpp:244]     Train net output #1: loss2 = 0.135307 (* 0.5 = 0.0676536 loss)
I0815 10:05:12.786180   668 sgd_solver.cpp:106] Iteration 9480, lr = 1e-06
I0815 10:05:17.699128   668 solver.cpp:228] Iteration 9500, loss = 0.0564867
I0815 10:05:17.699185   668 solver.cpp:244]     Train net output #0: loss1 = 0.0113241 (* 0.5 = 0.00566206 loss)
I0815 10:05:17.699200   668 solver.cpp:244]     Train net output #1: loss2 = 0.101649 (* 0.5 = 0.0508246 loss)
I0815 10:05:17.699214   668 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0815 10:05:22.649864   668 solver.cpp:228] Iteration 9520, loss = 0.0715804
I0815 10:05:22.649921   668 solver.cpp:244]     Train net output #0: loss1 = 0.0251629 (* 0.5 = 0.0125814 loss)
I0815 10:05:22.649937   668 solver.cpp:244]     Train net output #1: loss2 = 0.117998 (* 0.5 = 0.0589989 loss)
I0815 10:05:22.649950   668 sgd_solver.cpp:106] Iteration 9520, lr = 1e-06
I0815 10:05:27.550886   668 solver.cpp:228] Iteration 9540, loss = 0.0682315
I0815 10:05:27.550951   668 solver.cpp:244]     Train net output #0: loss1 = 0.0351681 (* 0.5 = 0.017584 loss)
I0815 10:05:27.550967   668 solver.cpp:244]     Train net output #1: loss2 = 0.101295 (* 0.5 = 0.0506474 loss)
I0815 10:05:27.550981   668 sgd_solver.cpp:106] Iteration 9540, lr = 1e-06
I0815 10:05:32.472239   668 solver.cpp:228] Iteration 9560, loss = 0.0257139
I0815 10:05:32.472352   668 solver.cpp:244]     Train net output #0: loss1 = 0.0141962 (* 0.5 = 0.0070981 loss)
I0815 10:05:32.472369   668 solver.cpp:244]     Train net output #1: loss2 = 0.0372314 (* 0.5 = 0.0186157 loss)
I0815 10:05:32.472383   668 sgd_solver.cpp:106] Iteration 9560, lr = 1e-06
I0815 10:05:37.400575   668 solver.cpp:228] Iteration 9580, loss = 0.0608936
I0815 10:05:37.400630   668 solver.cpp:244]     Train net output #0: loss1 = 0.0387183 (* 0.5 = 0.0193591 loss)
I0815 10:05:37.400646   668 solver.cpp:244]     Train net output #1: loss2 = 0.0830688 (* 0.5 = 0.0415344 loss)
I0815 10:05:37.400660   668 sgd_solver.cpp:106] Iteration 9580, lr = 1e-06
I0815 10:05:42.313271   668 solver.cpp:228] Iteration 9600, loss = 0.0528798
I0815 10:05:42.313329   668 solver.cpp:244]     Train net output #0: loss1 = 0.00867412 (* 0.5 = 0.00433706 loss)
I0815 10:05:42.313345   668 solver.cpp:244]     Train net output #1: loss2 = 0.0970853 (* 0.5 = 0.0485427 loss)
I0815 10:05:42.313359   668 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0815 10:05:47.223031   668 solver.cpp:228] Iteration 9620, loss = 0.0712569
I0815 10:05:47.223151   668 solver.cpp:244]     Train net output #0: loss1 = 0.0453321 (* 0.5 = 0.0226661 loss)
I0815 10:05:47.223168   668 solver.cpp:244]     Train net output #1: loss2 = 0.0971814 (* 0.5 = 0.0485907 loss)
I0815 10:05:47.223186   668 sgd_solver.cpp:106] Iteration 9620, lr = 1e-06
I0815 10:05:52.184862   668 solver.cpp:228] Iteration 9640, loss = 0.0465896
I0815 10:05:52.184923   668 solver.cpp:244]     Train net output #0: loss1 = 0.014459 (* 0.5 = 0.00722949 loss)
I0815 10:05:52.184939   668 solver.cpp:244]     Train net output #1: loss2 = 0.07872 (* 0.5 = 0.03936 loss)
I0815 10:05:52.184952   668 sgd_solver.cpp:106] Iteration 9640, lr = 1e-06
I0815 10:05:57.092735   668 solver.cpp:228] Iteration 9660, loss = 0.0563227
I0815 10:05:57.092789   668 solver.cpp:244]     Train net output #0: loss1 = 0.0117497 (* 0.5 = 0.00587485 loss)
I0815 10:05:57.092805   668 solver.cpp:244]     Train net output #1: loss2 = 0.100896 (* 0.5 = 0.0504478 loss)
I0815 10:05:57.092819   668 sgd_solver.cpp:106] Iteration 9660, lr = 1e-06
I0815 10:06:01.997658   668 solver.cpp:228] Iteration 9680, loss = 0.0769032
I0815 10:06:01.997714   668 solver.cpp:244]     Train net output #0: loss1 = 0.043098 (* 0.5 = 0.021549 loss)
I0815 10:06:01.997730   668 solver.cpp:244]     Train net output #1: loss2 = 0.110708 (* 0.5 = 0.0553541 loss)
I0815 10:06:01.997743   668 sgd_solver.cpp:106] Iteration 9680, lr = 1e-06
I0815 10:06:06.969511   668 solver.cpp:228] Iteration 9700, loss = 0.0870534
I0815 10:06:06.972656   668 solver.cpp:244]     Train net output #0: loss1 = 0.0366641 (* 0.5 = 0.0183321 loss)
I0815 10:06:06.972682   668 solver.cpp:244]     Train net output #1: loss2 = 0.137443 (* 0.5 = 0.0687213 loss)
I0815 10:06:06.972697   668 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0815 10:06:11.933815   668 solver.cpp:228] Iteration 9720, loss = 0.0632606
I0815 10:06:11.933874   668 solver.cpp:244]     Train net output #0: loss1 = 0.0547967 (* 0.5 = 0.0273984 loss)
I0815 10:06:11.933890   668 solver.cpp:244]     Train net output #1: loss2 = 0.0717243 (* 0.5 = 0.0358621 loss)
I0815 10:06:11.933903   668 sgd_solver.cpp:106] Iteration 9720, lr = 1e-06
I0815 10:06:16.894364   668 solver.cpp:228] Iteration 9740, loss = 0.103526
I0815 10:06:16.894418   668 solver.cpp:244]     Train net output #0: loss1 = 0.0281363 (* 0.5 = 0.0140682 loss)
I0815 10:06:16.894433   668 solver.cpp:244]     Train net output #1: loss2 = 0.178915 (* 0.5 = 0.0894577 loss)
I0815 10:06:16.894446   668 sgd_solver.cpp:106] Iteration 9740, lr = 1e-06
I0815 10:06:21.822993   668 solver.cpp:228] Iteration 9760, loss = 0.128665
I0815 10:06:21.823045   668 solver.cpp:244]     Train net output #0: loss1 = 0.0278144 (* 0.5 = 0.0139072 loss)
I0815 10:06:21.823061   668 solver.cpp:244]     Train net output #1: loss2 = 0.229515 (* 0.5 = 0.114758 loss)
I0815 10:06:21.823074   668 sgd_solver.cpp:106] Iteration 9760, lr = 1e-06
I0815 10:06:26.896227   668 solver.cpp:228] Iteration 9780, loss = 0.0648563
I0815 10:06:26.896281   668 solver.cpp:244]     Train net output #0: loss1 = 0.028599 (* 0.5 = 0.0142995 loss)
I0815 10:06:26.896299   668 solver.cpp:244]     Train net output #1: loss2 = 0.101113 (* 0.5 = 0.0505566 loss)
I0815 10:06:26.896317   668 sgd_solver.cpp:106] Iteration 9780, lr = 1e-06
I0815 10:06:31.892840   668 solver.cpp:228] Iteration 9800, loss = 0.0366269
I0815 10:06:31.892900   668 solver.cpp:244]     Train net output #0: loss1 = 0.0206263 (* 0.5 = 0.0103131 loss)
I0815 10:06:31.892916   668 solver.cpp:244]     Train net output #1: loss2 = 0.0526272 (* 0.5 = 0.0263136 loss)
I0815 10:06:31.892930   668 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0815 10:06:36.925117   668 solver.cpp:228] Iteration 9820, loss = 0.0877656
I0815 10:06:36.925174   668 solver.cpp:244]     Train net output #0: loss1 = 0.0314372 (* 0.5 = 0.0157186 loss)
I0815 10:06:36.925189   668 solver.cpp:244]     Train net output #1: loss2 = 0.144094 (* 0.5 = 0.0720469 loss)
I0815 10:06:36.925204   668 sgd_solver.cpp:106] Iteration 9820, lr = 1e-06
I0815 10:06:41.855128   668 solver.cpp:228] Iteration 9840, loss = 0.0866783
I0815 10:06:41.855274   668 solver.cpp:244]     Train net output #0: loss1 = 0.0713833 (* 0.5 = 0.0356917 loss)
I0815 10:06:41.855291   668 solver.cpp:244]     Train net output #1: loss2 = 0.101973 (* 0.5 = 0.0509865 loss)
I0815 10:06:41.855305   668 sgd_solver.cpp:106] Iteration 9840, lr = 1e-06
I0815 10:06:46.762878   668 solver.cpp:228] Iteration 9860, loss = 0.0504053
I0815 10:06:46.762938   668 solver.cpp:244]     Train net output #0: loss1 = 0.00770915 (* 0.5 = 0.00385458 loss)
I0815 10:06:46.762953   668 solver.cpp:244]     Train net output #1: loss2 = 0.0931013 (* 0.5 = 0.0465506 loss)
I0815 10:06:46.762967   668 sgd_solver.cpp:106] Iteration 9860, lr = 1e-06
I0815 10:06:51.681083   668 solver.cpp:228] Iteration 9880, loss = 0.0686292
I0815 10:06:51.681143   668 solver.cpp:244]     Train net output #0: loss1 = 0.0482518 (* 0.5 = 0.0241259 loss)
I0815 10:06:51.681159   668 solver.cpp:244]     Train net output #1: loss2 = 0.0890064 (* 0.5 = 0.0445032 loss)
I0815 10:06:51.681172   668 sgd_solver.cpp:106] Iteration 9880, lr = 1e-06
I0815 10:06:56.625671   668 solver.cpp:228] Iteration 9900, loss = 0.114322
I0815 10:06:56.625730   668 solver.cpp:244]     Train net output #0: loss1 = 0.028812 (* 0.5 = 0.014406 loss)
I0815 10:06:56.625746   668 solver.cpp:244]     Train net output #1: loss2 = 0.199832 (* 0.5 = 0.099916 loss)
I0815 10:06:56.625759   668 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0815 10:07:01.550911   668 solver.cpp:228] Iteration 9920, loss = 0.0864024
I0815 10:07:01.550971   668 solver.cpp:244]     Train net output #0: loss1 = 0.0832705 (* 0.5 = 0.0416352 loss)
I0815 10:07:01.550987   668 solver.cpp:244]     Train net output #1: loss2 = 0.0895341 (* 0.5 = 0.0447671 loss)
I0815 10:07:01.551000   668 sgd_solver.cpp:106] Iteration 9920, lr = 1e-06
I0815 10:07:06.467550   668 solver.cpp:228] Iteration 9940, loss = 0.0955034
I0815 10:07:06.467608   668 solver.cpp:244]     Train net output #0: loss1 = 0.0595948 (* 0.5 = 0.0297974 loss)
I0815 10:07:06.467623   668 solver.cpp:244]     Train net output #1: loss2 = 0.131412 (* 0.5 = 0.0657059 loss)
I0815 10:07:06.467636   668 sgd_solver.cpp:106] Iteration 9940, lr = 1e-06
I0815 10:07:11.361115   668 solver.cpp:228] Iteration 9960, loss = 0.0817084
I0815 10:07:11.361169   668 solver.cpp:244]     Train net output #0: loss1 = 0.0271157 (* 0.5 = 0.0135579 loss)
I0815 10:07:11.361184   668 solver.cpp:244]     Train net output #1: loss2 = 0.136301 (* 0.5 = 0.0681504 loss)
I0815 10:07:11.361198   668 sgd_solver.cpp:106] Iteration 9960, lr = 1e-06
I0815 10:07:16.267380   668 solver.cpp:228] Iteration 9980, loss = 0.0955166
I0815 10:07:16.267498   668 solver.cpp:244]     Train net output #0: loss1 = 0.0774129 (* 0.5 = 0.0387064 loss)
I0815 10:07:16.267515   668 solver.cpp:244]     Train net output #1: loss2 = 0.11362 (* 0.5 = 0.05681 loss)
I0815 10:07:16.267529   668 sgd_solver.cpp:106] Iteration 9980, lr = 1e-06
I0815 10:07:20.908154   668 solver.cpp:454] Snapshotting to binary proto file models/gender_glasses/gg_net_train_iter_10000.caffemodel
I0815 10:07:21.581363   668 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/gender_glasses/gg_net_train_iter_10000.solverstate
I0815 10:07:21.728919   668 solver.cpp:317] Iteration 10000, loss = 0.126598
I0815 10:07:21.728971   668 solver.cpp:337] Iteration 10000, Testing net (#0)
I0815 10:08:18.979785   668 solver.cpp:404]     Test net output #0: accuracy_gender = 0.836719
I0815 10:08:18.979871   668 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.952328
I0815 10:08:18.979889   668 solver.cpp:404]     Test net output #2: loss1 = 0.163447 (* 0.5 = 0.0817237 loss)
I0815 10:08:18.979902   668 solver.cpp:404]     Test net output #3: loss2 = 0.41722 (* 0.5 = 0.20861 loss)
I0815 10:08:18.979913   668 solver.cpp:322] Optimization Done.
I0815 10:08:18.979923   668 caffe.cpp:254] Optimization Done.
