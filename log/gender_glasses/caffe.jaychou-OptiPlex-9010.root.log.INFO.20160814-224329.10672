Log file created at: 2016/08/14 22:43:29
Running on machine: jaychou-OptiPlex-9010
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0814 22:43:29.494245 10672 caffe.cpp:217] Using GPUs 0
I0814 22:43:29.523304 10672 caffe.cpp:222] GPU 0: GeForce GTX 650 Ti
I0814 22:43:29.638453 10672 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 10000
lr_policy: "inv"
gamma: 0.1
power: 0.75
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 10000
snapshot_prefix: "models/gender_glasses/gg_net_train"
solver_mode: GPU
device_id: 0
net: "models/gender_glasses/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0814 22:43:29.638653 10672 solver.cpp:91] Creating training net from net file: models/gender_glasses/train_val.prototxt
I0814 22:43:29.639188 10672 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0814 22:43:29.639204 10672 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer labels
I0814 22:43:29.639225 10672 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_glasses
I0814 22:43:29.639235 10672 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_gender
I0814 22:43:29.639369 10672 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 80
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv4"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.5
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.5
}
I0814 22:43:29.640033 10672 layer_factory.hpp:77] Creating layer data
I0814 22:43:29.640398 10672 net.cpp:100] Creating Layer data
I0814 22:43:29.640414 10672 net.cpp:408] data -> data
I0814 22:43:29.641741 10676 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb
I0814 22:43:29.651517 10672 data_layer.cpp:41] output data size: 100,3,100,100
I0814 22:43:29.670325 10672 net.cpp:150] Setting up data
I0814 22:43:29.670374 10672 net.cpp:157] Top shape: 100 3 100 100 (3000000)
I0814 22:43:29.670384 10672 net.cpp:165] Memory required for data: 12000000
I0814 22:43:29.670402 10672 layer_factory.hpp:77] Creating layer labels
I0814 22:43:29.670507 10672 net.cpp:100] Creating Layer labels
I0814 22:43:29.670522 10672 net.cpp:408] labels -> labels
I0814 22:43:29.672750 10678 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb
I0814 22:43:29.673651 10672 data_layer.cpp:41] output data size: 100,2,1,1
I0814 22:43:29.674104 10672 net.cpp:150] Setting up labels
I0814 22:43:29.674124 10672 net.cpp:157] Top shape: 100 2 1 1 (200)
I0814 22:43:29.674134 10672 net.cpp:165] Memory required for data: 12000800
I0814 22:43:29.674144 10672 layer_factory.hpp:77] Creating layer slice1
I0814 22:43:29.674160 10672 net.cpp:100] Creating Layer slice1
I0814 22:43:29.674172 10672 net.cpp:434] slice1 <- labels
I0814 22:43:29.674190 10672 net.cpp:408] slice1 -> glasses
I0814 22:43:29.674208 10672 net.cpp:408] slice1 -> gender
I0814 22:43:29.674250 10672 net.cpp:150] Setting up slice1
I0814 22:43:29.674264 10672 net.cpp:157] Top shape: 100 1 1 1 (100)
I0814 22:43:29.674274 10672 net.cpp:157] Top shape: 100 1 1 1 (100)
I0814 22:43:29.674283 10672 net.cpp:165] Memory required for data: 12001600
I0814 22:43:29.674291 10672 layer_factory.hpp:77] Creating layer conv1
I0814 22:43:29.674314 10672 net.cpp:100] Creating Layer conv1
I0814 22:43:29.674325 10672 net.cpp:434] conv1 <- data
I0814 22:43:29.674337 10672 net.cpp:408] conv1 -> conv1
I0814 22:43:29.823599 10672 net.cpp:150] Setting up conv1
I0814 22:43:29.823648 10672 net.cpp:157] Top shape: 100 20 96 96 (18432000)
I0814 22:43:29.823658 10672 net.cpp:165] Memory required for data: 85729600
I0814 22:43:29.823684 10672 layer_factory.hpp:77] Creating layer relu1
I0814 22:43:29.823703 10672 net.cpp:100] Creating Layer relu1
I0814 22:43:29.823714 10672 net.cpp:434] relu1 <- conv1
I0814 22:43:29.823724 10672 net.cpp:395] relu1 -> conv1 (in-place)
I0814 22:43:29.824247 10672 net.cpp:150] Setting up relu1
I0814 22:43:29.824265 10672 net.cpp:157] Top shape: 100 20 96 96 (18432000)
I0814 22:43:29.824275 10672 net.cpp:165] Memory required for data: 159457600
I0814 22:43:29.824288 10672 layer_factory.hpp:77] Creating layer pool1
I0814 22:43:29.824301 10672 net.cpp:100] Creating Layer pool1
I0814 22:43:29.824311 10672 net.cpp:434] pool1 <- conv1
I0814 22:43:29.824321 10672 net.cpp:408] pool1 -> pool1
I0814 22:43:29.824367 10672 net.cpp:150] Setting up pool1
I0814 22:43:29.824380 10672 net.cpp:157] Top shape: 100 20 48 48 (4608000)
I0814 22:43:29.824388 10672 net.cpp:165] Memory required for data: 177889600
I0814 22:43:29.824420 10672 layer_factory.hpp:77] Creating layer conv2
I0814 22:43:29.824439 10672 net.cpp:100] Creating Layer conv2
I0814 22:43:29.824450 10672 net.cpp:434] conv2 <- pool1
I0814 22:43:29.824461 10672 net.cpp:408] conv2 -> conv2
I0814 22:43:29.825770 10672 net.cpp:150] Setting up conv2
I0814 22:43:29.825793 10672 net.cpp:157] Top shape: 100 48 44 44 (9292800)
I0814 22:43:29.825803 10672 net.cpp:165] Memory required for data: 215060800
I0814 22:43:29.825816 10672 layer_factory.hpp:77] Creating layer relu2
I0814 22:43:29.825829 10672 net.cpp:100] Creating Layer relu2
I0814 22:43:29.825836 10672 net.cpp:434] relu2 <- conv2
I0814 22:43:29.825847 10672 net.cpp:395] relu2 -> conv2 (in-place)
I0814 22:43:29.826309 10672 net.cpp:150] Setting up relu2
I0814 22:43:29.826328 10672 net.cpp:157] Top shape: 100 48 44 44 (9292800)
I0814 22:43:29.826335 10672 net.cpp:165] Memory required for data: 252232000
I0814 22:43:29.826346 10672 layer_factory.hpp:77] Creating layer pool2
I0814 22:43:29.826360 10672 net.cpp:100] Creating Layer pool2
I0814 22:43:29.826370 10672 net.cpp:434] pool2 <- conv2
I0814 22:43:29.826380 10672 net.cpp:408] pool2 -> pool2
I0814 22:43:29.826421 10672 net.cpp:150] Setting up pool2
I0814 22:43:29.826433 10672 net.cpp:157] Top shape: 100 48 22 22 (2323200)
I0814 22:43:29.826442 10672 net.cpp:165] Memory required for data: 261524800
I0814 22:43:29.826450 10672 layer_factory.hpp:77] Creating layer conv3
I0814 22:43:29.826465 10672 net.cpp:100] Creating Layer conv3
I0814 22:43:29.826474 10672 net.cpp:434] conv3 <- pool2
I0814 22:43:29.826486 10672 net.cpp:408] conv3 -> conv3
I0814 22:43:29.827730 10672 net.cpp:150] Setting up conv3
I0814 22:43:29.827754 10672 net.cpp:157] Top shape: 100 64 20 20 (2560000)
I0814 22:43:29.827764 10672 net.cpp:165] Memory required for data: 271764800
I0814 22:43:29.827775 10672 layer_factory.hpp:77] Creating layer relu3
I0814 22:43:29.827786 10672 net.cpp:100] Creating Layer relu3
I0814 22:43:29.827795 10672 net.cpp:434] relu3 <- conv3
I0814 22:43:29.827808 10672 net.cpp:395] relu3 -> conv3 (in-place)
I0814 22:43:29.827905 10672 net.cpp:150] Setting up relu3
I0814 22:43:29.827919 10672 net.cpp:157] Top shape: 100 64 20 20 (2560000)
I0814 22:43:29.827929 10672 net.cpp:165] Memory required for data: 282004800
I0814 22:43:29.827942 10672 layer_factory.hpp:77] Creating layer conv4
I0814 22:43:29.827960 10672 net.cpp:100] Creating Layer conv4
I0814 22:43:29.827968 10672 net.cpp:434] conv4 <- conv3
I0814 22:43:29.827980 10672 net.cpp:408] conv4 -> conv4
I0814 22:43:29.829103 10672 net.cpp:150] Setting up conv4
I0814 22:43:29.829123 10672 net.cpp:157] Top shape: 100 80 18 18 (2592000)
I0814 22:43:29.829131 10672 net.cpp:165] Memory required for data: 292372800
I0814 22:43:29.829144 10672 layer_factory.hpp:77] Creating layer relu4
I0814 22:43:29.829154 10672 net.cpp:100] Creating Layer relu4
I0814 22:43:29.829164 10672 net.cpp:434] relu4 <- conv4
I0814 22:43:29.829174 10672 net.cpp:395] relu4 -> conv4 (in-place)
I0814 22:43:29.829274 10672 net.cpp:150] Setting up relu4
I0814 22:43:29.829289 10672 net.cpp:157] Top shape: 100 80 18 18 (2592000)
I0814 22:43:29.829298 10672 net.cpp:165] Memory required for data: 302740800
I0814 22:43:29.829308 10672 layer_factory.hpp:77] Creating layer ip1
I0814 22:43:29.829324 10672 net.cpp:100] Creating Layer ip1
I0814 22:43:29.829334 10672 net.cpp:434] ip1 <- conv4
I0814 22:43:29.829344 10672 net.cpp:408] ip1 -> ip1
I0814 22:43:29.926404 10672 net.cpp:150] Setting up ip1
I0814 22:43:29.926451 10672 net.cpp:157] Top shape: 100 512 (51200)
I0814 22:43:29.926461 10672 net.cpp:165] Memory required for data: 302945600
I0814 22:43:29.926477 10672 layer_factory.hpp:77] Creating layer relu5
I0814 22:43:29.926492 10672 net.cpp:100] Creating Layer relu5
I0814 22:43:29.926502 10672 net.cpp:434] relu5 <- ip1
I0814 22:43:29.926514 10672 net.cpp:395] relu5 -> ip1 (in-place)
I0814 22:43:29.926604 10672 net.cpp:150] Setting up relu5
I0814 22:43:29.926618 10672 net.cpp:157] Top shape: 100 512 (51200)
I0814 22:43:29.926626 10672 net.cpp:165] Memory required for data: 303150400
I0814 22:43:29.926661 10672 layer_factory.hpp:77] Creating layer drop1
I0814 22:43:29.926681 10672 net.cpp:100] Creating Layer drop1
I0814 22:43:29.926692 10672 net.cpp:434] drop1 <- ip1
I0814 22:43:29.926702 10672 net.cpp:395] drop1 -> ip1 (in-place)
I0814 22:43:29.926736 10672 net.cpp:150] Setting up drop1
I0814 22:43:29.926750 10672 net.cpp:157] Top shape: 100 512 (51200)
I0814 22:43:29.926759 10672 net.cpp:165] Memory required for data: 303355200
I0814 22:43:29.926767 10672 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0814 22:43:29.926785 10672 net.cpp:100] Creating Layer ip1_drop1_0_split
I0814 22:43:29.926796 10672 net.cpp:434] ip1_drop1_0_split <- ip1
I0814 22:43:29.926806 10672 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0814 22:43:29.926818 10672 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0814 22:43:29.926856 10672 net.cpp:150] Setting up ip1_drop1_0_split
I0814 22:43:29.926869 10672 net.cpp:157] Top shape: 100 512 (51200)
I0814 22:43:29.926879 10672 net.cpp:157] Top shape: 100 512 (51200)
I0814 22:43:29.926887 10672 net.cpp:165] Memory required for data: 303764800
I0814 22:43:29.926895 10672 layer_factory.hpp:77] Creating layer ip2
I0814 22:43:29.926908 10672 net.cpp:100] Creating Layer ip2
I0814 22:43:29.926918 10672 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0814 22:43:29.926928 10672 net.cpp:408] ip2 -> ip2
I0814 22:43:29.927019 10672 net.cpp:150] Setting up ip2
I0814 22:43:29.927033 10672 net.cpp:157] Top shape: 100 2 (200)
I0814 22:43:29.927042 10672 net.cpp:165] Memory required for data: 303765600
I0814 22:43:29.927057 10672 layer_factory.hpp:77] Creating layer loss1
I0814 22:43:29.927070 10672 net.cpp:100] Creating Layer loss1
I0814 22:43:29.927079 10672 net.cpp:434] loss1 <- ip2
I0814 22:43:29.927088 10672 net.cpp:434] loss1 <- glasses
I0814 22:43:29.927099 10672 net.cpp:408] loss1 -> loss1
I0814 22:43:29.927114 10672 layer_factory.hpp:77] Creating layer loss1
I0814 22:43:29.927572 10672 net.cpp:150] Setting up loss1
I0814 22:43:29.927588 10672 net.cpp:157] Top shape: (1)
I0814 22:43:29.927597 10672 net.cpp:160]     with loss weight 0.5
I0814 22:43:29.927621 10672 net.cpp:165] Memory required for data: 303765604
I0814 22:43:29.927629 10672 layer_factory.hpp:77] Creating layer ip3
I0814 22:43:29.927641 10672 net.cpp:100] Creating Layer ip3
I0814 22:43:29.927657 10672 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0814 22:43:29.927669 10672 net.cpp:408] ip3 -> ip3
I0814 22:43:29.929687 10672 net.cpp:150] Setting up ip3
I0814 22:43:29.929705 10672 net.cpp:157] Top shape: 100 512 (51200)
I0814 22:43:29.929714 10672 net.cpp:165] Memory required for data: 303970404
I0814 22:43:29.929725 10672 layer_factory.hpp:77] Creating layer loss2
I0814 22:43:29.929738 10672 net.cpp:100] Creating Layer loss2
I0814 22:43:29.929746 10672 net.cpp:434] loss2 <- ip3
I0814 22:43:29.929755 10672 net.cpp:434] loss2 <- gender
I0814 22:43:29.929767 10672 net.cpp:408] loss2 -> loss2
I0814 22:43:29.929782 10672 layer_factory.hpp:77] Creating layer loss2
I0814 22:43:29.930049 10672 net.cpp:150] Setting up loss2
I0814 22:43:29.930068 10672 net.cpp:157] Top shape: (1)
I0814 22:43:29.930078 10672 net.cpp:160]     with loss weight 0.5
I0814 22:43:29.930089 10672 net.cpp:165] Memory required for data: 303970408
I0814 22:43:29.930099 10672 net.cpp:226] loss2 needs backward computation.
I0814 22:43:29.930107 10672 net.cpp:226] ip3 needs backward computation.
I0814 22:43:29.930115 10672 net.cpp:226] loss1 needs backward computation.
I0814 22:43:29.930124 10672 net.cpp:226] ip2 needs backward computation.
I0814 22:43:29.930132 10672 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0814 22:43:29.930140 10672 net.cpp:226] drop1 needs backward computation.
I0814 22:43:29.930150 10672 net.cpp:226] relu5 needs backward computation.
I0814 22:43:29.930156 10672 net.cpp:226] ip1 needs backward computation.
I0814 22:43:29.930166 10672 net.cpp:226] relu4 needs backward computation.
I0814 22:43:29.930173 10672 net.cpp:226] conv4 needs backward computation.
I0814 22:43:29.930191 10672 net.cpp:226] relu3 needs backward computation.
I0814 22:43:29.930200 10672 net.cpp:226] conv3 needs backward computation.
I0814 22:43:29.930208 10672 net.cpp:226] pool2 needs backward computation.
I0814 22:43:29.930217 10672 net.cpp:226] relu2 needs backward computation.
I0814 22:43:29.930225 10672 net.cpp:226] conv2 needs backward computation.
I0814 22:43:29.930233 10672 net.cpp:226] pool1 needs backward computation.
I0814 22:43:29.930243 10672 net.cpp:226] relu1 needs backward computation.
I0814 22:43:29.930251 10672 net.cpp:226] conv1 needs backward computation.
I0814 22:43:29.930260 10672 net.cpp:228] slice1 does not need backward computation.
I0814 22:43:29.930269 10672 net.cpp:228] labels does not need backward computation.
I0814 22:43:29.930277 10672 net.cpp:228] data does not need backward computation.
I0814 22:43:29.930285 10672 net.cpp:270] This network produces output loss1
I0814 22:43:29.930294 10672 net.cpp:270] This network produces output loss2
I0814 22:43:29.930315 10672 net.cpp:283] Network initialization done.
I0814 22:43:29.930868 10672 solver.cpp:181] Creating test net (#0) specified by net file: models/gender_glasses/train_val.prototxt
I0814 22:43:29.930917 10672 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0814 22:43:29.930927 10672 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer labels
I0814 22:43:29.931082 10672 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 80
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv4"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.5
}
layer {
  name: "accuracy_glasses"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "glasses"
  top: "accuracy_glasses"
  include {
    phase: TEST
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.5
}
layer {
  name: "accuracy_gender"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "gender"
  top: "accuracy_gender"
  include {
    phase: TEST
  }
}
I0814 22:43:29.931723 10672 layer_factory.hpp:77] Creating layer data
I0814 22:43:29.931815 10672 net.cpp:100] Creating Layer data
I0814 22:43:29.931829 10672 net.cpp:408] data -> data
I0814 22:43:29.933320 10680 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb
I0814 22:43:29.933537 10672 data_layer.cpp:41] output data size: 64,3,100,100
I0814 22:43:29.947399 10672 net.cpp:150] Setting up data
I0814 22:43:29.947448 10672 net.cpp:157] Top shape: 64 3 100 100 (1920000)
I0814 22:43:29.947458 10672 net.cpp:165] Memory required for data: 7680000
I0814 22:43:29.947469 10672 layer_factory.hpp:77] Creating layer labels
I0814 22:43:29.947597 10672 net.cpp:100] Creating Layer labels
I0814 22:43:29.947613 10672 net.cpp:408] labels -> labels
I0814 22:43:29.949398 10682 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb
I0814 22:43:29.949888 10672 data_layer.cpp:41] output data size: 64,2,1,1
I0814 22:43:29.950219 10672 net.cpp:150] Setting up labels
I0814 22:43:29.950238 10672 net.cpp:157] Top shape: 64 2 1 1 (128)
I0814 22:43:29.950248 10672 net.cpp:165] Memory required for data: 7680512
I0814 22:43:29.950258 10672 layer_factory.hpp:77] Creating layer slice1
I0814 22:43:29.950273 10672 net.cpp:100] Creating Layer slice1
I0814 22:43:29.950284 10672 net.cpp:434] slice1 <- labels
I0814 22:43:29.950297 10672 net.cpp:408] slice1 -> glasses
I0814 22:43:29.950312 10672 net.cpp:408] slice1 -> gender
I0814 22:43:29.950351 10672 net.cpp:150] Setting up slice1
I0814 22:43:29.950366 10672 net.cpp:157] Top shape: 64 1 1 1 (64)
I0814 22:43:29.950374 10672 net.cpp:157] Top shape: 64 1 1 1 (64)
I0814 22:43:29.950382 10672 net.cpp:165] Memory required for data: 7681024
I0814 22:43:29.950390 10672 layer_factory.hpp:77] Creating layer glasses_slice1_0_split
I0814 22:43:29.950402 10672 net.cpp:100] Creating Layer glasses_slice1_0_split
I0814 22:43:29.950412 10672 net.cpp:434] glasses_slice1_0_split <- glasses
I0814 22:43:29.950423 10672 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_0
I0814 22:43:29.950434 10672 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_1
I0814 22:43:29.950474 10672 net.cpp:150] Setting up glasses_slice1_0_split
I0814 22:43:29.950498 10672 net.cpp:157] Top shape: 64 1 1 1 (64)
I0814 22:43:29.950508 10672 net.cpp:157] Top shape: 64 1 1 1 (64)
I0814 22:43:29.950516 10672 net.cpp:165] Memory required for data: 7681536
I0814 22:43:29.950525 10672 layer_factory.hpp:77] Creating layer gender_slice1_1_split
I0814 22:43:29.950554 10672 net.cpp:100] Creating Layer gender_slice1_1_split
I0814 22:43:29.950570 10672 net.cpp:434] gender_slice1_1_split <- gender
I0814 22:43:29.950584 10672 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_0
I0814 22:43:29.950597 10672 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_1
I0814 22:43:29.950634 10672 net.cpp:150] Setting up gender_slice1_1_split
I0814 22:43:29.950645 10672 net.cpp:157] Top shape: 64 1 1 1 (64)
I0814 22:43:29.950657 10672 net.cpp:157] Top shape: 64 1 1 1 (64)
I0814 22:43:29.950665 10672 net.cpp:165] Memory required for data: 7682048
I0814 22:43:29.950675 10672 layer_factory.hpp:77] Creating layer conv1
I0814 22:43:29.950693 10672 net.cpp:100] Creating Layer conv1
I0814 22:43:29.950702 10672 net.cpp:434] conv1 <- data
I0814 22:43:29.950713 10672 net.cpp:408] conv1 -> conv1
I0814 22:43:29.951792 10672 net.cpp:150] Setting up conv1
I0814 22:43:29.951812 10672 net.cpp:157] Top shape: 64 20 96 96 (11796480)
I0814 22:43:29.951822 10672 net.cpp:165] Memory required for data: 54867968
I0814 22:43:29.951845 10672 layer_factory.hpp:77] Creating layer relu1
I0814 22:43:29.951860 10672 net.cpp:100] Creating Layer relu1
I0814 22:43:29.951870 10672 net.cpp:434] relu1 <- conv1
I0814 22:43:29.951884 10672 net.cpp:395] relu1 -> conv1 (in-place)
I0814 22:43:29.952446 10672 net.cpp:150] Setting up relu1
I0814 22:43:29.952464 10672 net.cpp:157] Top shape: 64 20 96 96 (11796480)
I0814 22:43:29.952476 10672 net.cpp:165] Memory required for data: 102053888
I0814 22:43:29.952496 10672 layer_factory.hpp:77] Creating layer pool1
I0814 22:43:29.952508 10672 net.cpp:100] Creating Layer pool1
I0814 22:43:29.952517 10672 net.cpp:434] pool1 <- conv1
I0814 22:43:29.952529 10672 net.cpp:408] pool1 -> pool1
I0814 22:43:29.952574 10672 net.cpp:150] Setting up pool1
I0814 22:43:29.952594 10672 net.cpp:157] Top shape: 64 20 48 48 (2949120)
I0814 22:43:29.952602 10672 net.cpp:165] Memory required for data: 113850368
I0814 22:43:29.952611 10672 layer_factory.hpp:77] Creating layer conv2
I0814 22:43:29.952632 10672 net.cpp:100] Creating Layer conv2
I0814 22:43:29.952642 10672 net.cpp:434] conv2 <- pool1
I0814 22:43:29.952653 10672 net.cpp:408] conv2 -> conv2
I0814 22:43:29.953830 10672 net.cpp:150] Setting up conv2
I0814 22:43:29.953857 10672 net.cpp:157] Top shape: 64 48 44 44 (5947392)
I0814 22:43:29.953866 10672 net.cpp:165] Memory required for data: 137639936
I0814 22:43:29.953884 10672 layer_factory.hpp:77] Creating layer relu2
I0814 22:43:29.953904 10672 net.cpp:100] Creating Layer relu2
I0814 22:43:29.953913 10672 net.cpp:434] relu2 <- conv2
I0814 22:43:29.953924 10672 net.cpp:395] relu2 -> conv2 (in-place)
I0814 22:43:29.954134 10672 net.cpp:150] Setting up relu2
I0814 22:43:29.954149 10672 net.cpp:157] Top shape: 64 48 44 44 (5947392)
I0814 22:43:29.954156 10672 net.cpp:165] Memory required for data: 161429504
I0814 22:43:29.954166 10672 layer_factory.hpp:77] Creating layer pool2
I0814 22:43:29.954180 10672 net.cpp:100] Creating Layer pool2
I0814 22:43:29.954188 10672 net.cpp:434] pool2 <- conv2
I0814 22:43:29.954198 10672 net.cpp:408] pool2 -> pool2
I0814 22:43:29.954242 10672 net.cpp:150] Setting up pool2
I0814 22:43:29.954255 10672 net.cpp:157] Top shape: 64 48 22 22 (1486848)
I0814 22:43:29.954263 10672 net.cpp:165] Memory required for data: 167376896
I0814 22:43:29.954272 10672 layer_factory.hpp:77] Creating layer conv3
I0814 22:43:29.954288 10672 net.cpp:100] Creating Layer conv3
I0814 22:43:29.954296 10672 net.cpp:434] conv3 <- pool2
I0814 22:43:29.954308 10672 net.cpp:408] conv3 -> conv3
I0814 22:43:29.955641 10672 net.cpp:150] Setting up conv3
I0814 22:43:29.955669 10672 net.cpp:157] Top shape: 64 64 20 20 (1638400)
I0814 22:43:29.955678 10672 net.cpp:165] Memory required for data: 173930496
I0814 22:43:29.955693 10672 layer_factory.hpp:77] Creating layer relu3
I0814 22:43:29.955710 10672 net.cpp:100] Creating Layer relu3
I0814 22:43:29.955721 10672 net.cpp:434] relu3 <- conv3
I0814 22:43:29.955737 10672 net.cpp:395] relu3 -> conv3 (in-place)
I0814 22:43:29.956876 10672 net.cpp:150] Setting up relu3
I0814 22:43:29.956914 10672 net.cpp:157] Top shape: 64 64 20 20 (1638400)
I0814 22:43:29.956924 10672 net.cpp:165] Memory required for data: 180484096
I0814 22:43:29.956940 10672 layer_factory.hpp:77] Creating layer conv4
I0814 22:43:29.956957 10672 net.cpp:100] Creating Layer conv4
I0814 22:43:29.956969 10672 net.cpp:434] conv4 <- conv3
I0814 22:43:29.956981 10672 net.cpp:408] conv4 -> conv4
I0814 22:43:29.958328 10672 net.cpp:150] Setting up conv4
I0814 22:43:29.958348 10672 net.cpp:157] Top shape: 64 80 18 18 (1658880)
I0814 22:43:29.958358 10672 net.cpp:165] Memory required for data: 187119616
I0814 22:43:29.958369 10672 layer_factory.hpp:77] Creating layer relu4
I0814 22:43:29.958384 10672 net.cpp:100] Creating Layer relu4
I0814 22:43:29.958394 10672 net.cpp:434] relu4 <- conv4
I0814 22:43:29.958403 10672 net.cpp:395] relu4 -> conv4 (in-place)
I0814 22:43:29.958541 10672 net.cpp:150] Setting up relu4
I0814 22:43:29.958607 10672 net.cpp:157] Top shape: 64 80 18 18 (1658880)
I0814 22:43:29.958622 10672 net.cpp:165] Memory required for data: 193755136
I0814 22:43:29.958634 10672 layer_factory.hpp:77] Creating layer ip1
I0814 22:43:29.958657 10672 net.cpp:100] Creating Layer ip1
I0814 22:43:29.958670 10672 net.cpp:434] ip1 <- conv4
I0814 22:43:29.958684 10672 net.cpp:408] ip1 -> ip1
I0814 22:43:30.066485 10672 net.cpp:150] Setting up ip1
I0814 22:43:30.066532 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.066542 10672 net.cpp:165] Memory required for data: 193886208
I0814 22:43:30.066563 10672 layer_factory.hpp:77] Creating layer relu5
I0814 22:43:30.066583 10672 net.cpp:100] Creating Layer relu5
I0814 22:43:30.066594 10672 net.cpp:434] relu5 <- ip1
I0814 22:43:30.066607 10672 net.cpp:395] relu5 -> ip1 (in-place)
I0814 22:43:30.066699 10672 net.cpp:150] Setting up relu5
I0814 22:43:30.066714 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.066721 10672 net.cpp:165] Memory required for data: 194017280
I0814 22:43:30.066732 10672 layer_factory.hpp:77] Creating layer drop1
I0814 22:43:30.066745 10672 net.cpp:100] Creating Layer drop1
I0814 22:43:30.066753 10672 net.cpp:434] drop1 <- ip1
I0814 22:43:30.066763 10672 net.cpp:395] drop1 -> ip1 (in-place)
I0814 22:43:30.066793 10672 net.cpp:150] Setting up drop1
I0814 22:43:30.066807 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.066815 10672 net.cpp:165] Memory required for data: 194148352
I0814 22:43:30.066823 10672 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0814 22:43:30.066834 10672 net.cpp:100] Creating Layer ip1_drop1_0_split
I0814 22:43:30.066843 10672 net.cpp:434] ip1_drop1_0_split <- ip1
I0814 22:43:30.066853 10672 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0814 22:43:30.066865 10672 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0814 22:43:30.066907 10672 net.cpp:150] Setting up ip1_drop1_0_split
I0814 22:43:30.066920 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.066931 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.066939 10672 net.cpp:165] Memory required for data: 194410496
I0814 22:43:30.066947 10672 layer_factory.hpp:77] Creating layer ip2
I0814 22:43:30.066959 10672 net.cpp:100] Creating Layer ip2
I0814 22:43:30.066967 10672 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0814 22:43:30.066979 10672 net.cpp:408] ip2 -> ip2
I0814 22:43:30.067077 10672 net.cpp:150] Setting up ip2
I0814 22:43:30.067090 10672 net.cpp:157] Top shape: 64 2 (128)
I0814 22:43:30.067100 10672 net.cpp:165] Memory required for data: 194411008
I0814 22:43:30.067116 10672 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0814 22:43:30.067128 10672 net.cpp:100] Creating Layer ip2_ip2_0_split
I0814 22:43:30.067137 10672 net.cpp:434] ip2_ip2_0_split <- ip2
I0814 22:43:30.067147 10672 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0814 22:43:30.067158 10672 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0814 22:43:30.067198 10672 net.cpp:150] Setting up ip2_ip2_0_split
I0814 22:43:30.067210 10672 net.cpp:157] Top shape: 64 2 (128)
I0814 22:43:30.067220 10672 net.cpp:157] Top shape: 64 2 (128)
I0814 22:43:30.067251 10672 net.cpp:165] Memory required for data: 194412032
I0814 22:43:30.067260 10672 layer_factory.hpp:77] Creating layer loss1
I0814 22:43:30.067271 10672 net.cpp:100] Creating Layer loss1
I0814 22:43:30.067281 10672 net.cpp:434] loss1 <- ip2_ip2_0_split_0
I0814 22:43:30.067289 10672 net.cpp:434] loss1 <- glasses_slice1_0_split_0
I0814 22:43:30.067301 10672 net.cpp:408] loss1 -> loss1
I0814 22:43:30.067317 10672 layer_factory.hpp:77] Creating layer loss1
I0814 22:43:30.067560 10672 net.cpp:150] Setting up loss1
I0814 22:43:30.067576 10672 net.cpp:157] Top shape: (1)
I0814 22:43:30.067585 10672 net.cpp:160]     with loss weight 0.5
I0814 22:43:30.067602 10672 net.cpp:165] Memory required for data: 194412036
I0814 22:43:30.067611 10672 layer_factory.hpp:77] Creating layer accuracy_glasses
I0814 22:43:30.067625 10672 net.cpp:100] Creating Layer accuracy_glasses
I0814 22:43:30.067634 10672 net.cpp:434] accuracy_glasses <- ip2_ip2_0_split_1
I0814 22:43:30.067643 10672 net.cpp:434] accuracy_glasses <- glasses_slice1_0_split_1
I0814 22:43:30.067654 10672 net.cpp:408] accuracy_glasses -> accuracy_glasses
I0814 22:43:30.067669 10672 net.cpp:150] Setting up accuracy_glasses
I0814 22:43:30.067680 10672 net.cpp:157] Top shape: (1)
I0814 22:43:30.067688 10672 net.cpp:165] Memory required for data: 194412040
I0814 22:43:30.067697 10672 layer_factory.hpp:77] Creating layer ip3
I0814 22:43:30.067708 10672 net.cpp:100] Creating Layer ip3
I0814 22:43:30.067718 10672 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0814 22:43:30.067728 10672 net.cpp:408] ip3 -> ip3
I0814 22:43:30.069782 10672 net.cpp:150] Setting up ip3
I0814 22:43:30.069797 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.069807 10672 net.cpp:165] Memory required for data: 194543112
I0814 22:43:30.069818 10672 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0814 22:43:30.069830 10672 net.cpp:100] Creating Layer ip3_ip3_0_split
I0814 22:43:30.069839 10672 net.cpp:434] ip3_ip3_0_split <- ip3
I0814 22:43:30.069849 10672 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0814 22:43:30.069861 10672 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0814 22:43:30.069901 10672 net.cpp:150] Setting up ip3_ip3_0_split
I0814 22:43:30.069914 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.069923 10672 net.cpp:157] Top shape: 64 512 (32768)
I0814 22:43:30.069931 10672 net.cpp:165] Memory required for data: 194805256
I0814 22:43:30.069939 10672 layer_factory.hpp:77] Creating layer loss2
I0814 22:43:30.069949 10672 net.cpp:100] Creating Layer loss2
I0814 22:43:30.069958 10672 net.cpp:434] loss2 <- ip3_ip3_0_split_0
I0814 22:43:30.069967 10672 net.cpp:434] loss2 <- gender_slice1_1_split_0
I0814 22:43:30.069978 10672 net.cpp:408] loss2 -> loss2
I0814 22:43:30.069991 10672 layer_factory.hpp:77] Creating layer loss2
I0814 22:43:30.070405 10672 net.cpp:150] Setting up loss2
I0814 22:43:30.070420 10672 net.cpp:157] Top shape: (1)
I0814 22:43:30.070430 10672 net.cpp:160]     with loss weight 0.5
I0814 22:43:30.070441 10672 net.cpp:165] Memory required for data: 194805260
I0814 22:43:30.070448 10672 layer_factory.hpp:77] Creating layer accuracy_gender
I0814 22:43:30.070462 10672 net.cpp:100] Creating Layer accuracy_gender
I0814 22:43:30.070472 10672 net.cpp:434] accuracy_gender <- ip3_ip3_0_split_1
I0814 22:43:30.070482 10672 net.cpp:434] accuracy_gender <- gender_slice1_1_split_1
I0814 22:43:30.070492 10672 net.cpp:408] accuracy_gender -> accuracy_gender
I0814 22:43:30.070505 10672 net.cpp:150] Setting up accuracy_gender
I0814 22:43:30.070515 10672 net.cpp:157] Top shape: (1)
I0814 22:43:30.070523 10672 net.cpp:165] Memory required for data: 194805264
I0814 22:43:30.070533 10672 net.cpp:228] accuracy_gender does not need backward computation.
I0814 22:43:30.070540 10672 net.cpp:226] loss2 needs backward computation.
I0814 22:43:30.070549 10672 net.cpp:226] ip3_ip3_0_split needs backward computation.
I0814 22:43:30.070557 10672 net.cpp:226] ip3 needs backward computation.
I0814 22:43:30.070571 10672 net.cpp:228] accuracy_glasses does not need backward computation.
I0814 22:43:30.070590 10672 net.cpp:226] loss1 needs backward computation.
I0814 22:43:30.070600 10672 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0814 22:43:30.070610 10672 net.cpp:226] ip2 needs backward computation.
I0814 22:43:30.070617 10672 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0814 22:43:30.070626 10672 net.cpp:226] drop1 needs backward computation.
I0814 22:43:30.070636 10672 net.cpp:226] relu5 needs backward computation.
I0814 22:43:30.070643 10672 net.cpp:226] ip1 needs backward computation.
I0814 22:43:30.070652 10672 net.cpp:226] relu4 needs backward computation.
I0814 22:43:30.070660 10672 net.cpp:226] conv4 needs backward computation.
I0814 22:43:30.070668 10672 net.cpp:226] relu3 needs backward computation.
I0814 22:43:30.070677 10672 net.cpp:226] conv3 needs backward computation.
I0814 22:43:30.070685 10672 net.cpp:226] pool2 needs backward computation.
I0814 22:43:30.070693 10672 net.cpp:226] relu2 needs backward computation.
I0814 22:43:30.070701 10672 net.cpp:226] conv2 needs backward computation.
I0814 22:43:30.070709 10672 net.cpp:226] pool1 needs backward computation.
I0814 22:43:30.070718 10672 net.cpp:226] relu1 needs backward computation.
I0814 22:43:30.070726 10672 net.cpp:226] conv1 needs backward computation.
I0814 22:43:30.070734 10672 net.cpp:228] gender_slice1_1_split does not need backward computation.
I0814 22:43:30.070744 10672 net.cpp:228] glasses_slice1_0_split does not need backward computation.
I0814 22:43:30.070752 10672 net.cpp:228] slice1 does not need backward computation.
I0814 22:43:30.070761 10672 net.cpp:228] labels does not need backward computation.
I0814 22:43:30.070768 10672 net.cpp:228] data does not need backward computation.
I0814 22:43:30.070776 10672 net.cpp:270] This network produces output accuracy_gender
I0814 22:43:30.070785 10672 net.cpp:270] This network produces output accuracy_glasses
I0814 22:43:30.070793 10672 net.cpp:270] This network produces output loss1
I0814 22:43:30.070801 10672 net.cpp:270] This network produces output loss2
I0814 22:43:30.070824 10672 net.cpp:283] Network initialization done.
I0814 22:43:30.070924 10672 solver.cpp:60] Solver scaffolding done.
I0814 22:43:30.071506 10672 caffe.cpp:251] Starting Optimization
I0814 22:43:30.071519 10672 solver.cpp:279] Solving multi_task
I0814 22:43:30.071527 10672 solver.cpp:280] Learning Rate Policy: inv
I0814 22:43:30.072650 10672 solver.cpp:337] Iteration 0, Testing net (#0)
I0814 22:43:52.736862 10672 blocking_queue.cpp:50] Data layer prefetch queue empty
I0814 22:44:33.094678 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0
I0814 22:44:33.094769 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.757891
I0814 22:44:33.094787 10672 solver.cpp:404]     Test net output #2: loss1 = 0.648574 (* 0.5 = 0.324287 loss)
I0814 22:44:33.094800 10672 solver.cpp:404]     Test net output #3: loss2 = 6.27415 (* 0.5 = 3.13708 loss)
I0814 22:44:33.388375 10672 solver.cpp:228] Iteration 0, loss = 3.48003
I0814 22:44:33.388430 10672 solver.cpp:244]     Train net output #0: loss1 = 0.661685 (* 0.5 = 0.330842 loss)
I0814 22:44:33.388445 10672 solver.cpp:244]     Train net output #1: loss2 = 6.29837 (* 0.5 = 3.14918 loss)
I0814 22:44:33.388466 10672 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0814 22:44:38.747423 10672 solver.cpp:228] Iteration 20, loss = 0.750832
I0814 22:44:38.747478 10672 solver.cpp:244]     Train net output #0: loss1 = 0.744174 (* 0.5 = 0.372087 loss)
I0814 22:44:38.747493 10672 solver.cpp:244]     Train net output #1: loss2 = 0.757489 (* 0.5 = 0.378745 loss)
I0814 22:44:38.747506 10672 sgd_solver.cpp:106] Iteration 20, lr = 0.00438691
I0814 22:44:44.260983 10672 solver.cpp:228] Iteration 40, loss = 0.628202
I0814 22:44:44.261042 10672 solver.cpp:244]     Train net output #0: loss1 = 0.577249 (* 0.5 = 0.288624 loss)
I0814 22:44:44.261059 10672 solver.cpp:244]     Train net output #1: loss2 = 0.679155 (* 0.5 = 0.339577 loss)
I0814 22:44:44.261071 10672 sgd_solver.cpp:106] Iteration 40, lr = 0.0029907
I0814 22:44:49.786206 10672 solver.cpp:228] Iteration 60, loss = 0.698906
I0814 22:44:49.786262 10672 solver.cpp:244]     Train net output #0: loss1 = 0.722916 (* 0.5 = 0.361458 loss)
I0814 22:44:49.786279 10672 solver.cpp:244]     Train net output #1: loss2 = 0.674896 (* 0.5 = 0.337448 loss)
I0814 22:44:49.786293 10672 sgd_solver.cpp:106] Iteration 60, lr = 0.00232368
I0814 22:44:55.309496 10672 solver.cpp:228] Iteration 80, loss = 0.655012
I0814 22:44:55.309552 10672 solver.cpp:244]     Train net output #0: loss1 = 0.567176 (* 0.5 = 0.283588 loss)
I0814 22:44:55.309567 10672 solver.cpp:244]     Train net output #1: loss2 = 0.742848 (* 0.5 = 0.371424 loss)
I0814 22:44:55.309581 10672 sgd_solver.cpp:106] Iteration 80, lr = 0.0019245
I0814 22:45:00.854996 10672 solver.cpp:228] Iteration 100, loss = 0.578736
I0814 22:45:00.855057 10672 solver.cpp:244]     Train net output #0: loss1 = 0.499016 (* 0.5 = 0.249508 loss)
I0814 22:45:00.855072 10672 solver.cpp:244]     Train net output #1: loss2 = 0.658455 (* 0.5 = 0.329228 loss)
I0814 22:45:00.855085 10672 sgd_solver.cpp:106] Iteration 100, lr = 0.0016556
I0814 22:45:06.402874 10672 solver.cpp:228] Iteration 120, loss = 0.593601
I0814 22:45:06.403065 10672 solver.cpp:244]     Train net output #0: loss1 = 0.570004 (* 0.5 = 0.285002 loss)
I0814 22:45:06.403090 10672 solver.cpp:244]     Train net output #1: loss2 = 0.617197 (* 0.5 = 0.308599 loss)
I0814 22:45:06.403106 10672 sgd_solver.cpp:106] Iteration 120, lr = 0.00146064
I0814 22:45:11.936851 10672 solver.cpp:228] Iteration 140, loss = 0.613589
I0814 22:45:11.936909 10672 solver.cpp:244]     Train net output #0: loss1 = 0.565339 (* 0.5 = 0.282669 loss)
I0814 22:45:11.936925 10672 solver.cpp:244]     Train net output #1: loss2 = 0.661839 (* 0.5 = 0.330919 loss)
I0814 22:45:11.936939 10672 sgd_solver.cpp:106] Iteration 140, lr = 0.00131199
I0814 22:45:17.449512 10672 solver.cpp:228] Iteration 160, loss = 0.588793
I0814 22:45:17.449573 10672 solver.cpp:244]     Train net output #0: loss1 = 0.532633 (* 0.5 = 0.266316 loss)
I0814 22:45:17.449589 10672 solver.cpp:244]     Train net output #1: loss2 = 0.644952 (* 0.5 = 0.322476 loss)
I0814 22:45:17.449601 10672 sgd_solver.cpp:106] Iteration 160, lr = 0.00119444
I0814 22:45:23.023308 10672 solver.cpp:228] Iteration 180, loss = 0.565499
I0814 22:45:23.023363 10672 solver.cpp:244]     Train net output #0: loss1 = 0.538123 (* 0.5 = 0.269061 loss)
I0814 22:45:23.023380 10672 solver.cpp:244]     Train net output #1: loss2 = 0.592875 (* 0.5 = 0.296437 loss)
I0814 22:45:23.023394 10672 sgd_solver.cpp:106] Iteration 180, lr = 0.00109884
I0814 22:45:28.565979 10672 solver.cpp:228] Iteration 200, loss = 0.558501
I0814 22:45:28.566036 10672 solver.cpp:244]     Train net output #0: loss1 = 0.516592 (* 0.5 = 0.258296 loss)
I0814 22:45:28.566053 10672 solver.cpp:244]     Train net output #1: loss2 = 0.60041 (* 0.5 = 0.300205 loss)
I0814 22:45:28.566067 10672 sgd_solver.cpp:106] Iteration 200, lr = 0.00101938
I0814 22:45:34.162962 10672 solver.cpp:228] Iteration 220, loss = 0.568108
I0814 22:45:34.163023 10672 solver.cpp:244]     Train net output #0: loss1 = 0.488239 (* 0.5 = 0.24412 loss)
I0814 22:45:34.163039 10672 solver.cpp:244]     Train net output #1: loss2 = 0.647977 (* 0.5 = 0.323988 loss)
I0814 22:45:34.163053 10672 sgd_solver.cpp:106] Iteration 220, lr = 0.000952147
I0814 22:45:39.732465 10672 solver.cpp:228] Iteration 240, loss = 0.547387
I0814 22:45:39.732625 10672 solver.cpp:244]     Train net output #0: loss1 = 0.515031 (* 0.5 = 0.257515 loss)
I0814 22:45:39.732648 10672 solver.cpp:244]     Train net output #1: loss2 = 0.579744 (* 0.5 = 0.289872 loss)
I0814 22:45:39.732664 10672 sgd_solver.cpp:106] Iteration 240, lr = 0.000894427
I0814 22:45:45.243218 10672 solver.cpp:228] Iteration 260, loss = 0.585779
I0814 22:45:45.243283 10672 solver.cpp:244]     Train net output #0: loss1 = 0.515249 (* 0.5 = 0.257624 loss)
I0814 22:45:45.243299 10672 solver.cpp:244]     Train net output #1: loss2 = 0.65631 (* 0.5 = 0.328155 loss)
I0814 22:45:45.243314 10672 sgd_solver.cpp:106] Iteration 260, lr = 0.000844262
I0814 22:45:50.863732 10672 solver.cpp:228] Iteration 280, loss = 0.603173
I0814 22:45:50.863791 10672 solver.cpp:244]     Train net output #0: loss1 = 0.588038 (* 0.5 = 0.294019 loss)
I0814 22:45:50.863807 10672 solver.cpp:244]     Train net output #1: loss2 = 0.618308 (* 0.5 = 0.309154 loss)
I0814 22:45:50.863821 10672 sgd_solver.cpp:106] Iteration 280, lr = 0.000800205
I0814 22:45:56.483134 10672 solver.cpp:228] Iteration 300, loss = 0.597096
I0814 22:45:56.483194 10672 solver.cpp:244]     Train net output #0: loss1 = 0.527267 (* 0.5 = 0.263634 loss)
I0814 22:45:56.483211 10672 solver.cpp:244]     Train net output #1: loss2 = 0.666924 (* 0.5 = 0.333462 loss)
I0814 22:45:56.483237 10672 sgd_solver.cpp:106] Iteration 300, lr = 0.000761165
I0814 22:46:02.037297 10672 solver.cpp:228] Iteration 320, loss = 0.531401
I0814 22:46:02.037355 10672 solver.cpp:244]     Train net output #0: loss1 = 0.463573 (* 0.5 = 0.231786 loss)
I0814 22:46:02.037371 10672 solver.cpp:244]     Train net output #1: loss2 = 0.59923 (* 0.5 = 0.299615 loss)
I0814 22:46:02.037385 10672 sgd_solver.cpp:106] Iteration 320, lr = 0.000726297
I0814 22:46:07.612026 10672 solver.cpp:228] Iteration 340, loss = 0.554452
I0814 22:46:07.612084 10672 solver.cpp:244]     Train net output #0: loss1 = 0.540046 (* 0.5 = 0.270023 loss)
I0814 22:46:07.612099 10672 solver.cpp:244]     Train net output #1: loss2 = 0.568859 (* 0.5 = 0.284429 loss)
I0814 22:46:07.612112 10672 sgd_solver.cpp:106] Iteration 340, lr = 0.000694943
I0814 22:46:13.147604 10672 solver.cpp:228] Iteration 360, loss = 0.574329
I0814 22:46:13.147763 10672 solver.cpp:244]     Train net output #0: loss1 = 0.605781 (* 0.5 = 0.30289 loss)
I0814 22:46:13.147783 10672 solver.cpp:244]     Train net output #1: loss2 = 0.542878 (* 0.5 = 0.271439 loss)
I0814 22:46:13.147797 10672 sgd_solver.cpp:106] Iteration 360, lr = 0.000666575
I0814 22:46:18.786530 10672 solver.cpp:228] Iteration 380, loss = 0.574772
I0814 22:46:18.786599 10672 solver.cpp:244]     Train net output #0: loss1 = 0.571035 (* 0.5 = 0.285517 loss)
I0814 22:46:18.786617 10672 solver.cpp:244]     Train net output #1: loss2 = 0.57851 (* 0.5 = 0.289255 loss)
I0814 22:46:18.786631 10672 sgd_solver.cpp:106] Iteration 380, lr = 0.000640769
I0814 22:46:24.338393 10672 solver.cpp:228] Iteration 400, loss = 0.528922
I0814 22:46:24.338449 10672 solver.cpp:244]     Train net output #0: loss1 = 0.509286 (* 0.5 = 0.254643 loss)
I0814 22:46:24.338465 10672 solver.cpp:244]     Train net output #1: loss2 = 0.548557 (* 0.5 = 0.274278 loss)
I0814 22:46:24.338479 10672 sgd_solver.cpp:106] Iteration 400, lr = 0.00061718
I0814 22:46:29.884469 10672 solver.cpp:228] Iteration 420, loss = 0.531236
I0814 22:46:29.884522 10672 solver.cpp:244]     Train net output #0: loss1 = 0.45279 (* 0.5 = 0.226395 loss)
I0814 22:46:29.884538 10672 solver.cpp:244]     Train net output #1: loss2 = 0.609681 (* 0.5 = 0.304841 loss)
I0814 22:46:29.884552 10672 sgd_solver.cpp:106] Iteration 420, lr = 0.000595523
I0814 22:46:35.468830 10672 solver.cpp:228] Iteration 440, loss = 0.514942
I0814 22:46:35.468890 10672 solver.cpp:244]     Train net output #0: loss1 = 0.422853 (* 0.5 = 0.211427 loss)
I0814 22:46:35.468906 10672 solver.cpp:244]     Train net output #1: loss2 = 0.60703 (* 0.5 = 0.303515 loss)
I0814 22:46:35.468919 10672 sgd_solver.cpp:106] Iteration 440, lr = 0.00057556
I0814 22:46:40.975486 10672 solver.cpp:228] Iteration 460, loss = 0.541961
I0814 22:46:40.975546 10672 solver.cpp:244]     Train net output #0: loss1 = 0.532656 (* 0.5 = 0.266328 loss)
I0814 22:46:40.975563 10672 solver.cpp:244]     Train net output #1: loss2 = 0.551267 (* 0.5 = 0.275633 loss)
I0814 22:46:40.975575 10672 sgd_solver.cpp:106] Iteration 460, lr = 0.000557092
I0814 22:46:46.480041 10672 solver.cpp:228] Iteration 480, loss = 0.537619
I0814 22:46:46.480207 10672 solver.cpp:244]     Train net output #0: loss1 = 0.484857 (* 0.5 = 0.242429 loss)
I0814 22:46:46.480232 10672 solver.cpp:244]     Train net output #1: loss2 = 0.590381 (* 0.5 = 0.295191 loss)
I0814 22:46:46.480248 10672 sgd_solver.cpp:106] Iteration 480, lr = 0.000539949
I0814 22:46:51.986933 10672 solver.cpp:228] Iteration 500, loss = 0.549039
I0814 22:46:51.986992 10672 solver.cpp:244]     Train net output #0: loss1 = 0.448996 (* 0.5 = 0.224498 loss)
I0814 22:46:51.987009 10672 solver.cpp:244]     Train net output #1: loss2 = 0.649081 (* 0.5 = 0.324541 loss)
I0814 22:46:51.987022 10672 sgd_solver.cpp:106] Iteration 500, lr = 0.000523989
I0814 22:46:57.507433 10672 solver.cpp:228] Iteration 520, loss = 0.529511
I0814 22:46:57.507489 10672 solver.cpp:244]     Train net output #0: loss1 = 0.489434 (* 0.5 = 0.244717 loss)
I0814 22:46:57.507505 10672 solver.cpp:244]     Train net output #1: loss2 = 0.569587 (* 0.5 = 0.284793 loss)
I0814 22:46:57.507519 10672 sgd_solver.cpp:106] Iteration 520, lr = 0.000509088
I0814 22:47:03.101672 10672 solver.cpp:228] Iteration 540, loss = 0.530381
I0814 22:47:03.101732 10672 solver.cpp:244]     Train net output #0: loss1 = 0.470001 (* 0.5 = 0.235001 loss)
I0814 22:47:03.101747 10672 solver.cpp:244]     Train net output #1: loss2 = 0.590762 (* 0.5 = 0.295381 loss)
I0814 22:47:03.101760 10672 sgd_solver.cpp:106] Iteration 540, lr = 0.00049514
I0814 22:47:08.675557 10672 solver.cpp:228] Iteration 560, loss = 0.556671
I0814 22:47:08.675639 10672 solver.cpp:244]     Train net output #0: loss1 = 0.53372 (* 0.5 = 0.26686 loss)
I0814 22:47:08.675657 10672 solver.cpp:244]     Train net output #1: loss2 = 0.579622 (* 0.5 = 0.289811 loss)
I0814 22:47:08.675670 10672 sgd_solver.cpp:106] Iteration 560, lr = 0.000482052
I0814 22:47:14.178633 10672 solver.cpp:228] Iteration 580, loss = 0.510772
I0814 22:47:14.178692 10672 solver.cpp:244]     Train net output #0: loss1 = 0.485244 (* 0.5 = 0.242622 loss)
I0814 22:47:14.178709 10672 solver.cpp:244]     Train net output #1: loss2 = 0.5363 (* 0.5 = 0.26815 loss)
I0814 22:47:14.178724 10672 sgd_solver.cpp:106] Iteration 580, lr = 0.000469744
I0814 22:47:19.682497 10672 solver.cpp:228] Iteration 600, loss = 0.500006
I0814 22:47:19.682684 10672 solver.cpp:244]     Train net output #0: loss1 = 0.515925 (* 0.5 = 0.257963 loss)
I0814 22:47:19.682709 10672 solver.cpp:244]     Train net output #1: loss2 = 0.484087 (* 0.5 = 0.242044 loss)
I0814 22:47:19.682725 10672 sgd_solver.cpp:106] Iteration 600, lr = 0.000458145
I0814 22:47:25.297768 10672 solver.cpp:228] Iteration 620, loss = 0.55191
I0814 22:47:25.297827 10672 solver.cpp:244]     Train net output #0: loss1 = 0.519299 (* 0.5 = 0.25965 loss)
I0814 22:47:25.297843 10672 solver.cpp:244]     Train net output #1: loss2 = 0.584521 (* 0.5 = 0.292261 loss)
I0814 22:47:25.297857 10672 sgd_solver.cpp:106] Iteration 620, lr = 0.000447193
I0814 22:47:30.862874 10672 solver.cpp:228] Iteration 640, loss = 0.494639
I0814 22:47:30.862933 10672 solver.cpp:244]     Train net output #0: loss1 = 0.441822 (* 0.5 = 0.220911 loss)
I0814 22:47:30.862949 10672 solver.cpp:244]     Train net output #1: loss2 = 0.547456 (* 0.5 = 0.273728 loss)
I0814 22:47:30.862964 10672 sgd_solver.cpp:106] Iteration 640, lr = 0.000436833
I0814 22:47:36.365809 10672 solver.cpp:228] Iteration 660, loss = 0.499365
I0814 22:47:36.365867 10672 solver.cpp:244]     Train net output #0: loss1 = 0.42155 (* 0.5 = 0.210775 loss)
I0814 22:47:36.365883 10672 solver.cpp:244]     Train net output #1: loss2 = 0.57718 (* 0.5 = 0.28859 loss)
I0814 22:47:36.365896 10672 sgd_solver.cpp:106] Iteration 660, lr = 0.000427016
I0814 22:47:41.867947 10672 solver.cpp:228] Iteration 680, loss = 0.453152
I0814 22:47:41.868003 10672 solver.cpp:244]     Train net output #0: loss1 = 0.426353 (* 0.5 = 0.213176 loss)
I0814 22:47:41.868019 10672 solver.cpp:244]     Train net output #1: loss2 = 0.479951 (* 0.5 = 0.239976 loss)
I0814 22:47:41.868033 10672 sgd_solver.cpp:106] Iteration 680, lr = 0.000417699
I0814 22:47:47.369410 10672 solver.cpp:228] Iteration 700, loss = 0.502194
I0814 22:47:47.369467 10672 solver.cpp:244]     Train net output #0: loss1 = 0.442073 (* 0.5 = 0.221036 loss)
I0814 22:47:47.369483 10672 solver.cpp:244]     Train net output #1: loss2 = 0.562316 (* 0.5 = 0.281158 loss)
I0814 22:47:47.369496 10672 sgd_solver.cpp:106] Iteration 700, lr = 0.000408843
I0814 22:47:52.869215 10672 solver.cpp:228] Iteration 720, loss = 0.458171
I0814 22:47:52.870314 10672 solver.cpp:244]     Train net output #0: loss1 = 0.411846 (* 0.5 = 0.205923 loss)
I0814 22:47:52.870337 10672 solver.cpp:244]     Train net output #1: loss2 = 0.504497 (* 0.5 = 0.252248 loss)
I0814 22:47:52.870352 10672 sgd_solver.cpp:106] Iteration 720, lr = 0.000400413
I0814 22:47:58.371737 10672 solver.cpp:228] Iteration 740, loss = 0.477459
I0814 22:47:58.371793 10672 solver.cpp:244]     Train net output #0: loss1 = 0.453462 (* 0.5 = 0.226731 loss)
I0814 22:47:58.371809 10672 solver.cpp:244]     Train net output #1: loss2 = 0.501456 (* 0.5 = 0.250728 loss)
I0814 22:47:58.371824 10672 sgd_solver.cpp:106] Iteration 740, lr = 0.000392377
I0814 22:48:03.952697 10672 solver.cpp:228] Iteration 760, loss = 0.48573
I0814 22:48:03.952754 10672 solver.cpp:244]     Train net output #0: loss1 = 0.390282 (* 0.5 = 0.195141 loss)
I0814 22:48:03.952769 10672 solver.cpp:244]     Train net output #1: loss2 = 0.581177 (* 0.5 = 0.290589 loss)
I0814 22:48:03.952783 10672 sgd_solver.cpp:106] Iteration 760, lr = 0.000384709
I0814 22:48:09.455075 10672 solver.cpp:228] Iteration 780, loss = 0.434323
I0814 22:48:09.455133 10672 solver.cpp:244]     Train net output #0: loss1 = 0.390205 (* 0.5 = 0.195103 loss)
I0814 22:48:09.455149 10672 solver.cpp:244]     Train net output #1: loss2 = 0.478441 (* 0.5 = 0.239221 loss)
I0814 22:48:09.455163 10672 sgd_solver.cpp:106] Iteration 780, lr = 0.000377381
I0814 22:48:14.961431 10672 solver.cpp:228] Iteration 800, loss = 0.487617
I0814 22:48:14.961484 10672 solver.cpp:244]     Train net output #0: loss1 = 0.400808 (* 0.5 = 0.200404 loss)
I0814 22:48:14.961500 10672 solver.cpp:244]     Train net output #1: loss2 = 0.574426 (* 0.5 = 0.287213 loss)
I0814 22:48:14.961513 10672 sgd_solver.cpp:106] Iteration 800, lr = 0.00037037
I0814 22:48:20.465095 10672 solver.cpp:228] Iteration 820, loss = 0.487544
I0814 22:48:20.465154 10672 solver.cpp:244]     Train net output #0: loss1 = 0.479023 (* 0.5 = 0.239512 loss)
I0814 22:48:20.465170 10672 solver.cpp:244]     Train net output #1: loss2 = 0.496065 (* 0.5 = 0.248033 loss)
I0814 22:48:20.465183 10672 sgd_solver.cpp:106] Iteration 820, lr = 0.000363657
I0814 22:48:25.970109 10672 solver.cpp:228] Iteration 840, loss = 0.459227
I0814 22:48:25.970229 10672 solver.cpp:244]     Train net output #0: loss1 = 0.3392 (* 0.5 = 0.1696 loss)
I0814 22:48:25.970247 10672 solver.cpp:244]     Train net output #1: loss2 = 0.579253 (* 0.5 = 0.289626 loss)
I0814 22:48:25.970260 10672 sgd_solver.cpp:106] Iteration 840, lr = 0.00035722
I0814 22:48:31.475134 10672 solver.cpp:228] Iteration 860, loss = 0.441308
I0814 22:48:31.475193 10672 solver.cpp:244]     Train net output #0: loss1 = 0.398649 (* 0.5 = 0.199325 loss)
I0814 22:48:31.475208 10672 solver.cpp:244]     Train net output #1: loss2 = 0.483967 (* 0.5 = 0.241983 loss)
I0814 22:48:31.475221 10672 sgd_solver.cpp:106] Iteration 860, lr = 0.000351043
I0814 22:48:36.980532 10672 solver.cpp:228] Iteration 880, loss = 0.45369
I0814 22:48:36.980592 10672 solver.cpp:244]     Train net output #0: loss1 = 0.359064 (* 0.5 = 0.179532 loss)
I0814 22:48:36.980607 10672 solver.cpp:244]     Train net output #1: loss2 = 0.548317 (* 0.5 = 0.274158 loss)
I0814 22:48:36.980621 10672 sgd_solver.cpp:106] Iteration 880, lr = 0.00034511
I0814 22:48:42.484616 10672 solver.cpp:228] Iteration 900, loss = 0.439158
I0814 22:48:42.484673 10672 solver.cpp:244]     Train net output #0: loss1 = 0.381929 (* 0.5 = 0.190964 loss)
I0814 22:48:42.484688 10672 solver.cpp:244]     Train net output #1: loss2 = 0.496387 (* 0.5 = 0.248194 loss)
I0814 22:48:42.484702 10672 sgd_solver.cpp:106] Iteration 900, lr = 0.000339406
I0814 22:48:47.990602 10672 solver.cpp:228] Iteration 920, loss = 0.490009
I0814 22:48:47.990658 10672 solver.cpp:244]     Train net output #0: loss1 = 0.377862 (* 0.5 = 0.188931 loss)
I0814 22:48:47.990674 10672 solver.cpp:244]     Train net output #1: loss2 = 0.602157 (* 0.5 = 0.301078 loss)
I0814 22:48:47.990686 10672 sgd_solver.cpp:106] Iteration 920, lr = 0.000333916
I0814 22:48:53.493836 10672 solver.cpp:228] Iteration 940, loss = 0.427443
I0814 22:48:53.493894 10672 solver.cpp:244]     Train net output #0: loss1 = 0.383973 (* 0.5 = 0.191987 loss)
I0814 22:48:53.493911 10672 solver.cpp:244]     Train net output #1: loss2 = 0.470913 (* 0.5 = 0.235456 loss)
I0814 22:48:53.493923 10672 sgd_solver.cpp:106] Iteration 940, lr = 0.00032863
I0814 22:48:58.996824 10672 solver.cpp:228] Iteration 960, loss = 0.4197
I0814 22:48:58.996978 10672 solver.cpp:244]     Train net output #0: loss1 = 0.316005 (* 0.5 = 0.158002 loss)
I0814 22:48:58.996995 10672 solver.cpp:244]     Train net output #1: loss2 = 0.523396 (* 0.5 = 0.261698 loss)
I0814 22:48:58.997009 10672 sgd_solver.cpp:106] Iteration 960, lr = 0.000323535
I0814 22:49:04.502835 10672 solver.cpp:228] Iteration 980, loss = 0.454054
I0814 22:49:04.502889 10672 solver.cpp:244]     Train net output #0: loss1 = 0.460199 (* 0.5 = 0.2301 loss)
I0814 22:49:04.502905 10672 solver.cpp:244]     Train net output #1: loss2 = 0.447908 (* 0.5 = 0.223954 loss)
I0814 22:49:04.502919 10672 sgd_solver.cpp:106] Iteration 980, lr = 0.00031862
I0814 22:49:09.733618 10672 solver.cpp:337] Iteration 1000, Testing net (#0)
I0814 22:50:13.001646 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.657875
I0814 22:50:13.001735 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.830875
I0814 22:50:13.001754 10672 solver.cpp:404]     Test net output #2: loss1 = 0.411716 (* 0.5 = 0.205858 loss)
I0814 22:50:13.001770 10672 solver.cpp:404]     Test net output #3: loss2 = 0.609363 (* 0.5 = 0.304681 loss)
I0814 22:50:13.086036 10672 solver.cpp:228] Iteration 1000, loss = 0.425187
I0814 22:50:13.086091 10672 solver.cpp:244]     Train net output #0: loss1 = 0.374396 (* 0.5 = 0.187198 loss)
I0814 22:50:13.086107 10672 solver.cpp:244]     Train net output #1: loss2 = 0.475978 (* 0.5 = 0.237989 loss)
I0814 22:50:13.086120 10672 sgd_solver.cpp:106] Iteration 1000, lr = 0.000313877
I0814 22:50:18.587074 10672 solver.cpp:228] Iteration 1020, loss = 0.465643
I0814 22:50:18.587132 10672 solver.cpp:244]     Train net output #0: loss1 = 0.399806 (* 0.5 = 0.199903 loss)
I0814 22:50:18.587148 10672 solver.cpp:244]     Train net output #1: loss2 = 0.531479 (* 0.5 = 0.265739 loss)
I0814 22:50:18.587162 10672 sgd_solver.cpp:106] Iteration 1020, lr = 0.000309294
I0814 22:50:24.087806 10672 solver.cpp:228] Iteration 1040, loss = 0.485602
I0814 22:50:24.087863 10672 solver.cpp:244]     Train net output #0: loss1 = 0.434693 (* 0.5 = 0.217346 loss)
I0814 22:50:24.087879 10672 solver.cpp:244]     Train net output #1: loss2 = 0.536511 (* 0.5 = 0.268255 loss)
I0814 22:50:24.087893 10672 sgd_solver.cpp:106] Iteration 1040, lr = 0.000304865
I0814 22:50:29.593032 10672 solver.cpp:228] Iteration 1060, loss = 0.447821
I0814 22:50:29.593093 10672 solver.cpp:244]     Train net output #0: loss1 = 0.363093 (* 0.5 = 0.181547 loss)
I0814 22:50:29.593108 10672 solver.cpp:244]     Train net output #1: loss2 = 0.532548 (* 0.5 = 0.266274 loss)
I0814 22:50:29.593122 10672 sgd_solver.cpp:106] Iteration 1060, lr = 0.000300581
I0814 22:50:35.098745 10672 solver.cpp:228] Iteration 1080, loss = 0.528212
I0814 22:50:35.098803 10672 solver.cpp:244]     Train net output #0: loss1 = 0.501066 (* 0.5 = 0.250533 loss)
I0814 22:50:35.098819 10672 solver.cpp:244]     Train net output #1: loss2 = 0.555358 (* 0.5 = 0.277679 loss)
I0814 22:50:35.098832 10672 sgd_solver.cpp:106] Iteration 1080, lr = 0.000296435
I0814 22:50:40.602114 10672 solver.cpp:228] Iteration 1100, loss = 0.448761
I0814 22:50:40.602175 10672 solver.cpp:244]     Train net output #0: loss1 = 0.393968 (* 0.5 = 0.196984 loss)
I0814 22:50:40.602192 10672 solver.cpp:244]     Train net output #1: loss2 = 0.503555 (* 0.5 = 0.251777 loss)
I0814 22:50:40.602207 10672 sgd_solver.cpp:106] Iteration 1100, lr = 0.00029242
I0814 22:50:46.103533 10672 solver.cpp:228] Iteration 1120, loss = 0.444102
I0814 22:50:46.103688 10672 solver.cpp:244]     Train net output #0: loss1 = 0.387215 (* 0.5 = 0.193607 loss)
I0814 22:50:46.103708 10672 solver.cpp:244]     Train net output #1: loss2 = 0.50099 (* 0.5 = 0.250495 loss)
I0814 22:50:46.103721 10672 sgd_solver.cpp:106] Iteration 1120, lr = 0.00028853
I0814 22:50:51.611831 10672 solver.cpp:228] Iteration 1140, loss = 0.40547
I0814 22:50:51.611883 10672 solver.cpp:244]     Train net output #0: loss1 = 0.325535 (* 0.5 = 0.162767 loss)
I0814 22:50:51.611899 10672 solver.cpp:244]     Train net output #1: loss2 = 0.485405 (* 0.5 = 0.242702 loss)
I0814 22:50:51.611912 10672 sgd_solver.cpp:106] Iteration 1140, lr = 0.000284758
I0814 22:50:57.113075 10672 solver.cpp:228] Iteration 1160, loss = 0.450231
I0814 22:50:57.113135 10672 solver.cpp:244]     Train net output #0: loss1 = 0.286438 (* 0.5 = 0.143219 loss)
I0814 22:50:57.113152 10672 solver.cpp:244]     Train net output #1: loss2 = 0.614025 (* 0.5 = 0.307012 loss)
I0814 22:50:57.113164 10672 sgd_solver.cpp:106] Iteration 1160, lr = 0.0002811
I0814 22:51:02.617604 10672 solver.cpp:228] Iteration 1180, loss = 0.467983
I0814 22:51:02.617660 10672 solver.cpp:244]     Train net output #0: loss1 = 0.398813 (* 0.5 = 0.199406 loss)
I0814 22:51:02.617676 10672 solver.cpp:244]     Train net output #1: loss2 = 0.537153 (* 0.5 = 0.268576 loss)
I0814 22:51:02.617689 10672 sgd_solver.cpp:106] Iteration 1180, lr = 0.000277549
I0814 22:51:08.120532 10672 solver.cpp:228] Iteration 1200, loss = 0.358633
I0814 22:51:08.120587 10672 solver.cpp:244]     Train net output #0: loss1 = 0.241712 (* 0.5 = 0.120856 loss)
I0814 22:51:08.120604 10672 solver.cpp:244]     Train net output #1: loss2 = 0.475554 (* 0.5 = 0.237777 loss)
I0814 22:51:08.120617 10672 sgd_solver.cpp:106] Iteration 1200, lr = 0.000274101
I0814 22:51:13.623054 10672 solver.cpp:228] Iteration 1220, loss = 0.386694
I0814 22:51:13.623111 10672 solver.cpp:244]     Train net output #0: loss1 = 0.279445 (* 0.5 = 0.139723 loss)
I0814 22:51:13.623127 10672 solver.cpp:244]     Train net output #1: loss2 = 0.493943 (* 0.5 = 0.246972 loss)
I0814 22:51:13.623142 10672 sgd_solver.cpp:106] Iteration 1220, lr = 0.000270752
I0814 22:51:19.127553 10672 solver.cpp:228] Iteration 1240, loss = 0.43254
I0814 22:51:19.127668 10672 solver.cpp:244]     Train net output #0: loss1 = 0.398039 (* 0.5 = 0.199019 loss)
I0814 22:51:19.127686 10672 solver.cpp:244]     Train net output #1: loss2 = 0.467041 (* 0.5 = 0.23352 loss)
I0814 22:51:19.127699 10672 sgd_solver.cpp:106] Iteration 1240, lr = 0.000267496
I0814 22:51:24.635350 10672 solver.cpp:228] Iteration 1260, loss = 0.451483
I0814 22:51:24.635407 10672 solver.cpp:244]     Train net output #0: loss1 = 0.354532 (* 0.5 = 0.177266 loss)
I0814 22:51:24.635423 10672 solver.cpp:244]     Train net output #1: loss2 = 0.548434 (* 0.5 = 0.274217 loss)
I0814 22:51:24.635437 10672 sgd_solver.cpp:106] Iteration 1260, lr = 0.00026433
I0814 22:51:30.142586 10672 solver.cpp:228] Iteration 1280, loss = 0.461543
I0814 22:51:30.142645 10672 solver.cpp:244]     Train net output #0: loss1 = 0.351556 (* 0.5 = 0.175778 loss)
I0814 22:51:30.142663 10672 solver.cpp:244]     Train net output #1: loss2 = 0.57153 (* 0.5 = 0.285765 loss)
I0814 22:51:30.142675 10672 sgd_solver.cpp:106] Iteration 1280, lr = 0.000261251
I0814 22:51:35.645256 10672 solver.cpp:228] Iteration 1300, loss = 0.438237
I0814 22:51:35.645310 10672 solver.cpp:244]     Train net output #0: loss1 = 0.365663 (* 0.5 = 0.182831 loss)
I0814 22:51:35.645326 10672 solver.cpp:244]     Train net output #1: loss2 = 0.51081 (* 0.5 = 0.255405 loss)
I0814 22:51:35.645340 10672 sgd_solver.cpp:106] Iteration 1300, lr = 0.000258254
I0814 22:51:41.150820 10672 solver.cpp:228] Iteration 1320, loss = 0.419182
I0814 22:51:41.150878 10672 solver.cpp:244]     Train net output #0: loss1 = 0.280361 (* 0.5 = 0.14018 loss)
I0814 22:51:41.150894 10672 solver.cpp:244]     Train net output #1: loss2 = 0.558003 (* 0.5 = 0.279001 loss)
I0814 22:51:41.150907 10672 sgd_solver.cpp:106] Iteration 1320, lr = 0.000255336
I0814 22:51:46.651336 10672 solver.cpp:228] Iteration 1340, loss = 0.444611
I0814 22:51:46.651394 10672 solver.cpp:244]     Train net output #0: loss1 = 0.331695 (* 0.5 = 0.165847 loss)
I0814 22:51:46.651410 10672 solver.cpp:244]     Train net output #1: loss2 = 0.557528 (* 0.5 = 0.278764 loss)
I0814 22:51:46.651423 10672 sgd_solver.cpp:106] Iteration 1340, lr = 0.000252493
I0814 22:51:52.157734 10672 solver.cpp:228] Iteration 1360, loss = 0.376842
I0814 22:51:52.157884 10672 solver.cpp:244]     Train net output #0: loss1 = 0.322753 (* 0.5 = 0.161376 loss)
I0814 22:51:52.157903 10672 solver.cpp:244]     Train net output #1: loss2 = 0.430931 (* 0.5 = 0.215465 loss)
I0814 22:51:52.157917 10672 sgd_solver.cpp:106] Iteration 1360, lr = 0.000249724
I0814 22:51:57.660524 10672 solver.cpp:228] Iteration 1380, loss = 0.49753
I0814 22:51:57.660584 10672 solver.cpp:244]     Train net output #0: loss1 = 0.407667 (* 0.5 = 0.203834 loss)
I0814 22:51:57.660603 10672 solver.cpp:244]     Train net output #1: loss2 = 0.587393 (* 0.5 = 0.293697 loss)
I0814 22:51:57.660625 10672 sgd_solver.cpp:106] Iteration 1380, lr = 0.000247024
I0814 22:52:03.182799 10672 solver.cpp:228] Iteration 1400, loss = 0.424279
I0814 22:52:03.182859 10672 solver.cpp:244]     Train net output #0: loss1 = 0.295233 (* 0.5 = 0.147616 loss)
I0814 22:52:03.182875 10672 solver.cpp:244]     Train net output #1: loss2 = 0.553325 (* 0.5 = 0.276662 loss)
I0814 22:52:03.182888 10672 sgd_solver.cpp:106] Iteration 1400, lr = 0.000244391
I0814 22:52:08.695437 10672 solver.cpp:228] Iteration 1420, loss = 0.414143
I0814 22:52:08.695495 10672 solver.cpp:244]     Train net output #0: loss1 = 0.355287 (* 0.5 = 0.177643 loss)
I0814 22:52:08.695510 10672 solver.cpp:244]     Train net output #1: loss2 = 0.472999 (* 0.5 = 0.2365 loss)
I0814 22:52:08.695523 10672 sgd_solver.cpp:106] Iteration 1420, lr = 0.000241823
I0814 22:52:14.224278 10672 solver.cpp:228] Iteration 1440, loss = 0.450395
I0814 22:52:14.224331 10672 solver.cpp:244]     Train net output #0: loss1 = 0.366262 (* 0.5 = 0.183131 loss)
I0814 22:52:14.224347 10672 solver.cpp:244]     Train net output #1: loss2 = 0.534528 (* 0.5 = 0.267264 loss)
I0814 22:52:14.224360 10672 sgd_solver.cpp:106] Iteration 1440, lr = 0.000239317
I0814 22:52:19.736976 10672 solver.cpp:228] Iteration 1460, loss = 0.515043
I0814 22:52:19.737036 10672 solver.cpp:244]     Train net output #0: loss1 = 0.501297 (* 0.5 = 0.250649 loss)
I0814 22:52:19.737051 10672 solver.cpp:244]     Train net output #1: loss2 = 0.528789 (* 0.5 = 0.264394 loss)
I0814 22:52:19.737066 10672 sgd_solver.cpp:106] Iteration 1460, lr = 0.000236871
I0814 22:52:25.243839 10672 solver.cpp:228] Iteration 1480, loss = 0.41446
I0814 22:52:25.243926 10672 solver.cpp:244]     Train net output #0: loss1 = 0.336705 (* 0.5 = 0.168353 loss)
I0814 22:52:25.243942 10672 solver.cpp:244]     Train net output #1: loss2 = 0.492214 (* 0.5 = 0.246107 loss)
I0814 22:52:25.243957 10672 sgd_solver.cpp:106] Iteration 1480, lr = 0.000234482
I0814 22:52:30.757495 10672 solver.cpp:228] Iteration 1500, loss = 0.446684
I0814 22:52:30.757555 10672 solver.cpp:244]     Train net output #0: loss1 = 0.310512 (* 0.5 = 0.155256 loss)
I0814 22:52:30.757570 10672 solver.cpp:244]     Train net output #1: loss2 = 0.582856 (* 0.5 = 0.291428 loss)
I0814 22:52:30.757583 10672 sgd_solver.cpp:106] Iteration 1500, lr = 0.000232149
I0814 22:52:36.267686 10672 solver.cpp:228] Iteration 1520, loss = 0.404481
I0814 22:52:36.267742 10672 solver.cpp:244]     Train net output #0: loss1 = 0.318396 (* 0.5 = 0.159198 loss)
I0814 22:52:36.267758 10672 solver.cpp:244]     Train net output #1: loss2 = 0.490567 (* 0.5 = 0.245283 loss)
I0814 22:52:36.267771 10672 sgd_solver.cpp:106] Iteration 1520, lr = 0.00022987
I0814 22:52:41.780521 10672 solver.cpp:228] Iteration 1540, loss = 0.420802
I0814 22:52:41.780580 10672 solver.cpp:244]     Train net output #0: loss1 = 0.336403 (* 0.5 = 0.168202 loss)
I0814 22:52:41.780596 10672 solver.cpp:244]     Train net output #1: loss2 = 0.505201 (* 0.5 = 0.2526 loss)
I0814 22:52:41.780609 10672 sgd_solver.cpp:106] Iteration 1540, lr = 0.000227641
I0814 22:52:47.292575 10672 solver.cpp:228] Iteration 1560, loss = 0.390974
I0814 22:52:47.292634 10672 solver.cpp:244]     Train net output #0: loss1 = 0.312317 (* 0.5 = 0.156158 loss)
I0814 22:52:47.292649 10672 solver.cpp:244]     Train net output #1: loss2 = 0.469631 (* 0.5 = 0.234815 loss)
I0814 22:52:47.292662 10672 sgd_solver.cpp:106] Iteration 1560, lr = 0.000225463
I0814 22:52:52.805837 10672 solver.cpp:228] Iteration 1580, loss = 0.413712
I0814 22:52:52.805896 10672 solver.cpp:244]     Train net output #0: loss1 = 0.315742 (* 0.5 = 0.157871 loss)
I0814 22:52:52.805912 10672 solver.cpp:244]     Train net output #1: loss2 = 0.511683 (* 0.5 = 0.255841 loss)
I0814 22:52:52.805924 10672 sgd_solver.cpp:106] Iteration 1580, lr = 0.000223333
I0814 22:52:58.317874 10672 solver.cpp:228] Iteration 1600, loss = 0.354718
I0814 22:52:58.318027 10672 solver.cpp:244]     Train net output #0: loss1 = 0.262808 (* 0.5 = 0.131404 loss)
I0814 22:52:58.318047 10672 solver.cpp:244]     Train net output #1: loss2 = 0.446629 (* 0.5 = 0.223315 loss)
I0814 22:52:58.318059 10672 sgd_solver.cpp:106] Iteration 1600, lr = 0.000221249
I0814 22:53:03.831804 10672 solver.cpp:228] Iteration 1620, loss = 0.452512
I0814 22:53:03.831861 10672 solver.cpp:244]     Train net output #0: loss1 = 0.35281 (* 0.5 = 0.176405 loss)
I0814 22:53:03.831877 10672 solver.cpp:244]     Train net output #1: loss2 = 0.552215 (* 0.5 = 0.276107 loss)
I0814 22:53:03.831892 10672 sgd_solver.cpp:106] Iteration 1620, lr = 0.000219209
I0814 22:53:09.341791 10672 solver.cpp:228] Iteration 1640, loss = 0.430879
I0814 22:53:09.341850 10672 solver.cpp:244]     Train net output #0: loss1 = 0.355036 (* 0.5 = 0.177518 loss)
I0814 22:53:09.341866 10672 solver.cpp:244]     Train net output #1: loss2 = 0.506722 (* 0.5 = 0.253361 loss)
I0814 22:53:09.341879 10672 sgd_solver.cpp:106] Iteration 1640, lr = 0.000217214
I0814 22:53:14.856134 10672 solver.cpp:228] Iteration 1660, loss = 0.34485
I0814 22:53:14.856194 10672 solver.cpp:244]     Train net output #0: loss1 = 0.248401 (* 0.5 = 0.1242 loss)
I0814 22:53:14.856212 10672 solver.cpp:244]     Train net output #1: loss2 = 0.441299 (* 0.5 = 0.220649 loss)
I0814 22:53:14.856226 10672 sgd_solver.cpp:106] Iteration 1660, lr = 0.00021526
I0814 22:53:20.366356 10672 solver.cpp:228] Iteration 1680, loss = 0.399605
I0814 22:53:20.366410 10672 solver.cpp:244]     Train net output #0: loss1 = 0.314589 (* 0.5 = 0.157295 loss)
I0814 22:53:20.366425 10672 solver.cpp:244]     Train net output #1: loss2 = 0.484621 (* 0.5 = 0.24231 loss)
I0814 22:53:20.366439 10672 sgd_solver.cpp:106] Iteration 1680, lr = 0.000213346
I0814 22:53:25.875295 10672 solver.cpp:228] Iteration 1700, loss = 0.407304
I0814 22:53:25.875355 10672 solver.cpp:244]     Train net output #0: loss1 = 0.261828 (* 0.5 = 0.130914 loss)
I0814 22:53:25.875370 10672 solver.cpp:244]     Train net output #1: loss2 = 0.552779 (* 0.5 = 0.27639 loss)
I0814 22:53:25.875385 10672 sgd_solver.cpp:106] Iteration 1700, lr = 0.000211472
I0814 22:53:31.387369 10672 solver.cpp:228] Iteration 1720, loss = 0.417041
I0814 22:53:31.387490 10672 solver.cpp:244]     Train net output #0: loss1 = 0.318286 (* 0.5 = 0.159143 loss)
I0814 22:53:31.387506 10672 solver.cpp:244]     Train net output #1: loss2 = 0.515796 (* 0.5 = 0.257898 loss)
I0814 22:53:31.387519 10672 sgd_solver.cpp:106] Iteration 1720, lr = 0.000209636
I0814 22:53:36.899102 10672 solver.cpp:228] Iteration 1740, loss = 0.391957
I0814 22:53:36.899159 10672 solver.cpp:244]     Train net output #0: loss1 = 0.243387 (* 0.5 = 0.121693 loss)
I0814 22:53:36.899175 10672 solver.cpp:244]     Train net output #1: loss2 = 0.540527 (* 0.5 = 0.270263 loss)
I0814 22:53:36.899188 10672 sgd_solver.cpp:106] Iteration 1740, lr = 0.000207836
I0814 22:53:42.409276 10672 solver.cpp:228] Iteration 1760, loss = 0.419884
I0814 22:53:42.409330 10672 solver.cpp:244]     Train net output #0: loss1 = 0.232534 (* 0.5 = 0.116267 loss)
I0814 22:53:42.409346 10672 solver.cpp:244]     Train net output #1: loss2 = 0.607233 (* 0.5 = 0.303616 loss)
I0814 22:53:42.409359 10672 sgd_solver.cpp:106] Iteration 1760, lr = 0.000206072
I0814 22:53:47.922953 10672 solver.cpp:228] Iteration 1780, loss = 0.376635
I0814 22:53:47.923010 10672 solver.cpp:244]     Train net output #0: loss1 = 0.288903 (* 0.5 = 0.144452 loss)
I0814 22:53:47.923027 10672 solver.cpp:244]     Train net output #1: loss2 = 0.464367 (* 0.5 = 0.232184 loss)
I0814 22:53:47.923040 10672 sgd_solver.cpp:106] Iteration 1780, lr = 0.000204343
I0814 22:53:53.432170 10672 solver.cpp:228] Iteration 1800, loss = 0.421707
I0814 22:53:53.432226 10672 solver.cpp:244]     Train net output #0: loss1 = 0.301972 (* 0.5 = 0.150986 loss)
I0814 22:53:53.432241 10672 solver.cpp:244]     Train net output #1: loss2 = 0.541442 (* 0.5 = 0.270721 loss)
I0814 22:53:53.432255 10672 sgd_solver.cpp:106] Iteration 1800, lr = 0.000202647
I0814 22:53:58.944538 10672 solver.cpp:228] Iteration 1820, loss = 0.395956
I0814 22:53:58.944596 10672 solver.cpp:244]     Train net output #0: loss1 = 0.258177 (* 0.5 = 0.129089 loss)
I0814 22:53:58.944612 10672 solver.cpp:244]     Train net output #1: loss2 = 0.533735 (* 0.5 = 0.266868 loss)
I0814 22:53:58.944625 10672 sgd_solver.cpp:106] Iteration 1820, lr = 0.000200984
I0814 22:54:04.455438 10672 solver.cpp:228] Iteration 1840, loss = 0.393214
I0814 22:54:04.455631 10672 solver.cpp:244]     Train net output #0: loss1 = 0.273771 (* 0.5 = 0.136885 loss)
I0814 22:54:04.455652 10672 solver.cpp:244]     Train net output #1: loss2 = 0.512657 (* 0.5 = 0.256328 loss)
I0814 22:54:04.455667 10672 sgd_solver.cpp:106] Iteration 1840, lr = 0.000199352
I0814 22:54:09.965560 10672 solver.cpp:228] Iteration 1860, loss = 0.38881
I0814 22:54:09.965620 10672 solver.cpp:244]     Train net output #0: loss1 = 0.256629 (* 0.5 = 0.128315 loss)
I0814 22:54:09.965636 10672 solver.cpp:244]     Train net output #1: loss2 = 0.52099 (* 0.5 = 0.260495 loss)
I0814 22:54:09.965649 10672 sgd_solver.cpp:106] Iteration 1860, lr = 0.000197751
I0814 22:54:15.473937 10672 solver.cpp:228] Iteration 1880, loss = 0.397802
I0814 22:54:15.473987 10672 solver.cpp:244]     Train net output #0: loss1 = 0.301601 (* 0.5 = 0.1508 loss)
I0814 22:54:15.474004 10672 solver.cpp:244]     Train net output #1: loss2 = 0.494002 (* 0.5 = 0.247001 loss)
I0814 22:54:15.474016 10672 sgd_solver.cpp:106] Iteration 1880, lr = 0.00019618
I0814 22:54:20.984906 10672 solver.cpp:228] Iteration 1900, loss = 0.375525
I0814 22:54:20.984966 10672 solver.cpp:244]     Train net output #0: loss1 = 0.254771 (* 0.5 = 0.127385 loss)
I0814 22:54:20.984982 10672 solver.cpp:244]     Train net output #1: loss2 = 0.49628 (* 0.5 = 0.24814 loss)
I0814 22:54:20.984995 10672 sgd_solver.cpp:106] Iteration 1900, lr = 0.000194637
I0814 22:54:26.494452 10672 solver.cpp:228] Iteration 1920, loss = 0.355697
I0814 22:54:26.494513 10672 solver.cpp:244]     Train net output #0: loss1 = 0.187094 (* 0.5 = 0.0935471 loss)
I0814 22:54:26.494527 10672 solver.cpp:244]     Train net output #1: loss2 = 0.5243 (* 0.5 = 0.26215 loss)
I0814 22:54:26.494540 10672 sgd_solver.cpp:106] Iteration 1920, lr = 0.000193122
I0814 22:54:32.010380 10672 solver.cpp:228] Iteration 1940, loss = 0.341199
I0814 22:54:32.010438 10672 solver.cpp:244]     Train net output #0: loss1 = 0.235651 (* 0.5 = 0.117826 loss)
I0814 22:54:32.010453 10672 solver.cpp:244]     Train net output #1: loss2 = 0.446747 (* 0.5 = 0.223374 loss)
I0814 22:54:32.010468 10672 sgd_solver.cpp:106] Iteration 1940, lr = 0.000191635
I0814 22:54:37.521742 10672 solver.cpp:228] Iteration 1960, loss = 0.525736
I0814 22:54:37.521868 10672 solver.cpp:244]     Train net output #0: loss1 = 0.516532 (* 0.5 = 0.258266 loss)
I0814 22:54:37.521885 10672 solver.cpp:244]     Train net output #1: loss2 = 0.53494 (* 0.5 = 0.26747 loss)
I0814 22:54:37.521899 10672 sgd_solver.cpp:106] Iteration 1960, lr = 0.000190174
I0814 22:54:43.034380 10672 solver.cpp:228] Iteration 1980, loss = 0.419457
I0814 22:54:43.034440 10672 solver.cpp:244]     Train net output #0: loss1 = 0.231727 (* 0.5 = 0.115863 loss)
I0814 22:54:43.034457 10672 solver.cpp:244]     Train net output #1: loss2 = 0.607188 (* 0.5 = 0.303594 loss)
I0814 22:54:43.034471 10672 sgd_solver.cpp:106] Iteration 1980, lr = 0.000188738
I0814 22:54:48.269459 10672 solver.cpp:337] Iteration 2000, Testing net (#0)
I0814 22:55:51.506796 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.678422
I0814 22:55:51.506942 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.879391
I0814 22:55:51.506963 10672 solver.cpp:404]     Test net output #2: loss1 = 0.343333 (* 0.5 = 0.171667 loss)
I0814 22:55:51.506976 10672 solver.cpp:404]     Test net output #3: loss2 = 0.611788 (* 0.5 = 0.305894 loss)
I0814 22:55:51.591006 10672 solver.cpp:228] Iteration 2000, loss = 0.340425
I0814 22:55:51.591058 10672 solver.cpp:244]     Train net output #0: loss1 = 0.216339 (* 0.5 = 0.108169 loss)
I0814 22:55:51.591073 10672 solver.cpp:244]     Train net output #1: loss2 = 0.464511 (* 0.5 = 0.232255 loss)
I0814 22:55:51.591086 10672 sgd_solver.cpp:106] Iteration 2000, lr = 0.000187328
I0814 22:55:57.098707 10672 solver.cpp:228] Iteration 2020, loss = 0.376093
I0814 22:55:57.098765 10672 solver.cpp:244]     Train net output #0: loss1 = 0.235744 (* 0.5 = 0.117872 loss)
I0814 22:55:57.098781 10672 solver.cpp:244]     Train net output #1: loss2 = 0.516442 (* 0.5 = 0.258221 loss)
I0814 22:55:57.098794 10672 sgd_solver.cpp:106] Iteration 2020, lr = 0.000185942
I0814 22:56:02.610712 10672 solver.cpp:228] Iteration 2040, loss = 0.398159
I0814 22:56:02.610774 10672 solver.cpp:244]     Train net output #0: loss1 = 0.288402 (* 0.5 = 0.144201 loss)
I0814 22:56:02.610792 10672 solver.cpp:244]     Train net output #1: loss2 = 0.507917 (* 0.5 = 0.253958 loss)
I0814 22:56:02.610807 10672 sgd_solver.cpp:106] Iteration 2040, lr = 0.00018458
I0814 22:56:08.121273 10672 solver.cpp:228] Iteration 2060, loss = 0.381318
I0814 22:56:08.121332 10672 solver.cpp:244]     Train net output #0: loss1 = 0.259377 (* 0.5 = 0.129688 loss)
I0814 22:56:08.121348 10672 solver.cpp:244]     Train net output #1: loss2 = 0.50326 (* 0.5 = 0.25163 loss)
I0814 22:56:08.121362 10672 sgd_solver.cpp:106] Iteration 2060, lr = 0.000183241
I0814 22:56:13.632199 10672 solver.cpp:228] Iteration 2080, loss = 0.379247
I0814 22:56:13.632258 10672 solver.cpp:244]     Train net output #0: loss1 = 0.204122 (* 0.5 = 0.102061 loss)
I0814 22:56:13.632274 10672 solver.cpp:244]     Train net output #1: loss2 = 0.554373 (* 0.5 = 0.277186 loss)
I0814 22:56:13.632287 10672 sgd_solver.cpp:106] Iteration 2080, lr = 0.000181924
I0814 22:56:19.141953 10672 solver.cpp:228] Iteration 2100, loss = 0.373497
I0814 22:56:19.142015 10672 solver.cpp:244]     Train net output #0: loss1 = 0.246619 (* 0.5 = 0.123309 loss)
I0814 22:56:19.142030 10672 solver.cpp:244]     Train net output #1: loss2 = 0.500374 (* 0.5 = 0.250187 loss)
I0814 22:56:19.142045 10672 sgd_solver.cpp:106] Iteration 2100, lr = 0.000180629
I0814 22:56:24.648201 10672 solver.cpp:228] Iteration 2120, loss = 0.390454
I0814 22:56:24.648355 10672 solver.cpp:244]     Train net output #0: loss1 = 0.238571 (* 0.5 = 0.119286 loss)
I0814 22:56:24.648378 10672 solver.cpp:244]     Train net output #1: loss2 = 0.542337 (* 0.5 = 0.271169 loss)
I0814 22:56:24.648396 10672 sgd_solver.cpp:106] Iteration 2120, lr = 0.000179356
I0814 22:56:30.157596 10672 solver.cpp:228] Iteration 2140, loss = 0.354237
I0814 22:56:30.157650 10672 solver.cpp:244]     Train net output #0: loss1 = 0.233758 (* 0.5 = 0.116879 loss)
I0814 22:56:30.157665 10672 solver.cpp:244]     Train net output #1: loss2 = 0.474717 (* 0.5 = 0.237359 loss)
I0814 22:56:30.157680 10672 sgd_solver.cpp:106] Iteration 2140, lr = 0.000178103
I0814 22:56:35.672358 10672 solver.cpp:228] Iteration 2160, loss = 0.428631
I0814 22:56:35.672412 10672 solver.cpp:244]     Train net output #0: loss1 = 0.23655 (* 0.5 = 0.118275 loss)
I0814 22:56:35.672427 10672 solver.cpp:244]     Train net output #1: loss2 = 0.620711 (* 0.5 = 0.310355 loss)
I0814 22:56:35.672441 10672 sgd_solver.cpp:106] Iteration 2160, lr = 0.00017687
I0814 22:56:41.183158 10672 solver.cpp:228] Iteration 2180, loss = 0.360329
I0814 22:56:41.183218 10672 solver.cpp:244]     Train net output #0: loss1 = 0.221393 (* 0.5 = 0.110696 loss)
I0814 22:56:41.183234 10672 solver.cpp:244]     Train net output #1: loss2 = 0.499265 (* 0.5 = 0.249632 loss)
I0814 22:56:41.183248 10672 sgd_solver.cpp:106] Iteration 2180, lr = 0.000175658
I0814 22:56:46.695972 10672 solver.cpp:228] Iteration 2200, loss = 0.348075
I0814 22:56:46.696056 10672 solver.cpp:244]     Train net output #0: loss1 = 0.277548 (* 0.5 = 0.138774 loss)
I0814 22:56:46.696085 10672 solver.cpp:244]     Train net output #1: loss2 = 0.418602 (* 0.5 = 0.209301 loss)
I0814 22:56:46.696116 10672 sgd_solver.cpp:106] Iteration 2200, lr = 0.000174464
I0814 22:56:52.210799 10672 solver.cpp:228] Iteration 2220, loss = 0.442386
I0814 22:56:52.210858 10672 solver.cpp:244]     Train net output #0: loss1 = 0.294074 (* 0.5 = 0.147037 loss)
I0814 22:56:52.210875 10672 solver.cpp:244]     Train net output #1: loss2 = 0.590698 (* 0.5 = 0.295349 loss)
I0814 22:56:52.210887 10672 sgd_solver.cpp:106] Iteration 2220, lr = 0.000173289
I0814 22:56:57.721338 10672 solver.cpp:228] Iteration 2240, loss = 0.368917
I0814 22:56:57.721482 10672 solver.cpp:244]     Train net output #0: loss1 = 0.288335 (* 0.5 = 0.144167 loss)
I0814 22:56:57.721498 10672 solver.cpp:244]     Train net output #1: loss2 = 0.449499 (* 0.5 = 0.22475 loss)
I0814 22:56:57.721513 10672 sgd_solver.cpp:106] Iteration 2240, lr = 0.000172133
I0814 22:57:03.233391 10672 solver.cpp:228] Iteration 2260, loss = 0.376247
I0814 22:57:03.233453 10672 solver.cpp:244]     Train net output #0: loss1 = 0.285836 (* 0.5 = 0.142918 loss)
I0814 22:57:03.233469 10672 solver.cpp:244]     Train net output #1: loss2 = 0.466657 (* 0.5 = 0.233329 loss)
I0814 22:57:03.233482 10672 sgd_solver.cpp:106] Iteration 2260, lr = 0.000170994
I0814 22:57:08.746649 10672 solver.cpp:228] Iteration 2280, loss = 0.357102
I0814 22:57:08.746709 10672 solver.cpp:244]     Train net output #0: loss1 = 0.25541 (* 0.5 = 0.127705 loss)
I0814 22:57:08.746726 10672 solver.cpp:244]     Train net output #1: loss2 = 0.458795 (* 0.5 = 0.229398 loss)
I0814 22:57:08.746738 10672 sgd_solver.cpp:106] Iteration 2280, lr = 0.000169873
I0814 22:57:14.252734 10672 solver.cpp:228] Iteration 2300, loss = 0.466336
I0814 22:57:14.252799 10672 solver.cpp:244]     Train net output #0: loss1 = 0.315511 (* 0.5 = 0.157756 loss)
I0814 22:57:14.252815 10672 solver.cpp:244]     Train net output #1: loss2 = 0.617161 (* 0.5 = 0.308581 loss)
I0814 22:57:14.252832 10672 sgd_solver.cpp:106] Iteration 2300, lr = 0.000168768
I0814 22:57:19.988570 10672 solver.cpp:228] Iteration 2320, loss = 0.327293
I0814 22:57:19.988631 10672 solver.cpp:244]     Train net output #0: loss1 = 0.193803 (* 0.5 = 0.0969013 loss)
I0814 22:57:19.988648 10672 solver.cpp:244]     Train net output #1: loss2 = 0.460784 (* 0.5 = 0.230392 loss)
I0814 22:57:19.988662 10672 sgd_solver.cpp:106] Iteration 2320, lr = 0.000167681
I0814 22:57:25.765290 10672 solver.cpp:228] Iteration 2340, loss = 0.370231
I0814 22:57:25.765353 10672 solver.cpp:244]     Train net output #0: loss1 = 0.272075 (* 0.5 = 0.136038 loss)
I0814 22:57:25.765369 10672 solver.cpp:244]     Train net output #1: loss2 = 0.468386 (* 0.5 = 0.234193 loss)
I0814 22:57:25.765383 10672 sgd_solver.cpp:106] Iteration 2340, lr = 0.000166609
I0814 22:57:31.307268 10672 solver.cpp:228] Iteration 2360, loss = 0.367205
I0814 22:57:31.307423 10672 solver.cpp:244]     Train net output #0: loss1 = 0.28677 (* 0.5 = 0.143385 loss)
I0814 22:57:31.307448 10672 solver.cpp:244]     Train net output #1: loss2 = 0.447639 (* 0.5 = 0.22382 loss)
I0814 22:57:31.307464 10672 sgd_solver.cpp:106] Iteration 2360, lr = 0.000165554
I0814 22:57:36.824733 10672 solver.cpp:228] Iteration 2380, loss = 0.362868
I0814 22:57:36.824792 10672 solver.cpp:244]     Train net output #0: loss1 = 0.195795 (* 0.5 = 0.0978977 loss)
I0814 22:57:36.824808 10672 solver.cpp:244]     Train net output #1: loss2 = 0.529941 (* 0.5 = 0.264971 loss)
I0814 22:57:36.824822 10672 sgd_solver.cpp:106] Iteration 2380, lr = 0.000164514
I0814 22:57:42.354009 10672 solver.cpp:228] Iteration 2400, loss = 0.369842
I0814 22:57:42.354068 10672 solver.cpp:244]     Train net output #0: loss1 = 0.278483 (* 0.5 = 0.139241 loss)
I0814 22:57:42.354084 10672 solver.cpp:244]     Train net output #1: loss2 = 0.4612 (* 0.5 = 0.2306 loss)
I0814 22:57:42.354099 10672 sgd_solver.cpp:106] Iteration 2400, lr = 0.000163488
I0814 22:57:47.878515 10672 solver.cpp:228] Iteration 2420, loss = 0.396471
I0814 22:57:47.878582 10672 solver.cpp:244]     Train net output #0: loss1 = 0.271235 (* 0.5 = 0.135618 loss)
I0814 22:57:47.878598 10672 solver.cpp:244]     Train net output #1: loss2 = 0.521708 (* 0.5 = 0.260854 loss)
I0814 22:57:47.878612 10672 sgd_solver.cpp:106] Iteration 2420, lr = 0.000162478
I0814 22:57:53.401255 10672 solver.cpp:228] Iteration 2440, loss = 0.387331
I0814 22:57:53.401315 10672 solver.cpp:244]     Train net output #0: loss1 = 0.263026 (* 0.5 = 0.131513 loss)
I0814 22:57:53.401331 10672 solver.cpp:244]     Train net output #1: loss2 = 0.511636 (* 0.5 = 0.255818 loss)
I0814 22:57:53.401345 10672 sgd_solver.cpp:106] Iteration 2440, lr = 0.000161482
I0814 22:57:58.929807 10672 solver.cpp:228] Iteration 2460, loss = 0.398308
I0814 22:57:58.929865 10672 solver.cpp:244]     Train net output #0: loss1 = 0.264507 (* 0.5 = 0.132253 loss)
I0814 22:57:58.929882 10672 solver.cpp:244]     Train net output #1: loss2 = 0.53211 (* 0.5 = 0.266055 loss)
I0814 22:57:58.929895 10672 sgd_solver.cpp:106] Iteration 2460, lr = 0.000160501
I0814 22:58:04.454419 10672 solver.cpp:228] Iteration 2480, loss = 0.320574
I0814 22:58:04.454579 10672 solver.cpp:244]     Train net output #0: loss1 = 0.193148 (* 0.5 = 0.0965742 loss)
I0814 22:58:04.454598 10672 solver.cpp:244]     Train net output #1: loss2 = 0.447999 (* 0.5 = 0.223999 loss)
I0814 22:58:04.454612 10672 sgd_solver.cpp:106] Iteration 2480, lr = 0.000159533
I0814 22:58:09.976670 10672 solver.cpp:228] Iteration 2500, loss = 0.417276
I0814 22:58:09.976728 10672 solver.cpp:244]     Train net output #0: loss1 = 0.294975 (* 0.5 = 0.147487 loss)
I0814 22:58:09.976744 10672 solver.cpp:244]     Train net output #1: loss2 = 0.539577 (* 0.5 = 0.269789 loss)
I0814 22:58:09.976758 10672 sgd_solver.cpp:106] Iteration 2500, lr = 0.000158579
I0814 22:58:15.500603 10672 solver.cpp:228] Iteration 2520, loss = 0.420228
I0814 22:58:15.500660 10672 solver.cpp:244]     Train net output #0: loss1 = 0.301006 (* 0.5 = 0.150503 loss)
I0814 22:58:15.500676 10672 solver.cpp:244]     Train net output #1: loss2 = 0.539451 (* 0.5 = 0.269725 loss)
I0814 22:58:15.500690 10672 sgd_solver.cpp:106] Iteration 2520, lr = 0.000157638
I0814 22:58:21.025403 10672 solver.cpp:228] Iteration 2540, loss = 0.311923
I0814 22:58:21.025465 10672 solver.cpp:244]     Train net output #0: loss1 = 0.19696 (* 0.5 = 0.0984799 loss)
I0814 22:58:21.025480 10672 solver.cpp:244]     Train net output #1: loss2 = 0.426887 (* 0.5 = 0.213444 loss)
I0814 22:58:21.025495 10672 sgd_solver.cpp:106] Iteration 2540, lr = 0.000156709
I0814 22:58:26.549629 10672 solver.cpp:228] Iteration 2560, loss = 0.385905
I0814 22:58:26.549688 10672 solver.cpp:244]     Train net output #0: loss1 = 0.2881 (* 0.5 = 0.14405 loss)
I0814 22:58:26.549705 10672 solver.cpp:244]     Train net output #1: loss2 = 0.48371 (* 0.5 = 0.241855 loss)
I0814 22:58:26.549717 10672 sgd_solver.cpp:106] Iteration 2560, lr = 0.000155794
I0814 22:58:32.075881 10672 solver.cpp:228] Iteration 2580, loss = 0.353925
I0814 22:58:32.075938 10672 solver.cpp:244]     Train net output #0: loss1 = 0.257233 (* 0.5 = 0.128616 loss)
I0814 22:58:32.075955 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450617 (* 0.5 = 0.225309 loss)
I0814 22:58:32.075969 10672 sgd_solver.cpp:106] Iteration 2580, lr = 0.000154891
I0814 22:58:37.598095 10672 solver.cpp:228] Iteration 2600, loss = 0.372122
I0814 22:58:37.598413 10672 solver.cpp:244]     Train net output #0: loss1 = 0.326147 (* 0.5 = 0.163074 loss)
I0814 22:58:37.598438 10672 solver.cpp:244]     Train net output #1: loss2 = 0.418096 (* 0.5 = 0.209048 loss)
I0814 22:58:37.598455 10672 sgd_solver.cpp:106] Iteration 2600, lr = 0.000154
I0814 22:58:43.120412 10672 solver.cpp:228] Iteration 2620, loss = 0.393956
I0814 22:58:43.120472 10672 solver.cpp:244]     Train net output #0: loss1 = 0.35206 (* 0.5 = 0.17603 loss)
I0814 22:58:43.120488 10672 solver.cpp:244]     Train net output #1: loss2 = 0.435851 (* 0.5 = 0.217926 loss)
I0814 22:58:43.120501 10672 sgd_solver.cpp:106] Iteration 2620, lr = 0.00015312
I0814 22:58:48.643162 10672 solver.cpp:228] Iteration 2640, loss = 0.346585
I0814 22:58:48.643219 10672 solver.cpp:244]     Train net output #0: loss1 = 0.201829 (* 0.5 = 0.100914 loss)
I0814 22:58:48.643234 10672 solver.cpp:244]     Train net output #1: loss2 = 0.491341 (* 0.5 = 0.24567 loss)
I0814 22:58:48.643249 10672 sgd_solver.cpp:106] Iteration 2640, lr = 0.000152253
I0814 22:58:54.165076 10672 solver.cpp:228] Iteration 2660, loss = 0.392618
I0814 22:58:54.165137 10672 solver.cpp:244]     Train net output #0: loss1 = 0.314839 (* 0.5 = 0.15742 loss)
I0814 22:58:54.165153 10672 solver.cpp:244]     Train net output #1: loss2 = 0.470396 (* 0.5 = 0.235198 loss)
I0814 22:58:54.165168 10672 sgd_solver.cpp:106] Iteration 2660, lr = 0.000151397
I0814 22:58:59.685320 10672 solver.cpp:228] Iteration 2680, loss = 0.377539
I0814 22:58:59.685376 10672 solver.cpp:244]     Train net output #0: loss1 = 0.243878 (* 0.5 = 0.121939 loss)
I0814 22:58:59.685392 10672 solver.cpp:244]     Train net output #1: loss2 = 0.511199 (* 0.5 = 0.2556 loss)
I0814 22:58:59.685405 10672 sgd_solver.cpp:106] Iteration 2680, lr = 0.000150552
I0814 22:59:05.218197 10672 solver.cpp:228] Iteration 2700, loss = 0.414994
I0814 22:59:05.218256 10672 solver.cpp:244]     Train net output #0: loss1 = 0.288273 (* 0.5 = 0.144137 loss)
I0814 22:59:05.218272 10672 solver.cpp:244]     Train net output #1: loss2 = 0.541715 (* 0.5 = 0.270857 loss)
I0814 22:59:05.218286 10672 sgd_solver.cpp:106] Iteration 2700, lr = 0.000149718
I0814 22:59:10.740680 10672 solver.cpp:228] Iteration 2720, loss = 0.441366
I0814 22:59:10.740835 10672 solver.cpp:244]     Train net output #0: loss1 = 0.300991 (* 0.5 = 0.150495 loss)
I0814 22:59:10.740854 10672 solver.cpp:244]     Train net output #1: loss2 = 0.581742 (* 0.5 = 0.290871 loss)
I0814 22:59:10.740866 10672 sgd_solver.cpp:106] Iteration 2720, lr = 0.000148894
I0814 22:59:16.261282 10672 solver.cpp:228] Iteration 2740, loss = 0.277891
I0814 22:59:16.261339 10672 solver.cpp:244]     Train net output #0: loss1 = 0.236517 (* 0.5 = 0.118258 loss)
I0814 22:59:16.261354 10672 solver.cpp:244]     Train net output #1: loss2 = 0.319265 (* 0.5 = 0.159633 loss)
I0814 22:59:16.261368 10672 sgd_solver.cpp:106] Iteration 2740, lr = 0.000148081
I0814 22:59:21.781146 10672 solver.cpp:228] Iteration 2760, loss = 0.343124
I0814 22:59:21.781205 10672 solver.cpp:244]     Train net output #0: loss1 = 0.205258 (* 0.5 = 0.102629 loss)
I0814 22:59:21.781221 10672 solver.cpp:244]     Train net output #1: loss2 = 0.480991 (* 0.5 = 0.240495 loss)
I0814 22:59:21.781235 10672 sgd_solver.cpp:106] Iteration 2760, lr = 0.000147279
I0814 22:59:27.305516 10672 solver.cpp:228] Iteration 2780, loss = 0.348017
I0814 22:59:27.305575 10672 solver.cpp:244]     Train net output #0: loss1 = 0.212134 (* 0.5 = 0.106067 loss)
I0814 22:59:27.305591 10672 solver.cpp:244]     Train net output #1: loss2 = 0.483899 (* 0.5 = 0.24195 loss)
I0814 22:59:27.305605 10672 sgd_solver.cpp:106] Iteration 2780, lr = 0.000146486
I0814 22:59:32.829916 10672 solver.cpp:228] Iteration 2800, loss = 0.344077
I0814 22:59:32.829974 10672 solver.cpp:244]     Train net output #0: loss1 = 0.244954 (* 0.5 = 0.122477 loss)
I0814 22:59:32.829990 10672 solver.cpp:244]     Train net output #1: loss2 = 0.443199 (* 0.5 = 0.2216 loss)
I0814 22:59:32.830004 10672 sgd_solver.cpp:106] Iteration 2800, lr = 0.000145704
I0814 22:59:38.352480 10672 solver.cpp:228] Iteration 2820, loss = 0.356131
I0814 22:59:38.352540 10672 solver.cpp:244]     Train net output #0: loss1 = 0.279405 (* 0.5 = 0.139703 loss)
I0814 22:59:38.352555 10672 solver.cpp:244]     Train net output #1: loss2 = 0.432857 (* 0.5 = 0.216428 loss)
I0814 22:59:38.352568 10672 sgd_solver.cpp:106] Iteration 2820, lr = 0.000144931
I0814 22:59:43.874078 10672 solver.cpp:228] Iteration 2840, loss = 0.392846
I0814 22:59:43.874230 10672 solver.cpp:244]     Train net output #0: loss1 = 0.30123 (* 0.5 = 0.150615 loss)
I0814 22:59:43.874248 10672 solver.cpp:244]     Train net output #1: loss2 = 0.484462 (* 0.5 = 0.242231 loss)
I0814 22:59:43.874261 10672 sgd_solver.cpp:106] Iteration 2840, lr = 0.000144167
I0814 22:59:49.393584 10672 solver.cpp:228] Iteration 2860, loss = 0.344808
I0814 22:59:49.393645 10672 solver.cpp:244]     Train net output #0: loss1 = 0.178202 (* 0.5 = 0.0891009 loss)
I0814 22:59:49.393662 10672 solver.cpp:244]     Train net output #1: loss2 = 0.511414 (* 0.5 = 0.255707 loss)
I0814 22:59:49.393676 10672 sgd_solver.cpp:106] Iteration 2860, lr = 0.000143413
I0814 22:59:54.914907 10672 solver.cpp:228] Iteration 2880, loss = 0.474221
I0814 22:59:54.914966 10672 solver.cpp:244]     Train net output #0: loss1 = 0.372735 (* 0.5 = 0.186367 loss)
I0814 22:59:54.914983 10672 solver.cpp:244]     Train net output #1: loss2 = 0.575707 (* 0.5 = 0.287853 loss)
I0814 22:59:54.914995 10672 sgd_solver.cpp:106] Iteration 2880, lr = 0.000142668
I0814 23:00:00.444298 10672 solver.cpp:228] Iteration 2900, loss = 0.368278
I0814 23:00:00.444357 10672 solver.cpp:244]     Train net output #0: loss1 = 0.232249 (* 0.5 = 0.116124 loss)
I0814 23:00:00.444372 10672 solver.cpp:244]     Train net output #1: loss2 = 0.504307 (* 0.5 = 0.252154 loss)
I0814 23:00:00.444386 10672 sgd_solver.cpp:106] Iteration 2900, lr = 0.000141932
I0814 23:00:05.968209 10672 solver.cpp:228] Iteration 2920, loss = 0.43183
I0814 23:00:05.968266 10672 solver.cpp:244]     Train net output #0: loss1 = 0.359242 (* 0.5 = 0.179621 loss)
I0814 23:00:05.968281 10672 solver.cpp:244]     Train net output #1: loss2 = 0.504417 (* 0.5 = 0.252208 loss)
I0814 23:00:05.968294 10672 sgd_solver.cpp:106] Iteration 2920, lr = 0.000141205
I0814 23:00:11.486946 10672 solver.cpp:228] Iteration 2940, loss = 0.373977
I0814 23:00:11.487007 10672 solver.cpp:244]     Train net output #0: loss1 = 0.282078 (* 0.5 = 0.141039 loss)
I0814 23:00:11.487022 10672 solver.cpp:244]     Train net output #1: loss2 = 0.465875 (* 0.5 = 0.232938 loss)
I0814 23:00:11.487035 10672 sgd_solver.cpp:106] Iteration 2940, lr = 0.000140486
I0814 23:00:17.010917 10672 solver.cpp:228] Iteration 2960, loss = 0.415607
I0814 23:00:17.011132 10672 solver.cpp:244]     Train net output #0: loss1 = 0.314371 (* 0.5 = 0.157185 loss)
I0814 23:00:17.011163 10672 solver.cpp:244]     Train net output #1: loss2 = 0.516842 (* 0.5 = 0.258421 loss)
I0814 23:00:17.011183 10672 sgd_solver.cpp:106] Iteration 2960, lr = 0.000139776
I0814 23:00:22.533211 10672 solver.cpp:228] Iteration 2980, loss = 0.386676
I0814 23:00:22.533268 10672 solver.cpp:244]     Train net output #0: loss1 = 0.266786 (* 0.5 = 0.133393 loss)
I0814 23:00:22.533284 10672 solver.cpp:244]     Train net output #1: loss2 = 0.506565 (* 0.5 = 0.253282 loss)
I0814 23:00:22.533298 10672 sgd_solver.cpp:106] Iteration 2980, lr = 0.000139074
I0814 23:00:27.779490 10672 solver.cpp:337] Iteration 3000, Testing net (#0)
I0814 23:01:31.003190 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.690016
I0814 23:01:31.003298 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.892266
I0814 23:01:31.003316 10672 solver.cpp:404]     Test net output #2: loss1 = 0.317126 (* 0.5 = 0.158563 loss)
I0814 23:01:31.003329 10672 solver.cpp:404]     Test net output #3: loss2 = 0.603376 (* 0.5 = 0.301688 loss)
I0814 23:01:31.089625 10672 solver.cpp:228] Iteration 3000, loss = 0.360484
I0814 23:01:31.089676 10672 solver.cpp:244]     Train net output #0: loss1 = 0.210008 (* 0.5 = 0.105004 loss)
I0814 23:01:31.089692 10672 solver.cpp:244]     Train net output #1: loss2 = 0.51096 (* 0.5 = 0.25548 loss)
I0814 23:01:31.089706 10672 sgd_solver.cpp:106] Iteration 3000, lr = 0.000138381
I0814 23:01:36.608970 10672 solver.cpp:228] Iteration 3020, loss = 0.271753
I0814 23:01:36.609026 10672 solver.cpp:244]     Train net output #0: loss1 = 0.121938 (* 0.5 = 0.0609688 loss)
I0814 23:01:36.609042 10672 solver.cpp:244]     Train net output #1: loss2 = 0.421568 (* 0.5 = 0.210784 loss)
I0814 23:01:36.609055 10672 sgd_solver.cpp:106] Iteration 3020, lr = 0.000137695
I0814 23:01:42.132247 10672 solver.cpp:228] Iteration 3040, loss = 0.365275
I0814 23:01:42.132304 10672 solver.cpp:244]     Train net output #0: loss1 = 0.224186 (* 0.5 = 0.112093 loss)
I0814 23:01:42.132320 10672 solver.cpp:244]     Train net output #1: loss2 = 0.506364 (* 0.5 = 0.253182 loss)
I0814 23:01:42.132334 10672 sgd_solver.cpp:106] Iteration 3040, lr = 0.000137017
I0814 23:01:47.659322 10672 solver.cpp:228] Iteration 3060, loss = 0.347795
I0814 23:01:47.659382 10672 solver.cpp:244]     Train net output #0: loss1 = 0.242384 (* 0.5 = 0.121192 loss)
I0814 23:01:47.659399 10672 solver.cpp:244]     Train net output #1: loss2 = 0.453206 (* 0.5 = 0.226603 loss)
I0814 23:01:47.659413 10672 sgd_solver.cpp:106] Iteration 3060, lr = 0.000136347
I0814 23:01:53.185151 10672 solver.cpp:228] Iteration 3080, loss = 0.355403
I0814 23:01:53.185205 10672 solver.cpp:244]     Train net output #0: loss1 = 0.250388 (* 0.5 = 0.125194 loss)
I0814 23:01:53.185221 10672 solver.cpp:244]     Train net output #1: loss2 = 0.460418 (* 0.5 = 0.230209 loss)
I0814 23:01:53.185235 10672 sgd_solver.cpp:106] Iteration 3080, lr = 0.000135685
I0814 23:01:58.711657 10672 solver.cpp:228] Iteration 3100, loss = 0.310065
I0814 23:01:58.711714 10672 solver.cpp:244]     Train net output #0: loss1 = 0.207757 (* 0.5 = 0.103878 loss)
I0814 23:01:58.711730 10672 solver.cpp:244]     Train net output #1: loss2 = 0.412372 (* 0.5 = 0.206186 loss)
I0814 23:01:58.711743 10672 sgd_solver.cpp:106] Iteration 3100, lr = 0.00013503
I0814 23:02:04.238862 10672 solver.cpp:228] Iteration 3120, loss = 0.369523
I0814 23:02:04.239015 10672 solver.cpp:244]     Train net output #0: loss1 = 0.255638 (* 0.5 = 0.127819 loss)
I0814 23:02:04.239032 10672 solver.cpp:244]     Train net output #1: loss2 = 0.483409 (* 0.5 = 0.241705 loss)
I0814 23:02:04.239047 10672 sgd_solver.cpp:106] Iteration 3120, lr = 0.000134382
I0814 23:02:09.760499 10672 solver.cpp:228] Iteration 3140, loss = 0.35553
I0814 23:02:09.760557 10672 solver.cpp:244]     Train net output #0: loss1 = 0.242341 (* 0.5 = 0.121171 loss)
I0814 23:02:09.760573 10672 solver.cpp:244]     Train net output #1: loss2 = 0.468719 (* 0.5 = 0.234359 loss)
I0814 23:02:09.760588 10672 sgd_solver.cpp:106] Iteration 3140, lr = 0.000133742
I0814 23:02:15.286020 10672 solver.cpp:228] Iteration 3160, loss = 0.327163
I0814 23:02:15.286079 10672 solver.cpp:244]     Train net output #0: loss1 = 0.209794 (* 0.5 = 0.104897 loss)
I0814 23:02:15.286095 10672 solver.cpp:244]     Train net output #1: loss2 = 0.444533 (* 0.5 = 0.222266 loss)
I0814 23:02:15.286108 10672 sgd_solver.cpp:106] Iteration 3160, lr = 0.000133108
I0814 23:02:20.806380 10672 solver.cpp:228] Iteration 3180, loss = 0.352002
I0814 23:02:20.806439 10672 solver.cpp:244]     Train net output #0: loss1 = 0.195116 (* 0.5 = 0.0975581 loss)
I0814 23:02:20.806455 10672 solver.cpp:244]     Train net output #1: loss2 = 0.508887 (* 0.5 = 0.254443 loss)
I0814 23:02:20.806469 10672 sgd_solver.cpp:106] Iteration 3180, lr = 0.000132482
I0814 23:02:26.326416 10672 solver.cpp:228] Iteration 3200, loss = 0.299429
I0814 23:02:26.326472 10672 solver.cpp:244]     Train net output #0: loss1 = 0.208595 (* 0.5 = 0.104298 loss)
I0814 23:02:26.326488 10672 solver.cpp:244]     Train net output #1: loss2 = 0.390263 (* 0.5 = 0.195132 loss)
I0814 23:02:26.326503 10672 sgd_solver.cpp:106] Iteration 3200, lr = 0.000131862
I0814 23:02:31.848919 10672 solver.cpp:228] Iteration 3220, loss = 0.351221
I0814 23:02:31.848978 10672 solver.cpp:244]     Train net output #0: loss1 = 0.170325 (* 0.5 = 0.0851627 loss)
I0814 23:02:31.848994 10672 solver.cpp:244]     Train net output #1: loss2 = 0.532116 (* 0.5 = 0.266058 loss)
I0814 23:02:31.849007 10672 sgd_solver.cpp:106] Iteration 3220, lr = 0.00013125
I0814 23:02:37.367660 10672 solver.cpp:228] Iteration 3240, loss = 0.32986
I0814 23:02:37.367816 10672 solver.cpp:244]     Train net output #0: loss1 = 0.221314 (* 0.5 = 0.110657 loss)
I0814 23:02:37.367835 10672 solver.cpp:244]     Train net output #1: loss2 = 0.438405 (* 0.5 = 0.219203 loss)
I0814 23:02:37.367848 10672 sgd_solver.cpp:106] Iteration 3240, lr = 0.000130643
I0814 23:02:42.897634 10672 solver.cpp:228] Iteration 3260, loss = 0.338061
I0814 23:02:42.897691 10672 solver.cpp:244]     Train net output #0: loss1 = 0.186972 (* 0.5 = 0.0934862 loss)
I0814 23:02:42.897706 10672 solver.cpp:244]     Train net output #1: loss2 = 0.48915 (* 0.5 = 0.244575 loss)
I0814 23:02:42.897719 10672 sgd_solver.cpp:106] Iteration 3260, lr = 0.000130044
I0814 23:02:48.417222 10672 solver.cpp:228] Iteration 3280, loss = 0.310035
I0814 23:02:48.417280 10672 solver.cpp:244]     Train net output #0: loss1 = 0.169791 (* 0.5 = 0.0848953 loss)
I0814 23:02:48.417297 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450278 (* 0.5 = 0.225139 loss)
I0814 23:02:48.417310 10672 sgd_solver.cpp:106] Iteration 3280, lr = 0.00012945
I0814 23:02:53.937849 10672 solver.cpp:228] Iteration 3300, loss = 0.358966
I0814 23:02:53.937906 10672 solver.cpp:244]     Train net output #0: loss1 = 0.186751 (* 0.5 = 0.0933753 loss)
I0814 23:02:53.937922 10672 solver.cpp:244]     Train net output #1: loss2 = 0.531182 (* 0.5 = 0.265591 loss)
I0814 23:02:53.937937 10672 sgd_solver.cpp:106] Iteration 3300, lr = 0.000128863
I0814 23:02:59.460520 10672 solver.cpp:228] Iteration 3320, loss = 0.271269
I0814 23:02:59.460575 10672 solver.cpp:244]     Train net output #0: loss1 = 0.180469 (* 0.5 = 0.0902345 loss)
I0814 23:02:59.460590 10672 solver.cpp:244]     Train net output #1: loss2 = 0.362069 (* 0.5 = 0.181035 loss)
I0814 23:02:59.460604 10672 sgd_solver.cpp:106] Iteration 3320, lr = 0.000128282
I0814 23:03:04.991209 10672 solver.cpp:228] Iteration 3340, loss = 0.324683
I0814 23:03:04.991268 10672 solver.cpp:244]     Train net output #0: loss1 = 0.212663 (* 0.5 = 0.106332 loss)
I0814 23:03:04.991284 10672 solver.cpp:244]     Train net output #1: loss2 = 0.436702 (* 0.5 = 0.218351 loss)
I0814 23:03:04.991297 10672 sgd_solver.cpp:106] Iteration 3340, lr = 0.000127707
I0814 23:03:10.515031 10672 solver.cpp:228] Iteration 3360, loss = 0.37281
I0814 23:03:10.515154 10672 solver.cpp:244]     Train net output #0: loss1 = 0.275712 (* 0.5 = 0.137856 loss)
I0814 23:03:10.515172 10672 solver.cpp:244]     Train net output #1: loss2 = 0.469908 (* 0.5 = 0.234954 loss)
I0814 23:03:10.515185 10672 sgd_solver.cpp:106] Iteration 3360, lr = 0.000127139
I0814 23:03:16.032070 10672 solver.cpp:228] Iteration 3380, loss = 0.424834
I0814 23:03:16.032127 10672 solver.cpp:244]     Train net output #0: loss1 = 0.326531 (* 0.5 = 0.163265 loss)
I0814 23:03:16.032143 10672 solver.cpp:244]     Train net output #1: loss2 = 0.523138 (* 0.5 = 0.261569 loss)
I0814 23:03:16.032156 10672 sgd_solver.cpp:106] Iteration 3380, lr = 0.000126576
I0814 23:03:21.614892 10672 solver.cpp:228] Iteration 3400, loss = 0.330495
I0814 23:03:21.614954 10672 solver.cpp:244]     Train net output #0: loss1 = 0.189082 (* 0.5 = 0.0945412 loss)
I0814 23:03:21.614969 10672 solver.cpp:244]     Train net output #1: loss2 = 0.471907 (* 0.5 = 0.235954 loss)
I0814 23:03:21.614984 10672 sgd_solver.cpp:106] Iteration 3400, lr = 0.000126018
I0814 23:03:27.284780 10672 solver.cpp:228] Iteration 3420, loss = 0.399242
I0814 23:03:27.284837 10672 solver.cpp:244]     Train net output #0: loss1 = 0.290674 (* 0.5 = 0.145337 loss)
I0814 23:03:27.284853 10672 solver.cpp:244]     Train net output #1: loss2 = 0.50781 (* 0.5 = 0.253905 loss)
I0814 23:03:27.284867 10672 sgd_solver.cpp:106] Iteration 3420, lr = 0.000125467
I0814 23:03:32.837986 10672 solver.cpp:228] Iteration 3440, loss = 0.35855
I0814 23:03:32.838043 10672 solver.cpp:244]     Train net output #0: loss1 = 0.206563 (* 0.5 = 0.103281 loss)
I0814 23:03:32.838059 10672 solver.cpp:244]     Train net output #1: loss2 = 0.510537 (* 0.5 = 0.255269 loss)
I0814 23:03:32.838073 10672 sgd_solver.cpp:106] Iteration 3440, lr = 0.000124921
I0814 23:03:38.375219 10672 solver.cpp:228] Iteration 3460, loss = 0.37727
I0814 23:03:38.375274 10672 solver.cpp:244]     Train net output #0: loss1 = 0.221879 (* 0.5 = 0.110939 loss)
I0814 23:03:38.375290 10672 solver.cpp:244]     Train net output #1: loss2 = 0.532662 (* 0.5 = 0.266331 loss)
I0814 23:03:38.375303 10672 sgd_solver.cpp:106] Iteration 3460, lr = 0.000124381
I0814 23:03:43.872427 10672 solver.cpp:228] Iteration 3480, loss = 0.394047
I0814 23:03:43.872628 10672 solver.cpp:244]     Train net output #0: loss1 = 0.21753 (* 0.5 = 0.108765 loss)
I0814 23:03:43.872651 10672 solver.cpp:244]     Train net output #1: loss2 = 0.570564 (* 0.5 = 0.285282 loss)
I0814 23:03:43.872681 10672 sgd_solver.cpp:106] Iteration 3480, lr = 0.000123846
I0814 23:03:49.370769 10672 solver.cpp:228] Iteration 3500, loss = 0.375078
I0814 23:03:49.370826 10672 solver.cpp:244]     Train net output #0: loss1 = 0.297674 (* 0.5 = 0.148837 loss)
I0814 23:03:49.370841 10672 solver.cpp:244]     Train net output #1: loss2 = 0.452483 (* 0.5 = 0.226241 loss)
I0814 23:03:49.370854 10672 sgd_solver.cpp:106] Iteration 3500, lr = 0.000123316
I0814 23:03:54.867442 10672 solver.cpp:228] Iteration 3520, loss = 0.359337
I0814 23:03:54.867502 10672 solver.cpp:244]     Train net output #0: loss1 = 0.236885 (* 0.5 = 0.118442 loss)
I0814 23:03:54.867518 10672 solver.cpp:244]     Train net output #1: loss2 = 0.48179 (* 0.5 = 0.240895 loss)
I0814 23:03:54.867532 10672 sgd_solver.cpp:106] Iteration 3520, lr = 0.000122792
I0814 23:04:00.406921 10672 solver.cpp:228] Iteration 3540, loss = 0.330432
I0814 23:04:00.406978 10672 solver.cpp:244]     Train net output #0: loss1 = 0.226405 (* 0.5 = 0.113202 loss)
I0814 23:04:00.406994 10672 solver.cpp:244]     Train net output #1: loss2 = 0.434459 (* 0.5 = 0.21723 loss)
I0814 23:04:00.407007 10672 sgd_solver.cpp:106] Iteration 3540, lr = 0.000122272
I0814 23:04:05.932425 10672 solver.cpp:228] Iteration 3560, loss = 0.37572
I0814 23:04:05.932479 10672 solver.cpp:244]     Train net output #0: loss1 = 0.238764 (* 0.5 = 0.119382 loss)
I0814 23:04:05.932495 10672 solver.cpp:244]     Train net output #1: loss2 = 0.512676 (* 0.5 = 0.256338 loss)
I0814 23:04:05.932508 10672 sgd_solver.cpp:106] Iteration 3560, lr = 0.000121758
I0814 23:04:11.440682 10672 solver.cpp:228] Iteration 3580, loss = 0.374902
I0814 23:04:11.440742 10672 solver.cpp:244]     Train net output #0: loss1 = 0.221543 (* 0.5 = 0.110772 loss)
I0814 23:04:11.440757 10672 solver.cpp:244]     Train net output #1: loss2 = 0.528261 (* 0.5 = 0.26413 loss)
I0814 23:04:11.440771 10672 sgd_solver.cpp:106] Iteration 3580, lr = 0.000121249
I0814 23:04:16.947161 10672 solver.cpp:228] Iteration 3600, loss = 0.348367
I0814 23:04:16.947278 10672 solver.cpp:244]     Train net output #0: loss1 = 0.231559 (* 0.5 = 0.115779 loss)
I0814 23:04:16.947295 10672 solver.cpp:244]     Train net output #1: loss2 = 0.465176 (* 0.5 = 0.232588 loss)
I0814 23:04:16.947309 10672 sgd_solver.cpp:106] Iteration 3600, lr = 0.000120745
I0814 23:04:22.451378 10672 solver.cpp:228] Iteration 3620, loss = 0.441382
I0814 23:04:22.451431 10672 solver.cpp:244]     Train net output #0: loss1 = 0.290605 (* 0.5 = 0.145303 loss)
I0814 23:04:22.451447 10672 solver.cpp:244]     Train net output #1: loss2 = 0.592159 (* 0.5 = 0.296079 loss)
I0814 23:04:22.451460 10672 sgd_solver.cpp:106] Iteration 3620, lr = 0.000120246
I0814 23:04:27.961933 10672 solver.cpp:228] Iteration 3640, loss = 0.408742
I0814 23:04:27.961990 10672 solver.cpp:244]     Train net output #0: loss1 = 0.324955 (* 0.5 = 0.162478 loss)
I0814 23:04:27.962005 10672 solver.cpp:244]     Train net output #1: loss2 = 0.492528 (* 0.5 = 0.246264 loss)
I0814 23:04:27.962018 10672 sgd_solver.cpp:106] Iteration 3640, lr = 0.000119751
I0814 23:04:33.465862 10672 solver.cpp:228] Iteration 3660, loss = 0.257433
I0814 23:04:33.465917 10672 solver.cpp:244]     Train net output #0: loss1 = 0.106042 (* 0.5 = 0.0530208 loss)
I0814 23:04:33.465934 10672 solver.cpp:244]     Train net output #1: loss2 = 0.408824 (* 0.5 = 0.204412 loss)
I0814 23:04:33.465947 10672 sgd_solver.cpp:106] Iteration 3660, lr = 0.000119262
I0814 23:04:38.981400 10672 solver.cpp:228] Iteration 3680, loss = 0.317584
I0814 23:04:38.981456 10672 solver.cpp:244]     Train net output #0: loss1 = 0.206614 (* 0.5 = 0.103307 loss)
I0814 23:04:38.981472 10672 solver.cpp:244]     Train net output #1: loss2 = 0.428554 (* 0.5 = 0.214277 loss)
I0814 23:04:38.981487 10672 sgd_solver.cpp:106] Iteration 3680, lr = 0.000118776
I0814 23:04:44.491833 10672 solver.cpp:228] Iteration 3700, loss = 0.369524
I0814 23:04:44.491891 10672 solver.cpp:244]     Train net output #0: loss1 = 0.270106 (* 0.5 = 0.135053 loss)
I0814 23:04:44.491907 10672 solver.cpp:244]     Train net output #1: loss2 = 0.468941 (* 0.5 = 0.23447 loss)
I0814 23:04:44.491920 10672 sgd_solver.cpp:106] Iteration 3700, lr = 0.000118296
I0814 23:04:50.004673 10672 solver.cpp:228] Iteration 3720, loss = 0.327044
I0814 23:04:50.004865 10672 solver.cpp:244]     Train net output #0: loss1 = 0.259759 (* 0.5 = 0.12988 loss)
I0814 23:04:50.004890 10672 solver.cpp:244]     Train net output #1: loss2 = 0.394329 (* 0.5 = 0.197165 loss)
I0814 23:04:50.004906 10672 sgd_solver.cpp:106] Iteration 3720, lr = 0.00011782
I0814 23:04:55.512277 10672 solver.cpp:228] Iteration 3740, loss = 0.325692
I0814 23:04:55.512331 10672 solver.cpp:244]     Train net output #0: loss1 = 0.204455 (* 0.5 = 0.102228 loss)
I0814 23:04:55.512346 10672 solver.cpp:244]     Train net output #1: loss2 = 0.446929 (* 0.5 = 0.223465 loss)
I0814 23:04:55.512359 10672 sgd_solver.cpp:106] Iteration 3740, lr = 0.000117348
I0814 23:05:01.021503 10672 solver.cpp:228] Iteration 3760, loss = 0.341938
I0814 23:05:01.021562 10672 solver.cpp:244]     Train net output #0: loss1 = 0.212454 (* 0.5 = 0.106227 loss)
I0814 23:05:01.021579 10672 solver.cpp:244]     Train net output #1: loss2 = 0.471422 (* 0.5 = 0.235711 loss)
I0814 23:05:01.021592 10672 sgd_solver.cpp:106] Iteration 3760, lr = 0.000116881
I0814 23:05:06.529379 10672 solver.cpp:228] Iteration 3780, loss = 0.375735
I0814 23:05:06.529435 10672 solver.cpp:244]     Train net output #0: loss1 = 0.330141 (* 0.5 = 0.16507 loss)
I0814 23:05:06.529453 10672 solver.cpp:244]     Train net output #1: loss2 = 0.421329 (* 0.5 = 0.210664 loss)
I0814 23:05:06.529465 10672 sgd_solver.cpp:106] Iteration 3780, lr = 0.000116418
I0814 23:05:12.041818 10672 solver.cpp:228] Iteration 3800, loss = 0.334186
I0814 23:05:12.041874 10672 solver.cpp:244]     Train net output #0: loss1 = 0.18974 (* 0.5 = 0.09487 loss)
I0814 23:05:12.041892 10672 solver.cpp:244]     Train net output #1: loss2 = 0.478632 (* 0.5 = 0.239316 loss)
I0814 23:05:12.041905 10672 sgd_solver.cpp:106] Iteration 3800, lr = 0.000115959
I0814 23:05:17.546597 10672 solver.cpp:228] Iteration 3820, loss = 0.347237
I0814 23:05:17.546658 10672 solver.cpp:244]     Train net output #0: loss1 = 0.218495 (* 0.5 = 0.109248 loss)
I0814 23:05:17.546674 10672 solver.cpp:244]     Train net output #1: loss2 = 0.47598 (* 0.5 = 0.23799 loss)
I0814 23:05:17.546689 10672 sgd_solver.cpp:106] Iteration 3820, lr = 0.000115505
I0814 23:05:23.054859 10672 solver.cpp:228] Iteration 3840, loss = 0.361181
I0814 23:05:23.055009 10672 solver.cpp:244]     Train net output #0: loss1 = 0.24885 (* 0.5 = 0.124425 loss)
I0814 23:05:23.055033 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473512 (* 0.5 = 0.236756 loss)
I0814 23:05:23.055050 10672 sgd_solver.cpp:106] Iteration 3840, lr = 0.000115055
I0814 23:05:28.566948 10672 solver.cpp:228] Iteration 3860, loss = 0.417732
I0814 23:05:28.567008 10672 solver.cpp:244]     Train net output #0: loss1 = 0.332897 (* 0.5 = 0.166449 loss)
I0814 23:05:28.567023 10672 solver.cpp:244]     Train net output #1: loss2 = 0.502567 (* 0.5 = 0.251284 loss)
I0814 23:05:28.567036 10672 sgd_solver.cpp:106] Iteration 3860, lr = 0.000114608
I0814 23:05:34.073959 10672 solver.cpp:228] Iteration 3880, loss = 0.335543
I0814 23:05:34.074017 10672 solver.cpp:244]     Train net output #0: loss1 = 0.197434 (* 0.5 = 0.0987171 loss)
I0814 23:05:34.074033 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473651 (* 0.5 = 0.236825 loss)
I0814 23:05:34.074048 10672 sgd_solver.cpp:106] Iteration 3880, lr = 0.000114166
I0814 23:05:39.579939 10672 solver.cpp:228] Iteration 3900, loss = 0.322695
I0814 23:05:39.580003 10672 solver.cpp:244]     Train net output #0: loss1 = 0.179578 (* 0.5 = 0.0897892 loss)
I0814 23:05:39.580020 10672 solver.cpp:244]     Train net output #1: loss2 = 0.465811 (* 0.5 = 0.232905 loss)
I0814 23:05:39.580034 10672 sgd_solver.cpp:106] Iteration 3900, lr = 0.000113728
I0814 23:05:45.089176 10672 solver.cpp:228] Iteration 3920, loss = 0.312754
I0814 23:05:45.089231 10672 solver.cpp:244]     Train net output #0: loss1 = 0.191132 (* 0.5 = 0.0955661 loss)
I0814 23:05:45.089246 10672 solver.cpp:244]     Train net output #1: loss2 = 0.434375 (* 0.5 = 0.217188 loss)
I0814 23:05:45.089259 10672 sgd_solver.cpp:106] Iteration 3920, lr = 0.000113294
I0814 23:05:50.599779 10672 solver.cpp:228] Iteration 3940, loss = 0.401795
I0814 23:05:50.599838 10672 solver.cpp:244]     Train net output #0: loss1 = 0.299825 (* 0.5 = 0.149913 loss)
I0814 23:05:50.599854 10672 solver.cpp:244]     Train net output #1: loss2 = 0.503764 (* 0.5 = 0.251882 loss)
I0814 23:05:50.599867 10672 sgd_solver.cpp:106] Iteration 3940, lr = 0.000112863
I0814 23:05:56.107136 10672 solver.cpp:228] Iteration 3960, loss = 0.324379
I0814 23:05:56.107296 10672 solver.cpp:244]     Train net output #0: loss1 = 0.170326 (* 0.5 = 0.0851628 loss)
I0814 23:05:56.107313 10672 solver.cpp:244]     Train net output #1: loss2 = 0.478433 (* 0.5 = 0.239216 loss)
I0814 23:05:56.107327 10672 sgd_solver.cpp:106] Iteration 3960, lr = 0.000112436
I0814 23:06:01.610694 10672 solver.cpp:228] Iteration 3980, loss = 0.318219
I0814 23:06:01.610748 10672 solver.cpp:244]     Train net output #0: loss1 = 0.199688 (* 0.5 = 0.0998442 loss)
I0814 23:06:01.610764 10672 solver.cpp:244]     Train net output #1: loss2 = 0.43675 (* 0.5 = 0.218375 loss)
I0814 23:06:01.610777 10672 sgd_solver.cpp:106] Iteration 3980, lr = 0.000112013
I0814 23:06:06.842046 10672 solver.cpp:337] Iteration 4000, Testing net (#0)
I0814 23:07:09.921696 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.695766
I0814 23:07:09.921809 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.898922
I0814 23:07:09.921828 10672 solver.cpp:404]     Test net output #2: loss1 = 0.300122 (* 0.5 = 0.150061 loss)
I0814 23:07:09.921843 10672 solver.cpp:404]     Test net output #3: loss2 = 0.597973 (* 0.5 = 0.298986 loss)
I0814 23:07:10.005745 10672 solver.cpp:228] Iteration 4000, loss = 0.358198
I0814 23:07:10.005798 10672 solver.cpp:244]     Train net output #0: loss1 = 0.310125 (* 0.5 = 0.155063 loss)
I0814 23:07:10.005815 10672 solver.cpp:244]     Train net output #1: loss2 = 0.406271 (* 0.5 = 0.203136 loss)
I0814 23:07:10.005830 10672 sgd_solver.cpp:106] Iteration 4000, lr = 0.000111594
I0814 23:07:15.510663 10672 solver.cpp:228] Iteration 4020, loss = 0.369958
I0814 23:07:15.510722 10672 solver.cpp:244]     Train net output #0: loss1 = 0.276589 (* 0.5 = 0.138294 loss)
I0814 23:07:15.510737 10672 solver.cpp:244]     Train net output #1: loss2 = 0.463328 (* 0.5 = 0.231664 loss)
I0814 23:07:15.510751 10672 sgd_solver.cpp:106] Iteration 4020, lr = 0.000111179
I0814 23:07:21.014994 10672 solver.cpp:228] Iteration 4040, loss = 0.351807
I0814 23:07:21.015050 10672 solver.cpp:244]     Train net output #0: loss1 = 0.184989 (* 0.5 = 0.0924944 loss)
I0814 23:07:21.015065 10672 solver.cpp:244]     Train net output #1: loss2 = 0.518625 (* 0.5 = 0.259313 loss)
I0814 23:07:21.015079 10672 sgd_solver.cpp:106] Iteration 4040, lr = 0.000110767
I0814 23:07:26.516649 10672 solver.cpp:228] Iteration 4060, loss = 0.301919
I0814 23:07:26.516708 10672 solver.cpp:244]     Train net output #0: loss1 = 0.169775 (* 0.5 = 0.0848873 loss)
I0814 23:07:26.516724 10672 solver.cpp:244]     Train net output #1: loss2 = 0.434064 (* 0.5 = 0.217032 loss)
I0814 23:07:26.516738 10672 sgd_solver.cpp:106] Iteration 4060, lr = 0.000110358
I0814 23:07:32.022495 10672 solver.cpp:228] Iteration 4080, loss = 0.399666
I0814 23:07:32.022557 10672 solver.cpp:244]     Train net output #0: loss1 = 0.296843 (* 0.5 = 0.148421 loss)
I0814 23:07:32.022577 10672 solver.cpp:244]     Train net output #1: loss2 = 0.50249 (* 0.5 = 0.251245 loss)
I0814 23:07:32.022588 10672 sgd_solver.cpp:106] Iteration 4080, lr = 0.000109953
I0814 23:07:37.532640 10672 solver.cpp:228] Iteration 4100, loss = 0.355874
I0814 23:07:37.532694 10672 solver.cpp:244]     Train net output #0: loss1 = 0.229719 (* 0.5 = 0.114859 loss)
I0814 23:07:37.532711 10672 solver.cpp:244]     Train net output #1: loss2 = 0.482029 (* 0.5 = 0.241014 loss)
I0814 23:07:37.532724 10672 sgd_solver.cpp:106] Iteration 4100, lr = 0.000109552
I0814 23:07:43.040753 10672 solver.cpp:228] Iteration 4120, loss = 0.404883
I0814 23:07:43.040941 10672 solver.cpp:244]     Train net output #0: loss1 = 0.21379 (* 0.5 = 0.106895 loss)
I0814 23:07:43.040966 10672 solver.cpp:244]     Train net output #1: loss2 = 0.595976 (* 0.5 = 0.297988 loss)
I0814 23:07:43.040982 10672 sgd_solver.cpp:106] Iteration 4120, lr = 0.000109153
I0814 23:07:48.547534 10672 solver.cpp:228] Iteration 4140, loss = 0.391543
I0814 23:07:48.547590 10672 solver.cpp:244]     Train net output #0: loss1 = 0.31118 (* 0.5 = 0.15559 loss)
I0814 23:07:48.547605 10672 solver.cpp:244]     Train net output #1: loss2 = 0.471905 (* 0.5 = 0.235953 loss)
I0814 23:07:48.547619 10672 sgd_solver.cpp:106] Iteration 4140, lr = 0.000108759
I0814 23:07:54.054687 10672 solver.cpp:228] Iteration 4160, loss = 0.291008
I0814 23:07:54.054745 10672 solver.cpp:244]     Train net output #0: loss1 = 0.185033 (* 0.5 = 0.0925164 loss)
I0814 23:07:54.054760 10672 solver.cpp:244]     Train net output #1: loss2 = 0.396984 (* 0.5 = 0.198492 loss)
I0814 23:07:54.054774 10672 sgd_solver.cpp:106] Iteration 4160, lr = 0.000108367
I0814 23:07:59.559149 10672 solver.cpp:228] Iteration 4180, loss = 0.342286
I0814 23:07:59.559206 10672 solver.cpp:244]     Train net output #0: loss1 = 0.264542 (* 0.5 = 0.132271 loss)
I0814 23:07:59.559222 10672 solver.cpp:244]     Train net output #1: loss2 = 0.42003 (* 0.5 = 0.210015 loss)
I0814 23:07:59.559237 10672 sgd_solver.cpp:106] Iteration 4180, lr = 0.000107979
I0814 23:08:05.068903 10672 solver.cpp:228] Iteration 4200, loss = 0.31346
I0814 23:08:05.068963 10672 solver.cpp:244]     Train net output #0: loss1 = 0.183512 (* 0.5 = 0.0917558 loss)
I0814 23:08:05.068979 10672 solver.cpp:244]     Train net output #1: loss2 = 0.443408 (* 0.5 = 0.221704 loss)
I0814 23:08:05.068992 10672 sgd_solver.cpp:106] Iteration 4200, lr = 0.000107594
I0814 23:08:10.573248 10672 solver.cpp:228] Iteration 4220, loss = 0.341498
I0814 23:08:10.573302 10672 solver.cpp:244]     Train net output #0: loss1 = 0.238484 (* 0.5 = 0.119242 loss)
I0814 23:08:10.573318 10672 solver.cpp:244]     Train net output #1: loss2 = 0.444512 (* 0.5 = 0.222256 loss)
I0814 23:08:10.573330 10672 sgd_solver.cpp:106] Iteration 4220, lr = 0.000107212
I0814 23:08:16.081215 10672 solver.cpp:228] Iteration 4240, loss = 0.327952
I0814 23:08:16.081332 10672 solver.cpp:244]     Train net output #0: loss1 = 0.255001 (* 0.5 = 0.1275 loss)
I0814 23:08:16.081351 10672 solver.cpp:244]     Train net output #1: loss2 = 0.400903 (* 0.5 = 0.200451 loss)
I0814 23:08:16.081363 10672 sgd_solver.cpp:106] Iteration 4240, lr = 0.000106834
I0814 23:08:21.587744 10672 solver.cpp:228] Iteration 4260, loss = 0.297569
I0814 23:08:21.587800 10672 solver.cpp:244]     Train net output #0: loss1 = 0.158908 (* 0.5 = 0.0794538 loss)
I0814 23:08:21.587815 10672 solver.cpp:244]     Train net output #1: loss2 = 0.436231 (* 0.5 = 0.218115 loss)
I0814 23:08:21.587828 10672 sgd_solver.cpp:106] Iteration 4260, lr = 0.000106458
I0814 23:08:27.093572 10672 solver.cpp:228] Iteration 4280, loss = 0.387625
I0814 23:08:27.093631 10672 solver.cpp:244]     Train net output #0: loss1 = 0.216359 (* 0.5 = 0.108179 loss)
I0814 23:08:27.093646 10672 solver.cpp:244]     Train net output #1: loss2 = 0.558892 (* 0.5 = 0.279446 loss)
I0814 23:08:27.093659 10672 sgd_solver.cpp:106] Iteration 4280, lr = 0.000106086
I0814 23:08:32.596251 10672 solver.cpp:228] Iteration 4300, loss = 0.402679
I0814 23:08:32.596310 10672 solver.cpp:244]     Train net output #0: loss1 = 0.231285 (* 0.5 = 0.115642 loss)
I0814 23:08:32.596328 10672 solver.cpp:244]     Train net output #1: loss2 = 0.574073 (* 0.5 = 0.287037 loss)
I0814 23:08:32.596341 10672 sgd_solver.cpp:106] Iteration 4300, lr = 0.000105716
I0814 23:08:38.109693 10672 solver.cpp:228] Iteration 4320, loss = 0.308627
I0814 23:08:38.109750 10672 solver.cpp:244]     Train net output #0: loss1 = 0.229383 (* 0.5 = 0.114691 loss)
I0814 23:08:38.109766 10672 solver.cpp:244]     Train net output #1: loss2 = 0.387871 (* 0.5 = 0.193935 loss)
I0814 23:08:38.109779 10672 sgd_solver.cpp:106] Iteration 4320, lr = 0.00010535
I0814 23:08:43.613773 10672 solver.cpp:228] Iteration 4340, loss = 0.416206
I0814 23:08:43.613831 10672 solver.cpp:244]     Train net output #0: loss1 = 0.304845 (* 0.5 = 0.152423 loss)
I0814 23:08:43.613845 10672 solver.cpp:244]     Train net output #1: loss2 = 0.527566 (* 0.5 = 0.263783 loss)
I0814 23:08:43.613858 10672 sgd_solver.cpp:106] Iteration 4340, lr = 0.000104986
I0814 23:08:49.126106 10672 solver.cpp:228] Iteration 4360, loss = 0.351076
I0814 23:08:49.126253 10672 solver.cpp:244]     Train net output #0: loss1 = 0.244662 (* 0.5 = 0.122331 loss)
I0814 23:08:49.126271 10672 solver.cpp:244]     Train net output #1: loss2 = 0.45749 (* 0.5 = 0.228745 loss)
I0814 23:08:49.126284 10672 sgd_solver.cpp:106] Iteration 4360, lr = 0.000104626
I0814 23:08:54.631451 10672 solver.cpp:228] Iteration 4380, loss = 0.285112
I0814 23:08:54.631505 10672 solver.cpp:244]     Train net output #0: loss1 = 0.101891 (* 0.5 = 0.0509457 loss)
I0814 23:08:54.631521 10672 solver.cpp:244]     Train net output #1: loss2 = 0.468333 (* 0.5 = 0.234166 loss)
I0814 23:08:54.631534 10672 sgd_solver.cpp:106] Iteration 4380, lr = 0.000104268
I0814 23:09:00.142832 10672 solver.cpp:228] Iteration 4400, loss = 0.305703
I0814 23:09:00.142889 10672 solver.cpp:244]     Train net output #0: loss1 = 0.183797 (* 0.5 = 0.0918986 loss)
I0814 23:09:00.142906 10672 solver.cpp:244]     Train net output #1: loss2 = 0.427608 (* 0.5 = 0.213804 loss)
I0814 23:09:00.142930 10672 sgd_solver.cpp:106] Iteration 4400, lr = 0.000103913
I0814 23:09:05.654289 10672 solver.cpp:228] Iteration 4420, loss = 0.37759
I0814 23:09:05.654348 10672 solver.cpp:244]     Train net output #0: loss1 = 0.282899 (* 0.5 = 0.141449 loss)
I0814 23:09:05.654364 10672 solver.cpp:244]     Train net output #1: loss2 = 0.472281 (* 0.5 = 0.236141 loss)
I0814 23:09:05.654377 10672 sgd_solver.cpp:106] Iteration 4420, lr = 0.000103561
I0814 23:09:11.163786 10672 solver.cpp:228] Iteration 4440, loss = 0.339375
I0814 23:09:11.163844 10672 solver.cpp:244]     Train net output #0: loss1 = 0.203839 (* 0.5 = 0.10192 loss)
I0814 23:09:11.163861 10672 solver.cpp:244]     Train net output #1: loss2 = 0.47491 (* 0.5 = 0.237455 loss)
I0814 23:09:11.163874 10672 sgd_solver.cpp:106] Iteration 4440, lr = 0.000103212
I0814 23:09:16.672462 10672 solver.cpp:228] Iteration 4460, loss = 0.339036
I0814 23:09:16.672518 10672 solver.cpp:244]     Train net output #0: loss1 = 0.262775 (* 0.5 = 0.131387 loss)
I0814 23:09:16.672533 10672 solver.cpp:244]     Train net output #1: loss2 = 0.415297 (* 0.5 = 0.207649 loss)
I0814 23:09:16.672546 10672 sgd_solver.cpp:106] Iteration 4460, lr = 0.000102865
I0814 23:09:22.173457 10672 solver.cpp:228] Iteration 4480, loss = 0.370276
I0814 23:09:22.173616 10672 solver.cpp:244]     Train net output #0: loss1 = 0.258512 (* 0.5 = 0.129256 loss)
I0814 23:09:22.173635 10672 solver.cpp:244]     Train net output #1: loss2 = 0.48204 (* 0.5 = 0.24102 loss)
I0814 23:09:22.173648 10672 sgd_solver.cpp:106] Iteration 4480, lr = 0.000102522
I0814 23:09:27.679137 10672 solver.cpp:228] Iteration 4500, loss = 0.319003
I0814 23:09:27.679198 10672 solver.cpp:244]     Train net output #0: loss1 = 0.245465 (* 0.5 = 0.122733 loss)
I0814 23:09:27.679214 10672 solver.cpp:244]     Train net output #1: loss2 = 0.392542 (* 0.5 = 0.196271 loss)
I0814 23:09:27.679227 10672 sgd_solver.cpp:106] Iteration 4500, lr = 0.00010218
I0814 23:09:33.182548 10672 solver.cpp:228] Iteration 4520, loss = 0.306697
I0814 23:09:33.182611 10672 solver.cpp:244]     Train net output #0: loss1 = 0.136048 (* 0.5 = 0.0680238 loss)
I0814 23:09:33.182626 10672 solver.cpp:244]     Train net output #1: loss2 = 0.477347 (* 0.5 = 0.238673 loss)
I0814 23:09:33.182641 10672 sgd_solver.cpp:106] Iteration 4520, lr = 0.000101842
I0814 23:09:38.712168 10672 solver.cpp:228] Iteration 4540, loss = 0.37877
I0814 23:09:38.712224 10672 solver.cpp:244]     Train net output #0: loss1 = 0.202752 (* 0.5 = 0.101376 loss)
I0814 23:09:38.712239 10672 solver.cpp:244]     Train net output #1: loss2 = 0.554787 (* 0.5 = 0.277394 loss)
I0814 23:09:38.712252 10672 sgd_solver.cpp:106] Iteration 4540, lr = 0.000101506
I0814 23:09:44.229598 10672 solver.cpp:228] Iteration 4560, loss = 0.333763
I0814 23:09:44.229658 10672 solver.cpp:244]     Train net output #0: loss1 = 0.23766 (* 0.5 = 0.11883 loss)
I0814 23:09:44.229674 10672 solver.cpp:244]     Train net output #1: loss2 = 0.429866 (* 0.5 = 0.214933 loss)
I0814 23:09:44.229687 10672 sgd_solver.cpp:106] Iteration 4560, lr = 0.000101173
I0814 23:09:49.727401 10672 solver.cpp:228] Iteration 4580, loss = 0.342792
I0814 23:09:49.727459 10672 solver.cpp:244]     Train net output #0: loss1 = 0.243122 (* 0.5 = 0.121561 loss)
I0814 23:09:49.727475 10672 solver.cpp:244]     Train net output #1: loss2 = 0.442462 (* 0.5 = 0.221231 loss)
I0814 23:09:49.727488 10672 sgd_solver.cpp:106] Iteration 4580, lr = 0.000100842
I0814 23:09:55.222616 10672 solver.cpp:228] Iteration 4600, loss = 0.330178
I0814 23:09:55.222770 10672 solver.cpp:244]     Train net output #0: loss1 = 0.22549 (* 0.5 = 0.112745 loss)
I0814 23:09:55.222796 10672 solver.cpp:244]     Train net output #1: loss2 = 0.434865 (* 0.5 = 0.217432 loss)
I0814 23:09:55.222813 10672 sgd_solver.cpp:106] Iteration 4600, lr = 0.000100513
I0814 23:10:00.721259 10672 solver.cpp:228] Iteration 4620, loss = 0.33671
I0814 23:10:00.721319 10672 solver.cpp:244]     Train net output #0: loss1 = 0.185081 (* 0.5 = 0.0925407 loss)
I0814 23:10:00.721335 10672 solver.cpp:244]     Train net output #1: loss2 = 0.488338 (* 0.5 = 0.244169 loss)
I0814 23:10:00.721349 10672 sgd_solver.cpp:106] Iteration 4620, lr = 0.000100188
I0814 23:10:06.222692 10672 solver.cpp:228] Iteration 4640, loss = 0.323564
I0814 23:10:06.222753 10672 solver.cpp:244]     Train net output #0: loss1 = 0.213879 (* 0.5 = 0.106939 loss)
I0814 23:10:06.222769 10672 solver.cpp:244]     Train net output #1: loss2 = 0.433248 (* 0.5 = 0.216624 loss)
I0814 23:10:06.222781 10672 sgd_solver.cpp:106] Iteration 4640, lr = 9.98643e-05
I0814 23:10:11.716954 10672 solver.cpp:228] Iteration 4660, loss = 0.336774
I0814 23:10:11.717011 10672 solver.cpp:244]     Train net output #0: loss1 = 0.175601 (* 0.5 = 0.0878005 loss)
I0814 23:10:11.717026 10672 solver.cpp:244]     Train net output #1: loss2 = 0.497946 (* 0.5 = 0.248973 loss)
I0814 23:10:11.717041 10672 sgd_solver.cpp:106] Iteration 4660, lr = 9.95434e-05
I0814 23:10:17.213270 10672 solver.cpp:228] Iteration 4680, loss = 0.308869
I0814 23:10:17.213328 10672 solver.cpp:244]     Train net output #0: loss1 = 0.200374 (* 0.5 = 0.100187 loss)
I0814 23:10:17.213345 10672 solver.cpp:244]     Train net output #1: loss2 = 0.417365 (* 0.5 = 0.208682 loss)
I0814 23:10:17.213357 10672 sgd_solver.cpp:106] Iteration 4680, lr = 9.92248e-05
I0814 23:10:22.709175 10672 solver.cpp:228] Iteration 4700, loss = 0.38121
I0814 23:10:22.709236 10672 solver.cpp:244]     Train net output #0: loss1 = 0.283246 (* 0.5 = 0.141623 loss)
I0814 23:10:22.709251 10672 solver.cpp:244]     Train net output #1: loss2 = 0.479174 (* 0.5 = 0.239587 loss)
I0814 23:10:22.709265 10672 sgd_solver.cpp:106] Iteration 4700, lr = 9.89087e-05
I0814 23:10:28.203840 10672 solver.cpp:228] Iteration 4720, loss = 0.374007
I0814 23:10:28.203996 10672 solver.cpp:244]     Train net output #0: loss1 = 0.216497 (* 0.5 = 0.108248 loss)
I0814 23:10:28.204015 10672 solver.cpp:244]     Train net output #1: loss2 = 0.531517 (* 0.5 = 0.265758 loss)
I0814 23:10:28.204028 10672 sgd_solver.cpp:106] Iteration 4720, lr = 9.85948e-05
I0814 23:10:33.700614 10672 solver.cpp:228] Iteration 4740, loss = 0.314322
I0814 23:10:33.700675 10672 solver.cpp:244]     Train net output #0: loss1 = 0.17055 (* 0.5 = 0.085275 loss)
I0814 23:10:33.700690 10672 solver.cpp:244]     Train net output #1: loss2 = 0.458095 (* 0.5 = 0.229047 loss)
I0814 23:10:33.700703 10672 sgd_solver.cpp:106] Iteration 4740, lr = 9.82833e-05
I0814 23:10:39.201037 10672 solver.cpp:228] Iteration 4760, loss = 0.327549
I0814 23:10:39.201097 10672 solver.cpp:244]     Train net output #0: loss1 = 0.210601 (* 0.5 = 0.105301 loss)
I0814 23:10:39.201112 10672 solver.cpp:244]     Train net output #1: loss2 = 0.444496 (* 0.5 = 0.222248 loss)
I0814 23:10:39.201127 10672 sgd_solver.cpp:106] Iteration 4760, lr = 9.79741e-05
I0814 23:10:44.695083 10672 solver.cpp:228] Iteration 4780, loss = 0.357615
I0814 23:10:44.695143 10672 solver.cpp:244]     Train net output #0: loss1 = 0.218452 (* 0.5 = 0.109226 loss)
I0814 23:10:44.695159 10672 solver.cpp:244]     Train net output #1: loss2 = 0.496778 (* 0.5 = 0.248389 loss)
I0814 23:10:44.695173 10672 sgd_solver.cpp:106] Iteration 4780, lr = 9.76671e-05
I0814 23:10:50.193394 10672 solver.cpp:228] Iteration 4800, loss = 0.315279
I0814 23:10:50.193454 10672 solver.cpp:244]     Train net output #0: loss1 = 0.193808 (* 0.5 = 0.0969042 loss)
I0814 23:10:50.193470 10672 solver.cpp:244]     Train net output #1: loss2 = 0.436749 (* 0.5 = 0.218374 loss)
I0814 23:10:50.193483 10672 sgd_solver.cpp:106] Iteration 4800, lr = 9.73624e-05
I0814 23:10:55.687841 10672 solver.cpp:228] Iteration 4820, loss = 0.287441
I0814 23:10:55.687902 10672 solver.cpp:244]     Train net output #0: loss1 = 0.142393 (* 0.5 = 0.0711964 loss)
I0814 23:10:55.687918 10672 solver.cpp:244]     Train net output #1: loss2 = 0.432489 (* 0.5 = 0.216245 loss)
I0814 23:10:55.687932 10672 sgd_solver.cpp:106] Iteration 4820, lr = 9.70599e-05
I0814 23:11:01.185631 10672 solver.cpp:228] Iteration 4840, loss = 0.28083
I0814 23:11:01.185784 10672 solver.cpp:244]     Train net output #0: loss1 = 0.174921 (* 0.5 = 0.0874607 loss)
I0814 23:11:01.185802 10672 solver.cpp:244]     Train net output #1: loss2 = 0.386738 (* 0.5 = 0.193369 loss)
I0814 23:11:01.185816 10672 sgd_solver.cpp:106] Iteration 4840, lr = 9.67595e-05
I0814 23:11:06.683221 10672 solver.cpp:228] Iteration 4860, loss = 0.309628
I0814 23:11:06.683284 10672 solver.cpp:244]     Train net output #0: loss1 = 0.222593 (* 0.5 = 0.111296 loss)
I0814 23:11:06.683300 10672 solver.cpp:244]     Train net output #1: loss2 = 0.396664 (* 0.5 = 0.198332 loss)
I0814 23:11:06.683313 10672 sgd_solver.cpp:106] Iteration 4860, lr = 9.64613e-05
I0814 23:11:12.180501 10672 solver.cpp:228] Iteration 4880, loss = 0.321269
I0814 23:11:12.180557 10672 solver.cpp:244]     Train net output #0: loss1 = 0.169319 (* 0.5 = 0.0846597 loss)
I0814 23:11:12.180572 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473219 (* 0.5 = 0.236609 loss)
I0814 23:11:12.180585 10672 sgd_solver.cpp:106] Iteration 4880, lr = 9.61653e-05
I0814 23:11:17.678894 10672 solver.cpp:228] Iteration 4900, loss = 0.332757
I0814 23:11:17.678952 10672 solver.cpp:244]     Train net output #0: loss1 = 0.229683 (* 0.5 = 0.114842 loss)
I0814 23:11:17.678968 10672 solver.cpp:244]     Train net output #1: loss2 = 0.435831 (* 0.5 = 0.217915 loss)
I0814 23:11:17.678982 10672 sgd_solver.cpp:106] Iteration 4900, lr = 9.58714e-05
I0814 23:11:23.171775 10672 solver.cpp:228] Iteration 4920, loss = 0.329632
I0814 23:11:23.171833 10672 solver.cpp:244]     Train net output #0: loss1 = 0.251527 (* 0.5 = 0.125763 loss)
I0814 23:11:23.171849 10672 solver.cpp:244]     Train net output #1: loss2 = 0.407737 (* 0.5 = 0.203868 loss)
I0814 23:11:23.171861 10672 sgd_solver.cpp:106] Iteration 4920, lr = 9.55795e-05
I0814 23:11:28.679462 10672 solver.cpp:228] Iteration 4940, loss = 0.364764
I0814 23:11:28.679519 10672 solver.cpp:244]     Train net output #0: loss1 = 0.28176 (* 0.5 = 0.14088 loss)
I0814 23:11:28.679535 10672 solver.cpp:244]     Train net output #1: loss2 = 0.447768 (* 0.5 = 0.223884 loss)
I0814 23:11:28.679548 10672 sgd_solver.cpp:106] Iteration 4940, lr = 9.52897e-05
I0814 23:11:34.211935 10672 solver.cpp:228] Iteration 4960, loss = 0.308609
I0814 23:11:34.212085 10672 solver.cpp:244]     Train net output #0: loss1 = 0.224562 (* 0.5 = 0.112281 loss)
I0814 23:11:34.212101 10672 solver.cpp:244]     Train net output #1: loss2 = 0.392656 (* 0.5 = 0.196328 loss)
I0814 23:11:34.212116 10672 sgd_solver.cpp:106] Iteration 4960, lr = 9.5002e-05
I0814 23:11:39.705780 10672 solver.cpp:228] Iteration 4980, loss = 0.361645
I0814 23:11:39.705838 10672 solver.cpp:244]     Train net output #0: loss1 = 0.180573 (* 0.5 = 0.0902865 loss)
I0814 23:11:39.705854 10672 solver.cpp:244]     Train net output #1: loss2 = 0.542718 (* 0.5 = 0.271359 loss)
I0814 23:11:39.705868 10672 sgd_solver.cpp:106] Iteration 4980, lr = 9.47163e-05
I0814 23:11:44.927959 10672 solver.cpp:337] Iteration 5000, Testing net (#0)
I0814 23:12:48.018551 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.699766
I0814 23:12:48.018684 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.902719
I0814 23:12:48.018712 10672 solver.cpp:404]     Test net output #2: loss1 = 0.297171 (* 0.5 = 0.148585 loss)
I0814 23:12:48.018728 10672 solver.cpp:404]     Test net output #3: loss2 = 0.592455 (* 0.5 = 0.296228 loss)
I0814 23:12:48.101624 10672 solver.cpp:228] Iteration 5000, loss = 0.357203
I0814 23:12:48.101678 10672 solver.cpp:244]     Train net output #0: loss1 = 0.290741 (* 0.5 = 0.14537 loss)
I0814 23:12:48.101693 10672 solver.cpp:244]     Train net output #1: loss2 = 0.423666 (* 0.5 = 0.211833 loss)
I0814 23:12:48.101707 10672 sgd_solver.cpp:106] Iteration 5000, lr = 9.44325e-05
I0814 23:12:53.596473 10672 solver.cpp:228] Iteration 5020, loss = 0.351323
I0814 23:12:53.596534 10672 solver.cpp:244]     Train net output #0: loss1 = 0.208416 (* 0.5 = 0.104208 loss)
I0814 23:12:53.596549 10672 solver.cpp:244]     Train net output #1: loss2 = 0.49423 (* 0.5 = 0.247115 loss)
I0814 23:12:53.596561 10672 sgd_solver.cpp:106] Iteration 5020, lr = 9.41508e-05
I0814 23:12:59.092856 10672 solver.cpp:228] Iteration 5040, loss = 0.342671
I0814 23:12:59.092914 10672 solver.cpp:244]     Train net output #0: loss1 = 0.249354 (* 0.5 = 0.124677 loss)
I0814 23:12:59.092931 10672 solver.cpp:244]     Train net output #1: loss2 = 0.435988 (* 0.5 = 0.217994 loss)
I0814 23:12:59.092944 10672 sgd_solver.cpp:106] Iteration 5040, lr = 9.3871e-05
I0814 23:13:04.588335 10672 solver.cpp:228] Iteration 5060, loss = 0.317201
I0814 23:13:04.588390 10672 solver.cpp:244]     Train net output #0: loss1 = 0.202271 (* 0.5 = 0.101135 loss)
I0814 23:13:04.588405 10672 solver.cpp:244]     Train net output #1: loss2 = 0.43213 (* 0.5 = 0.216065 loss)
I0814 23:13:04.588419 10672 sgd_solver.cpp:106] Iteration 5060, lr = 9.35931e-05
I0814 23:13:10.087843 10672 solver.cpp:228] Iteration 5080, loss = 0.344692
I0814 23:13:10.087905 10672 solver.cpp:244]     Train net output #0: loss1 = 0.142472 (* 0.5 = 0.0712359 loss)
I0814 23:13:10.087921 10672 solver.cpp:244]     Train net output #1: loss2 = 0.546911 (* 0.5 = 0.273456 loss)
I0814 23:13:10.087935 10672 sgd_solver.cpp:106] Iteration 5080, lr = 9.33172e-05
I0814 23:13:15.584380 10672 solver.cpp:228] Iteration 5100, loss = 0.280333
I0814 23:13:15.584436 10672 solver.cpp:244]     Train net output #0: loss1 = 0.188795 (* 0.5 = 0.0943976 loss)
I0814 23:13:15.584452 10672 solver.cpp:244]     Train net output #1: loss2 = 0.37187 (* 0.5 = 0.185935 loss)
I0814 23:13:15.584466 10672 sgd_solver.cpp:106] Iteration 5100, lr = 9.30431e-05
I0814 23:13:21.080015 10672 solver.cpp:228] Iteration 5120, loss = 0.341227
I0814 23:13:21.080132 10672 solver.cpp:244]     Train net output #0: loss1 = 0.219498 (* 0.5 = 0.109749 loss)
I0814 23:13:21.080149 10672 solver.cpp:244]     Train net output #1: loss2 = 0.462955 (* 0.5 = 0.231478 loss)
I0814 23:13:21.080163 10672 sgd_solver.cpp:106] Iteration 5120, lr = 9.27709e-05
I0814 23:13:26.577369 10672 solver.cpp:228] Iteration 5140, loss = 0.279762
I0814 23:13:26.577427 10672 solver.cpp:244]     Train net output #0: loss1 = 0.155056 (* 0.5 = 0.0775279 loss)
I0814 23:13:26.577443 10672 solver.cpp:244]     Train net output #1: loss2 = 0.404469 (* 0.5 = 0.202235 loss)
I0814 23:13:26.577456 10672 sgd_solver.cpp:106] Iteration 5140, lr = 9.25006e-05
I0814 23:13:32.074849 10672 solver.cpp:228] Iteration 5160, loss = 0.316085
I0814 23:13:32.074913 10672 solver.cpp:244]     Train net output #0: loss1 = 0.206494 (* 0.5 = 0.103247 loss)
I0814 23:13:32.074928 10672 solver.cpp:244]     Train net output #1: loss2 = 0.425676 (* 0.5 = 0.212838 loss)
I0814 23:13:32.074942 10672 sgd_solver.cpp:106] Iteration 5160, lr = 9.22321e-05
I0814 23:13:37.570796 10672 solver.cpp:228] Iteration 5180, loss = 0.431001
I0814 23:13:37.570855 10672 solver.cpp:244]     Train net output #0: loss1 = 0.262674 (* 0.5 = 0.131337 loss)
I0814 23:13:37.570871 10672 solver.cpp:244]     Train net output #1: loss2 = 0.599327 (* 0.5 = 0.299664 loss)
I0814 23:13:37.570885 10672 sgd_solver.cpp:106] Iteration 5180, lr = 9.19654e-05
I0814 23:13:43.070770 10672 solver.cpp:228] Iteration 5200, loss = 0.315632
I0814 23:13:43.070830 10672 solver.cpp:244]     Train net output #0: loss1 = 0.206646 (* 0.5 = 0.103323 loss)
I0814 23:13:43.070845 10672 solver.cpp:244]     Train net output #1: loss2 = 0.424617 (* 0.5 = 0.212309 loss)
I0814 23:13:43.070859 10672 sgd_solver.cpp:106] Iteration 5200, lr = 9.17005e-05
I0814 23:13:48.568163 10672 solver.cpp:228] Iteration 5220, loss = 0.337455
I0814 23:13:48.568223 10672 solver.cpp:244]     Train net output #0: loss1 = 0.230013 (* 0.5 = 0.115007 loss)
I0814 23:13:48.568238 10672 solver.cpp:244]     Train net output #1: loss2 = 0.444897 (* 0.5 = 0.222448 loss)
I0814 23:13:48.568253 10672 sgd_solver.cpp:106] Iteration 5220, lr = 9.14374e-05
I0814 23:13:54.068502 10672 solver.cpp:228] Iteration 5240, loss = 0.272496
I0814 23:13:54.068658 10672 solver.cpp:244]     Train net output #0: loss1 = 0.151402 (* 0.5 = 0.0757012 loss)
I0814 23:13:54.068681 10672 solver.cpp:244]     Train net output #1: loss2 = 0.393589 (* 0.5 = 0.196794 loss)
I0814 23:13:54.068696 10672 sgd_solver.cpp:106] Iteration 5240, lr = 9.1176e-05
I0814 23:13:59.561455 10672 solver.cpp:228] Iteration 5260, loss = 0.39835
I0814 23:13:59.561511 10672 solver.cpp:244]     Train net output #0: loss1 = 0.224901 (* 0.5 = 0.11245 loss)
I0814 23:13:59.561527 10672 solver.cpp:244]     Train net output #1: loss2 = 0.571799 (* 0.5 = 0.285899 loss)
I0814 23:13:59.561540 10672 sgd_solver.cpp:106] Iteration 5260, lr = 9.09164e-05
I0814 23:14:05.062364 10672 solver.cpp:228] Iteration 5280, loss = 0.332293
I0814 23:14:05.062422 10672 solver.cpp:244]     Train net output #0: loss1 = 0.266086 (* 0.5 = 0.133043 loss)
I0814 23:14:05.062443 10672 solver.cpp:244]     Train net output #1: loss2 = 0.3985 (* 0.5 = 0.19925 loss)
I0814 23:14:05.062458 10672 sgd_solver.cpp:106] Iteration 5280, lr = 9.06584e-05
I0814 23:14:10.556802 10672 solver.cpp:228] Iteration 5300, loss = 0.316172
I0814 23:14:10.556861 10672 solver.cpp:244]     Train net output #0: loss1 = 0.239644 (* 0.5 = 0.119822 loss)
I0814 23:14:10.556876 10672 solver.cpp:244]     Train net output #1: loss2 = 0.392701 (* 0.5 = 0.196351 loss)
I0814 23:14:10.556890 10672 sgd_solver.cpp:106] Iteration 5300, lr = 9.04022e-05
I0814 23:14:16.053530 10672 solver.cpp:228] Iteration 5320, loss = 0.282864
I0814 23:14:16.053593 10672 solver.cpp:244]     Train net output #0: loss1 = 0.142866 (* 0.5 = 0.0714328 loss)
I0814 23:14:16.053609 10672 solver.cpp:244]     Train net output #1: loss2 = 0.422863 (* 0.5 = 0.211432 loss)
I0814 23:14:16.053622 10672 sgd_solver.cpp:106] Iteration 5320, lr = 9.01477e-05
I0814 23:14:21.547309 10672 solver.cpp:228] Iteration 5340, loss = 0.333176
I0814 23:14:21.547365 10672 solver.cpp:244]     Train net output #0: loss1 = 0.226133 (* 0.5 = 0.113066 loss)
I0814 23:14:21.547381 10672 solver.cpp:244]     Train net output #1: loss2 = 0.440219 (* 0.5 = 0.22011 loss)
I0814 23:14:21.547394 10672 sgd_solver.cpp:106] Iteration 5340, lr = 8.98948e-05
I0814 23:14:27.049222 10672 solver.cpp:228] Iteration 5360, loss = 0.344558
I0814 23:14:27.049392 10672 solver.cpp:244]     Train net output #0: loss1 = 0.226041 (* 0.5 = 0.11302 loss)
I0814 23:14:27.049410 10672 solver.cpp:244]     Train net output #1: loss2 = 0.463075 (* 0.5 = 0.231538 loss)
I0814 23:14:27.049424 10672 sgd_solver.cpp:106] Iteration 5360, lr = 8.96436e-05
I0814 23:14:32.543846 10672 solver.cpp:228] Iteration 5380, loss = 0.353809
I0814 23:14:32.543903 10672 solver.cpp:244]     Train net output #0: loss1 = 0.196855 (* 0.5 = 0.0984276 loss)
I0814 23:14:32.543918 10672 solver.cpp:244]     Train net output #1: loss2 = 0.510763 (* 0.5 = 0.255381 loss)
I0814 23:14:32.543932 10672 sgd_solver.cpp:106] Iteration 5380, lr = 8.9394e-05
I0814 23:14:38.038282 10672 solver.cpp:228] Iteration 5400, loss = 0.347701
I0814 23:14:38.038338 10672 solver.cpp:244]     Train net output #0: loss1 = 0.151987 (* 0.5 = 0.0759935 loss)
I0814 23:14:38.038354 10672 solver.cpp:244]     Train net output #1: loss2 = 0.543415 (* 0.5 = 0.271707 loss)
I0814 23:14:38.038368 10672 sgd_solver.cpp:106] Iteration 5400, lr = 8.9146e-05
I0814 23:14:43.531675 10672 solver.cpp:228] Iteration 5420, loss = 0.305226
I0814 23:14:43.531735 10672 solver.cpp:244]     Train net output #0: loss1 = 0.19107 (* 0.5 = 0.0955348 loss)
I0814 23:14:43.531751 10672 solver.cpp:244]     Train net output #1: loss2 = 0.419382 (* 0.5 = 0.209691 loss)
I0814 23:14:43.531765 10672 sgd_solver.cpp:106] Iteration 5420, lr = 8.88997e-05
I0814 23:14:49.029240 10672 solver.cpp:228] Iteration 5440, loss = 0.288581
I0814 23:14:49.029295 10672 solver.cpp:244]     Train net output #0: loss1 = 0.201063 (* 0.5 = 0.100531 loss)
I0814 23:14:49.029311 10672 solver.cpp:244]     Train net output #1: loss2 = 0.376099 (* 0.5 = 0.18805 loss)
I0814 23:14:49.029325 10672 sgd_solver.cpp:106] Iteration 5440, lr = 8.86549e-05
I0814 23:14:54.521733 10672 solver.cpp:228] Iteration 5460, loss = 0.26824
I0814 23:14:54.521786 10672 solver.cpp:244]     Train net output #0: loss1 = 0.160519 (* 0.5 = 0.0802594 loss)
I0814 23:14:54.521801 10672 solver.cpp:244]     Train net output #1: loss2 = 0.375962 (* 0.5 = 0.187981 loss)
I0814 23:14:54.521814 10672 sgd_solver.cpp:106] Iteration 5460, lr = 8.84117e-05
I0814 23:15:00.013000 10672 solver.cpp:228] Iteration 5480, loss = 0.250048
I0814 23:15:00.013164 10672 solver.cpp:244]     Train net output #0: loss1 = 0.154367 (* 0.5 = 0.0771833 loss)
I0814 23:15:00.013188 10672 solver.cpp:244]     Train net output #1: loss2 = 0.34573 (* 0.5 = 0.172865 loss)
I0814 23:15:00.013206 10672 sgd_solver.cpp:106] Iteration 5480, lr = 8.817e-05
I0814 23:15:05.512781 10672 solver.cpp:228] Iteration 5500, loss = 0.299229
I0814 23:15:05.512840 10672 solver.cpp:244]     Train net output #0: loss1 = 0.128701 (* 0.5 = 0.0643505 loss)
I0814 23:15:05.512856 10672 solver.cpp:244]     Train net output #1: loss2 = 0.469756 (* 0.5 = 0.234878 loss)
I0814 23:15:05.512871 10672 sgd_solver.cpp:106] Iteration 5500, lr = 8.79298e-05
I0814 23:15:11.008628 10672 solver.cpp:228] Iteration 5520, loss = 0.36116
I0814 23:15:11.008678 10672 solver.cpp:244]     Train net output #0: loss1 = 0.287984 (* 0.5 = 0.143992 loss)
I0814 23:15:11.008689 10672 solver.cpp:244]     Train net output #1: loss2 = 0.434336 (* 0.5 = 0.217168 loss)
I0814 23:15:11.008699 10672 sgd_solver.cpp:106] Iteration 5520, lr = 8.76912e-05
I0814 23:15:16.504596 10672 solver.cpp:228] Iteration 5540, loss = 0.266324
I0814 23:15:16.504655 10672 solver.cpp:244]     Train net output #0: loss1 = 0.132037 (* 0.5 = 0.0660185 loss)
I0814 23:15:16.504672 10672 solver.cpp:244]     Train net output #1: loss2 = 0.400611 (* 0.5 = 0.200306 loss)
I0814 23:15:16.504684 10672 sgd_solver.cpp:106] Iteration 5540, lr = 8.74541e-05
I0814 23:15:21.999830 10672 solver.cpp:228] Iteration 5560, loss = 0.341847
I0814 23:15:21.999889 10672 solver.cpp:244]     Train net output #0: loss1 = 0.254899 (* 0.5 = 0.127449 loss)
I0814 23:15:21.999905 10672 solver.cpp:244]     Train net output #1: loss2 = 0.428795 (* 0.5 = 0.214398 loss)
I0814 23:15:21.999918 10672 sgd_solver.cpp:106] Iteration 5560, lr = 8.72185e-05
I0814 23:15:27.495072 10672 solver.cpp:228] Iteration 5580, loss = 0.340585
I0814 23:15:27.495133 10672 solver.cpp:244]     Train net output #0: loss1 = 0.204728 (* 0.5 = 0.102364 loss)
I0814 23:15:27.495151 10672 solver.cpp:244]     Train net output #1: loss2 = 0.476442 (* 0.5 = 0.238221 loss)
I0814 23:15:27.495163 10672 sgd_solver.cpp:106] Iteration 5580, lr = 8.69843e-05
I0814 23:15:32.991981 10672 solver.cpp:228] Iteration 5600, loss = 0.304767
I0814 23:15:32.992130 10672 solver.cpp:244]     Train net output #0: loss1 = 0.19671 (* 0.5 = 0.0983549 loss)
I0814 23:15:32.992148 10672 solver.cpp:244]     Train net output #1: loss2 = 0.412824 (* 0.5 = 0.206412 loss)
I0814 23:15:32.992162 10672 sgd_solver.cpp:106] Iteration 5600, lr = 8.67517e-05
I0814 23:15:38.487398 10672 solver.cpp:228] Iteration 5620, loss = 0.316164
I0814 23:15:38.487457 10672 solver.cpp:244]     Train net output #0: loss1 = 0.240647 (* 0.5 = 0.120324 loss)
I0814 23:15:38.487473 10672 solver.cpp:244]     Train net output #1: loss2 = 0.391682 (* 0.5 = 0.195841 loss)
I0814 23:15:38.487488 10672 sgd_solver.cpp:106] Iteration 5620, lr = 8.65204e-05
I0814 23:15:43.984375 10672 solver.cpp:228] Iteration 5640, loss = 0.27515
I0814 23:15:43.984436 10672 solver.cpp:244]     Train net output #0: loss1 = 0.14837 (* 0.5 = 0.0741852 loss)
I0814 23:15:43.984452 10672 solver.cpp:244]     Train net output #1: loss2 = 0.401931 (* 0.5 = 0.200965 loss)
I0814 23:15:43.984464 10672 sgd_solver.cpp:106] Iteration 5640, lr = 8.62906e-05
I0814 23:15:49.477361 10672 solver.cpp:228] Iteration 5660, loss = 0.307556
I0814 23:15:49.477421 10672 solver.cpp:244]     Train net output #0: loss1 = 0.151884 (* 0.5 = 0.0759422 loss)
I0814 23:15:49.477437 10672 solver.cpp:244]     Train net output #1: loss2 = 0.463227 (* 0.5 = 0.231614 loss)
I0814 23:15:49.477450 10672 sgd_solver.cpp:106] Iteration 5660, lr = 8.60623e-05
I0814 23:15:54.970337 10672 solver.cpp:228] Iteration 5680, loss = 0.308649
I0814 23:15:54.970397 10672 solver.cpp:244]     Train net output #0: loss1 = 0.196976 (* 0.5 = 0.0984879 loss)
I0814 23:15:54.970413 10672 solver.cpp:244]     Train net output #1: loss2 = 0.420322 (* 0.5 = 0.210161 loss)
I0814 23:15:54.970427 10672 sgd_solver.cpp:106] Iteration 5680, lr = 8.58353e-05
I0814 23:16:00.468345 10672 solver.cpp:228] Iteration 5700, loss = 0.338802
I0814 23:16:00.468402 10672 solver.cpp:244]     Train net output #0: loss1 = 0.234278 (* 0.5 = 0.117139 loss)
I0814 23:16:00.468418 10672 solver.cpp:244]     Train net output #1: loss2 = 0.443327 (* 0.5 = 0.221663 loss)
I0814 23:16:00.468432 10672 sgd_solver.cpp:106] Iteration 5700, lr = 8.56097e-05
I0814 23:16:05.966886 10672 solver.cpp:228] Iteration 5720, loss = 0.246654
I0814 23:16:05.967003 10672 solver.cpp:244]     Train net output #0: loss1 = 0.138914 (* 0.5 = 0.0694572 loss)
I0814 23:16:05.967020 10672 solver.cpp:244]     Train net output #1: loss2 = 0.354394 (* 0.5 = 0.177197 loss)
I0814 23:16:05.967033 10672 sgd_solver.cpp:106] Iteration 5720, lr = 8.53855e-05
I0814 23:16:11.465251 10672 solver.cpp:228] Iteration 5740, loss = 0.372569
I0814 23:16:11.465308 10672 solver.cpp:244]     Train net output #0: loss1 = 0.294916 (* 0.5 = 0.147458 loss)
I0814 23:16:11.465324 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450222 (* 0.5 = 0.225111 loss)
I0814 23:16:11.465337 10672 sgd_solver.cpp:106] Iteration 5740, lr = 8.51626e-05
I0814 23:16:16.962198 10672 solver.cpp:228] Iteration 5760, loss = 0.339705
I0814 23:16:16.962256 10672 solver.cpp:244]     Train net output #0: loss1 = 0.205461 (* 0.5 = 0.102731 loss)
I0814 23:16:16.962272 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473949 (* 0.5 = 0.236974 loss)
I0814 23:16:16.962285 10672 sgd_solver.cpp:106] Iteration 5760, lr = 8.49412e-05
I0814 23:16:22.455390 10672 solver.cpp:228] Iteration 5780, loss = 0.404983
I0814 23:16:22.455449 10672 solver.cpp:244]     Train net output #0: loss1 = 0.221771 (* 0.5 = 0.110886 loss)
I0814 23:16:22.455464 10672 solver.cpp:244]     Train net output #1: loss2 = 0.588195 (* 0.5 = 0.294098 loss)
I0814 23:16:22.455478 10672 sgd_solver.cpp:106] Iteration 5780, lr = 8.4721e-05
I0814 23:16:27.951366 10672 solver.cpp:228] Iteration 5800, loss = 0.389281
I0814 23:16:27.951426 10672 solver.cpp:244]     Train net output #0: loss1 = 0.207747 (* 0.5 = 0.103873 loss)
I0814 23:16:27.951442 10672 solver.cpp:244]     Train net output #1: loss2 = 0.570816 (* 0.5 = 0.285408 loss)
I0814 23:16:27.951457 10672 sgd_solver.cpp:106] Iteration 5800, lr = 8.45022e-05
I0814 23:16:33.447569 10672 solver.cpp:228] Iteration 5820, loss = 0.275231
I0814 23:16:33.447626 10672 solver.cpp:244]     Train net output #0: loss1 = 0.182255 (* 0.5 = 0.0911277 loss)
I0814 23:16:33.447641 10672 solver.cpp:244]     Train net output #1: loss2 = 0.368207 (* 0.5 = 0.184104 loss)
I0814 23:16:33.447654 10672 sgd_solver.cpp:106] Iteration 5820, lr = 8.42847e-05
I0814 23:16:38.948943 10672 solver.cpp:228] Iteration 5840, loss = 0.306978
I0814 23:16:38.949084 10672 solver.cpp:244]     Train net output #0: loss1 = 0.181479 (* 0.5 = 0.0907397 loss)
I0814 23:16:38.949101 10672 solver.cpp:244]     Train net output #1: loss2 = 0.432476 (* 0.5 = 0.216238 loss)
I0814 23:16:38.949115 10672 sgd_solver.cpp:106] Iteration 5840, lr = 8.40685e-05
I0814 23:16:44.443423 10672 solver.cpp:228] Iteration 5860, loss = 0.318663
I0814 23:16:44.443485 10672 solver.cpp:244]     Train net output #0: loss1 = 0.163669 (* 0.5 = 0.0818343 loss)
I0814 23:16:44.443500 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473657 (* 0.5 = 0.236829 loss)
I0814 23:16:44.443512 10672 sgd_solver.cpp:106] Iteration 5860, lr = 8.38535e-05
I0814 23:16:50.110008 10672 solver.cpp:228] Iteration 5880, loss = 0.435802
I0814 23:16:50.110064 10672 solver.cpp:244]     Train net output #0: loss1 = 0.29109 (* 0.5 = 0.145545 loss)
I0814 23:16:50.110080 10672 solver.cpp:244]     Train net output #1: loss2 = 0.580513 (* 0.5 = 0.290256 loss)
I0814 23:16:50.110095 10672 sgd_solver.cpp:106] Iteration 5880, lr = 8.36399e-05
I0814 23:16:55.889201 10672 solver.cpp:228] Iteration 5900, loss = 0.357945
I0814 23:16:55.889257 10672 solver.cpp:244]     Train net output #0: loss1 = 0.284241 (* 0.5 = 0.142121 loss)
I0814 23:16:55.889274 10672 solver.cpp:244]     Train net output #1: loss2 = 0.43165 (* 0.5 = 0.215825 loss)
I0814 23:16:55.889287 10672 sgd_solver.cpp:106] Iteration 5900, lr = 8.34275e-05
I0814 23:17:01.493289 10672 solver.cpp:228] Iteration 5920, loss = 0.261298
I0814 23:17:01.493350 10672 solver.cpp:244]     Train net output #0: loss1 = 0.153083 (* 0.5 = 0.0765414 loss)
I0814 23:17:01.493366 10672 solver.cpp:244]     Train net output #1: loss2 = 0.369513 (* 0.5 = 0.184757 loss)
I0814 23:17:01.493381 10672 sgd_solver.cpp:106] Iteration 5920, lr = 8.32164e-05
I0814 23:17:07.012054 10672 solver.cpp:228] Iteration 5940, loss = 0.367033
I0814 23:17:07.012111 10672 solver.cpp:244]     Train net output #0: loss1 = 0.251793 (* 0.5 = 0.125896 loss)
I0814 23:17:07.012127 10672 solver.cpp:244]     Train net output #1: loss2 = 0.482273 (* 0.5 = 0.241137 loss)
I0814 23:17:07.012140 10672 sgd_solver.cpp:106] Iteration 5940, lr = 8.30065e-05
I0814 23:17:12.528023 10672 solver.cpp:228] Iteration 5960, loss = 0.289861
I0814 23:17:12.528147 10672 solver.cpp:244]     Train net output #0: loss1 = 0.190572 (* 0.5 = 0.0952861 loss)
I0814 23:17:12.528164 10672 solver.cpp:244]     Train net output #1: loss2 = 0.389151 (* 0.5 = 0.194575 loss)
I0814 23:17:12.528178 10672 sgd_solver.cpp:106] Iteration 5960, lr = 8.27979e-05
I0814 23:17:18.044791 10672 solver.cpp:228] Iteration 5980, loss = 0.300088
I0814 23:17:18.044849 10672 solver.cpp:244]     Train net output #0: loss1 = 0.175209 (* 0.5 = 0.0876043 loss)
I0814 23:17:18.044865 10672 solver.cpp:244]     Train net output #1: loss2 = 0.424968 (* 0.5 = 0.212484 loss)
I0814 23:17:18.044879 10672 sgd_solver.cpp:106] Iteration 5980, lr = 8.25905e-05
I0814 23:17:23.288305 10672 solver.cpp:337] Iteration 6000, Testing net (#0)
I0814 23:18:26.445302 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.704484
I0814 23:18:26.445412 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.908687
I0814 23:18:26.445431 10672 solver.cpp:404]     Test net output #2: loss1 = 0.289067 (* 0.5 = 0.144534 loss)
I0814 23:18:26.445444 10672 solver.cpp:404]     Test net output #3: loss2 = 0.591368 (* 0.5 = 0.295684 loss)
I0814 23:18:26.529374 10672 solver.cpp:228] Iteration 6000, loss = 0.298952
I0814 23:18:26.529430 10672 solver.cpp:244]     Train net output #0: loss1 = 0.168138 (* 0.5 = 0.0840688 loss)
I0814 23:18:26.529446 10672 solver.cpp:244]     Train net output #1: loss2 = 0.429767 (* 0.5 = 0.214884 loss)
I0814 23:18:26.529459 10672 sgd_solver.cpp:106] Iteration 6000, lr = 8.23842e-05
I0814 23:18:32.043826 10672 solver.cpp:228] Iteration 6020, loss = 0.339907
I0814 23:18:32.043886 10672 solver.cpp:244]     Train net output #0: loss1 = 0.185395 (* 0.5 = 0.0926976 loss)
I0814 23:18:32.043902 10672 solver.cpp:244]     Train net output #1: loss2 = 0.494418 (* 0.5 = 0.247209 loss)
I0814 23:18:32.043916 10672 sgd_solver.cpp:106] Iteration 6020, lr = 8.21792e-05
I0814 23:18:37.563071 10672 solver.cpp:228] Iteration 6040, loss = 0.393665
I0814 23:18:37.563128 10672 solver.cpp:244]     Train net output #0: loss1 = 0.343651 (* 0.5 = 0.171825 loss)
I0814 23:18:37.563143 10672 solver.cpp:244]     Train net output #1: loss2 = 0.443678 (* 0.5 = 0.221839 loss)
I0814 23:18:37.563156 10672 sgd_solver.cpp:106] Iteration 6040, lr = 8.19754e-05
I0814 23:18:43.076119 10672 solver.cpp:228] Iteration 6060, loss = 0.310173
I0814 23:18:43.076179 10672 solver.cpp:244]     Train net output #0: loss1 = 0.16989 (* 0.5 = 0.0849452 loss)
I0814 23:18:43.076195 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450456 (* 0.5 = 0.225228 loss)
I0814 23:18:43.076210 10672 sgd_solver.cpp:106] Iteration 6060, lr = 8.17727e-05
I0814 23:18:48.589859 10672 solver.cpp:228] Iteration 6080, loss = 0.383786
I0814 23:18:48.589915 10672 solver.cpp:244]     Train net output #0: loss1 = 0.293177 (* 0.5 = 0.146589 loss)
I0814 23:18:48.589931 10672 solver.cpp:244]     Train net output #1: loss2 = 0.474395 (* 0.5 = 0.237198 loss)
I0814 23:18:48.589946 10672 sgd_solver.cpp:106] Iteration 6080, lr = 8.15712e-05
I0814 23:18:54.107974 10672 solver.cpp:228] Iteration 6100, loss = 0.287396
I0814 23:18:54.108031 10672 solver.cpp:244]     Train net output #0: loss1 = 0.171241 (* 0.5 = 0.0856206 loss)
I0814 23:18:54.108045 10672 solver.cpp:244]     Train net output #1: loss2 = 0.40355 (* 0.5 = 0.201775 loss)
I0814 23:18:54.108059 10672 sgd_solver.cpp:106] Iteration 6100, lr = 8.13709e-05
I0814 23:18:59.621886 10672 solver.cpp:228] Iteration 6120, loss = 0.29607
I0814 23:18:59.622061 10672 solver.cpp:244]     Train net output #0: loss1 = 0.150174 (* 0.5 = 0.075087 loss)
I0814 23:18:59.622086 10672 solver.cpp:244]     Train net output #1: loss2 = 0.441965 (* 0.5 = 0.220983 loss)
I0814 23:18:59.622102 10672 sgd_solver.cpp:106] Iteration 6120, lr = 8.11717e-05
I0814 23:19:05.144347 10672 solver.cpp:228] Iteration 6140, loss = 0.318629
I0814 23:19:05.144404 10672 solver.cpp:244]     Train net output #0: loss1 = 0.178913 (* 0.5 = 0.0894567 loss)
I0814 23:19:05.144420 10672 solver.cpp:244]     Train net output #1: loss2 = 0.458345 (* 0.5 = 0.229173 loss)
I0814 23:19:05.144433 10672 sgd_solver.cpp:106] Iteration 6140, lr = 8.09736e-05
I0814 23:19:10.656239 10672 solver.cpp:228] Iteration 6160, loss = 0.296379
I0814 23:19:10.656297 10672 solver.cpp:244]     Train net output #0: loss1 = 0.147219 (* 0.5 = 0.0736096 loss)
I0814 23:19:10.656312 10672 solver.cpp:244]     Train net output #1: loss2 = 0.445538 (* 0.5 = 0.222769 loss)
I0814 23:19:10.656327 10672 sgd_solver.cpp:106] Iteration 6160, lr = 8.07767e-05
I0814 23:19:16.173745 10672 solver.cpp:228] Iteration 6180, loss = 0.333077
I0814 23:19:16.173804 10672 solver.cpp:244]     Train net output #0: loss1 = 0.192983 (* 0.5 = 0.0964913 loss)
I0814 23:19:16.173820 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473172 (* 0.5 = 0.236586 loss)
I0814 23:19:16.173833 10672 sgd_solver.cpp:106] Iteration 6180, lr = 8.05809e-05
I0814 23:19:21.696238 10672 solver.cpp:228] Iteration 6200, loss = 0.339183
I0814 23:19:21.696298 10672 solver.cpp:244]     Train net output #0: loss1 = 0.226709 (* 0.5 = 0.113354 loss)
I0814 23:19:21.696315 10672 solver.cpp:244]     Train net output #1: loss2 = 0.451658 (* 0.5 = 0.225829 loss)
I0814 23:19:21.696328 10672 sgd_solver.cpp:106] Iteration 6200, lr = 8.03862e-05
I0814 23:19:27.212580 10672 solver.cpp:228] Iteration 6220, loss = 0.323682
I0814 23:19:27.212641 10672 solver.cpp:244]     Train net output #0: loss1 = 0.192644 (* 0.5 = 0.0963222 loss)
I0814 23:19:27.212656 10672 solver.cpp:244]     Train net output #1: loss2 = 0.454721 (* 0.5 = 0.22736 loss)
I0814 23:19:27.212671 10672 sgd_solver.cpp:106] Iteration 6220, lr = 8.01925e-05
I0814 23:19:32.729295 10672 solver.cpp:228] Iteration 6240, loss = 0.304205
I0814 23:19:32.729471 10672 solver.cpp:244]     Train net output #0: loss1 = 0.156051 (* 0.5 = 0.0780254 loss)
I0814 23:19:32.729490 10672 solver.cpp:244]     Train net output #1: loss2 = 0.452358 (* 0.5 = 0.226179 loss)
I0814 23:19:32.729503 10672 sgd_solver.cpp:106] Iteration 6240, lr = 8e-05
I0814 23:19:38.252982 10672 solver.cpp:228] Iteration 6260, loss = 0.311982
I0814 23:19:38.253042 10672 solver.cpp:244]     Train net output #0: loss1 = 0.113156 (* 0.5 = 0.056578 loss)
I0814 23:19:38.253058 10672 solver.cpp:244]     Train net output #1: loss2 = 0.510809 (* 0.5 = 0.255404 loss)
I0814 23:19:38.253072 10672 sgd_solver.cpp:106] Iteration 6260, lr = 7.98085e-05
I0814 23:19:43.769843 10672 solver.cpp:228] Iteration 6280, loss = 0.382013
I0814 23:19:43.769902 10672 solver.cpp:244]     Train net output #0: loss1 = 0.217433 (* 0.5 = 0.108716 loss)
I0814 23:19:43.769918 10672 solver.cpp:244]     Train net output #1: loss2 = 0.546593 (* 0.5 = 0.273297 loss)
I0814 23:19:43.769932 10672 sgd_solver.cpp:106] Iteration 6280, lr = 7.96181e-05
I0814 23:19:49.282074 10672 solver.cpp:228] Iteration 6300, loss = 0.306881
I0814 23:19:49.282135 10672 solver.cpp:244]     Train net output #0: loss1 = 0.214328 (* 0.5 = 0.107164 loss)
I0814 23:19:49.282150 10672 solver.cpp:244]     Train net output #1: loss2 = 0.399434 (* 0.5 = 0.199717 loss)
I0814 23:19:49.282163 10672 sgd_solver.cpp:106] Iteration 6300, lr = 7.94288e-05
I0814 23:19:54.801066 10672 solver.cpp:228] Iteration 6320, loss = 0.301262
I0814 23:19:54.801127 10672 solver.cpp:244]     Train net output #0: loss1 = 0.127534 (* 0.5 = 0.0637669 loss)
I0814 23:19:54.801143 10672 solver.cpp:244]     Train net output #1: loss2 = 0.47499 (* 0.5 = 0.237495 loss)
I0814 23:19:54.801156 10672 sgd_solver.cpp:106] Iteration 6320, lr = 7.92405e-05
I0814 23:20:00.324478 10672 solver.cpp:228] Iteration 6340, loss = 0.349461
I0814 23:20:00.324538 10672 solver.cpp:244]     Train net output #0: loss1 = 0.289822 (* 0.5 = 0.144911 loss)
I0814 23:20:00.324554 10672 solver.cpp:244]     Train net output #1: loss2 = 0.409101 (* 0.5 = 0.204551 loss)
I0814 23:20:00.324568 10672 sgd_solver.cpp:106] Iteration 6340, lr = 7.90532e-05
I0814 23:20:05.838708 10672 solver.cpp:228] Iteration 6360, loss = 0.299349
I0814 23:20:05.838829 10672 solver.cpp:244]     Train net output #0: loss1 = 0.182637 (* 0.5 = 0.0913187 loss)
I0814 23:20:05.838845 10672 solver.cpp:244]     Train net output #1: loss2 = 0.416061 (* 0.5 = 0.208031 loss)
I0814 23:20:05.838858 10672 sgd_solver.cpp:106] Iteration 6360, lr = 7.8867e-05
I0814 23:20:11.357538 10672 solver.cpp:228] Iteration 6380, loss = 0.354506
I0814 23:20:11.357594 10672 solver.cpp:244]     Train net output #0: loss1 = 0.263519 (* 0.5 = 0.131759 loss)
I0814 23:20:11.357609 10672 solver.cpp:244]     Train net output #1: loss2 = 0.445494 (* 0.5 = 0.222747 loss)
I0814 23:20:11.357623 10672 sgd_solver.cpp:106] Iteration 6380, lr = 7.86818e-05
I0814 23:20:16.876451 10672 solver.cpp:228] Iteration 6400, loss = 0.338188
I0814 23:20:16.876509 10672 solver.cpp:244]     Train net output #0: loss1 = 0.310382 (* 0.5 = 0.155191 loss)
I0814 23:20:16.876525 10672 solver.cpp:244]     Train net output #1: loss2 = 0.365995 (* 0.5 = 0.182997 loss)
I0814 23:20:16.876539 10672 sgd_solver.cpp:106] Iteration 6400, lr = 7.84976e-05
I0814 23:20:22.389909 10672 solver.cpp:228] Iteration 6420, loss = 0.41928
I0814 23:20:22.389963 10672 solver.cpp:244]     Train net output #0: loss1 = 0.332865 (* 0.5 = 0.166432 loss)
I0814 23:20:22.389979 10672 solver.cpp:244]     Train net output #1: loss2 = 0.505695 (* 0.5 = 0.252848 loss)
I0814 23:20:22.389992 10672 sgd_solver.cpp:106] Iteration 6420, lr = 7.83144e-05
I0814 23:20:27.909749 10672 solver.cpp:228] Iteration 6440, loss = 0.382336
I0814 23:20:27.909811 10672 solver.cpp:244]     Train net output #0: loss1 = 0.193298 (* 0.5 = 0.0966488 loss)
I0814 23:20:27.909826 10672 solver.cpp:244]     Train net output #1: loss2 = 0.571374 (* 0.5 = 0.285687 loss)
I0814 23:20:27.909840 10672 sgd_solver.cpp:106] Iteration 6440, lr = 7.81322e-05
I0814 23:20:33.425005 10672 solver.cpp:228] Iteration 6460, loss = 0.302729
I0814 23:20:33.425065 10672 solver.cpp:244]     Train net output #0: loss1 = 0.165094 (* 0.5 = 0.0825472 loss)
I0814 23:20:33.425079 10672 solver.cpp:244]     Train net output #1: loss2 = 0.440364 (* 0.5 = 0.220182 loss)
I0814 23:20:33.425093 10672 sgd_solver.cpp:106] Iteration 6460, lr = 7.7951e-05
I0814 23:20:38.945513 10672 solver.cpp:228] Iteration 6480, loss = 0.294037
I0814 23:20:38.945713 10672 solver.cpp:244]     Train net output #0: loss1 = 0.202126 (* 0.5 = 0.101063 loss)
I0814 23:20:38.945734 10672 solver.cpp:244]     Train net output #1: loss2 = 0.385947 (* 0.5 = 0.192974 loss)
I0814 23:20:38.945747 10672 sgd_solver.cpp:106] Iteration 6480, lr = 7.77708e-05
I0814 23:20:44.462678 10672 solver.cpp:228] Iteration 6500, loss = 0.294349
I0814 23:20:44.462738 10672 solver.cpp:244]     Train net output #0: loss1 = 0.170931 (* 0.5 = 0.0854654 loss)
I0814 23:20:44.462754 10672 solver.cpp:244]     Train net output #1: loss2 = 0.417766 (* 0.5 = 0.208883 loss)
I0814 23:20:44.462769 10672 sgd_solver.cpp:106] Iteration 6500, lr = 7.75915e-05
I0814 23:20:49.982036 10672 solver.cpp:228] Iteration 6520, loss = 0.298704
I0814 23:20:49.982098 10672 solver.cpp:244]     Train net output #0: loss1 = 0.231584 (* 0.5 = 0.115792 loss)
I0814 23:20:49.982113 10672 solver.cpp:244]     Train net output #1: loss2 = 0.365823 (* 0.5 = 0.182912 loss)
I0814 23:20:49.982127 10672 sgd_solver.cpp:106] Iteration 6520, lr = 7.74132e-05
I0814 23:20:55.500087 10672 solver.cpp:228] Iteration 6540, loss = 0.351091
I0814 23:20:55.500145 10672 solver.cpp:244]     Train net output #0: loss1 = 0.220008 (* 0.5 = 0.110004 loss)
I0814 23:20:55.500161 10672 solver.cpp:244]     Train net output #1: loss2 = 0.482175 (* 0.5 = 0.241087 loss)
I0814 23:20:55.500174 10672 sgd_solver.cpp:106] Iteration 6540, lr = 7.72359e-05
I0814 23:21:01.022047 10672 solver.cpp:228] Iteration 6560, loss = 0.292011
I0814 23:21:01.022106 10672 solver.cpp:244]     Train net output #0: loss1 = 0.195564 (* 0.5 = 0.0977818 loss)
I0814 23:21:01.022122 10672 solver.cpp:244]     Train net output #1: loss2 = 0.388458 (* 0.5 = 0.194229 loss)
I0814 23:21:01.022136 10672 sgd_solver.cpp:106] Iteration 6560, lr = 7.70595e-05
I0814 23:21:06.540971 10672 solver.cpp:228] Iteration 6580, loss = 0.338014
I0814 23:21:06.541030 10672 solver.cpp:244]     Train net output #0: loss1 = 0.216878 (* 0.5 = 0.108439 loss)
I0814 23:21:06.541046 10672 solver.cpp:244]     Train net output #1: loss2 = 0.45915 (* 0.5 = 0.229575 loss)
I0814 23:21:06.541059 10672 sgd_solver.cpp:106] Iteration 6580, lr = 7.6884e-05
I0814 23:21:12.056174 10672 solver.cpp:228] Iteration 6600, loss = 0.352895
I0814 23:21:12.058643 10672 solver.cpp:244]     Train net output #0: loss1 = 0.215759 (* 0.5 = 0.107879 loss)
I0814 23:21:12.058662 10672 solver.cpp:244]     Train net output #1: loss2 = 0.49003 (* 0.5 = 0.245015 loss)
I0814 23:21:12.058677 10672 sgd_solver.cpp:106] Iteration 6600, lr = 7.67095e-05
I0814 23:21:17.574582 10672 solver.cpp:228] Iteration 6620, loss = 0.327797
I0814 23:21:17.574641 10672 solver.cpp:244]     Train net output #0: loss1 = 0.182247 (* 0.5 = 0.0911235 loss)
I0814 23:21:17.574656 10672 solver.cpp:244]     Train net output #1: loss2 = 0.473348 (* 0.5 = 0.236674 loss)
I0814 23:21:17.574671 10672 sgd_solver.cpp:106] Iteration 6620, lr = 7.65358e-05
I0814 23:21:23.090126 10672 solver.cpp:228] Iteration 6640, loss = 0.35688
I0814 23:21:23.090183 10672 solver.cpp:244]     Train net output #0: loss1 = 0.207728 (* 0.5 = 0.103864 loss)
I0814 23:21:23.090198 10672 solver.cpp:244]     Train net output #1: loss2 = 0.506033 (* 0.5 = 0.253016 loss)
I0814 23:21:23.090210 10672 sgd_solver.cpp:106] Iteration 6640, lr = 7.63631e-05
I0814 23:21:28.608490 10672 solver.cpp:228] Iteration 6660, loss = 0.293507
I0814 23:21:28.608551 10672 solver.cpp:244]     Train net output #0: loss1 = 0.116646 (* 0.5 = 0.0583229 loss)
I0814 23:21:28.608566 10672 solver.cpp:244]     Train net output #1: loss2 = 0.470369 (* 0.5 = 0.235184 loss)
I0814 23:21:28.608580 10672 sgd_solver.cpp:106] Iteration 6660, lr = 7.61913e-05
I0814 23:21:34.123452 10672 solver.cpp:228] Iteration 6680, loss = 0.294935
I0814 23:21:34.123512 10672 solver.cpp:244]     Train net output #0: loss1 = 0.150402 (* 0.5 = 0.0752009 loss)
I0814 23:21:34.123528 10672 solver.cpp:244]     Train net output #1: loss2 = 0.439467 (* 0.5 = 0.219734 loss)
I0814 23:21:34.123540 10672 sgd_solver.cpp:106] Iteration 6680, lr = 7.60204e-05
I0814 23:21:39.639940 10672 solver.cpp:228] Iteration 6700, loss = 0.268685
I0814 23:21:39.639997 10672 solver.cpp:244]     Train net output #0: loss1 = 0.147196 (* 0.5 = 0.0735981 loss)
I0814 23:21:39.640012 10672 solver.cpp:244]     Train net output #1: loss2 = 0.390173 (* 0.5 = 0.195087 loss)
I0814 23:21:39.640027 10672 sgd_solver.cpp:106] Iteration 6700, lr = 7.58504e-05
I0814 23:21:45.159448 10672 solver.cpp:228] Iteration 6720, loss = 0.275073
I0814 23:21:45.159631 10672 solver.cpp:244]     Train net output #0: loss1 = 0.120786 (* 0.5 = 0.0603929 loss)
I0814 23:21:45.159654 10672 solver.cpp:244]     Train net output #1: loss2 = 0.429359 (* 0.5 = 0.21468 loss)
I0814 23:21:45.159672 10672 sgd_solver.cpp:106] Iteration 6720, lr = 7.56813e-05
I0814 23:21:50.679388 10672 solver.cpp:228] Iteration 6740, loss = 0.263666
I0814 23:21:50.679445 10672 solver.cpp:244]     Train net output #0: loss1 = 0.135091 (* 0.5 = 0.0675456 loss)
I0814 23:21:50.679461 10672 solver.cpp:244]     Train net output #1: loss2 = 0.392241 (* 0.5 = 0.196121 loss)
I0814 23:21:50.679474 10672 sgd_solver.cpp:106] Iteration 6740, lr = 7.55131e-05
I0814 23:21:56.192502 10672 solver.cpp:228] Iteration 6760, loss = 0.372392
I0814 23:21:56.192555 10672 solver.cpp:244]     Train net output #0: loss1 = 0.309609 (* 0.5 = 0.154804 loss)
I0814 23:21:56.192571 10672 solver.cpp:244]     Train net output #1: loss2 = 0.435175 (* 0.5 = 0.217588 loss)
I0814 23:21:56.192584 10672 sgd_solver.cpp:106] Iteration 6760, lr = 7.53457e-05
I0814 23:22:01.717190 10672 solver.cpp:228] Iteration 6780, loss = 0.290787
I0814 23:22:01.717247 10672 solver.cpp:244]     Train net output #0: loss1 = 0.177827 (* 0.5 = 0.0889134 loss)
I0814 23:22:01.717263 10672 solver.cpp:244]     Train net output #1: loss2 = 0.403747 (* 0.5 = 0.201874 loss)
I0814 23:22:01.717278 10672 sgd_solver.cpp:106] Iteration 6780, lr = 7.51792e-05
I0814 23:22:07.234230 10672 solver.cpp:228] Iteration 6800, loss = 0.29908
I0814 23:22:07.234287 10672 solver.cpp:244]     Train net output #0: loss1 = 0.16363 (* 0.5 = 0.0818151 loss)
I0814 23:22:07.234303 10672 solver.cpp:244]     Train net output #1: loss2 = 0.43453 (* 0.5 = 0.217265 loss)
I0814 23:22:07.234318 10672 sgd_solver.cpp:106] Iteration 6800, lr = 7.50135e-05
I0814 23:22:12.752404 10672 solver.cpp:228] Iteration 6820, loss = 0.32684
I0814 23:22:12.752460 10672 solver.cpp:244]     Train net output #0: loss1 = 0.190302 (* 0.5 = 0.0951509 loss)
I0814 23:22:12.752476 10672 solver.cpp:244]     Train net output #1: loss2 = 0.463378 (* 0.5 = 0.231689 loss)
I0814 23:22:12.752490 10672 sgd_solver.cpp:106] Iteration 6820, lr = 7.48487e-05
I0814 23:22:18.267799 10672 solver.cpp:228] Iteration 6840, loss = 0.327763
I0814 23:22:18.267897 10672 solver.cpp:244]     Train net output #0: loss1 = 0.184129 (* 0.5 = 0.0920646 loss)
I0814 23:22:18.267913 10672 solver.cpp:244]     Train net output #1: loss2 = 0.471396 (* 0.5 = 0.235698 loss)
I0814 23:22:18.267927 10672 sgd_solver.cpp:106] Iteration 6840, lr = 7.46848e-05
I0814 23:22:23.788846 10672 solver.cpp:228] Iteration 6860, loss = 0.289662
I0814 23:22:23.788908 10672 solver.cpp:244]     Train net output #0: loss1 = 0.136661 (* 0.5 = 0.0683303 loss)
I0814 23:22:23.788923 10672 solver.cpp:244]     Train net output #1: loss2 = 0.442664 (* 0.5 = 0.221332 loss)
I0814 23:22:23.788938 10672 sgd_solver.cpp:106] Iteration 6860, lr = 7.45216e-05
I0814 23:22:29.305866 10672 solver.cpp:228] Iteration 6880, loss = 0.314521
I0814 23:22:29.305927 10672 solver.cpp:244]     Train net output #0: loss1 = 0.178422 (* 0.5 = 0.0892111 loss)
I0814 23:22:29.305943 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450621 (* 0.5 = 0.22531 loss)
I0814 23:22:29.305956 10672 sgd_solver.cpp:106] Iteration 6880, lr = 7.43593e-05
I0814 23:22:34.823484 10672 solver.cpp:228] Iteration 6900, loss = 0.320971
I0814 23:22:34.823545 10672 solver.cpp:244]     Train net output #0: loss1 = 0.234833 (* 0.5 = 0.117416 loss)
I0814 23:22:34.823561 10672 solver.cpp:244]     Train net output #1: loss2 = 0.407109 (* 0.5 = 0.203554 loss)
I0814 23:22:34.823575 10672 sgd_solver.cpp:106] Iteration 6900, lr = 7.41979e-05
I0814 23:22:40.344569 10672 solver.cpp:228] Iteration 6920, loss = 0.310086
I0814 23:22:40.344660 10672 solver.cpp:244]     Train net output #0: loss1 = 0.202184 (* 0.5 = 0.101092 loss)
I0814 23:22:40.344689 10672 solver.cpp:244]     Train net output #1: loss2 = 0.417988 (* 0.5 = 0.208994 loss)
I0814 23:22:40.344719 10672 sgd_solver.cpp:106] Iteration 6920, lr = 7.40372e-05
I0814 23:22:45.864178 10672 solver.cpp:228] Iteration 6940, loss = 0.33778
I0814 23:22:45.864235 10672 solver.cpp:244]     Train net output #0: loss1 = 0.181138 (* 0.5 = 0.0905688 loss)
I0814 23:22:45.864251 10672 solver.cpp:244]     Train net output #1: loss2 = 0.494423 (* 0.5 = 0.247212 loss)
I0814 23:22:45.864264 10672 sgd_solver.cpp:106] Iteration 6940, lr = 7.38774e-05
I0814 23:22:51.383458 10672 solver.cpp:228] Iteration 6960, loss = 0.356943
I0814 23:22:51.383607 10672 solver.cpp:244]     Train net output #0: loss1 = 0.234788 (* 0.5 = 0.117394 loss)
I0814 23:22:51.383626 10672 solver.cpp:244]     Train net output #1: loss2 = 0.479097 (* 0.5 = 0.239549 loss)
I0814 23:22:51.383641 10672 sgd_solver.cpp:106] Iteration 6960, lr = 7.37183e-05
I0814 23:22:56.900960 10672 solver.cpp:228] Iteration 6980, loss = 0.311325
I0814 23:22:56.901020 10672 solver.cpp:244]     Train net output #0: loss1 = 0.208489 (* 0.5 = 0.104245 loss)
I0814 23:22:56.901036 10672 solver.cpp:244]     Train net output #1: loss2 = 0.41416 (* 0.5 = 0.20708 loss)
I0814 23:22:56.901049 10672 sgd_solver.cpp:106] Iteration 6980, lr = 7.35601e-05
I0814 23:23:02.148735 10672 solver.cpp:337] Iteration 7000, Testing net (#0)
I0814 23:24:05.296510 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.696703
I0814 23:24:05.296651 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.906641
I0814 23:24:05.296679 10672 solver.cpp:404]     Test net output #2: loss1 = 0.272495 (* 0.5 = 0.136247 loss)
I0814 23:24:05.296696 10672 solver.cpp:404]     Test net output #3: loss2 = 0.600332 (* 0.5 = 0.300166 loss)
I0814 23:24:05.382773 10672 solver.cpp:228] Iteration 7000, loss = 0.313124
I0814 23:24:05.382879 10672 solver.cpp:244]     Train net output #0: loss1 = 0.181652 (* 0.5 = 0.0908258 loss)
I0814 23:24:05.382899 10672 solver.cpp:244]     Train net output #1: loss2 = 0.444597 (* 0.5 = 0.222298 loss)
I0814 23:24:05.382915 10672 sgd_solver.cpp:106] Iteration 7000, lr = 7.34026e-05
I0814 23:24:10.898524 10672 solver.cpp:228] Iteration 7020, loss = 0.289511
I0814 23:24:10.898583 10672 solver.cpp:244]     Train net output #0: loss1 = 0.145748 (* 0.5 = 0.0728738 loss)
I0814 23:24:10.898599 10672 solver.cpp:244]     Train net output #1: loss2 = 0.433275 (* 0.5 = 0.216638 loss)
I0814 23:24:10.898613 10672 sgd_solver.cpp:106] Iteration 7020, lr = 7.32459e-05
I0814 23:24:16.416419 10672 solver.cpp:228] Iteration 7040, loss = 0.352085
I0814 23:24:16.416474 10672 solver.cpp:244]     Train net output #0: loss1 = 0.181081 (* 0.5 = 0.0905405 loss)
I0814 23:24:16.416491 10672 solver.cpp:244]     Train net output #1: loss2 = 0.523089 (* 0.5 = 0.261544 loss)
I0814 23:24:16.416504 10672 sgd_solver.cpp:106] Iteration 7040, lr = 7.309e-05
I0814 23:24:21.931648 10672 solver.cpp:228] Iteration 7060, loss = 0.353702
I0814 23:24:21.931706 10672 solver.cpp:244]     Train net output #0: loss1 = 0.22667 (* 0.5 = 0.113335 loss)
I0814 23:24:21.931722 10672 solver.cpp:244]     Train net output #1: loss2 = 0.480735 (* 0.5 = 0.240368 loss)
I0814 23:24:21.931735 10672 sgd_solver.cpp:106] Iteration 7060, lr = 7.29349e-05
I0814 23:24:27.450486 10672 solver.cpp:228] Iteration 7080, loss = 0.317866
I0814 23:24:27.450546 10672 solver.cpp:244]     Train net output #0: loss1 = 0.192529 (* 0.5 = 0.0962647 loss)
I0814 23:24:27.450567 10672 solver.cpp:244]     Train net output #1: loss2 = 0.443203 (* 0.5 = 0.221602 loss)
I0814 23:24:27.450580 10672 sgd_solver.cpp:106] Iteration 7080, lr = 7.27805e-05
I0814 23:24:32.968370 10672 solver.cpp:228] Iteration 7100, loss = 0.270141
I0814 23:24:32.968427 10672 solver.cpp:244]     Train net output #0: loss1 = 0.159128 (* 0.5 = 0.0795642 loss)
I0814 23:24:32.968443 10672 solver.cpp:244]     Train net output #1: loss2 = 0.381154 (* 0.5 = 0.190577 loss)
I0814 23:24:32.968456 10672 sgd_solver.cpp:106] Iteration 7100, lr = 7.26269e-05
I0814 23:24:38.491755 10672 solver.cpp:228] Iteration 7120, loss = 0.340045
I0814 23:24:38.491906 10672 solver.cpp:244]     Train net output #0: loss1 = 0.218184 (* 0.5 = 0.109092 loss)
I0814 23:24:38.491925 10672 solver.cpp:244]     Train net output #1: loss2 = 0.461906 (* 0.5 = 0.230953 loss)
I0814 23:24:38.491938 10672 sgd_solver.cpp:106] Iteration 7120, lr = 7.24741e-05
I0814 23:24:44.006513 10672 solver.cpp:228] Iteration 7140, loss = 0.320438
I0814 23:24:44.006574 10672 solver.cpp:244]     Train net output #0: loss1 = 0.2206 (* 0.5 = 0.1103 loss)
I0814 23:24:44.006590 10672 solver.cpp:244]     Train net output #1: loss2 = 0.420276 (* 0.5 = 0.210138 loss)
I0814 23:24:44.006604 10672 sgd_solver.cpp:106] Iteration 7140, lr = 7.2322e-05
I0814 23:24:49.521631 10672 solver.cpp:228] Iteration 7160, loss = 0.342125
I0814 23:24:49.521682 10672 solver.cpp:244]     Train net output #0: loss1 = 0.2475 (* 0.5 = 0.12375 loss)
I0814 23:24:49.521698 10672 solver.cpp:244]     Train net output #1: loss2 = 0.43675 (* 0.5 = 0.218375 loss)
I0814 23:24:49.521711 10672 sgd_solver.cpp:106] Iteration 7160, lr = 7.21707e-05
I0814 23:24:55.037781 10672 solver.cpp:228] Iteration 7180, loss = 0.334243
I0814 23:24:55.037838 10672 solver.cpp:244]     Train net output #0: loss1 = 0.15377 (* 0.5 = 0.0768852 loss)
I0814 23:24:55.037854 10672 solver.cpp:244]     Train net output #1: loss2 = 0.514715 (* 0.5 = 0.257358 loss)
I0814 23:24:55.037868 10672 sgd_solver.cpp:106] Iteration 7180, lr = 7.202e-05
I0814 23:25:00.554761 10672 solver.cpp:228] Iteration 7200, loss = 0.297207
I0814 23:25:00.554821 10672 solver.cpp:244]     Train net output #0: loss1 = 0.173292 (* 0.5 = 0.0866461 loss)
I0814 23:25:00.554836 10672 solver.cpp:244]     Train net output #1: loss2 = 0.421122 (* 0.5 = 0.210561 loss)
I0814 23:25:00.554850 10672 sgd_solver.cpp:106] Iteration 7200, lr = 7.18701e-05
I0814 23:25:06.076432 10672 solver.cpp:228] Iteration 7220, loss = 0.307309
I0814 23:25:06.076490 10672 solver.cpp:244]     Train net output #0: loss1 = 0.136406 (* 0.5 = 0.0682028 loss)
I0814 23:25:06.076506 10672 solver.cpp:244]     Train net output #1: loss2 = 0.478213 (* 0.5 = 0.239107 loss)
I0814 23:25:06.076521 10672 sgd_solver.cpp:106] Iteration 7220, lr = 7.1721e-05
I0814 23:25:11.590003 10672 solver.cpp:228] Iteration 7240, loss = 0.229754
I0814 23:25:11.590123 10672 solver.cpp:244]     Train net output #0: loss1 = 0.177648 (* 0.5 = 0.0888241 loss)
I0814 23:25:11.590142 10672 solver.cpp:244]     Train net output #1: loss2 = 0.281859 (* 0.5 = 0.14093 loss)
I0814 23:25:11.590154 10672 sgd_solver.cpp:106] Iteration 7240, lr = 7.15725e-05
I0814 23:25:17.106266 10672 solver.cpp:228] Iteration 7260, loss = 0.358138
I0814 23:25:17.106325 10672 solver.cpp:244]     Train net output #0: loss1 = 0.173142 (* 0.5 = 0.0865708 loss)
I0814 23:25:17.106341 10672 solver.cpp:244]     Train net output #1: loss2 = 0.543134 (* 0.5 = 0.271567 loss)
I0814 23:25:17.106354 10672 sgd_solver.cpp:106] Iteration 7260, lr = 7.14248e-05
I0814 23:25:22.625077 10672 solver.cpp:228] Iteration 7280, loss = 0.262376
I0814 23:25:22.625135 10672 solver.cpp:244]     Train net output #0: loss1 = 0.116442 (* 0.5 = 0.0582211 loss)
I0814 23:25:22.625152 10672 solver.cpp:244]     Train net output #1: loss2 = 0.408311 (* 0.5 = 0.204155 loss)
I0814 23:25:22.625165 10672 sgd_solver.cpp:106] Iteration 7280, lr = 7.12778e-05
I0814 23:25:28.138137 10672 solver.cpp:228] Iteration 7300, loss = 0.361072
I0814 23:25:28.138195 10672 solver.cpp:244]     Train net output #0: loss1 = 0.195841 (* 0.5 = 0.0979204 loss)
I0814 23:25:28.138211 10672 solver.cpp:244]     Train net output #1: loss2 = 0.526303 (* 0.5 = 0.263151 loss)
I0814 23:25:28.138226 10672 sgd_solver.cpp:106] Iteration 7300, lr = 7.11315e-05
I0814 23:25:33.660886 10672 solver.cpp:228] Iteration 7320, loss = 0.346911
I0814 23:25:33.660944 10672 solver.cpp:244]     Train net output #0: loss1 = 0.302788 (* 0.5 = 0.151394 loss)
I0814 23:25:33.660960 10672 solver.cpp:244]     Train net output #1: loss2 = 0.391034 (* 0.5 = 0.195517 loss)
I0814 23:25:33.660974 10672 sgd_solver.cpp:106] Iteration 7320, lr = 7.09859e-05
I0814 23:25:39.175871 10672 solver.cpp:228] Iteration 7340, loss = 0.366567
I0814 23:25:39.175935 10672 solver.cpp:244]     Train net output #0: loss1 = 0.199626 (* 0.5 = 0.0998131 loss)
I0814 23:25:39.175951 10672 solver.cpp:244]     Train net output #1: loss2 = 0.533507 (* 0.5 = 0.266754 loss)
I0814 23:25:39.175966 10672 sgd_solver.cpp:106] Iteration 7340, lr = 7.0841e-05
I0814 23:25:44.692124 10672 solver.cpp:228] Iteration 7360, loss = 0.333627
I0814 23:25:44.692272 10672 solver.cpp:244]     Train net output #0: loss1 = 0.263177 (* 0.5 = 0.131588 loss)
I0814 23:25:44.692291 10672 solver.cpp:244]     Train net output #1: loss2 = 0.404078 (* 0.5 = 0.202039 loss)
I0814 23:25:44.692306 10672 sgd_solver.cpp:106] Iteration 7360, lr = 7.06967e-05
I0814 23:25:50.212702 10672 solver.cpp:228] Iteration 7380, loss = 0.313782
I0814 23:25:50.212761 10672 solver.cpp:244]     Train net output #0: loss1 = 0.17329 (* 0.5 = 0.0866448 loss)
I0814 23:25:50.212779 10672 solver.cpp:244]     Train net output #1: loss2 = 0.454274 (* 0.5 = 0.227137 loss)
I0814 23:25:50.212793 10672 sgd_solver.cpp:106] Iteration 7380, lr = 7.05532e-05
I0814 23:25:55.726800 10672 solver.cpp:228] Iteration 7400, loss = 0.261508
I0814 23:25:55.726857 10672 solver.cpp:244]     Train net output #0: loss1 = 0.164375 (* 0.5 = 0.0821876 loss)
I0814 23:25:55.726873 10672 solver.cpp:244]     Train net output #1: loss2 = 0.358641 (* 0.5 = 0.17932 loss)
I0814 23:25:55.726886 10672 sgd_solver.cpp:106] Iteration 7400, lr = 7.04103e-05
I0814 23:26:01.250970 10672 solver.cpp:228] Iteration 7420, loss = 0.35626
I0814 23:26:01.251031 10672 solver.cpp:244]     Train net output #0: loss1 = 0.23751 (* 0.5 = 0.118755 loss)
I0814 23:26:01.251049 10672 solver.cpp:244]     Train net output #1: loss2 = 0.47501 (* 0.5 = 0.237505 loss)
I0814 23:26:01.251061 10672 sgd_solver.cpp:106] Iteration 7420, lr = 7.02681e-05
I0814 23:26:06.767298 10672 solver.cpp:228] Iteration 7440, loss = 0.297667
I0814 23:26:06.767372 10672 solver.cpp:244]     Train net output #0: loss1 = 0.221516 (* 0.5 = 0.110758 loss)
I0814 23:26:06.767397 10672 solver.cpp:244]     Train net output #1: loss2 = 0.373817 (* 0.5 = 0.186908 loss)
I0814 23:26:06.767418 10672 sgd_solver.cpp:106] Iteration 7440, lr = 7.01266e-05
I0814 23:26:12.282804 10672 solver.cpp:228] Iteration 7460, loss = 0.306828
I0814 23:26:12.282860 10672 solver.cpp:244]     Train net output #0: loss1 = 0.165038 (* 0.5 = 0.0825189 loss)
I0814 23:26:12.282876 10672 solver.cpp:244]     Train net output #1: loss2 = 0.448618 (* 0.5 = 0.224309 loss)
I0814 23:26:12.282889 10672 sgd_solver.cpp:106] Iteration 7460, lr = 6.99857e-05
I0814 23:26:17.801678 10672 solver.cpp:228] Iteration 7480, loss = 0.270809
I0814 23:26:17.801836 10672 solver.cpp:244]     Train net output #0: loss1 = 0.156022 (* 0.5 = 0.0780111 loss)
I0814 23:26:17.801854 10672 solver.cpp:244]     Train net output #1: loss2 = 0.385595 (* 0.5 = 0.192797 loss)
I0814 23:26:17.801868 10672 sgd_solver.cpp:106] Iteration 7480, lr = 6.98455e-05
I0814 23:26:23.319555 10672 solver.cpp:228] Iteration 7500, loss = 0.279217
I0814 23:26:23.319609 10672 solver.cpp:244]     Train net output #0: loss1 = 0.133963 (* 0.5 = 0.0669816 loss)
I0814 23:26:23.319625 10672 solver.cpp:244]     Train net output #1: loss2 = 0.424471 (* 0.5 = 0.212236 loss)
I0814 23:26:23.319639 10672 sgd_solver.cpp:106] Iteration 7500, lr = 6.9706e-05
I0814 23:26:28.832906 10672 solver.cpp:228] Iteration 7520, loss = 0.352519
I0814 23:26:28.832964 10672 solver.cpp:244]     Train net output #0: loss1 = 0.162845 (* 0.5 = 0.0814227 loss)
I0814 23:26:28.832980 10672 solver.cpp:244]     Train net output #1: loss2 = 0.542194 (* 0.5 = 0.271097 loss)
I0814 23:26:28.832994 10672 sgd_solver.cpp:106] Iteration 7520, lr = 6.95671e-05
I0814 23:26:34.351282 10672 solver.cpp:228] Iteration 7540, loss = 0.320568
I0814 23:26:34.351341 10672 solver.cpp:244]     Train net output #0: loss1 = 0.184439 (* 0.5 = 0.0922196 loss)
I0814 23:26:34.351356 10672 solver.cpp:244]     Train net output #1: loss2 = 0.456697 (* 0.5 = 0.228348 loss)
I0814 23:26:34.351371 10672 sgd_solver.cpp:106] Iteration 7540, lr = 6.94288e-05
I0814 23:26:39.869455 10672 solver.cpp:228] Iteration 7560, loss = 0.330676
I0814 23:26:39.869511 10672 solver.cpp:244]     Train net output #0: loss1 = 0.181903 (* 0.5 = 0.0909515 loss)
I0814 23:26:39.869527 10672 solver.cpp:244]     Train net output #1: loss2 = 0.479449 (* 0.5 = 0.239724 loss)
I0814 23:26:39.869540 10672 sgd_solver.cpp:106] Iteration 7560, lr = 6.92912e-05
I0814 23:26:45.384821 10672 solver.cpp:228] Iteration 7580, loss = 0.303179
I0814 23:26:45.384878 10672 solver.cpp:244]     Train net output #0: loss1 = 0.156196 (* 0.5 = 0.0780978 loss)
I0814 23:26:45.384894 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450162 (* 0.5 = 0.225081 loss)
I0814 23:26:45.384908 10672 sgd_solver.cpp:106] Iteration 7580, lr = 6.91542e-05
I0814 23:26:50.902477 10672 solver.cpp:228] Iteration 7600, loss = 0.396791
I0814 23:26:50.902645 10672 solver.cpp:244]     Train net output #0: loss1 = 0.279686 (* 0.5 = 0.139843 loss)
I0814 23:26:50.902669 10672 solver.cpp:244]     Train net output #1: loss2 = 0.513896 (* 0.5 = 0.256948 loss)
I0814 23:26:50.902685 10672 sgd_solver.cpp:106] Iteration 7600, lr = 6.90179e-05
I0814 23:26:56.414877 10672 solver.cpp:228] Iteration 7620, loss = 0.369494
I0814 23:26:56.414933 10672 solver.cpp:244]     Train net output #0: loss1 = 0.3035 (* 0.5 = 0.15175 loss)
I0814 23:26:56.414948 10672 solver.cpp:244]     Train net output #1: loss2 = 0.435487 (* 0.5 = 0.217744 loss)
I0814 23:26:56.414963 10672 sgd_solver.cpp:106] Iteration 7620, lr = 6.88821e-05
I0814 23:27:01.934948 10672 solver.cpp:228] Iteration 7640, loss = 0.362456
I0814 23:27:01.935009 10672 solver.cpp:244]     Train net output #0: loss1 = 0.215148 (* 0.5 = 0.107574 loss)
I0814 23:27:01.935025 10672 solver.cpp:244]     Train net output #1: loss2 = 0.509765 (* 0.5 = 0.254882 loss)
I0814 23:27:01.935039 10672 sgd_solver.cpp:106] Iteration 7640, lr = 6.8747e-05
I0814 23:27:07.458287 10672 solver.cpp:228] Iteration 7660, loss = 0.348675
I0814 23:27:07.458348 10672 solver.cpp:244]     Train net output #0: loss1 = 0.235371 (* 0.5 = 0.117686 loss)
I0814 23:27:07.458362 10672 solver.cpp:244]     Train net output #1: loss2 = 0.461979 (* 0.5 = 0.230989 loss)
I0814 23:27:07.458376 10672 sgd_solver.cpp:106] Iteration 7660, lr = 6.86125e-05
I0814 23:27:12.976838 10672 solver.cpp:228] Iteration 7680, loss = 0.339809
I0814 23:27:12.976902 10672 solver.cpp:244]     Train net output #0: loss1 = 0.223859 (* 0.5 = 0.11193 loss)
I0814 23:27:12.976919 10672 solver.cpp:244]     Train net output #1: loss2 = 0.455758 (* 0.5 = 0.227879 loss)
I0814 23:27:12.976933 10672 sgd_solver.cpp:106] Iteration 7680, lr = 6.84787e-05
I0814 23:27:18.493561 10672 solver.cpp:228] Iteration 7700, loss = 0.360193
I0814 23:27:18.493620 10672 solver.cpp:244]     Train net output #0: loss1 = 0.241974 (* 0.5 = 0.120987 loss)
I0814 23:27:18.493636 10672 solver.cpp:244]     Train net output #1: loss2 = 0.478413 (* 0.5 = 0.239206 loss)
I0814 23:27:18.493650 10672 sgd_solver.cpp:106] Iteration 7700, lr = 6.83454e-05
I0814 23:27:24.010275 10672 solver.cpp:228] Iteration 7720, loss = 0.226811
I0814 23:27:24.010423 10672 solver.cpp:244]     Train net output #0: loss1 = 0.150558 (* 0.5 = 0.0752792 loss)
I0814 23:27:24.010442 10672 solver.cpp:244]     Train net output #1: loss2 = 0.303063 (* 0.5 = 0.151531 loss)
I0814 23:27:24.010455 10672 sgd_solver.cpp:106] Iteration 7720, lr = 6.82127e-05
I0814 23:27:29.525418 10672 solver.cpp:228] Iteration 7740, loss = 0.293621
I0814 23:27:29.525472 10672 solver.cpp:244]     Train net output #0: loss1 = 0.180092 (* 0.5 = 0.0900459 loss)
I0814 23:27:29.525488 10672 solver.cpp:244]     Train net output #1: loss2 = 0.407151 (* 0.5 = 0.203575 loss)
I0814 23:27:29.525501 10672 sgd_solver.cpp:106] Iteration 7740, lr = 6.80807e-05
I0814 23:27:35.044584 10672 solver.cpp:228] Iteration 7760, loss = 0.29971
I0814 23:27:35.044643 10672 solver.cpp:244]     Train net output #0: loss1 = 0.179339 (* 0.5 = 0.0896696 loss)
I0814 23:27:35.044659 10672 solver.cpp:244]     Train net output #1: loss2 = 0.420081 (* 0.5 = 0.21004 loss)
I0814 23:27:35.044672 10672 sgd_solver.cpp:106] Iteration 7760, lr = 6.79492e-05
I0814 23:27:40.561888 10672 solver.cpp:228] Iteration 7780, loss = 0.242302
I0814 23:27:40.561944 10672 solver.cpp:244]     Train net output #0: loss1 = 0.148248 (* 0.5 = 0.0741239 loss)
I0814 23:27:40.561959 10672 solver.cpp:244]     Train net output #1: loss2 = 0.336356 (* 0.5 = 0.168178 loss)
I0814 23:27:40.561972 10672 sgd_solver.cpp:106] Iteration 7780, lr = 6.78183e-05
I0814 23:27:46.079051 10672 solver.cpp:228] Iteration 7800, loss = 0.311206
I0814 23:27:46.079107 10672 solver.cpp:244]     Train net output #0: loss1 = 0.231718 (* 0.5 = 0.115859 loss)
I0814 23:27:46.079123 10672 solver.cpp:244]     Train net output #1: loss2 = 0.390694 (* 0.5 = 0.195347 loss)
I0814 23:27:46.079136 10672 sgd_solver.cpp:106] Iteration 7800, lr = 6.7688e-05
I0814 23:27:51.594377 10672 solver.cpp:228] Iteration 7820, loss = 0.300984
I0814 23:27:51.594432 10672 solver.cpp:244]     Train net output #0: loss1 = 0.176268 (* 0.5 = 0.0881341 loss)
I0814 23:27:51.594449 10672 solver.cpp:244]     Train net output #1: loss2 = 0.425701 (* 0.5 = 0.21285 loss)
I0814 23:27:51.594461 10672 sgd_solver.cpp:106] Iteration 7820, lr = 6.75583e-05
I0814 23:27:57.111368 10672 solver.cpp:228] Iteration 7840, loss = 0.278431
I0814 23:27:57.111481 10672 solver.cpp:244]     Train net output #0: loss1 = 0.178733 (* 0.5 = 0.0893666 loss)
I0814 23:27:57.111498 10672 solver.cpp:244]     Train net output #1: loss2 = 0.378128 (* 0.5 = 0.189064 loss)
I0814 23:27:57.111511 10672 sgd_solver.cpp:106] Iteration 7840, lr = 6.74292e-05
I0814 23:28:02.629169 10672 solver.cpp:228] Iteration 7860, loss = 0.336383
I0814 23:28:02.629230 10672 solver.cpp:244]     Train net output #0: loss1 = 0.165146 (* 0.5 = 0.082573 loss)
I0814 23:28:02.629245 10672 solver.cpp:244]     Train net output #1: loss2 = 0.507619 (* 0.5 = 0.25381 loss)
I0814 23:28:02.629258 10672 sgd_solver.cpp:106] Iteration 7860, lr = 6.73006e-05
I0814 23:28:08.147636 10672 solver.cpp:228] Iteration 7880, loss = 0.352502
I0814 23:28:08.147696 10672 solver.cpp:244]     Train net output #0: loss1 = 0.208933 (* 0.5 = 0.104467 loss)
I0814 23:28:08.147713 10672 solver.cpp:244]     Train net output #1: loss2 = 0.496072 (* 0.5 = 0.248036 loss)
I0814 23:28:08.147727 10672 sgd_solver.cpp:106] Iteration 7880, lr = 6.71726e-05
I0814 23:28:13.666059 10672 solver.cpp:228] Iteration 7900, loss = 0.316622
I0814 23:28:13.666118 10672 solver.cpp:244]     Train net output #0: loss1 = 0.243825 (* 0.5 = 0.121913 loss)
I0814 23:28:13.666134 10672 solver.cpp:244]     Train net output #1: loss2 = 0.38942 (* 0.5 = 0.19471 loss)
I0814 23:28:13.666148 10672 sgd_solver.cpp:106] Iteration 7900, lr = 6.70452e-05
I0814 23:28:19.180740 10672 solver.cpp:228] Iteration 7920, loss = 0.294745
I0814 23:28:19.180795 10672 solver.cpp:244]     Train net output #0: loss1 = 0.154751 (* 0.5 = 0.0773753 loss)
I0814 23:28:19.180811 10672 solver.cpp:244]     Train net output #1: loss2 = 0.434739 (* 0.5 = 0.217369 loss)
I0814 23:28:19.180824 10672 sgd_solver.cpp:106] Iteration 7920, lr = 6.69183e-05
I0814 23:28:24.703928 10672 solver.cpp:228] Iteration 7940, loss = 0.269548
I0814 23:28:24.703987 10672 solver.cpp:244]     Train net output #0: loss1 = 0.119515 (* 0.5 = 0.0597574 loss)
I0814 23:28:24.704004 10672 solver.cpp:244]     Train net output #1: loss2 = 0.419582 (* 0.5 = 0.209791 loss)
I0814 23:28:24.704016 10672 sgd_solver.cpp:106] Iteration 7940, lr = 6.6792e-05
I0814 23:28:30.220015 10672 solver.cpp:228] Iteration 7960, loss = 0.356516
I0814 23:28:30.220273 10672 solver.cpp:244]     Train net output #0: loss1 = 0.201342 (* 0.5 = 0.100671 loss)
I0814 23:28:30.220309 10672 solver.cpp:244]     Train net output #1: loss2 = 0.511689 (* 0.5 = 0.255845 loss)
I0814 23:28:30.220335 10672 sgd_solver.cpp:106] Iteration 7960, lr = 6.66663e-05
I0814 23:28:35.732331 10672 solver.cpp:228] Iteration 7980, loss = 0.308551
I0814 23:28:35.732389 10672 solver.cpp:244]     Train net output #0: loss1 = 0.181002 (* 0.5 = 0.0905009 loss)
I0814 23:28:35.732404 10672 solver.cpp:244]     Train net output #1: loss2 = 0.4361 (* 0.5 = 0.21805 loss)
I0814 23:28:35.732419 10672 sgd_solver.cpp:106] Iteration 7980, lr = 6.65411e-05
I0814 23:28:40.981271 10672 solver.cpp:337] Iteration 8000, Testing net (#0)
I0814 23:29:44.089136 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.706484
I0814 23:29:44.089251 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.902906
I0814 23:29:44.089269 10672 solver.cpp:404]     Test net output #2: loss1 = 0.271822 (* 0.5 = 0.135911 loss)
I0814 23:29:44.089289 10672 solver.cpp:404]     Test net output #3: loss2 = 0.581526 (* 0.5 = 0.290763 loss)
I0814 23:29:44.173148 10672 solver.cpp:228] Iteration 8000, loss = 0.309163
I0814 23:29:44.173205 10672 solver.cpp:244]     Train net output #0: loss1 = 0.213176 (* 0.5 = 0.106588 loss)
I0814 23:29:44.173221 10672 solver.cpp:244]     Train net output #1: loss2 = 0.405149 (* 0.5 = 0.202575 loss)
I0814 23:29:44.173234 10672 sgd_solver.cpp:106] Iteration 8000, lr = 6.64164e-05
I0814 23:29:49.690755 10672 solver.cpp:228] Iteration 8020, loss = 0.333953
I0814 23:29:49.690811 10672 solver.cpp:244]     Train net output #0: loss1 = 0.150936 (* 0.5 = 0.075468 loss)
I0814 23:29:49.690829 10672 solver.cpp:244]     Train net output #1: loss2 = 0.51697 (* 0.5 = 0.258485 loss)
I0814 23:29:49.690842 10672 sgd_solver.cpp:106] Iteration 8020, lr = 6.62923e-05
I0814 23:29:55.210593 10672 solver.cpp:228] Iteration 8040, loss = 0.29867
I0814 23:29:55.210654 10672 solver.cpp:244]     Train net output #0: loss1 = 0.191901 (* 0.5 = 0.0959507 loss)
I0814 23:29:55.210670 10672 solver.cpp:244]     Train net output #1: loss2 = 0.405438 (* 0.5 = 0.202719 loss)
I0814 23:29:55.210685 10672 sgd_solver.cpp:106] Iteration 8040, lr = 6.61688e-05
I0814 23:30:00.738634 10672 solver.cpp:228] Iteration 8060, loss = 0.377138
I0814 23:30:00.738690 10672 solver.cpp:244]     Train net output #0: loss1 = 0.34076 (* 0.5 = 0.17038 loss)
I0814 23:30:00.738706 10672 solver.cpp:244]     Train net output #1: loss2 = 0.413516 (* 0.5 = 0.206758 loss)
I0814 23:30:00.738720 10672 sgd_solver.cpp:106] Iteration 8060, lr = 6.60457e-05
I0814 23:30:06.255750 10672 solver.cpp:228] Iteration 8080, loss = 0.323938
I0814 23:30:06.255810 10672 solver.cpp:244]     Train net output #0: loss1 = 0.201871 (* 0.5 = 0.100936 loss)
I0814 23:30:06.255826 10672 solver.cpp:244]     Train net output #1: loss2 = 0.446004 (* 0.5 = 0.223002 loss)
I0814 23:30:06.255841 10672 sgd_solver.cpp:106] Iteration 8080, lr = 6.59232e-05
I0814 23:30:11.770783 10672 solver.cpp:228] Iteration 8100, loss = 0.371932
I0814 23:30:11.770843 10672 solver.cpp:244]     Train net output #0: loss1 = 0.20449 (* 0.5 = 0.102245 loss)
I0814 23:30:11.770859 10672 solver.cpp:244]     Train net output #1: loss2 = 0.539373 (* 0.5 = 0.269687 loss)
I0814 23:30:11.770872 10672 sgd_solver.cpp:106] Iteration 8100, lr = 6.58013e-05
I0814 23:30:17.287307 10672 solver.cpp:228] Iteration 8120, loss = 0.343246
I0814 23:30:17.287498 10672 solver.cpp:244]     Train net output #0: loss1 = 0.23236 (* 0.5 = 0.11618 loss)
I0814 23:30:17.287523 10672 solver.cpp:244]     Train net output #1: loss2 = 0.454131 (* 0.5 = 0.227066 loss)
I0814 23:30:17.287539 10672 sgd_solver.cpp:106] Iteration 8120, lr = 6.56798e-05
I0814 23:30:22.800014 10672 solver.cpp:228] Iteration 8140, loss = 0.332724
I0814 23:30:22.800071 10672 solver.cpp:244]     Train net output #0: loss1 = 0.194181 (* 0.5 = 0.0970906 loss)
I0814 23:30:22.800086 10672 solver.cpp:244]     Train net output #1: loss2 = 0.471267 (* 0.5 = 0.235633 loss)
I0814 23:30:22.800099 10672 sgd_solver.cpp:106] Iteration 8140, lr = 6.55589e-05
I0814 23:30:28.320235 10672 solver.cpp:228] Iteration 8160, loss = 0.234705
I0814 23:30:28.320288 10672 solver.cpp:244]     Train net output #0: loss1 = 0.140256 (* 0.5 = 0.0701278 loss)
I0814 23:30:28.320303 10672 solver.cpp:244]     Train net output #1: loss2 = 0.329155 (* 0.5 = 0.164578 loss)
I0814 23:30:28.320317 10672 sgd_solver.cpp:106] Iteration 8160, lr = 6.54385e-05
I0814 23:30:33.837003 10672 solver.cpp:228] Iteration 8180, loss = 0.284287
I0814 23:30:33.837059 10672 solver.cpp:244]     Train net output #0: loss1 = 0.14791 (* 0.5 = 0.0739549 loss)
I0814 23:30:33.837074 10672 solver.cpp:244]     Train net output #1: loss2 = 0.420665 (* 0.5 = 0.210333 loss)
I0814 23:30:33.837088 10672 sgd_solver.cpp:106] Iteration 8180, lr = 6.53186e-05
I0814 23:30:39.352097 10672 solver.cpp:228] Iteration 8200, loss = 0.345048
I0814 23:30:39.352151 10672 solver.cpp:244]     Train net output #0: loss1 = 0.196147 (* 0.5 = 0.0980735 loss)
I0814 23:30:39.352167 10672 solver.cpp:244]     Train net output #1: loss2 = 0.493949 (* 0.5 = 0.246974 loss)
I0814 23:30:39.352181 10672 sgd_solver.cpp:106] Iteration 8200, lr = 6.51993e-05
I0814 23:30:44.868109 10672 solver.cpp:228] Iteration 8220, loss = 0.333793
I0814 23:30:44.868168 10672 solver.cpp:244]     Train net output #0: loss1 = 0.201942 (* 0.5 = 0.100971 loss)
I0814 23:30:44.868185 10672 solver.cpp:244]     Train net output #1: loss2 = 0.465644 (* 0.5 = 0.232822 loss)
I0814 23:30:44.868198 10672 sgd_solver.cpp:106] Iteration 8220, lr = 6.50804e-05
I0814 23:30:50.387148 10672 solver.cpp:228] Iteration 8240, loss = 0.325461
I0814 23:30:50.387331 10672 solver.cpp:244]     Train net output #0: loss1 = 0.318301 (* 0.5 = 0.15915 loss)
I0814 23:30:50.387353 10672 solver.cpp:244]     Train net output #1: loss2 = 0.332622 (* 0.5 = 0.166311 loss)
I0814 23:30:50.387367 10672 sgd_solver.cpp:106] Iteration 8240, lr = 6.4962e-05
I0814 23:30:55.901163 10672 solver.cpp:228] Iteration 8260, loss = 0.27849
I0814 23:30:55.901221 10672 solver.cpp:244]     Train net output #0: loss1 = 0.173061 (* 0.5 = 0.0865303 loss)
I0814 23:30:55.901237 10672 solver.cpp:244]     Train net output #1: loss2 = 0.38392 (* 0.5 = 0.19196 loss)
I0814 23:30:55.901252 10672 sgd_solver.cpp:106] Iteration 8260, lr = 6.48442e-05
I0814 23:31:01.421102 10672 solver.cpp:228] Iteration 8280, loss = 0.280334
I0814 23:31:01.421157 10672 solver.cpp:244]     Train net output #0: loss1 = 0.19472 (* 0.5 = 0.0973602 loss)
I0814 23:31:01.421175 10672 solver.cpp:244]     Train net output #1: loss2 = 0.365948 (* 0.5 = 0.182974 loss)
I0814 23:31:01.421188 10672 sgd_solver.cpp:106] Iteration 8280, lr = 6.47268e-05
I0814 23:31:06.938627 10672 solver.cpp:228] Iteration 8300, loss = 0.313655
I0814 23:31:06.938684 10672 solver.cpp:244]     Train net output #0: loss1 = 0.196381 (* 0.5 = 0.0981904 loss)
I0814 23:31:06.938700 10672 solver.cpp:244]     Train net output #1: loss2 = 0.430929 (* 0.5 = 0.215464 loss)
I0814 23:31:06.938714 10672 sgd_solver.cpp:106] Iteration 8300, lr = 6.46099e-05
I0814 23:31:12.455607 10672 solver.cpp:228] Iteration 8320, loss = 0.430514
I0814 23:31:12.455662 10672 solver.cpp:244]     Train net output #0: loss1 = 0.298382 (* 0.5 = 0.149191 loss)
I0814 23:31:12.455677 10672 solver.cpp:244]     Train net output #1: loss2 = 0.562646 (* 0.5 = 0.281323 loss)
I0814 23:31:12.455691 10672 sgd_solver.cpp:106] Iteration 8320, lr = 6.44935e-05
I0814 23:31:17.972910 10672 solver.cpp:228] Iteration 8340, loss = 0.229146
I0814 23:31:17.972968 10672 solver.cpp:244]     Train net output #0: loss1 = 0.142104 (* 0.5 = 0.0710519 loss)
I0814 23:31:17.972985 10672 solver.cpp:244]     Train net output #1: loss2 = 0.316187 (* 0.5 = 0.158094 loss)
I0814 23:31:17.972998 10672 sgd_solver.cpp:106] Iteration 8340, lr = 6.43777e-05
I0814 23:31:23.486176 10672 solver.cpp:228] Iteration 8360, loss = 0.265875
I0814 23:31:23.486358 10672 solver.cpp:244]     Train net output #0: loss1 = 0.123671 (* 0.5 = 0.0618353 loss)
I0814 23:31:23.486382 10672 solver.cpp:244]     Train net output #1: loss2 = 0.408078 (* 0.5 = 0.204039 loss)
I0814 23:31:23.486398 10672 sgd_solver.cpp:106] Iteration 8360, lr = 6.42622e-05
I0814 23:31:29.003944 10672 solver.cpp:228] Iteration 8380, loss = 0.358845
I0814 23:31:29.003998 10672 solver.cpp:244]     Train net output #0: loss1 = 0.299899 (* 0.5 = 0.14995 loss)
I0814 23:31:29.004012 10672 solver.cpp:244]     Train net output #1: loss2 = 0.417791 (* 0.5 = 0.208895 loss)
I0814 23:31:29.004026 10672 sgd_solver.cpp:106] Iteration 8380, lr = 6.41473e-05
I0814 23:31:34.521689 10672 solver.cpp:228] Iteration 8400, loss = 0.283806
I0814 23:31:34.521747 10672 solver.cpp:244]     Train net output #0: loss1 = 0.13511 (* 0.5 = 0.0675549 loss)
I0814 23:31:34.521762 10672 solver.cpp:244]     Train net output #1: loss2 = 0.432502 (* 0.5 = 0.216251 loss)
I0814 23:31:34.521776 10672 sgd_solver.cpp:106] Iteration 8400, lr = 6.40329e-05
I0814 23:31:40.040029 10672 solver.cpp:228] Iteration 8420, loss = 0.348215
I0814 23:31:40.040089 10672 solver.cpp:244]     Train net output #0: loss1 = 0.253649 (* 0.5 = 0.126824 loss)
I0814 23:31:40.040104 10672 solver.cpp:244]     Train net output #1: loss2 = 0.442782 (* 0.5 = 0.221391 loss)
I0814 23:31:40.040117 10672 sgd_solver.cpp:106] Iteration 8420, lr = 6.39189e-05
I0814 23:31:45.559173 10672 solver.cpp:228] Iteration 8440, loss = 0.295159
I0814 23:31:45.559233 10672 solver.cpp:244]     Train net output #0: loss1 = 0.162088 (* 0.5 = 0.0810438 loss)
I0814 23:31:45.559249 10672 solver.cpp:244]     Train net output #1: loss2 = 0.428231 (* 0.5 = 0.214115 loss)
I0814 23:31:45.559263 10672 sgd_solver.cpp:106] Iteration 8440, lr = 6.38054e-05
I0814 23:31:51.076452 10672 solver.cpp:228] Iteration 8460, loss = 0.331324
I0814 23:31:51.076509 10672 solver.cpp:244]     Train net output #0: loss1 = 0.199935 (* 0.5 = 0.0999677 loss)
I0814 23:31:51.076525 10672 solver.cpp:244]     Train net output #1: loss2 = 0.462712 (* 0.5 = 0.231356 loss)
I0814 23:31:51.076539 10672 sgd_solver.cpp:106] Iteration 8460, lr = 6.36924e-05
I0814 23:31:56.588836 10672 solver.cpp:228] Iteration 8480, loss = 0.24064
I0814 23:31:56.588953 10672 solver.cpp:244]     Train net output #0: loss1 = 0.110967 (* 0.5 = 0.0554836 loss)
I0814 23:31:56.588969 10672 solver.cpp:244]     Train net output #1: loss2 = 0.370313 (* 0.5 = 0.185156 loss)
I0814 23:31:56.588984 10672 sgd_solver.cpp:106] Iteration 8480, lr = 6.35798e-05
I0814 23:32:02.118597 10672 solver.cpp:228] Iteration 8500, loss = 0.333672
I0814 23:32:02.118654 10672 solver.cpp:244]     Train net output #0: loss1 = 0.179805 (* 0.5 = 0.0899024 loss)
I0814 23:32:02.118669 10672 solver.cpp:244]     Train net output #1: loss2 = 0.48754 (* 0.5 = 0.24377 loss)
I0814 23:32:02.118683 10672 sgd_solver.cpp:106] Iteration 8500, lr = 6.34677e-05
I0814 23:32:07.635828 10672 solver.cpp:228] Iteration 8520, loss = 0.336802
I0814 23:32:07.635885 10672 solver.cpp:244]     Train net output #0: loss1 = 0.20623 (* 0.5 = 0.103115 loss)
I0814 23:32:07.635900 10672 solver.cpp:244]     Train net output #1: loss2 = 0.467373 (* 0.5 = 0.233687 loss)
I0814 23:32:07.635913 10672 sgd_solver.cpp:106] Iteration 8520, lr = 6.33561e-05
I0814 23:32:13.151728 10672 solver.cpp:228] Iteration 8540, loss = 0.244145
I0814 23:32:13.151782 10672 solver.cpp:244]     Train net output #0: loss1 = 0.119283 (* 0.5 = 0.0596417 loss)
I0814 23:32:13.151798 10672 solver.cpp:244]     Train net output #1: loss2 = 0.369007 (* 0.5 = 0.184503 loss)
I0814 23:32:13.151813 10672 sgd_solver.cpp:106] Iteration 8540, lr = 6.32449e-05
I0814 23:32:18.673737 10672 solver.cpp:228] Iteration 8560, loss = 0.328059
I0814 23:32:18.673792 10672 solver.cpp:244]     Train net output #0: loss1 = 0.217722 (* 0.5 = 0.108861 loss)
I0814 23:32:18.673810 10672 solver.cpp:244]     Train net output #1: loss2 = 0.438396 (* 0.5 = 0.219198 loss)
I0814 23:32:18.673822 10672 sgd_solver.cpp:106] Iteration 8560, lr = 6.31342e-05
I0814 23:32:24.192195 10672 solver.cpp:228] Iteration 8580, loss = 0.328848
I0814 23:32:24.192258 10672 solver.cpp:244]     Train net output #0: loss1 = 0.151472 (* 0.5 = 0.075736 loss)
I0814 23:32:24.192275 10672 solver.cpp:244]     Train net output #1: loss2 = 0.506223 (* 0.5 = 0.253112 loss)
I0814 23:32:24.192287 10672 sgd_solver.cpp:106] Iteration 8580, lr = 6.30239e-05
I0814 23:32:29.709216 10672 solver.cpp:228] Iteration 8600, loss = 0.291
I0814 23:32:29.709399 10672 solver.cpp:244]     Train net output #0: loss1 = 0.204382 (* 0.5 = 0.102191 loss)
I0814 23:32:29.709424 10672 solver.cpp:244]     Train net output #1: loss2 = 0.377619 (* 0.5 = 0.188809 loss)
I0814 23:32:29.709441 10672 sgd_solver.cpp:106] Iteration 8600, lr = 6.2914e-05
I0814 23:32:35.220671 10672 solver.cpp:228] Iteration 8620, loss = 0.250069
I0814 23:32:35.220732 10672 solver.cpp:244]     Train net output #0: loss1 = 0.137429 (* 0.5 = 0.0687144 loss)
I0814 23:32:35.220749 10672 solver.cpp:244]     Train net output #1: loss2 = 0.362709 (* 0.5 = 0.181354 loss)
I0814 23:32:35.220763 10672 sgd_solver.cpp:106] Iteration 8620, lr = 6.28047e-05
I0814 23:32:40.740572 10672 solver.cpp:228] Iteration 8640, loss = 0.281839
I0814 23:32:40.740631 10672 solver.cpp:244]     Train net output #0: loss1 = 0.147767 (* 0.5 = 0.0738834 loss)
I0814 23:32:40.740648 10672 solver.cpp:244]     Train net output #1: loss2 = 0.415911 (* 0.5 = 0.207956 loss)
I0814 23:32:40.740660 10672 sgd_solver.cpp:106] Iteration 8640, lr = 6.26957e-05
I0814 23:32:46.256625 10672 solver.cpp:228] Iteration 8660, loss = 0.343225
I0814 23:32:46.256686 10672 solver.cpp:244]     Train net output #0: loss1 = 0.278588 (* 0.5 = 0.139294 loss)
I0814 23:32:46.256701 10672 solver.cpp:244]     Train net output #1: loss2 = 0.407863 (* 0.5 = 0.203931 loss)
I0814 23:32:46.256716 10672 sgd_solver.cpp:106] Iteration 8660, lr = 6.25872e-05
I0814 23:32:51.774529 10672 solver.cpp:228] Iteration 8680, loss = 0.365561
I0814 23:32:51.774593 10672 solver.cpp:244]     Train net output #0: loss1 = 0.294569 (* 0.5 = 0.147285 loss)
I0814 23:32:51.774610 10672 solver.cpp:244]     Train net output #1: loss2 = 0.436554 (* 0.5 = 0.218277 loss)
I0814 23:32:51.774623 10672 sgd_solver.cpp:106] Iteration 8680, lr = 6.24792e-05
I0814 23:32:57.290995 10672 solver.cpp:228] Iteration 8700, loss = 0.293689
I0814 23:32:57.291054 10672 solver.cpp:244]     Train net output #0: loss1 = 0.168202 (* 0.5 = 0.084101 loss)
I0814 23:32:57.291069 10672 solver.cpp:244]     Train net output #1: loss2 = 0.419177 (* 0.5 = 0.209589 loss)
I0814 23:32:57.291084 10672 sgd_solver.cpp:106] Iteration 8700, lr = 6.23715e-05
I0814 23:33:02.815008 10672 solver.cpp:228] Iteration 8720, loss = 0.304152
I0814 23:33:02.815135 10672 solver.cpp:244]     Train net output #0: loss1 = 0.201358 (* 0.5 = 0.100679 loss)
I0814 23:33:02.815152 10672 solver.cpp:244]     Train net output #1: loss2 = 0.406945 (* 0.5 = 0.203473 loss)
I0814 23:33:02.815166 10672 sgd_solver.cpp:106] Iteration 8720, lr = 6.22643e-05
I0814 23:33:08.330130 10672 solver.cpp:228] Iteration 8740, loss = 0.352768
I0814 23:33:08.330188 10672 solver.cpp:244]     Train net output #0: loss1 = 0.242517 (* 0.5 = 0.121259 loss)
I0814 23:33:08.330204 10672 solver.cpp:244]     Train net output #1: loss2 = 0.463019 (* 0.5 = 0.23151 loss)
I0814 23:33:08.330219 10672 sgd_solver.cpp:106] Iteration 8740, lr = 6.21576e-05
I0814 23:33:13.842659 10672 solver.cpp:228] Iteration 8760, loss = 0.279934
I0814 23:33:13.842717 10672 solver.cpp:244]     Train net output #0: loss1 = 0.134218 (* 0.5 = 0.0671089 loss)
I0814 23:33:13.842732 10672 solver.cpp:244]     Train net output #1: loss2 = 0.42565 (* 0.5 = 0.212825 loss)
I0814 23:33:13.842746 10672 sgd_solver.cpp:106] Iteration 8760, lr = 6.20512e-05
I0814 23:33:19.363072 10672 solver.cpp:228] Iteration 8780, loss = 0.30619
I0814 23:33:19.363127 10672 solver.cpp:244]     Train net output #0: loss1 = 0.184651 (* 0.5 = 0.0923254 loss)
I0814 23:33:19.363143 10672 solver.cpp:244]     Train net output #1: loss2 = 0.427729 (* 0.5 = 0.213865 loss)
I0814 23:33:19.363157 10672 sgd_solver.cpp:106] Iteration 8780, lr = 6.19453e-05
I0814 23:33:24.878901 10672 solver.cpp:228] Iteration 8800, loss = 0.279088
I0814 23:33:24.878958 10672 solver.cpp:244]     Train net output #0: loss1 = 0.154022 (* 0.5 = 0.0770112 loss)
I0814 23:33:24.878974 10672 solver.cpp:244]     Train net output #1: loss2 = 0.404154 (* 0.5 = 0.202077 loss)
I0814 23:33:24.878988 10672 sgd_solver.cpp:106] Iteration 8800, lr = 6.18398e-05
I0814 23:33:30.391868 10672 solver.cpp:228] Iteration 8820, loss = 0.376203
I0814 23:33:30.391924 10672 solver.cpp:244]     Train net output #0: loss1 = 0.283899 (* 0.5 = 0.14195 loss)
I0814 23:33:30.391940 10672 solver.cpp:244]     Train net output #1: loss2 = 0.468507 (* 0.5 = 0.234253 loss)
I0814 23:33:30.391953 10672 sgd_solver.cpp:106] Iteration 8820, lr = 6.17347e-05
I0814 23:33:35.917197 10672 solver.cpp:228] Iteration 8840, loss = 0.298781
I0814 23:33:35.917349 10672 solver.cpp:244]     Train net output #0: loss1 = 0.216153 (* 0.5 = 0.108077 loss)
I0814 23:33:35.917366 10672 solver.cpp:244]     Train net output #1: loss2 = 0.381408 (* 0.5 = 0.190704 loss)
I0814 23:33:35.917382 10672 sgd_solver.cpp:106] Iteration 8840, lr = 6.16301e-05
I0814 23:33:41.432595 10672 solver.cpp:228] Iteration 8860, loss = 0.36786
I0814 23:33:41.432657 10672 solver.cpp:244]     Train net output #0: loss1 = 0.235909 (* 0.5 = 0.117955 loss)
I0814 23:33:41.432673 10672 solver.cpp:244]     Train net output #1: loss2 = 0.499811 (* 0.5 = 0.249906 loss)
I0814 23:33:41.432687 10672 sgd_solver.cpp:106] Iteration 8860, lr = 6.15258e-05
I0814 23:33:46.950453 10672 solver.cpp:228] Iteration 8880, loss = 0.313576
I0814 23:33:46.950512 10672 solver.cpp:244]     Train net output #0: loss1 = 0.200356 (* 0.5 = 0.100178 loss)
I0814 23:33:46.950530 10672 solver.cpp:244]     Train net output #1: loss2 = 0.426796 (* 0.5 = 0.213398 loss)
I0814 23:33:46.950543 10672 sgd_solver.cpp:106] Iteration 8880, lr = 6.1422e-05
I0814 23:33:52.471981 10672 solver.cpp:228] Iteration 8900, loss = 0.427478
I0814 23:33:52.472039 10672 solver.cpp:244]     Train net output #0: loss1 = 0.309681 (* 0.5 = 0.15484 loss)
I0814 23:33:52.472055 10672 solver.cpp:244]     Train net output #1: loss2 = 0.545276 (* 0.5 = 0.272638 loss)
I0814 23:33:52.472069 10672 sgd_solver.cpp:106] Iteration 8900, lr = 6.13185e-05
I0814 23:33:57.986174 10672 solver.cpp:228] Iteration 8920, loss = 0.304632
I0814 23:33:57.986228 10672 solver.cpp:244]     Train net output #0: loss1 = 0.125805 (* 0.5 = 0.0629023 loss)
I0814 23:33:57.986244 10672 solver.cpp:244]     Train net output #1: loss2 = 0.483458 (* 0.5 = 0.241729 loss)
I0814 23:33:57.986258 10672 sgd_solver.cpp:106] Iteration 8920, lr = 6.12155e-05
I0814 23:34:03.505717 10672 solver.cpp:228] Iteration 8940, loss = 0.236445
I0814 23:34:03.505776 10672 solver.cpp:244]     Train net output #0: loss1 = 0.0946029 (* 0.5 = 0.0473014 loss)
I0814 23:34:03.505792 10672 solver.cpp:244]     Train net output #1: loss2 = 0.378287 (* 0.5 = 0.189144 loss)
I0814 23:34:03.505805 10672 sgd_solver.cpp:106] Iteration 8940, lr = 6.11129e-05
I0814 23:34:09.022758 10672 solver.cpp:228] Iteration 8960, loss = 0.292756
I0814 23:34:09.022878 10672 solver.cpp:244]     Train net output #0: loss1 = 0.190383 (* 0.5 = 0.0951917 loss)
I0814 23:34:09.022896 10672 solver.cpp:244]     Train net output #1: loss2 = 0.395129 (* 0.5 = 0.197564 loss)
I0814 23:34:09.022909 10672 sgd_solver.cpp:106] Iteration 8960, lr = 6.10107e-05
I0814 23:34:14.541110 10672 solver.cpp:228] Iteration 8980, loss = 0.242651
I0814 23:34:14.541167 10672 solver.cpp:244]     Train net output #0: loss1 = 0.126006 (* 0.5 = 0.0630028 loss)
I0814 23:34:14.541182 10672 solver.cpp:244]     Train net output #1: loss2 = 0.359297 (* 0.5 = 0.179648 loss)
I0814 23:34:14.541196 10672 sgd_solver.cpp:106] Iteration 8980, lr = 6.09088e-05
I0814 23:34:19.781790 10672 solver.cpp:337] Iteration 9000, Testing net (#0)
I0814 23:35:22.898051 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.704484
I0814 23:35:22.898178 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.917375
I0814 23:35:22.898198 10672 solver.cpp:404]     Test net output #2: loss1 = 0.266667 (* 0.5 = 0.133334 loss)
I0814 23:35:22.898212 10672 solver.cpp:404]     Test net output #3: loss2 = 0.578207 (* 0.5 = 0.289103 loss)
I0814 23:35:22.981976 10672 solver.cpp:228] Iteration 9000, loss = 0.245989
I0814 23:35:22.982028 10672 solver.cpp:244]     Train net output #0: loss1 = 0.109147 (* 0.5 = 0.0545735 loss)
I0814 23:35:22.982043 10672 solver.cpp:244]     Train net output #1: loss2 = 0.382831 (* 0.5 = 0.191416 loss)
I0814 23:35:22.982059 10672 sgd_solver.cpp:106] Iteration 9000, lr = 6.08074e-05
I0814 23:35:28.499814 10672 solver.cpp:228] Iteration 9020, loss = 0.294524
I0814 23:35:28.499872 10672 solver.cpp:244]     Train net output #0: loss1 = 0.138541 (* 0.5 = 0.0692706 loss)
I0814 23:35:28.499888 10672 solver.cpp:244]     Train net output #1: loss2 = 0.450507 (* 0.5 = 0.225253 loss)
I0814 23:35:28.499902 10672 sgd_solver.cpp:106] Iteration 9020, lr = 6.07064e-05
I0814 23:35:34.016166 10672 solver.cpp:228] Iteration 9040, loss = 0.338407
I0814 23:35:34.016227 10672 solver.cpp:244]     Train net output #0: loss1 = 0.157701 (* 0.5 = 0.0788507 loss)
I0814 23:35:34.016242 10672 solver.cpp:244]     Train net output #1: loss2 = 0.519113 (* 0.5 = 0.259556 loss)
I0814 23:35:34.016257 10672 sgd_solver.cpp:106] Iteration 9040, lr = 6.06057e-05
I0814 23:35:39.534271 10672 solver.cpp:228] Iteration 9060, loss = 0.251042
I0814 23:35:39.534329 10672 solver.cpp:244]     Train net output #0: loss1 = 0.1958 (* 0.5 = 0.0978998 loss)
I0814 23:35:39.534345 10672 solver.cpp:244]     Train net output #1: loss2 = 0.306284 (* 0.5 = 0.153142 loss)
I0814 23:35:39.534359 10672 sgd_solver.cpp:106] Iteration 9060, lr = 6.05055e-05
I0814 23:35:45.044891 10672 solver.cpp:228] Iteration 9080, loss = 0.368799
I0814 23:35:45.044952 10672 solver.cpp:244]     Train net output #0: loss1 = 0.203232 (* 0.5 = 0.101616 loss)
I0814 23:35:45.044967 10672 solver.cpp:244]     Train net output #1: loss2 = 0.534366 (* 0.5 = 0.267183 loss)
I0814 23:35:45.044981 10672 sgd_solver.cpp:106] Iteration 9080, lr = 6.04056e-05
I0814 23:35:50.559664 10672 solver.cpp:228] Iteration 9100, loss = 0.261603
I0814 23:35:50.559723 10672 solver.cpp:244]     Train net output #0: loss1 = 0.14531 (* 0.5 = 0.0726552 loss)
I0814 23:35:50.559739 10672 solver.cpp:244]     Train net output #1: loss2 = 0.377896 (* 0.5 = 0.188948 loss)
I0814 23:35:50.559753 10672 sgd_solver.cpp:106] Iteration 9100, lr = 6.03061e-05
I0814 23:35:56.072923 10672 solver.cpp:228] Iteration 9120, loss = 0.321499
I0814 23:35:56.073062 10672 solver.cpp:244]     Train net output #0: loss1 = 0.205892 (* 0.5 = 0.102946 loss)
I0814 23:35:56.073086 10672 solver.cpp:244]     Train net output #1: loss2 = 0.437107 (* 0.5 = 0.218553 loss)
I0814 23:35:56.073102 10672 sgd_solver.cpp:106] Iteration 9120, lr = 6.0207e-05
I0814 23:36:01.591796 10672 solver.cpp:228] Iteration 9140, loss = 0.343835
I0814 23:36:01.591855 10672 solver.cpp:244]     Train net output #0: loss1 = 0.207246 (* 0.5 = 0.103623 loss)
I0814 23:36:01.591871 10672 solver.cpp:244]     Train net output #1: loss2 = 0.480424 (* 0.5 = 0.240212 loss)
I0814 23:36:01.591883 10672 sgd_solver.cpp:106] Iteration 9140, lr = 6.01083e-05
I0814 23:36:07.108798 10672 solver.cpp:228] Iteration 9160, loss = 0.264997
I0814 23:36:07.108860 10672 solver.cpp:244]     Train net output #0: loss1 = 0.135344 (* 0.5 = 0.067672 loss)
I0814 23:36:07.108875 10672 solver.cpp:244]     Train net output #1: loss2 = 0.39465 (* 0.5 = 0.197325 loss)
I0814 23:36:07.108889 10672 sgd_solver.cpp:106] Iteration 9160, lr = 6.00099e-05
I0814 23:36:12.628516 10672 solver.cpp:228] Iteration 9180, loss = 0.328314
I0814 23:36:12.628576 10672 solver.cpp:244]     Train net output #0: loss1 = 0.205543 (* 0.5 = 0.102772 loss)
I0814 23:36:12.628592 10672 solver.cpp:244]     Train net output #1: loss2 = 0.451085 (* 0.5 = 0.225543 loss)
I0814 23:36:12.628604 10672 sgd_solver.cpp:106] Iteration 9180, lr = 5.99119e-05
I0814 23:36:18.143285 10672 solver.cpp:228] Iteration 9200, loss = 0.338431
I0814 23:36:18.143344 10672 solver.cpp:244]     Train net output #0: loss1 = 0.236641 (* 0.5 = 0.11832 loss)
I0814 23:36:18.143360 10672 solver.cpp:244]     Train net output #1: loss2 = 0.440221 (* 0.5 = 0.220111 loss)
I0814 23:36:18.143373 10672 sgd_solver.cpp:106] Iteration 9200, lr = 5.98143e-05
I0814 23:36:23.661502 10672 solver.cpp:228] Iteration 9220, loss = 0.284649
I0814 23:36:23.661561 10672 solver.cpp:244]     Train net output #0: loss1 = 0.130149 (* 0.5 = 0.0650747 loss)
I0814 23:36:23.661577 10672 solver.cpp:244]     Train net output #1: loss2 = 0.439149 (* 0.5 = 0.219575 loss)
I0814 23:36:23.661592 10672 sgd_solver.cpp:106] Iteration 9220, lr = 5.97171e-05
I0814 23:36:29.181093 10672 solver.cpp:228] Iteration 9240, loss = 0.371931
I0814 23:36:29.181242 10672 solver.cpp:244]     Train net output #0: loss1 = 0.297602 (* 0.5 = 0.148801 loss)
I0814 23:36:29.181262 10672 solver.cpp:244]     Train net output #1: loss2 = 0.446261 (* 0.5 = 0.22313 loss)
I0814 23:36:29.181275 10672 sgd_solver.cpp:106] Iteration 9240, lr = 5.96202e-05
I0814 23:36:34.698979 10672 solver.cpp:228] Iteration 9260, loss = 0.30831
I0814 23:36:34.699035 10672 solver.cpp:244]     Train net output #0: loss1 = 0.23576 (* 0.5 = 0.11788 loss)
I0814 23:36:34.699051 10672 solver.cpp:244]     Train net output #1: loss2 = 0.38086 (* 0.5 = 0.19043 loss)
I0814 23:36:34.699064 10672 sgd_solver.cpp:106] Iteration 9260, lr = 5.95237e-05
I0814 23:36:40.220607 10672 solver.cpp:228] Iteration 9280, loss = 0.263677
I0814 23:36:40.220667 10672 solver.cpp:244]     Train net output #0: loss1 = 0.126442 (* 0.5 = 0.063221 loss)
I0814 23:36:40.220684 10672 solver.cpp:244]     Train net output #1: loss2 = 0.400912 (* 0.5 = 0.200456 loss)
I0814 23:36:40.220697 10672 sgd_solver.cpp:106] Iteration 9280, lr = 5.94276e-05
I0814 23:36:45.734596 10672 solver.cpp:228] Iteration 9300, loss = 0.289197
I0814 23:36:45.734653 10672 solver.cpp:244]     Train net output #0: loss1 = 0.191682 (* 0.5 = 0.0958411 loss)
I0814 23:36:45.734669 10672 solver.cpp:244]     Train net output #1: loss2 = 0.386712 (* 0.5 = 0.193356 loss)
I0814 23:36:45.734683 10672 sgd_solver.cpp:106] Iteration 9300, lr = 5.93318e-05
I0814 23:36:51.250989 10672 solver.cpp:228] Iteration 9320, loss = 0.337953
I0814 23:36:51.251047 10672 solver.cpp:244]     Train net output #0: loss1 = 0.163023 (* 0.5 = 0.0815113 loss)
I0814 23:36:51.251063 10672 solver.cpp:244]     Train net output #1: loss2 = 0.512882 (* 0.5 = 0.256441 loss)
I0814 23:36:51.251076 10672 sgd_solver.cpp:106] Iteration 9320, lr = 5.92364e-05
I0814 23:36:56.772958 10672 solver.cpp:228] Iteration 9340, loss = 0.278434
I0814 23:36:56.773020 10672 solver.cpp:244]     Train net output #0: loss1 = 0.202691 (* 0.5 = 0.101345 loss)
I0814 23:36:56.773036 10672 solver.cpp:244]     Train net output #1: loss2 = 0.354178 (* 0.5 = 0.177089 loss)
I0814 23:36:56.773048 10672 sgd_solver.cpp:106] Iteration 9340, lr = 5.91414e-05
I0814 23:37:02.294167 10672 solver.cpp:228] Iteration 9360, loss = 0.326262
I0814 23:37:02.294291 10672 solver.cpp:244]     Train net output #0: loss1 = 0.208409 (* 0.5 = 0.104204 loss)
I0814 23:37:02.294309 10672 solver.cpp:244]     Train net output #1: loss2 = 0.444115 (* 0.5 = 0.222058 loss)
I0814 23:37:02.294323 10672 sgd_solver.cpp:106] Iteration 9360, lr = 5.90467e-05
I0814 23:37:07.808784 10672 solver.cpp:228] Iteration 9380, loss = 0.32241
I0814 23:37:07.808864 10672 solver.cpp:244]     Train net output #0: loss1 = 0.232056 (* 0.5 = 0.116028 loss)
I0814 23:37:07.808881 10672 solver.cpp:244]     Train net output #1: loss2 = 0.412764 (* 0.5 = 0.206382 loss)
I0814 23:37:07.808893 10672 sgd_solver.cpp:106] Iteration 9380, lr = 5.89523e-05
I0814 23:37:13.327534 10672 solver.cpp:228] Iteration 9400, loss = 0.291866
I0814 23:37:13.327592 10672 solver.cpp:244]     Train net output #0: loss1 = 0.162627 (* 0.5 = 0.0813136 loss)
I0814 23:37:13.327608 10672 solver.cpp:244]     Train net output #1: loss2 = 0.421105 (* 0.5 = 0.210552 loss)
I0814 23:37:13.327622 10672 sgd_solver.cpp:106] Iteration 9400, lr = 5.88583e-05
I0814 23:37:18.838932 10672 solver.cpp:228] Iteration 9420, loss = 0.298014
I0814 23:37:18.838994 10672 solver.cpp:244]     Train net output #0: loss1 = 0.19011 (* 0.5 = 0.0950549 loss)
I0814 23:37:18.839010 10672 solver.cpp:244]     Train net output #1: loss2 = 0.405918 (* 0.5 = 0.202959 loss)
I0814 23:37:18.839023 10672 sgd_solver.cpp:106] Iteration 9420, lr = 5.87647e-05
I0814 23:37:24.355238 10672 solver.cpp:228] Iteration 9440, loss = 0.318931
I0814 23:37:24.355295 10672 solver.cpp:244]     Train net output #0: loss1 = 0.130314 (* 0.5 = 0.0651571 loss)
I0814 23:37:24.355310 10672 solver.cpp:244]     Train net output #1: loss2 = 0.507547 (* 0.5 = 0.253774 loss)
I0814 23:37:24.355324 10672 sgd_solver.cpp:106] Iteration 9440, lr = 5.86714e-05
I0814 23:37:29.871495 10672 solver.cpp:228] Iteration 9460, loss = 0.324547
I0814 23:37:29.871556 10672 solver.cpp:244]     Train net output #0: loss1 = 0.197037 (* 0.5 = 0.0985185 loss)
I0814 23:37:29.871572 10672 solver.cpp:244]     Train net output #1: loss2 = 0.452057 (* 0.5 = 0.226028 loss)
I0814 23:37:29.871585 10672 sgd_solver.cpp:106] Iteration 9460, lr = 5.85784e-05
I0814 23:37:35.382051 10672 solver.cpp:228] Iteration 9480, loss = 0.310041
I0814 23:37:35.382201 10672 solver.cpp:244]     Train net output #0: loss1 = 0.126094 (* 0.5 = 0.0630471 loss)
I0814 23:37:35.382220 10672 solver.cpp:244]     Train net output #1: loss2 = 0.493987 (* 0.5 = 0.246994 loss)
I0814 23:37:35.382233 10672 sgd_solver.cpp:106] Iteration 9480, lr = 5.84858e-05
I0814 23:37:40.898573 10672 solver.cpp:228] Iteration 9500, loss = 0.244493
I0814 23:37:40.898633 10672 solver.cpp:244]     Train net output #0: loss1 = 0.113606 (* 0.5 = 0.0568029 loss)
I0814 23:37:40.898648 10672 solver.cpp:244]     Train net output #1: loss2 = 0.375379 (* 0.5 = 0.18769 loss)
I0814 23:37:40.898661 10672 sgd_solver.cpp:106] Iteration 9500, lr = 5.83935e-05
I0814 23:37:46.417058 10672 solver.cpp:228] Iteration 9520, loss = 0.339639
I0814 23:37:46.417117 10672 solver.cpp:244]     Train net output #0: loss1 = 0.224076 (* 0.5 = 0.112038 loss)
I0814 23:37:46.417134 10672 solver.cpp:244]     Train net output #1: loss2 = 0.455202 (* 0.5 = 0.227601 loss)
I0814 23:37:46.417146 10672 sgd_solver.cpp:106] Iteration 9520, lr = 5.83016e-05
I0814 23:37:51.932597 10672 solver.cpp:228] Iteration 9540, loss = 0.255007
I0814 23:37:51.932656 10672 solver.cpp:244]     Train net output #0: loss1 = 0.128178 (* 0.5 = 0.064089 loss)
I0814 23:37:51.932672 10672 solver.cpp:244]     Train net output #1: loss2 = 0.381836 (* 0.5 = 0.190918 loss)
I0814 23:37:51.932687 10672 sgd_solver.cpp:106] Iteration 9540, lr = 5.821e-05
I0814 23:37:57.450036 10672 solver.cpp:228] Iteration 9560, loss = 0.220722
I0814 23:37:57.450093 10672 solver.cpp:244]     Train net output #0: loss1 = 0.0713468 (* 0.5 = 0.0356734 loss)
I0814 23:37:57.450109 10672 solver.cpp:244]     Train net output #1: loss2 = 0.370097 (* 0.5 = 0.185048 loss)
I0814 23:37:57.450124 10672 sgd_solver.cpp:106] Iteration 9560, lr = 5.81187e-05
I0814 23:38:02.971732 10672 solver.cpp:228] Iteration 9580, loss = 0.288222
I0814 23:38:02.971791 10672 solver.cpp:244]     Train net output #0: loss1 = 0.130354 (* 0.5 = 0.0651771 loss)
I0814 23:38:02.971807 10672 solver.cpp:244]     Train net output #1: loss2 = 0.44609 (* 0.5 = 0.223045 loss)
I0814 23:38:02.971820 10672 sgd_solver.cpp:106] Iteration 9580, lr = 5.80278e-05
I0814 23:38:08.493908 10672 solver.cpp:228] Iteration 9600, loss = 0.233366
I0814 23:38:08.494050 10672 solver.cpp:244]     Train net output #0: loss1 = 0.0882409 (* 0.5 = 0.0441205 loss)
I0814 23:38:08.494074 10672 solver.cpp:244]     Train net output #1: loss2 = 0.378491 (* 0.5 = 0.189245 loss)
I0814 23:38:08.494091 10672 sgd_solver.cpp:106] Iteration 9600, lr = 5.79372e-05
I0814 23:38:14.010448 10672 solver.cpp:228] Iteration 9620, loss = 0.39985
I0814 23:38:14.010514 10672 solver.cpp:244]     Train net output #0: loss1 = 0.337614 (* 0.5 = 0.168807 loss)
I0814 23:38:14.010529 10672 solver.cpp:244]     Train net output #1: loss2 = 0.462086 (* 0.5 = 0.231043 loss)
I0814 23:38:14.010543 10672 sgd_solver.cpp:106] Iteration 9620, lr = 5.78469e-05
I0814 23:38:19.529388 10672 solver.cpp:228] Iteration 9640, loss = 0.270844
I0814 23:38:19.529448 10672 solver.cpp:244]     Train net output #0: loss1 = 0.150287 (* 0.5 = 0.0751433 loss)
I0814 23:38:19.529464 10672 solver.cpp:244]     Train net output #1: loss2 = 0.391402 (* 0.5 = 0.195701 loss)
I0814 23:38:19.529476 10672 sgd_solver.cpp:106] Iteration 9640, lr = 5.7757e-05
I0814 23:38:25.040232 10672 solver.cpp:228] Iteration 9660, loss = 0.314888
I0814 23:38:25.040292 10672 solver.cpp:244]     Train net output #0: loss1 = 0.157061 (* 0.5 = 0.0785307 loss)
I0814 23:38:25.040308 10672 solver.cpp:244]     Train net output #1: loss2 = 0.472714 (* 0.5 = 0.236357 loss)
I0814 23:38:25.040323 10672 sgd_solver.cpp:106] Iteration 9660, lr = 5.76674e-05
I0814 23:38:30.561743 10672 solver.cpp:228] Iteration 9680, loss = 0.345851
I0814 23:38:30.561799 10672 solver.cpp:244]     Train net output #0: loss1 = 0.231804 (* 0.5 = 0.115902 loss)
I0814 23:38:30.561815 10672 solver.cpp:244]     Train net output #1: loss2 = 0.459899 (* 0.5 = 0.229949 loss)
I0814 23:38:30.561827 10672 sgd_solver.cpp:106] Iteration 9680, lr = 5.75781e-05
I0814 23:38:36.079254 10672 solver.cpp:228] Iteration 9700, loss = 0.276619
I0814 23:38:36.079311 10672 solver.cpp:244]     Train net output #0: loss1 = 0.149345 (* 0.5 = 0.0746723 loss)
I0814 23:38:36.079327 10672 solver.cpp:244]     Train net output #1: loss2 = 0.403893 (* 0.5 = 0.201946 loss)
I0814 23:38:36.079341 10672 sgd_solver.cpp:106] Iteration 9700, lr = 5.74891e-05
I0814 23:38:41.594153 10672 solver.cpp:228] Iteration 9720, loss = 0.305942
I0814 23:38:41.594300 10672 solver.cpp:244]     Train net output #0: loss1 = 0.213098 (* 0.5 = 0.106549 loss)
I0814 23:38:41.594317 10672 solver.cpp:244]     Train net output #1: loss2 = 0.398786 (* 0.5 = 0.199393 loss)
I0814 23:38:41.594334 10672 sgd_solver.cpp:106] Iteration 9720, lr = 5.74005e-05
I0814 23:38:47.116341 10672 solver.cpp:228] Iteration 9740, loss = 0.288519
I0814 23:38:47.116401 10672 solver.cpp:244]     Train net output #0: loss1 = 0.129195 (* 0.5 = 0.0645977 loss)
I0814 23:38:47.116417 10672 solver.cpp:244]     Train net output #1: loss2 = 0.447843 (* 0.5 = 0.223921 loss)
I0814 23:38:47.116431 10672 sgd_solver.cpp:106] Iteration 9740, lr = 5.73121e-05
I0814 23:38:52.630023 10672 solver.cpp:228] Iteration 9760, loss = 0.28824
I0814 23:38:52.630081 10672 solver.cpp:244]     Train net output #0: loss1 = 0.129208 (* 0.5 = 0.0646042 loss)
I0814 23:38:52.630097 10672 solver.cpp:244]     Train net output #1: loss2 = 0.447272 (* 0.5 = 0.223636 loss)
I0814 23:38:52.630110 10672 sgd_solver.cpp:106] Iteration 9760, lr = 5.72241e-05
I0814 23:38:58.145889 10672 solver.cpp:228] Iteration 9780, loss = 0.290039
I0814 23:38:58.145953 10672 solver.cpp:244]     Train net output #0: loss1 = 0.159954 (* 0.5 = 0.0799768 loss)
I0814 23:38:58.145970 10672 solver.cpp:244]     Train net output #1: loss2 = 0.420124 (* 0.5 = 0.210062 loss)
I0814 23:38:58.145985 10672 sgd_solver.cpp:106] Iteration 9780, lr = 5.71364e-05
I0814 23:39:03.668721 10672 solver.cpp:228] Iteration 9800, loss = 0.239364
I0814 23:39:03.668781 10672 solver.cpp:244]     Train net output #0: loss1 = 0.136444 (* 0.5 = 0.0682219 loss)
I0814 23:39:03.668797 10672 solver.cpp:244]     Train net output #1: loss2 = 0.342284 (* 0.5 = 0.171142 loss)
I0814 23:39:03.668810 10672 sgd_solver.cpp:106] Iteration 9800, lr = 5.7049e-05
I0814 23:39:09.187746 10672 solver.cpp:228] Iteration 9820, loss = 0.364283
I0814 23:39:09.187803 10672 solver.cpp:244]     Train net output #0: loss1 = 0.16699 (* 0.5 = 0.0834952 loss)
I0814 23:39:09.187819 10672 solver.cpp:244]     Train net output #1: loss2 = 0.561576 (* 0.5 = 0.280788 loss)
I0814 23:39:09.187831 10672 sgd_solver.cpp:106] Iteration 9820, lr = 5.6962e-05
I0814 23:39:14.706842 10672 solver.cpp:228] Iteration 9840, loss = 0.268024
I0814 23:39:14.706996 10672 solver.cpp:244]     Train net output #0: loss1 = 0.178621 (* 0.5 = 0.0893103 loss)
I0814 23:39:14.707015 10672 solver.cpp:244]     Train net output #1: loss2 = 0.357427 (* 0.5 = 0.178714 loss)
I0814 23:39:14.707028 10672 sgd_solver.cpp:106] Iteration 9840, lr = 5.68752e-05
I0814 23:39:20.224005 10672 solver.cpp:228] Iteration 9860, loss = 0.213917
I0814 23:39:20.224066 10672 solver.cpp:244]     Train net output #0: loss1 = 0.0854173 (* 0.5 = 0.0427087 loss)
I0814 23:39:20.224081 10672 solver.cpp:244]     Train net output #1: loss2 = 0.342418 (* 0.5 = 0.171209 loss)
I0814 23:39:20.224095 10672 sgd_solver.cpp:106] Iteration 9860, lr = 5.67887e-05
I0814 23:39:25.739089 10672 solver.cpp:228] Iteration 9880, loss = 0.288836
I0814 23:39:25.739145 10672 solver.cpp:244]     Train net output #0: loss1 = 0.107617 (* 0.5 = 0.0538086 loss)
I0814 23:39:25.739162 10672 solver.cpp:244]     Train net output #1: loss2 = 0.470055 (* 0.5 = 0.235028 loss)
I0814 23:39:25.739176 10672 sgd_solver.cpp:106] Iteration 9880, lr = 5.67026e-05
I0814 23:39:31.254004 10672 solver.cpp:228] Iteration 9900, loss = 0.319894
I0814 23:39:31.254063 10672 solver.cpp:244]     Train net output #0: loss1 = 0.117401 (* 0.5 = 0.0587007 loss)
I0814 23:39:31.254078 10672 solver.cpp:244]     Train net output #1: loss2 = 0.522386 (* 0.5 = 0.261193 loss)
I0814 23:39:31.254092 10672 sgd_solver.cpp:106] Iteration 9900, lr = 5.66167e-05
I0814 23:39:36.769820 10672 solver.cpp:228] Iteration 9920, loss = 0.295812
I0814 23:39:36.769877 10672 solver.cpp:244]     Train net output #0: loss1 = 0.220326 (* 0.5 = 0.110163 loss)
I0814 23:39:36.769892 10672 solver.cpp:244]     Train net output #1: loss2 = 0.371298 (* 0.5 = 0.185649 loss)
I0814 23:39:36.769906 10672 sgd_solver.cpp:106] Iteration 9920, lr = 5.65312e-05
I0814 23:39:42.286900 10672 solver.cpp:228] Iteration 9940, loss = 0.313104
I0814 23:39:42.286955 10672 solver.cpp:244]     Train net output #0: loss1 = 0.172885 (* 0.5 = 0.0864424 loss)
I0814 23:39:42.286970 10672 solver.cpp:244]     Train net output #1: loss2 = 0.453323 (* 0.5 = 0.226662 loss)
I0814 23:39:42.286984 10672 sgd_solver.cpp:106] Iteration 9940, lr = 5.64459e-05
I0814 23:39:47.801421 10672 solver.cpp:228] Iteration 9960, loss = 0.262819
I0814 23:39:47.801542 10672 solver.cpp:244]     Train net output #0: loss1 = 0.136307 (* 0.5 = 0.0681536 loss)
I0814 23:39:47.801558 10672 solver.cpp:244]     Train net output #1: loss2 = 0.389331 (* 0.5 = 0.194665 loss)
I0814 23:39:47.801571 10672 sgd_solver.cpp:106] Iteration 9960, lr = 5.6361e-05
I0814 23:39:53.312805 10672 solver.cpp:228] Iteration 9980, loss = 0.298892
I0814 23:39:53.312866 10672 solver.cpp:244]     Train net output #0: loss1 = 0.166738 (* 0.5 = 0.0833691 loss)
I0814 23:39:53.312882 10672 solver.cpp:244]     Train net output #1: loss2 = 0.431047 (* 0.5 = 0.215523 loss)
I0814 23:39:53.312896 10672 sgd_solver.cpp:106] Iteration 9980, lr = 5.62763e-05
I0814 23:39:58.551988 10672 solver.cpp:454] Snapshotting to binary proto file models/gender_glasses/gg_net_train_iter_10000.caffemodel
I0814 23:40:00.763155 10672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/gender_glasses/gg_net_train_iter_10000.solverstate
I0814 23:40:01.088465 10672 solver.cpp:317] Iteration 10000, loss = 0.371215
I0814 23:40:01.088544 10672 solver.cpp:337] Iteration 10000, Testing net (#0)
I0814 23:41:03.959962 10672 solver.cpp:404]     Test net output #0: accuracy_gender = 0.701766
I0814 23:41:03.960054 10672 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.919281
I0814 23:41:03.960074 10672 solver.cpp:404]     Test net output #2: loss1 = 0.266657 (* 0.5 = 0.133328 loss)
I0814 23:41:03.960088 10672 solver.cpp:404]     Test net output #3: loss2 = 0.592431 (* 0.5 = 0.296216 loss)
I0814 23:41:03.960098 10672 solver.cpp:322] Optimization Done.
I0814 23:41:03.960106 10672 caffe.cpp:254] Optimization Done.
