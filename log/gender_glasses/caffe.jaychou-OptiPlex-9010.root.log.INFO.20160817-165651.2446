Log file created at: 2016/08/17 16:56:51
Running on machine: jaychou-OptiPlex-9010
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0817 16:56:51.102489  2446 caffe.cpp:217] Using GPUs 0
I0817 16:56:51.266242  2446 caffe.cpp:222] GPU 0: GeForce GTX 650 Ti
I0817 16:56:51.976153  2446 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 10000
snapshot_prefix: "models/gender_glasses/gg_net_train"
solver_mode: GPU
device_id: 0
net: "models/gender_glasses/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0817 16:56:51.980948  2446 solver.cpp:91] Creating training net from net file: models/gender_glasses/train_val.prototxt
I0817 16:56:51.985051  2446 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0817 16:56:51.985098  2446 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer labels
I0817 16:56:51.985141  2446 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_glasses
I0817 16:56:51.985165  2446 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_gender
I0817 16:56:51.985410  2446 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.4
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.6
}
I0817 16:56:51.986551  2446 layer_factory.hpp:77] Creating layer data
I0817 16:56:51.991504  2446 net.cpp:100] Creating Layer data
I0817 16:56:51.991557  2446 net.cpp:408] data -> data
I0817 16:56:52.015148  2455 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_lmdb
I0817 16:56:52.383718  2446 data_layer.cpp:41] output data size: 100,3,80,80
I0817 16:56:52.399705  2446 net.cpp:150] Setting up data
I0817 16:56:52.399772  2446 net.cpp:157] Top shape: 100 3 80 80 (1920000)
I0817 16:56:52.399791  2446 net.cpp:165] Memory required for data: 7680000
I0817 16:56:52.399816  2446 layer_factory.hpp:77] Creating layer labels
I0817 16:56:52.399996  2446 net.cpp:100] Creating Layer labels
I0817 16:56:52.400030  2446 net.cpp:408] labels -> labels
I0817 16:56:52.403894  2457 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_train_label_lmdb
I0817 16:56:52.413002  2446 data_layer.cpp:41] output data size: 100,2,1,1
I0817 16:56:52.413674  2446 net.cpp:150] Setting up labels
I0817 16:56:52.413725  2446 net.cpp:157] Top shape: 100 2 1 1 (200)
I0817 16:56:52.413745  2446 net.cpp:165] Memory required for data: 7680800
I0817 16:56:52.413764  2446 layer_factory.hpp:77] Creating layer slice1
I0817 16:56:52.413800  2446 net.cpp:100] Creating Layer slice1
I0817 16:56:52.413821  2446 net.cpp:434] slice1 <- labels
I0817 16:56:52.413851  2446 net.cpp:408] slice1 -> glasses
I0817 16:56:52.413894  2446 net.cpp:408] slice1 -> gender
I0817 16:56:52.414697  2446 net.cpp:150] Setting up slice1
I0817 16:56:52.414743  2446 net.cpp:157] Top shape: 100 1 1 1 (100)
I0817 16:56:52.414763  2446 net.cpp:157] Top shape: 100 1 1 1 (100)
I0817 16:56:52.414783  2446 net.cpp:165] Memory required for data: 7681600
I0817 16:56:52.414798  2446 layer_factory.hpp:77] Creating layer conv1
I0817 16:56:52.414841  2446 net.cpp:100] Creating Layer conv1
I0817 16:56:52.414863  2446 net.cpp:434] conv1 <- data
I0817 16:56:52.414887  2446 net.cpp:408] conv1 -> conv1
I0817 16:56:53.697860  2446 net.cpp:150] Setting up conv1
I0817 16:56:53.697923  2446 net.cpp:157] Top shape: 100 20 76 76 (11552000)
I0817 16:56:53.697942  2446 net.cpp:165] Memory required for data: 53889600
I0817 16:56:53.697981  2446 layer_factory.hpp:77] Creating layer relu1
I0817 16:56:53.698012  2446 net.cpp:100] Creating Layer relu1
I0817 16:56:53.698035  2446 net.cpp:434] relu1 <- conv1
I0817 16:56:53.698055  2446 net.cpp:395] relu1 -> conv1 (in-place)
I0817 16:56:53.698869  2446 net.cpp:150] Setting up relu1
I0817 16:56:53.698915  2446 net.cpp:157] Top shape: 100 20 76 76 (11552000)
I0817 16:56:53.698943  2446 net.cpp:165] Memory required for data: 100097600
I0817 16:56:53.698966  2446 layer_factory.hpp:77] Creating layer pool1
I0817 16:56:53.698990  2446 net.cpp:100] Creating Layer pool1
I0817 16:56:53.699007  2446 net.cpp:434] pool1 <- conv1
I0817 16:56:53.699025  2446 net.cpp:408] pool1 -> pool1
I0817 16:56:53.699101  2446 net.cpp:150] Setting up pool1
I0817 16:56:53.699126  2446 net.cpp:157] Top shape: 100 20 38 38 (2888000)
I0817 16:56:53.699141  2446 net.cpp:165] Memory required for data: 111649600
I0817 16:56:53.699156  2446 layer_factory.hpp:77] Creating layer conv2
I0817 16:56:53.699182  2446 net.cpp:100] Creating Layer conv2
I0817 16:56:53.699201  2446 net.cpp:434] conv2 <- pool1
I0817 16:56:53.699220  2446 net.cpp:408] conv2 -> conv2
I0817 16:56:53.701258  2446 net.cpp:150] Setting up conv2
I0817 16:56:53.701293  2446 net.cpp:157] Top shape: 100 48 34 34 (5548800)
I0817 16:56:53.701310  2446 net.cpp:165] Memory required for data: 133844800
I0817 16:56:53.701373  2446 layer_factory.hpp:77] Creating layer relu2
I0817 16:56:53.701396  2446 net.cpp:100] Creating Layer relu2
I0817 16:56:53.701412  2446 net.cpp:434] relu2 <- conv2
I0817 16:56:53.701431  2446 net.cpp:395] relu2 -> conv2 (in-place)
I0817 16:56:53.701611  2446 net.cpp:150] Setting up relu2
I0817 16:56:53.701637  2446 net.cpp:157] Top shape: 100 48 34 34 (5548800)
I0817 16:56:53.701653  2446 net.cpp:165] Memory required for data: 156040000
I0817 16:56:53.701670  2446 layer_factory.hpp:77] Creating layer pool2
I0817 16:56:53.701691  2446 net.cpp:100] Creating Layer pool2
I0817 16:56:53.701706  2446 net.cpp:434] pool2 <- conv2
I0817 16:56:53.701725  2446 net.cpp:408] pool2 -> pool2
I0817 16:56:53.701788  2446 net.cpp:150] Setting up pool2
I0817 16:56:53.701812  2446 net.cpp:157] Top shape: 100 48 17 17 (1387200)
I0817 16:56:53.701850  2446 net.cpp:165] Memory required for data: 161588800
I0817 16:56:53.701866  2446 layer_factory.hpp:77] Creating layer conv3
I0817 16:56:53.701889  2446 net.cpp:100] Creating Layer conv3
I0817 16:56:53.701905  2446 net.cpp:434] conv3 <- pool2
I0817 16:56:53.701925  2446 net.cpp:408] conv3 -> conv3
I0817 16:56:53.703323  2446 net.cpp:150] Setting up conv3
I0817 16:56:53.703358  2446 net.cpp:157] Top shape: 100 64 15 15 (1440000)
I0817 16:56:53.703374  2446 net.cpp:165] Memory required for data: 167348800
I0817 16:56:53.703395  2446 layer_factory.hpp:77] Creating layer relu3
I0817 16:56:53.703414  2446 net.cpp:100] Creating Layer relu3
I0817 16:56:53.703430  2446 net.cpp:434] relu3 <- conv3
I0817 16:56:53.703451  2446 net.cpp:395] relu3 -> conv3 (in-place)
I0817 16:56:53.703609  2446 net.cpp:150] Setting up relu3
I0817 16:56:53.703634  2446 net.cpp:157] Top shape: 100 64 15 15 (1440000)
I0817 16:56:53.703649  2446 net.cpp:165] Memory required for data: 173108800
I0817 16:56:53.703670  2446 layer_factory.hpp:77] Creating layer ip1
I0817 16:56:53.722811  2446 net.cpp:100] Creating Layer ip1
I0817 16:56:53.722849  2446 net.cpp:434] ip1 <- conv3
I0817 16:56:53.722870  2446 net.cpp:408] ip1 -> ip1
I0817 16:56:53.799729  2446 net.cpp:150] Setting up ip1
I0817 16:56:53.799784  2446 net.cpp:157] Top shape: 100 512 (51200)
I0817 16:56:53.799798  2446 net.cpp:165] Memory required for data: 173313600
I0817 16:56:53.799818  2446 layer_factory.hpp:77] Creating layer relu5
I0817 16:56:53.799840  2446 net.cpp:100] Creating Layer relu5
I0817 16:56:53.799854  2446 net.cpp:434] relu5 <- ip1
I0817 16:56:53.799870  2446 net.cpp:395] relu5 -> ip1 (in-place)
I0817 16:56:53.799973  2446 net.cpp:150] Setting up relu5
I0817 16:56:53.799993  2446 net.cpp:157] Top shape: 100 512 (51200)
I0817 16:56:53.800004  2446 net.cpp:165] Memory required for data: 173518400
I0817 16:56:53.800017  2446 layer_factory.hpp:77] Creating layer drop1
I0817 16:56:53.813168  2446 net.cpp:100] Creating Layer drop1
I0817 16:56:53.813199  2446 net.cpp:434] drop1 <- ip1
I0817 16:56:53.813216  2446 net.cpp:395] drop1 -> ip1 (in-place)
I0817 16:56:53.813274  2446 net.cpp:150] Setting up drop1
I0817 16:56:53.813344  2446 net.cpp:157] Top shape: 100 512 (51200)
I0817 16:56:53.813359  2446 net.cpp:165] Memory required for data: 173723200
I0817 16:56:53.813370  2446 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0817 16:56:53.820361  2446 net.cpp:100] Creating Layer ip1_drop1_0_split
I0817 16:56:53.820392  2446 net.cpp:434] ip1_drop1_0_split <- ip1
I0817 16:56:53.820410  2446 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0817 16:56:53.820426  2446 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0817 16:56:53.820489  2446 net.cpp:150] Setting up ip1_drop1_0_split
I0817 16:56:53.820509  2446 net.cpp:157] Top shape: 100 512 (51200)
I0817 16:56:53.820523  2446 net.cpp:157] Top shape: 100 512 (51200)
I0817 16:56:53.820534  2446 net.cpp:165] Memory required for data: 174132800
I0817 16:56:53.820545  2446 layer_factory.hpp:77] Creating layer ip2
I0817 16:56:53.820561  2446 net.cpp:100] Creating Layer ip2
I0817 16:56:53.820572  2446 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0817 16:56:53.820616  2446 net.cpp:408] ip2 -> ip2
I0817 16:56:53.820742  2446 net.cpp:150] Setting up ip2
I0817 16:56:53.820761  2446 net.cpp:157] Top shape: 100 2 (200)
I0817 16:56:53.820773  2446 net.cpp:165] Memory required for data: 174133600
I0817 16:56:53.820790  2446 layer_factory.hpp:77] Creating layer loss1
I0817 16:56:53.820811  2446 net.cpp:100] Creating Layer loss1
I0817 16:56:53.820824  2446 net.cpp:434] loss1 <- ip2
I0817 16:56:53.820837  2446 net.cpp:434] loss1 <- glasses
I0817 16:56:53.820853  2446 net.cpp:408] loss1 -> loss1
I0817 16:56:53.820875  2446 layer_factory.hpp:77] Creating layer loss1
I0817 16:56:53.821383  2446 net.cpp:150] Setting up loss1
I0817 16:56:53.821408  2446 net.cpp:157] Top shape: (1)
I0817 16:56:53.821421  2446 net.cpp:160]     with loss weight 0.4
I0817 16:56:53.821450  2446 net.cpp:165] Memory required for data: 174133604
I0817 16:56:53.821462  2446 layer_factory.hpp:77] Creating layer ip3
I0817 16:56:53.821477  2446 net.cpp:100] Creating Layer ip3
I0817 16:56:53.821490  2446 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0817 16:56:53.821507  2446 net.cpp:408] ip3 -> ip3
I0817 16:56:53.824107  2446 net.cpp:150] Setting up ip3
I0817 16:56:53.824132  2446 net.cpp:157] Top shape: 100 512 (51200)
I0817 16:56:53.824144  2446 net.cpp:165] Memory required for data: 174338404
I0817 16:56:53.824160  2446 layer_factory.hpp:77] Creating layer loss2
I0817 16:56:53.824175  2446 net.cpp:100] Creating Layer loss2
I0817 16:56:53.824187  2446 net.cpp:434] loss2 <- ip3
I0817 16:56:53.824199  2446 net.cpp:434] loss2 <- gender
I0817 16:56:53.824219  2446 net.cpp:408] loss2 -> loss2
I0817 16:56:53.824237  2446 layer_factory.hpp:77] Creating layer loss2
I0817 16:56:53.824549  2446 net.cpp:150] Setting up loss2
I0817 16:56:53.824571  2446 net.cpp:157] Top shape: (1)
I0817 16:56:53.824582  2446 net.cpp:160]     with loss weight 0.6
I0817 16:56:53.824597  2446 net.cpp:165] Memory required for data: 174338408
I0817 16:56:53.824609  2446 net.cpp:226] loss2 needs backward computation.
I0817 16:56:53.824620  2446 net.cpp:226] ip3 needs backward computation.
I0817 16:56:53.824631  2446 net.cpp:226] loss1 needs backward computation.
I0817 16:56:53.824642  2446 net.cpp:226] ip2 needs backward computation.
I0817 16:56:53.824653  2446 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0817 16:56:53.824664  2446 net.cpp:226] drop1 needs backward computation.
I0817 16:56:53.824676  2446 net.cpp:226] relu5 needs backward computation.
I0817 16:56:53.824687  2446 net.cpp:226] ip1 needs backward computation.
I0817 16:56:53.824698  2446 net.cpp:226] relu3 needs backward computation.
I0817 16:56:53.824709  2446 net.cpp:226] conv3 needs backward computation.
I0817 16:56:53.824720  2446 net.cpp:226] pool2 needs backward computation.
I0817 16:56:53.824731  2446 net.cpp:226] relu2 needs backward computation.
I0817 16:56:53.824741  2446 net.cpp:226] conv2 needs backward computation.
I0817 16:56:53.824753  2446 net.cpp:226] pool1 needs backward computation.
I0817 16:56:53.824764  2446 net.cpp:226] relu1 needs backward computation.
I0817 16:56:53.824774  2446 net.cpp:226] conv1 needs backward computation.
I0817 16:56:53.824784  2446 net.cpp:228] slice1 does not need backward computation.
I0817 16:56:53.824796  2446 net.cpp:228] labels does not need backward computation.
I0817 16:56:53.824806  2446 net.cpp:228] data does not need backward computation.
I0817 16:56:53.824816  2446 net.cpp:270] This network produces output loss1
I0817 16:56:53.824827  2446 net.cpp:270] This network produces output loss2
I0817 16:56:53.824854  2446 net.cpp:283] Network initialization done.
I0817 16:56:53.825489  2446 solver.cpp:181] Creating test net (#0) specified by net file: models/gender_glasses/train_val.prototxt
I0817 16:56:53.825542  2446 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0817 16:56:53.825556  2446 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer labels
I0817 16:56:53.825727  2446 net.cpp:58] Initializing net from parameters: 
name: "multi_task"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "labels"
  type: "Data"
  top: "labels"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "slice1"
  type: "Slice"
  bottom: "labels"
  top: "glasses"
  top: "gender"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 20
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 48
    pad: 0
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0.1
  }
  param {
    lr_mult: 0.1
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "glasses"
  top: "loss1"
  loss_weight: 0.4
}
layer {
  name: "accuracy_glasses"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "glasses"
  top: "accuracy_glasses"
  include {
    phase: TEST
  }
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip3"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss2"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "gender"
  top: "loss2"
  loss_weight: 0.6
}
layer {
  name: "accuracy_gender"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "gender"
  top: "accuracy_gender"
  include {
    phase: TEST
  }
}
I0817 16:56:53.826494  2446 layer_factory.hpp:77] Creating layer data
I0817 16:56:53.826609  2446 net.cpp:100] Creating Layer data
I0817 16:56:53.826628  2446 net.cpp:408] data -> data
I0817 16:56:53.848220  2459 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_lmdb
I0817 16:56:53.852365  2446 data_layer.cpp:41] output data size: 64,3,80,80
I0817 16:56:53.862607  2446 net.cpp:150] Setting up data
I0817 16:56:53.862670  2446 net.cpp:157] Top shape: 64 3 80 80 (1228800)
I0817 16:56:53.862684  2446 net.cpp:165] Memory required for data: 4915200
I0817 16:56:53.862700  2446 layer_factory.hpp:77] Creating layer labels
I0817 16:56:53.862977  2446 net.cpp:100] Creating Layer labels
I0817 16:56:53.863004  2446 net.cpp:408] labels -> labels
I0817 16:56:53.873970  2460 blocking_queue.cpp:50] Waiting for data
I0817 16:56:53.888023  2461 db_lmdb.cpp:35] Opened lmdb /home/jaychou/code/new_caffe/caffe-master/examples/gender_glasses/gender_glasses_val_label_lmdb
I0817 16:56:53.889396  2446 data_layer.cpp:41] output data size: 64,2,1,1
I0817 16:56:53.890175  2446 net.cpp:150] Setting up labels
I0817 16:56:53.890220  2446 net.cpp:157] Top shape: 64 2 1 1 (128)
I0817 16:56:53.890234  2446 net.cpp:165] Memory required for data: 4915712
I0817 16:56:53.890249  2446 layer_factory.hpp:77] Creating layer slice1
I0817 16:56:53.890275  2446 net.cpp:100] Creating Layer slice1
I0817 16:56:53.890295  2446 net.cpp:434] slice1 <- labels
I0817 16:56:53.890312  2446 net.cpp:408] slice1 -> glasses
I0817 16:56:53.890336  2446 net.cpp:408] slice1 -> gender
I0817 16:56:53.890396  2446 net.cpp:150] Setting up slice1
I0817 16:56:53.890419  2446 net.cpp:157] Top shape: 64 1 1 1 (64)
I0817 16:56:53.890434  2446 net.cpp:157] Top shape: 64 1 1 1 (64)
I0817 16:56:53.890446  2446 net.cpp:165] Memory required for data: 4916224
I0817 16:56:53.890458  2446 layer_factory.hpp:77] Creating layer glasses_slice1_0_split
I0817 16:56:53.890475  2446 net.cpp:100] Creating Layer glasses_slice1_0_split
I0817 16:56:53.890491  2446 net.cpp:434] glasses_slice1_0_split <- glasses
I0817 16:56:53.890506  2446 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_0
I0817 16:56:53.890522  2446 net.cpp:408] glasses_slice1_0_split -> glasses_slice1_0_split_1
I0817 16:56:53.890581  2446 net.cpp:150] Setting up glasses_slice1_0_split
I0817 16:56:53.890602  2446 net.cpp:157] Top shape: 64 1 1 1 (64)
I0817 16:56:53.890616  2446 net.cpp:157] Top shape: 64 1 1 1 (64)
I0817 16:56:53.890630  2446 net.cpp:165] Memory required for data: 4916736
I0817 16:56:53.890641  2446 layer_factory.hpp:77] Creating layer gender_slice1_1_split
I0817 16:56:53.890660  2446 net.cpp:100] Creating Layer gender_slice1_1_split
I0817 16:56:53.890674  2446 net.cpp:434] gender_slice1_1_split <- gender
I0817 16:56:53.890688  2446 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_0
I0817 16:56:53.890708  2446 net.cpp:408] gender_slice1_1_split -> gender_slice1_1_split_1
I0817 16:56:53.890761  2446 net.cpp:150] Setting up gender_slice1_1_split
I0817 16:56:53.890781  2446 net.cpp:157] Top shape: 64 1 1 1 (64)
I0817 16:56:53.890796  2446 net.cpp:157] Top shape: 64 1 1 1 (64)
I0817 16:56:53.890808  2446 net.cpp:165] Memory required for data: 4917248
I0817 16:56:53.890820  2446 layer_factory.hpp:77] Creating layer conv1
I0817 16:56:53.890842  2446 net.cpp:100] Creating Layer conv1
I0817 16:56:53.890857  2446 net.cpp:434] conv1 <- data
I0817 16:56:53.890877  2446 net.cpp:408] conv1 -> conv1
I0817 16:56:53.892920  2446 net.cpp:150] Setting up conv1
I0817 16:56:53.892956  2446 net.cpp:157] Top shape: 64 20 76 76 (7393280)
I0817 16:56:53.892983  2446 net.cpp:165] Memory required for data: 34490368
I0817 16:56:53.893009  2446 layer_factory.hpp:77] Creating layer relu1
I0817 16:56:53.893030  2446 net.cpp:100] Creating Layer relu1
I0817 16:56:53.893044  2446 net.cpp:434] relu1 <- conv1
I0817 16:56:53.893065  2446 net.cpp:395] relu1 -> conv1 (in-place)
I0817 16:56:53.893331  2446 net.cpp:150] Setting up relu1
I0817 16:56:53.893353  2446 net.cpp:157] Top shape: 64 20 76 76 (7393280)
I0817 16:56:53.893365  2446 net.cpp:165] Memory required for data: 64063488
I0817 16:56:53.893383  2446 layer_factory.hpp:77] Creating layer pool1
I0817 16:56:53.893400  2446 net.cpp:100] Creating Layer pool1
I0817 16:56:53.893414  2446 net.cpp:434] pool1 <- conv1
I0817 16:56:53.893430  2446 net.cpp:408] pool1 -> pool1
I0817 16:56:53.893491  2446 net.cpp:150] Setting up pool1
I0817 16:56:53.893513  2446 net.cpp:157] Top shape: 64 20 38 38 (1848320)
I0817 16:56:53.893548  2446 net.cpp:165] Memory required for data: 71456768
I0817 16:56:53.893561  2446 layer_factory.hpp:77] Creating layer conv2
I0817 16:56:53.893589  2446 net.cpp:100] Creating Layer conv2
I0817 16:56:53.893610  2446 net.cpp:434] conv2 <- pool1
I0817 16:56:53.893630  2446 net.cpp:408] conv2 -> conv2
I0817 16:56:53.895071  2446 net.cpp:150] Setting up conv2
I0817 16:56:53.895098  2446 net.cpp:157] Top shape: 64 48 34 34 (3551232)
I0817 16:56:53.895112  2446 net.cpp:165] Memory required for data: 85661696
I0817 16:56:53.895133  2446 layer_factory.hpp:77] Creating layer relu2
I0817 16:56:53.895151  2446 net.cpp:100] Creating Layer relu2
I0817 16:56:53.895164  2446 net.cpp:434] relu2 <- conv2
I0817 16:56:53.895179  2446 net.cpp:395] relu2 -> conv2 (in-place)
I0817 16:56:53.895368  2446 net.cpp:150] Setting up relu2
I0817 16:56:53.895390  2446 net.cpp:157] Top shape: 64 48 34 34 (3551232)
I0817 16:56:53.895403  2446 net.cpp:165] Memory required for data: 99866624
I0817 16:56:53.895417  2446 layer_factory.hpp:77] Creating layer pool2
I0817 16:56:53.895433  2446 net.cpp:100] Creating Layer pool2
I0817 16:56:53.895445  2446 net.cpp:434] pool2 <- conv2
I0817 16:56:53.895459  2446 net.cpp:408] pool2 -> pool2
I0817 16:56:53.895522  2446 net.cpp:150] Setting up pool2
I0817 16:56:53.895540  2446 net.cpp:157] Top shape: 64 48 17 17 (887808)
I0817 16:56:53.895552  2446 net.cpp:165] Memory required for data: 103417856
I0817 16:56:53.895565  2446 layer_factory.hpp:77] Creating layer conv3
I0817 16:56:53.895586  2446 net.cpp:100] Creating Layer conv3
I0817 16:56:53.895598  2446 net.cpp:434] conv3 <- pool2
I0817 16:56:53.895617  2446 net.cpp:408] conv3 -> conv3
I0817 16:56:53.897701  2446 net.cpp:150] Setting up conv3
I0817 16:56:53.897728  2446 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0817 16:56:53.897742  2446 net.cpp:165] Memory required for data: 107104256
I0817 16:56:53.897759  2446 layer_factory.hpp:77] Creating layer relu3
I0817 16:56:53.897776  2446 net.cpp:100] Creating Layer relu3
I0817 16:56:53.897789  2446 net.cpp:434] relu3 <- conv3
I0817 16:56:53.897806  2446 net.cpp:395] relu3 -> conv3 (in-place)
I0817 16:56:53.897965  2446 net.cpp:150] Setting up relu3
I0817 16:56:53.897985  2446 net.cpp:157] Top shape: 64 64 15 15 (921600)
I0817 16:56:53.897997  2446 net.cpp:165] Memory required for data: 110790656
I0817 16:56:53.898016  2446 layer_factory.hpp:77] Creating layer ip1
I0817 16:56:53.898037  2446 net.cpp:100] Creating Layer ip1
I0817 16:56:53.898051  2446 net.cpp:434] ip1 <- conv3
I0817 16:56:53.898066  2446 net.cpp:408] ip1 -> ip1
I0817 16:56:53.970438  2446 net.cpp:150] Setting up ip1
I0817 16:56:53.970496  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.970509  2446 net.cpp:165] Memory required for data: 110921728
I0817 16:56:53.970527  2446 layer_factory.hpp:77] Creating layer relu5
I0817 16:56:53.970546  2446 net.cpp:100] Creating Layer relu5
I0817 16:56:53.970557  2446 net.cpp:434] relu5 <- ip1
I0817 16:56:53.970571  2446 net.cpp:395] relu5 -> ip1 (in-place)
I0817 16:56:53.970682  2446 net.cpp:150] Setting up relu5
I0817 16:56:53.970700  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.970710  2446 net.cpp:165] Memory required for data: 111052800
I0817 16:56:53.970721  2446 layer_factory.hpp:77] Creating layer drop1
I0817 16:56:53.970736  2446 net.cpp:100] Creating Layer drop1
I0817 16:56:53.970746  2446 net.cpp:434] drop1 <- ip1
I0817 16:56:53.970760  2446 net.cpp:395] drop1 -> ip1 (in-place)
I0817 16:56:53.970798  2446 net.cpp:150] Setting up drop1
I0817 16:56:53.970813  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.970824  2446 net.cpp:165] Memory required for data: 111183872
I0817 16:56:53.970834  2446 layer_factory.hpp:77] Creating layer ip1_drop1_0_split
I0817 16:56:53.970850  2446 net.cpp:100] Creating Layer ip1_drop1_0_split
I0817 16:56:53.970860  2446 net.cpp:434] ip1_drop1_0_split <- ip1
I0817 16:56:53.970875  2446 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_0
I0817 16:56:53.970896  2446 net.cpp:408] ip1_drop1_0_split -> ip1_drop1_0_split_1
I0817 16:56:53.970970  2446 net.cpp:150] Setting up ip1_drop1_0_split
I0817 16:56:53.970986  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.970998  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.971007  2446 net.cpp:165] Memory required for data: 111446016
I0817 16:56:53.971019  2446 layer_factory.hpp:77] Creating layer ip2
I0817 16:56:53.971035  2446 net.cpp:100] Creating Layer ip2
I0817 16:56:53.971050  2446 net.cpp:434] ip2 <- ip1_drop1_0_split_0
I0817 16:56:53.971065  2446 net.cpp:408] ip2 -> ip2
I0817 16:56:53.971191  2446 net.cpp:150] Setting up ip2
I0817 16:56:53.971211  2446 net.cpp:157] Top shape: 64 2 (128)
I0817 16:56:53.971222  2446 net.cpp:165] Memory required for data: 111446528
I0817 16:56:53.971237  2446 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0817 16:56:53.971251  2446 net.cpp:100] Creating Layer ip2_ip2_0_split
I0817 16:56:53.971261  2446 net.cpp:434] ip2_ip2_0_split <- ip2
I0817 16:56:53.971271  2446 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0817 16:56:53.971288  2446 net.cpp:408] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0817 16:56:53.971334  2446 net.cpp:150] Setting up ip2_ip2_0_split
I0817 16:56:53.971350  2446 net.cpp:157] Top shape: 64 2 (128)
I0817 16:56:53.971362  2446 net.cpp:157] Top shape: 64 2 (128)
I0817 16:56:53.971372  2446 net.cpp:165] Memory required for data: 111447552
I0817 16:56:53.971382  2446 layer_factory.hpp:77] Creating layer loss1
I0817 16:56:53.971396  2446 net.cpp:100] Creating Layer loss1
I0817 16:56:53.971406  2446 net.cpp:434] loss1 <- ip2_ip2_0_split_0
I0817 16:56:53.971421  2446 net.cpp:434] loss1 <- glasses_slice1_0_split_0
I0817 16:56:53.971434  2446 net.cpp:408] loss1 -> loss1
I0817 16:56:53.971451  2446 layer_factory.hpp:77] Creating layer loss1
I0817 16:56:53.971732  2446 net.cpp:150] Setting up loss1
I0817 16:56:53.971752  2446 net.cpp:157] Top shape: (1)
I0817 16:56:53.971763  2446 net.cpp:160]     with loss weight 0.4
I0817 16:56:53.971784  2446 net.cpp:165] Memory required for data: 111447556
I0817 16:56:53.971794  2446 layer_factory.hpp:77] Creating layer accuracy_glasses
I0817 16:56:53.971808  2446 net.cpp:100] Creating Layer accuracy_glasses
I0817 16:56:53.971820  2446 net.cpp:434] accuracy_glasses <- ip2_ip2_0_split_1
I0817 16:56:53.971832  2446 net.cpp:434] accuracy_glasses <- glasses_slice1_0_split_1
I0817 16:56:53.971849  2446 net.cpp:408] accuracy_glasses -> accuracy_glasses
I0817 16:56:53.971869  2446 net.cpp:150] Setting up accuracy_glasses
I0817 16:56:53.971884  2446 net.cpp:157] Top shape: (1)
I0817 16:56:53.971894  2446 net.cpp:165] Memory required for data: 111447560
I0817 16:56:53.971904  2446 layer_factory.hpp:77] Creating layer ip3
I0817 16:56:53.971916  2446 net.cpp:100] Creating Layer ip3
I0817 16:56:53.971927  2446 net.cpp:434] ip3 <- ip1_drop1_0_split_1
I0817 16:56:53.971942  2446 net.cpp:408] ip3 -> ip3
I0817 16:56:53.974398  2446 net.cpp:150] Setting up ip3
I0817 16:56:53.974418  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.974429  2446 net.cpp:165] Memory required for data: 111578632
I0817 16:56:53.974443  2446 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I0817 16:56:53.974457  2446 net.cpp:100] Creating Layer ip3_ip3_0_split
I0817 16:56:53.974467  2446 net.cpp:434] ip3_ip3_0_split <- ip3
I0817 16:56:53.974479  2446 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_0
I0817 16:56:53.974500  2446 net.cpp:408] ip3_ip3_0_split -> ip3_ip3_0_split_1
I0817 16:56:53.974547  2446 net.cpp:150] Setting up ip3_ip3_0_split
I0817 16:56:53.974563  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.974575  2446 net.cpp:157] Top shape: 64 512 (32768)
I0817 16:56:53.974584  2446 net.cpp:165] Memory required for data: 111840776
I0817 16:56:53.974594  2446 layer_factory.hpp:77] Creating layer loss2
I0817 16:56:53.974609  2446 net.cpp:100] Creating Layer loss2
I0817 16:56:53.974620  2446 net.cpp:434] loss2 <- ip3_ip3_0_split_0
I0817 16:56:53.974632  2446 net.cpp:434] loss2 <- gender_slice1_1_split_0
I0817 16:56:53.974644  2446 net.cpp:408] loss2 -> loss2
I0817 16:56:53.974671  2446 layer_factory.hpp:77] Creating layer loss2
I0817 16:56:53.975133  2446 net.cpp:150] Setting up loss2
I0817 16:56:53.975153  2446 net.cpp:157] Top shape: (1)
I0817 16:56:53.975163  2446 net.cpp:160]     with loss weight 0.6
I0817 16:56:53.975177  2446 net.cpp:165] Memory required for data: 111840780
I0817 16:56:53.975186  2446 layer_factory.hpp:77] Creating layer accuracy_gender
I0817 16:56:53.975201  2446 net.cpp:100] Creating Layer accuracy_gender
I0817 16:56:53.975213  2446 net.cpp:434] accuracy_gender <- ip3_ip3_0_split_1
I0817 16:56:53.975224  2446 net.cpp:434] accuracy_gender <- gender_slice1_1_split_1
I0817 16:56:53.975239  2446 net.cpp:408] accuracy_gender -> accuracy_gender
I0817 16:56:53.975256  2446 net.cpp:150] Setting up accuracy_gender
I0817 16:56:53.975268  2446 net.cpp:157] Top shape: (1)
I0817 16:56:53.975278  2446 net.cpp:165] Memory required for data: 111840784
I0817 16:56:53.975288  2446 net.cpp:228] accuracy_gender does not need backward computation.
I0817 16:56:53.975298  2446 net.cpp:226] loss2 needs backward computation.
I0817 16:56:53.975309  2446 net.cpp:226] ip3_ip3_0_split needs backward computation.
I0817 16:56:53.975319  2446 net.cpp:226] ip3 needs backward computation.
I0817 16:56:53.975329  2446 net.cpp:228] accuracy_glasses does not need backward computation.
I0817 16:56:53.975339  2446 net.cpp:226] loss1 needs backward computation.
I0817 16:56:53.975350  2446 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0817 16:56:53.975360  2446 net.cpp:226] ip2 needs backward computation.
I0817 16:56:53.975370  2446 net.cpp:226] ip1_drop1_0_split needs backward computation.
I0817 16:56:53.975380  2446 net.cpp:226] drop1 needs backward computation.
I0817 16:56:53.975389  2446 net.cpp:226] relu5 needs backward computation.
I0817 16:56:53.975399  2446 net.cpp:226] ip1 needs backward computation.
I0817 16:56:53.975409  2446 net.cpp:226] relu3 needs backward computation.
I0817 16:56:53.975419  2446 net.cpp:226] conv3 needs backward computation.
I0817 16:56:53.975427  2446 net.cpp:226] pool2 needs backward computation.
I0817 16:56:53.975437  2446 net.cpp:226] relu2 needs backward computation.
I0817 16:56:53.975447  2446 net.cpp:226] conv2 needs backward computation.
I0817 16:56:53.975456  2446 net.cpp:226] pool1 needs backward computation.
I0817 16:56:53.975466  2446 net.cpp:226] relu1 needs backward computation.
I0817 16:56:53.975476  2446 net.cpp:226] conv1 needs backward computation.
I0817 16:56:53.975486  2446 net.cpp:228] gender_slice1_1_split does not need backward computation.
I0817 16:56:53.975497  2446 net.cpp:228] glasses_slice1_0_split does not need backward computation.
I0817 16:56:53.975508  2446 net.cpp:228] slice1 does not need backward computation.
I0817 16:56:53.975518  2446 net.cpp:228] labels does not need backward computation.
I0817 16:56:53.975528  2446 net.cpp:228] data does not need backward computation.
I0817 16:56:53.975536  2446 net.cpp:270] This network produces output accuracy_gender
I0817 16:56:53.975545  2446 net.cpp:270] This network produces output accuracy_glasses
I0817 16:56:53.975555  2446 net.cpp:270] This network produces output loss1
I0817 16:56:53.975565  2446 net.cpp:270] This network produces output loss2
I0817 16:56:53.975591  2446 net.cpp:283] Network initialization done.
I0817 16:56:53.975697  2446 solver.cpp:60] Solver scaffolding done.
I0817 16:56:53.976254  2446 caffe.cpp:251] Starting Optimization
I0817 16:56:53.976269  2446 solver.cpp:279] Solving multi_task
I0817 16:56:53.976279  2446 solver.cpp:280] Learning Rate Policy: step
I0817 16:56:53.977390  2446 solver.cpp:337] Iteration 0, Testing net (#0)
I0817 16:56:56.600913  2446 blocking_queue.cpp:50] Data layer prefetch queue empty
I0817 16:57:29.274610  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0
I0817 16:57:29.274868  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.759
I0817 16:57:29.274904  2446 solver.cpp:404]     Test net output #2: loss1 = 0.675808 (* 0.4 = 0.270323 loss)
I0817 16:57:29.274921  2446 solver.cpp:404]     Test net output #3: loss2 = 6.29253 (* 0.6 = 3.77552 loss)
I0817 16:57:29.445600  2446 solver.cpp:228] Iteration 0, loss = 4.05017
I0817 16:57:29.445648  2446 solver.cpp:244]     Train net output #0: loss1 = 0.670365 (* 0.4 = 0.268146 loss)
I0817 16:57:29.445664  2446 solver.cpp:244]     Train net output #1: loss2 = 6.30337 (* 0.6 = 3.78202 loss)
I0817 16:57:29.445683  2446 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0817 16:57:32.328064  2446 solver.cpp:228] Iteration 20, loss = 0.723735
I0817 16:57:32.328114  2446 solver.cpp:244]     Train net output #0: loss1 = 0.604592 (* 0.4 = 0.241837 loss)
I0817 16:57:32.328130  2446 solver.cpp:244]     Train net output #1: loss2 = 0.803165 (* 0.6 = 0.481899 loss)
I0817 16:57:32.328143  2446 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0817 16:57:35.294739  2446 solver.cpp:228] Iteration 40, loss = 0.648952
I0817 16:57:35.294788  2446 solver.cpp:244]     Train net output #0: loss1 = 0.531502 (* 0.4 = 0.212601 loss)
I0817 16:57:35.294805  2446 solver.cpp:244]     Train net output #1: loss2 = 0.727252 (* 0.6 = 0.436351 loss)
I0817 16:57:35.294817  2446 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0817 16:57:38.272009  2446 solver.cpp:228] Iteration 60, loss = 0.684329
I0817 16:57:38.272061  2446 solver.cpp:244]     Train net output #0: loss1 = 0.60154 (* 0.4 = 0.240616 loss)
I0817 16:57:38.272078  2446 solver.cpp:244]     Train net output #1: loss2 = 0.739523 (* 0.6 = 0.443714 loss)
I0817 16:57:38.272091  2446 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0817 16:57:41.239979  2446 solver.cpp:228] Iteration 80, loss = 0.636539
I0817 16:57:41.240030  2446 solver.cpp:244]     Train net output #0: loss1 = 0.565021 (* 0.4 = 0.226008 loss)
I0817 16:57:41.240046  2446 solver.cpp:244]     Train net output #1: loss2 = 0.684219 (* 0.6 = 0.410531 loss)
I0817 16:57:41.240058  2446 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0817 16:57:44.210376  2446 solver.cpp:228] Iteration 100, loss = 0.59556
I0817 16:57:44.210428  2446 solver.cpp:244]     Train net output #0: loss1 = 0.521525 (* 0.4 = 0.20861 loss)
I0817 16:57:44.210445  2446 solver.cpp:244]     Train net output #1: loss2 = 0.644918 (* 0.6 = 0.386951 loss)
I0817 16:57:44.210458  2446 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0817 16:57:47.178120  2446 solver.cpp:228] Iteration 120, loss = 0.590564
I0817 16:57:47.178170  2446 solver.cpp:244]     Train net output #0: loss1 = 0.47544 (* 0.4 = 0.190176 loss)
I0817 16:57:47.178187  2446 solver.cpp:244]     Train net output #1: loss2 = 0.667313 (* 0.6 = 0.400388 loss)
I0817 16:57:47.178201  2446 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0817 16:57:50.148905  2446 solver.cpp:228] Iteration 140, loss = 0.536223
I0817 16:57:50.148959  2446 solver.cpp:244]     Train net output #0: loss1 = 0.467032 (* 0.4 = 0.186813 loss)
I0817 16:57:50.148977  2446 solver.cpp:244]     Train net output #1: loss2 = 0.582352 (* 0.6 = 0.349411 loss)
I0817 16:57:50.148989  2446 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0817 16:57:53.117764  2446 solver.cpp:228] Iteration 160, loss = 0.546683
I0817 16:57:53.117817  2446 solver.cpp:244]     Train net output #0: loss1 = 0.389411 (* 0.4 = 0.155764 loss)
I0817 16:57:53.117835  2446 solver.cpp:244]     Train net output #1: loss2 = 0.651531 (* 0.6 = 0.390919 loss)
I0817 16:57:53.117848  2446 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0817 16:57:56.086287  2446 solver.cpp:228] Iteration 180, loss = 0.421064
I0817 16:57:56.086341  2446 solver.cpp:244]     Train net output #0: loss1 = 0.246442 (* 0.4 = 0.0985768 loss)
I0817 16:57:56.086359  2446 solver.cpp:244]     Train net output #1: loss2 = 0.53748 (* 0.6 = 0.322488 loss)
I0817 16:57:56.086371  2446 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0817 16:57:59.053040  2446 solver.cpp:228] Iteration 200, loss = 0.502906
I0817 16:57:59.053089  2446 solver.cpp:244]     Train net output #0: loss1 = 0.312211 (* 0.4 = 0.124885 loss)
I0817 16:57:59.053133  2446 solver.cpp:244]     Train net output #1: loss2 = 0.630037 (* 0.6 = 0.378022 loss)
I0817 16:57:59.053148  2446 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0817 16:58:02.023313  2446 solver.cpp:228] Iteration 220, loss = 0.498988
I0817 16:58:02.023439  2446 solver.cpp:244]     Train net output #0: loss1 = 0.353093 (* 0.4 = 0.141237 loss)
I0817 16:58:02.023458  2446 solver.cpp:244]     Train net output #1: loss2 = 0.596252 (* 0.6 = 0.357751 loss)
I0817 16:58:02.023471  2446 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0817 16:58:04.992879  2446 solver.cpp:228] Iteration 240, loss = 0.501058
I0817 16:58:04.992934  2446 solver.cpp:244]     Train net output #0: loss1 = 0.464249 (* 0.4 = 0.1857 loss)
I0817 16:58:04.992951  2446 solver.cpp:244]     Train net output #1: loss2 = 0.525598 (* 0.6 = 0.315359 loss)
I0817 16:58:04.992965  2446 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0817 16:58:07.962710  2446 solver.cpp:228] Iteration 260, loss = 0.343071
I0817 16:58:07.962762  2446 solver.cpp:244]     Train net output #0: loss1 = 0.285893 (* 0.4 = 0.114357 loss)
I0817 16:58:07.962779  2446 solver.cpp:244]     Train net output #1: loss2 = 0.38119 (* 0.6 = 0.228714 loss)
I0817 16:58:07.962793  2446 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0817 16:58:10.929430  2446 solver.cpp:228] Iteration 280, loss = 0.410276
I0817 16:58:10.929484  2446 solver.cpp:244]     Train net output #0: loss1 = 0.335673 (* 0.4 = 0.134269 loss)
I0817 16:58:10.929502  2446 solver.cpp:244]     Train net output #1: loss2 = 0.460012 (* 0.6 = 0.276007 loss)
I0817 16:58:10.929514  2446 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0817 16:58:13.898180  2446 solver.cpp:228] Iteration 300, loss = 0.420526
I0817 16:58:13.898231  2446 solver.cpp:244]     Train net output #0: loss1 = 0.292008 (* 0.4 = 0.116803 loss)
I0817 16:58:13.898248  2446 solver.cpp:244]     Train net output #1: loss2 = 0.506204 (* 0.6 = 0.303723 loss)
I0817 16:58:13.898262  2446 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0817 16:58:16.865257  2446 solver.cpp:228] Iteration 320, loss = 0.334433
I0817 16:58:16.865305  2446 solver.cpp:244]     Train net output #0: loss1 = 0.260097 (* 0.4 = 0.104039 loss)
I0817 16:58:16.865322  2446 solver.cpp:244]     Train net output #1: loss2 = 0.383991 (* 0.6 = 0.230395 loss)
I0817 16:58:16.865336  2446 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0817 16:58:19.833806  2446 solver.cpp:228] Iteration 340, loss = 0.418838
I0817 16:58:19.833874  2446 solver.cpp:244]     Train net output #0: loss1 = 0.284866 (* 0.4 = 0.113946 loss)
I0817 16:58:19.833892  2446 solver.cpp:244]     Train net output #1: loss2 = 0.508153 (* 0.6 = 0.304892 loss)
I0817 16:58:19.833909  2446 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0817 16:58:22.802659  2446 solver.cpp:228] Iteration 360, loss = 0.343361
I0817 16:58:22.802736  2446 solver.cpp:244]     Train net output #0: loss1 = 0.228559 (* 0.4 = 0.0914235 loss)
I0817 16:58:22.802767  2446 solver.cpp:244]     Train net output #1: loss2 = 0.419896 (* 0.6 = 0.251938 loss)
I0817 16:58:22.802798  2446 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0817 16:58:25.769994  2446 solver.cpp:228] Iteration 380, loss = 0.322719
I0817 16:58:25.770046  2446 solver.cpp:244]     Train net output #0: loss1 = 0.251475 (* 0.4 = 0.10059 loss)
I0817 16:58:25.770063  2446 solver.cpp:244]     Train net output #1: loss2 = 0.370215 (* 0.6 = 0.222129 loss)
I0817 16:58:25.770076  2446 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0817 16:58:28.738914  2446 solver.cpp:228] Iteration 400, loss = 0.288363
I0817 16:58:28.738962  2446 solver.cpp:244]     Train net output #0: loss1 = 0.107207 (* 0.4 = 0.0428829 loss)
I0817 16:58:28.738979  2446 solver.cpp:244]     Train net output #1: loss2 = 0.409133 (* 0.6 = 0.24548 loss)
I0817 16:58:28.738992  2446 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0817 16:58:31.708683  2446 solver.cpp:228] Iteration 420, loss = 0.323464
I0817 16:58:31.708737  2446 solver.cpp:244]     Train net output #0: loss1 = 0.23054 (* 0.4 = 0.0922161 loss)
I0817 16:58:31.708755  2446 solver.cpp:244]     Train net output #1: loss2 = 0.385413 (* 0.6 = 0.231248 loss)
I0817 16:58:31.708767  2446 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0817 16:58:34.675990  2446 solver.cpp:228] Iteration 440, loss = 0.316221
I0817 16:58:34.676208  2446 solver.cpp:244]     Train net output #0: loss1 = 0.317845 (* 0.4 = 0.127138 loss)
I0817 16:58:34.676229  2446 solver.cpp:244]     Train net output #1: loss2 = 0.315139 (* 0.6 = 0.189083 loss)
I0817 16:58:34.676241  2446 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0817 16:58:37.645130  2446 solver.cpp:228] Iteration 460, loss = 0.305325
I0817 16:58:37.645184  2446 solver.cpp:244]     Train net output #0: loss1 = 0.14706 (* 0.4 = 0.058824 loss)
I0817 16:58:37.645200  2446 solver.cpp:244]     Train net output #1: loss2 = 0.410836 (* 0.6 = 0.246501 loss)
I0817 16:58:37.645213  2446 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0817 16:58:40.614850  2446 solver.cpp:228] Iteration 480, loss = 0.256835
I0817 16:58:40.614910  2446 solver.cpp:244]     Train net output #0: loss1 = 0.124575 (* 0.4 = 0.0498301 loss)
I0817 16:58:40.614928  2446 solver.cpp:244]     Train net output #1: loss2 = 0.345009 (* 0.6 = 0.207005 loss)
I0817 16:58:40.614940  2446 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0817 16:58:43.584461  2446 solver.cpp:228] Iteration 500, loss = 0.357693
I0817 16:58:43.584516  2446 solver.cpp:244]     Train net output #0: loss1 = 0.170017 (* 0.4 = 0.0680067 loss)
I0817 16:58:43.584532  2446 solver.cpp:244]     Train net output #1: loss2 = 0.482811 (* 0.6 = 0.289687 loss)
I0817 16:58:43.584544  2446 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0817 16:58:46.551695  2446 solver.cpp:228] Iteration 520, loss = 0.35767
I0817 16:58:46.551749  2446 solver.cpp:244]     Train net output #0: loss1 = 0.23406 (* 0.4 = 0.0936241 loss)
I0817 16:58:46.551765  2446 solver.cpp:244]     Train net output #1: loss2 = 0.440078 (* 0.6 = 0.264047 loss)
I0817 16:58:46.551777  2446 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0817 16:58:49.525887  2446 solver.cpp:228] Iteration 540, loss = 0.274942
I0817 16:58:49.525939  2446 solver.cpp:244]     Train net output #0: loss1 = 0.187346 (* 0.4 = 0.0749385 loss)
I0817 16:58:49.525954  2446 solver.cpp:244]     Train net output #1: loss2 = 0.33334 (* 0.6 = 0.200004 loss)
I0817 16:58:49.525967  2446 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0817 16:58:52.505916  2446 solver.cpp:228] Iteration 560, loss = 0.272956
I0817 16:58:52.505967  2446 solver.cpp:244]     Train net output #0: loss1 = 0.143871 (* 0.4 = 0.0575486 loss)
I0817 16:58:52.505983  2446 solver.cpp:244]     Train net output #1: loss2 = 0.359013 (* 0.6 = 0.215408 loss)
I0817 16:58:52.505996  2446 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0817 16:58:55.495048  2446 solver.cpp:228] Iteration 580, loss = 0.258809
I0817 16:58:55.495095  2446 solver.cpp:244]     Train net output #0: loss1 = 0.186701 (* 0.4 = 0.0746804 loss)
I0817 16:58:55.495111  2446 solver.cpp:244]     Train net output #1: loss2 = 0.306882 (* 0.6 = 0.184129 loss)
I0817 16:58:55.495124  2446 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0817 16:58:58.467571  2446 solver.cpp:228] Iteration 600, loss = 0.363163
I0817 16:58:58.467617  2446 solver.cpp:244]     Train net output #0: loss1 = 0.33478 (* 0.4 = 0.133912 loss)
I0817 16:58:58.467633  2446 solver.cpp:244]     Train net output #1: loss2 = 0.382085 (* 0.6 = 0.229251 loss)
I0817 16:58:58.467646  2446 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0817 16:59:01.435974  2446 solver.cpp:228] Iteration 620, loss = 0.263967
I0817 16:59:01.436019  2446 solver.cpp:244]     Train net output #0: loss1 = 0.157082 (* 0.4 = 0.0628327 loss)
I0817 16:59:01.436035  2446 solver.cpp:244]     Train net output #1: loss2 = 0.335225 (* 0.6 = 0.201135 loss)
I0817 16:59:01.436048  2446 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0817 16:59:04.406496  2446 solver.cpp:228] Iteration 640, loss = 0.265161
I0817 16:59:04.406543  2446 solver.cpp:244]     Train net output #0: loss1 = 0.200788 (* 0.4 = 0.080315 loss)
I0817 16:59:04.406558  2446 solver.cpp:244]     Train net output #1: loss2 = 0.308077 (* 0.6 = 0.184846 loss)
I0817 16:59:04.406571  2446 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0817 16:59:07.414168  2446 solver.cpp:228] Iteration 660, loss = 0.277626
I0817 16:59:07.425474  2446 solver.cpp:244]     Train net output #0: loss1 = 0.104739 (* 0.4 = 0.0418958 loss)
I0817 16:59:07.425498  2446 solver.cpp:244]     Train net output #1: loss2 = 0.392884 (* 0.6 = 0.23573 loss)
I0817 16:59:07.425513  2446 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0817 16:59:10.452714  2446 solver.cpp:228] Iteration 680, loss = 0.318827
I0817 16:59:10.452769  2446 solver.cpp:244]     Train net output #0: loss1 = 0.230338 (* 0.4 = 0.0921354 loss)
I0817 16:59:10.452785  2446 solver.cpp:244]     Train net output #1: loss2 = 0.37782 (* 0.6 = 0.226692 loss)
I0817 16:59:10.452800  2446 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0817 16:59:13.494132  2446 solver.cpp:228] Iteration 700, loss = 0.269828
I0817 16:59:13.494189  2446 solver.cpp:244]     Train net output #0: loss1 = 0.180587 (* 0.4 = 0.0722349 loss)
I0817 16:59:13.494204  2446 solver.cpp:244]     Train net output #1: loss2 = 0.329322 (* 0.6 = 0.197593 loss)
I0817 16:59:13.494217  2446 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0817 16:59:16.555995  2446 solver.cpp:228] Iteration 720, loss = 0.273452
I0817 16:59:16.556052  2446 solver.cpp:244]     Train net output #0: loss1 = 0.128932 (* 0.4 = 0.0515729 loss)
I0817 16:59:16.556067  2446 solver.cpp:244]     Train net output #1: loss2 = 0.369799 (* 0.6 = 0.221879 loss)
I0817 16:59:16.556080  2446 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0817 16:59:19.584740  2446 solver.cpp:228] Iteration 740, loss = 0.264022
I0817 16:59:19.584807  2446 solver.cpp:244]     Train net output #0: loss1 = 0.16049 (* 0.4 = 0.064196 loss)
I0817 16:59:19.584825  2446 solver.cpp:244]     Train net output #1: loss2 = 0.333044 (* 0.6 = 0.199827 loss)
I0817 16:59:19.584837  2446 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0817 16:59:22.625360  2446 solver.cpp:228] Iteration 760, loss = 0.277494
I0817 16:59:22.625416  2446 solver.cpp:244]     Train net output #0: loss1 = 0.128794 (* 0.4 = 0.0515175 loss)
I0817 16:59:22.625433  2446 solver.cpp:244]     Train net output #1: loss2 = 0.376628 (* 0.6 = 0.225977 loss)
I0817 16:59:22.625447  2446 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0817 16:59:25.642571  2446 solver.cpp:228] Iteration 780, loss = 0.264752
I0817 16:59:25.642621  2446 solver.cpp:244]     Train net output #0: loss1 = 0.192694 (* 0.4 = 0.0770776 loss)
I0817 16:59:25.642637  2446 solver.cpp:244]     Train net output #1: loss2 = 0.312791 (* 0.6 = 0.187675 loss)
I0817 16:59:25.642649  2446 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0817 16:59:28.667677  2446 solver.cpp:228] Iteration 800, loss = 0.26718
I0817 16:59:28.667737  2446 solver.cpp:244]     Train net output #0: loss1 = 0.159618 (* 0.4 = 0.0638472 loss)
I0817 16:59:28.667752  2446 solver.cpp:244]     Train net output #1: loss2 = 0.338889 (* 0.6 = 0.203333 loss)
I0817 16:59:28.667765  2446 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0817 16:59:31.697239  2446 solver.cpp:228] Iteration 820, loss = 0.301416
I0817 16:59:31.697288  2446 solver.cpp:244]     Train net output #0: loss1 = 0.150073 (* 0.4 = 0.0600291 loss)
I0817 16:59:31.697304  2446 solver.cpp:244]     Train net output #1: loss2 = 0.402312 (* 0.6 = 0.241387 loss)
I0817 16:59:31.697317  2446 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0817 16:59:34.724126  2446 solver.cpp:228] Iteration 840, loss = 0.260985
I0817 16:59:34.724184  2446 solver.cpp:244]     Train net output #0: loss1 = 0.124201 (* 0.4 = 0.0496806 loss)
I0817 16:59:34.724200  2446 solver.cpp:244]     Train net output #1: loss2 = 0.352175 (* 0.6 = 0.211305 loss)
I0817 16:59:34.724212  2446 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0817 16:59:37.811480  2446 solver.cpp:228] Iteration 860, loss = 0.223381
I0817 16:59:37.811584  2446 solver.cpp:244]     Train net output #0: loss1 = 0.224526 (* 0.4 = 0.0898102 loss)
I0817 16:59:37.811602  2446 solver.cpp:244]     Train net output #1: loss2 = 0.222619 (* 0.6 = 0.133571 loss)
I0817 16:59:37.811616  2446 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0817 16:59:40.814031  2446 solver.cpp:228] Iteration 880, loss = 0.223522
I0817 16:59:40.814153  2446 solver.cpp:244]     Train net output #0: loss1 = 0.166778 (* 0.4 = 0.0667113 loss)
I0817 16:59:40.814172  2446 solver.cpp:244]     Train net output #1: loss2 = 0.261351 (* 0.6 = 0.156811 loss)
I0817 16:59:40.814185  2446 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0817 16:59:43.825352  2446 solver.cpp:228] Iteration 900, loss = 0.216873
I0817 16:59:43.825408  2446 solver.cpp:244]     Train net output #0: loss1 = 0.082609 (* 0.4 = 0.0330436 loss)
I0817 16:59:43.825424  2446 solver.cpp:244]     Train net output #1: loss2 = 0.306383 (* 0.6 = 0.18383 loss)
I0817 16:59:43.825438  2446 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0817 16:59:46.858830  2446 solver.cpp:228] Iteration 920, loss = 0.232841
I0817 16:59:46.858887  2446 solver.cpp:244]     Train net output #0: loss1 = 0.173685 (* 0.4 = 0.069474 loss)
I0817 16:59:46.858913  2446 solver.cpp:244]     Train net output #1: loss2 = 0.272279 (* 0.6 = 0.163367 loss)
I0817 16:59:46.858927  2446 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0817 16:59:49.873826  2446 solver.cpp:228] Iteration 940, loss = 0.268239
I0817 16:59:49.873881  2446 solver.cpp:244]     Train net output #0: loss1 = 0.114874 (* 0.4 = 0.0459495 loss)
I0817 16:59:49.873898  2446 solver.cpp:244]     Train net output #1: loss2 = 0.370483 (* 0.6 = 0.22229 loss)
I0817 16:59:49.873910  2446 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0817 16:59:52.901581  2446 solver.cpp:228] Iteration 960, loss = 0.204462
I0817 16:59:52.901633  2446 solver.cpp:244]     Train net output #0: loss1 = 0.156327 (* 0.4 = 0.0625307 loss)
I0817 16:59:52.901649  2446 solver.cpp:244]     Train net output #1: loss2 = 0.236553 (* 0.6 = 0.141932 loss)
I0817 16:59:52.901662  2446 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0817 16:59:55.918931  2446 solver.cpp:228] Iteration 980, loss = 0.243434
I0817 16:59:55.918989  2446 solver.cpp:244]     Train net output #0: loss1 = 0.181877 (* 0.4 = 0.0727509 loss)
I0817 16:59:55.919005  2446 solver.cpp:244]     Train net output #1: loss2 = 0.284473 (* 0.6 = 0.170684 loss)
I0817 16:59:55.919018  2446 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0817 16:59:58.775063  2446 solver.cpp:337] Iteration 1000, Testing net (#0)
I0817 17:00:35.007654  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.770688
I0817 17:00:35.007788  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.933859
I0817 17:00:35.007808  2446 solver.cpp:404]     Test net output #2: loss1 = 0.215837 (* 0.4 = 0.0863347 loss)
I0817 17:00:35.007822  2446 solver.cpp:404]     Test net output #3: loss2 = 0.489415 (* 0.6 = 0.293649 loss)
I0817 17:00:35.053880  2446 solver.cpp:228] Iteration 1000, loss = 0.224798
I0817 17:00:35.053926  2446 solver.cpp:244]     Train net output #0: loss1 = 0.12594 (* 0.4 = 0.050376 loss)
I0817 17:00:35.053942  2446 solver.cpp:244]     Train net output #1: loss2 = 0.290704 (* 0.6 = 0.174422 loss)
I0817 17:00:35.053956  2446 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0817 17:00:38.046519  2446 solver.cpp:228] Iteration 1020, loss = 0.233082
I0817 17:00:38.046571  2446 solver.cpp:244]     Train net output #0: loss1 = 0.155341 (* 0.4 = 0.0621363 loss)
I0817 17:00:38.046586  2446 solver.cpp:244]     Train net output #1: loss2 = 0.28491 (* 0.6 = 0.170946 loss)
I0817 17:00:38.046599  2446 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0817 17:00:41.040873  2446 solver.cpp:228] Iteration 1040, loss = 0.235284
I0817 17:00:41.040925  2446 solver.cpp:244]     Train net output #0: loss1 = 0.185846 (* 0.4 = 0.0743385 loss)
I0817 17:00:41.040940  2446 solver.cpp:244]     Train net output #1: loss2 = 0.268243 (* 0.6 = 0.160946 loss)
I0817 17:00:41.040953  2446 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0817 17:00:44.035351  2446 solver.cpp:228] Iteration 1060, loss = 0.225104
I0817 17:00:44.035404  2446 solver.cpp:244]     Train net output #0: loss1 = 0.186618 (* 0.4 = 0.0746472 loss)
I0817 17:00:44.035420  2446 solver.cpp:244]     Train net output #1: loss2 = 0.250761 (* 0.6 = 0.150457 loss)
I0817 17:00:44.035434  2446 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0817 17:00:47.030462  2446 solver.cpp:228] Iteration 1080, loss = 0.27954
I0817 17:00:47.030513  2446 solver.cpp:244]     Train net output #0: loss1 = 0.138009 (* 0.4 = 0.0552034 loss)
I0817 17:00:47.030529  2446 solver.cpp:244]     Train net output #1: loss2 = 0.373894 (* 0.6 = 0.224336 loss)
I0817 17:00:47.030541  2446 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0817 17:00:50.025629  2446 solver.cpp:228] Iteration 1100, loss = 0.220453
I0817 17:00:50.025679  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0778657 (* 0.4 = 0.0311463 loss)
I0817 17:00:50.025694  2446 solver.cpp:244]     Train net output #1: loss2 = 0.315512 (* 0.6 = 0.189307 loss)
I0817 17:00:50.025707  2446 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0817 17:00:53.020905  2446 solver.cpp:228] Iteration 1120, loss = 0.179843
I0817 17:00:53.020956  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0416334 (* 0.4 = 0.0166533 loss)
I0817 17:00:53.020972  2446 solver.cpp:244]     Train net output #1: loss2 = 0.271983 (* 0.6 = 0.16319 loss)
I0817 17:00:53.020984  2446 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0817 17:00:56.016378  2446 solver.cpp:228] Iteration 1140, loss = 0.150759
I0817 17:00:56.016430  2446 solver.cpp:244]     Train net output #0: loss1 = 0.108928 (* 0.4 = 0.0435712 loss)
I0817 17:00:56.016446  2446 solver.cpp:244]     Train net output #1: loss2 = 0.178646 (* 0.6 = 0.107188 loss)
I0817 17:00:56.016459  2446 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0817 17:00:59.007076  2446 solver.cpp:228] Iteration 1160, loss = 0.21862
I0817 17:00:59.007127  2446 solver.cpp:244]     Train net output #0: loss1 = 0.112159 (* 0.4 = 0.0448635 loss)
I0817 17:00:59.007143  2446 solver.cpp:244]     Train net output #1: loss2 = 0.289595 (* 0.6 = 0.173757 loss)
I0817 17:00:59.007155  2446 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0817 17:01:02.001019  2446 solver.cpp:228] Iteration 1180, loss = 0.204852
I0817 17:01:02.001070  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0703093 (* 0.4 = 0.0281237 loss)
I0817 17:01:02.001085  2446 solver.cpp:244]     Train net output #1: loss2 = 0.294548 (* 0.6 = 0.176729 loss)
I0817 17:01:02.001098  2446 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0817 17:01:04.995463  2446 solver.cpp:228] Iteration 1200, loss = 0.14805
I0817 17:01:04.995543  2446 solver.cpp:244]     Train net output #0: loss1 = 0.113774 (* 0.4 = 0.0455095 loss)
I0817 17:01:04.995560  2446 solver.cpp:244]     Train net output #1: loss2 = 0.170902 (* 0.6 = 0.102541 loss)
I0817 17:01:04.995573  2446 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0817 17:01:07.989329  2446 solver.cpp:228] Iteration 1220, loss = 0.145717
I0817 17:01:07.998400  2446 solver.cpp:244]     Train net output #0: loss1 = 0.164699 (* 0.4 = 0.0658796 loss)
I0817 17:01:07.998420  2446 solver.cpp:244]     Train net output #1: loss2 = 0.133063 (* 0.6 = 0.0798378 loss)
I0817 17:01:07.998433  2446 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0817 17:01:10.983952  2446 solver.cpp:228] Iteration 1240, loss = 0.248911
I0817 17:01:10.984006  2446 solver.cpp:244]     Train net output #0: loss1 = 0.204791 (* 0.4 = 0.0819165 loss)
I0817 17:01:10.984022  2446 solver.cpp:244]     Train net output #1: loss2 = 0.278324 (* 0.6 = 0.166994 loss)
I0817 17:01:10.984035  2446 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0817 17:01:13.980540  2446 solver.cpp:228] Iteration 1260, loss = 0.184534
I0817 17:01:13.980590  2446 solver.cpp:244]     Train net output #0: loss1 = 0.12651 (* 0.4 = 0.0506038 loss)
I0817 17:01:13.980607  2446 solver.cpp:244]     Train net output #1: loss2 = 0.223218 (* 0.6 = 0.133931 loss)
I0817 17:01:13.980619  2446 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0817 17:01:16.973002  2446 solver.cpp:228] Iteration 1280, loss = 0.199659
I0817 17:01:16.973055  2446 solver.cpp:244]     Train net output #0: loss1 = 0.197605 (* 0.4 = 0.079042 loss)
I0817 17:01:16.973072  2446 solver.cpp:244]     Train net output #1: loss2 = 0.201028 (* 0.6 = 0.120617 loss)
I0817 17:01:16.973084  2446 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0817 17:01:19.988919  2446 solver.cpp:228] Iteration 1300, loss = 0.236441
I0817 17:01:19.988977  2446 solver.cpp:244]     Train net output #0: loss1 = 0.164307 (* 0.4 = 0.0657227 loss)
I0817 17:01:19.988993  2446 solver.cpp:244]     Train net output #1: loss2 = 0.284531 (* 0.6 = 0.170718 loss)
I0817 17:01:19.989006  2446 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0817 17:01:23.013365  2446 solver.cpp:228] Iteration 1320, loss = 0.188305
I0817 17:01:23.013420  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0903226 (* 0.4 = 0.0361291 loss)
I0817 17:01:23.013437  2446 solver.cpp:244]     Train net output #1: loss2 = 0.253628 (* 0.6 = 0.152177 loss)
I0817 17:01:23.013449  2446 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0817 17:01:26.045667  2446 solver.cpp:228] Iteration 1340, loss = 0.178704
I0817 17:01:26.045723  2446 solver.cpp:244]     Train net output #0: loss1 = 0.122242 (* 0.4 = 0.0488969 loss)
I0817 17:01:26.045740  2446 solver.cpp:244]     Train net output #1: loss2 = 0.216345 (* 0.6 = 0.129807 loss)
I0817 17:01:26.045753  2446 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0817 17:01:29.073567  2446 solver.cpp:228] Iteration 1360, loss = 0.168499
I0817 17:01:29.073622  2446 solver.cpp:244]     Train net output #0: loss1 = 0.133855 (* 0.4 = 0.0535419 loss)
I0817 17:01:29.073638  2446 solver.cpp:244]     Train net output #1: loss2 = 0.191596 (* 0.6 = 0.114958 loss)
I0817 17:01:29.073652  2446 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0817 17:01:32.081338  2446 solver.cpp:228] Iteration 1380, loss = 0.163895
I0817 17:01:32.081393  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0739826 (* 0.4 = 0.0295931 loss)
I0817 17:01:32.081408  2446 solver.cpp:244]     Train net output #1: loss2 = 0.223837 (* 0.6 = 0.134302 loss)
I0817 17:01:32.081421  2446 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0817 17:01:35.075284  2446 solver.cpp:228] Iteration 1400, loss = 0.169864
I0817 17:01:35.075337  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0904653 (* 0.4 = 0.0361861 loss)
I0817 17:01:35.075353  2446 solver.cpp:244]     Train net output #1: loss2 = 0.222797 (* 0.6 = 0.133678 loss)
I0817 17:01:35.075366  2446 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0817 17:01:38.085665  2446 solver.cpp:228] Iteration 1420, loss = 0.178939
I0817 17:01:38.085788  2446 solver.cpp:244]     Train net output #0: loss1 = 0.16943 (* 0.4 = 0.0677719 loss)
I0817 17:01:38.085805  2446 solver.cpp:244]     Train net output #1: loss2 = 0.185279 (* 0.6 = 0.111167 loss)
I0817 17:01:38.085819  2446 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0817 17:01:41.100881  2446 solver.cpp:228] Iteration 1440, loss = 0.138744
I0817 17:01:41.100936  2446 solver.cpp:244]     Train net output #0: loss1 = 0.165412 (* 0.4 = 0.0661649 loss)
I0817 17:01:41.100952  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120965 (* 0.6 = 0.0725788 loss)
I0817 17:01:41.100965  2446 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0817 17:01:44.111996  2446 solver.cpp:228] Iteration 1460, loss = 0.190963
I0817 17:01:44.112051  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0559589 (* 0.4 = 0.0223836 loss)
I0817 17:01:44.112066  2446 solver.cpp:244]     Train net output #1: loss2 = 0.280967 (* 0.6 = 0.16858 loss)
I0817 17:01:44.112078  2446 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0817 17:01:47.124547  2446 solver.cpp:228] Iteration 1480, loss = 0.183904
I0817 17:01:47.124608  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0759717 (* 0.4 = 0.0303887 loss)
I0817 17:01:47.124624  2446 solver.cpp:244]     Train net output #1: loss2 = 0.25586 (* 0.6 = 0.153516 loss)
I0817 17:01:47.124637  2446 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0817 17:01:50.153271  2446 solver.cpp:228] Iteration 1500, loss = 0.141289
I0817 17:01:50.153327  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0653209 (* 0.4 = 0.0261284 loss)
I0817 17:01:50.153343  2446 solver.cpp:244]     Train net output #1: loss2 = 0.191935 (* 0.6 = 0.115161 loss)
I0817 17:01:50.153357  2446 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0817 17:01:53.184073  2446 solver.cpp:228] Iteration 1520, loss = 0.248048
I0817 17:01:53.184128  2446 solver.cpp:244]     Train net output #0: loss1 = 0.125421 (* 0.4 = 0.0501684 loss)
I0817 17:01:53.184144  2446 solver.cpp:244]     Train net output #1: loss2 = 0.3298 (* 0.6 = 0.19788 loss)
I0817 17:01:53.184156  2446 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0817 17:01:56.218772  2446 solver.cpp:228] Iteration 1540, loss = 0.149682
I0817 17:01:56.218832  2446 solver.cpp:244]     Train net output #0: loss1 = 0.107012 (* 0.4 = 0.0428046 loss)
I0817 17:01:56.218847  2446 solver.cpp:244]     Train net output #1: loss2 = 0.17813 (* 0.6 = 0.106878 loss)
I0817 17:01:56.218859  2446 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0817 17:01:59.244659  2446 solver.cpp:228] Iteration 1560, loss = 0.227533
I0817 17:01:59.244715  2446 solver.cpp:244]     Train net output #0: loss1 = 0.173882 (* 0.4 = 0.0695527 loss)
I0817 17:01:59.244731  2446 solver.cpp:244]     Train net output #1: loss2 = 0.2633 (* 0.6 = 0.15798 loss)
I0817 17:01:59.244745  2446 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0817 17:02:02.274819  2446 solver.cpp:228] Iteration 1580, loss = 0.233646
I0817 17:02:02.274873  2446 solver.cpp:244]     Train net output #0: loss1 = 0.153639 (* 0.4 = 0.0614555 loss)
I0817 17:02:02.274889  2446 solver.cpp:244]     Train net output #1: loss2 = 0.286984 (* 0.6 = 0.172191 loss)
I0817 17:02:02.274909  2446 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0817 17:02:05.293541  2446 solver.cpp:228] Iteration 1600, loss = 0.138478
I0817 17:02:05.293594  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0924386 (* 0.4 = 0.0369754 loss)
I0817 17:02:05.293611  2446 solver.cpp:244]     Train net output #1: loss2 = 0.169172 (* 0.6 = 0.101503 loss)
I0817 17:02:05.293624  2446 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0817 17:02:08.333968  2446 solver.cpp:228] Iteration 1620, loss = 0.150831
I0817 17:02:08.334115  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0337761 (* 0.4 = 0.0135104 loss)
I0817 17:02:08.334131  2446 solver.cpp:244]     Train net output #1: loss2 = 0.228868 (* 0.6 = 0.137321 loss)
I0817 17:02:08.334144  2446 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0817 17:02:11.361464  2446 solver.cpp:228] Iteration 1640, loss = 0.152505
I0817 17:02:11.361522  2446 solver.cpp:244]     Train net output #0: loss1 = 0.103333 (* 0.4 = 0.0413331 loss)
I0817 17:02:11.361538  2446 solver.cpp:244]     Train net output #1: loss2 = 0.185287 (* 0.6 = 0.111172 loss)
I0817 17:02:11.361552  2446 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0817 17:02:14.382853  2446 solver.cpp:228] Iteration 1660, loss = 0.163652
I0817 17:02:14.382915  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0509072 (* 0.4 = 0.0203629 loss)
I0817 17:02:14.382931  2446 solver.cpp:244]     Train net output #1: loss2 = 0.238815 (* 0.6 = 0.143289 loss)
I0817 17:02:14.382944  2446 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0817 17:02:17.394158  2446 solver.cpp:228] Iteration 1680, loss = 0.158395
I0817 17:02:17.394210  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0923598 (* 0.4 = 0.0369439 loss)
I0817 17:02:17.394227  2446 solver.cpp:244]     Train net output #1: loss2 = 0.202418 (* 0.6 = 0.121451 loss)
I0817 17:02:17.394238  2446 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0817 17:02:20.420147  2446 solver.cpp:228] Iteration 1700, loss = 0.156746
I0817 17:02:20.420204  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0972227 (* 0.4 = 0.0388891 loss)
I0817 17:02:20.420220  2446 solver.cpp:244]     Train net output #1: loss2 = 0.196429 (* 0.6 = 0.117857 loss)
I0817 17:02:20.420233  2446 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0817 17:02:23.423405  2446 solver.cpp:228] Iteration 1720, loss = 0.189102
I0817 17:02:23.423462  2446 solver.cpp:244]     Train net output #0: loss1 = 0.094417 (* 0.4 = 0.0377668 loss)
I0817 17:02:23.423478  2446 solver.cpp:244]     Train net output #1: loss2 = 0.252226 (* 0.6 = 0.151336 loss)
I0817 17:02:23.423491  2446 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0817 17:02:26.416451  2446 solver.cpp:228] Iteration 1740, loss = 0.0988763
I0817 17:02:26.416506  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0943334 (* 0.4 = 0.0377334 loss)
I0817 17:02:26.416522  2446 solver.cpp:244]     Train net output #1: loss2 = 0.101905 (* 0.6 = 0.0611431 loss)
I0817 17:02:26.416534  2446 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0817 17:02:29.430271  2446 solver.cpp:228] Iteration 1760, loss = 0.167608
I0817 17:02:29.430328  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0477593 (* 0.4 = 0.0191037 loss)
I0817 17:02:29.430344  2446 solver.cpp:244]     Train net output #1: loss2 = 0.247507 (* 0.6 = 0.148504 loss)
I0817 17:02:29.430357  2446 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0817 17:02:32.445008  2446 solver.cpp:228] Iteration 1780, loss = 0.110725
I0817 17:02:32.445065  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0367807 (* 0.4 = 0.0147123 loss)
I0817 17:02:32.445080  2446 solver.cpp:244]     Train net output #1: loss2 = 0.160022 (* 0.6 = 0.0960134 loss)
I0817 17:02:32.445093  2446 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0817 17:02:35.468164  2446 solver.cpp:228] Iteration 1800, loss = 0.185706
I0817 17:02:35.468219  2446 solver.cpp:244]     Train net output #0: loss1 = 0.111412 (* 0.4 = 0.0445647 loss)
I0817 17:02:35.468235  2446 solver.cpp:244]     Train net output #1: loss2 = 0.235236 (* 0.6 = 0.141142 loss)
I0817 17:02:35.468247  2446 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0817 17:02:38.502748  2446 solver.cpp:228] Iteration 1820, loss = 0.134747
I0817 17:02:38.502928  2446 solver.cpp:244]     Train net output #0: loss1 = 0.104339 (* 0.4 = 0.0417356 loss)
I0817 17:02:38.502945  2446 solver.cpp:244]     Train net output #1: loss2 = 0.15502 (* 0.6 = 0.0930121 loss)
I0817 17:02:38.502959  2446 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0817 17:02:41.529325  2446 solver.cpp:228] Iteration 1840, loss = 0.127629
I0817 17:02:41.529381  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0869626 (* 0.4 = 0.034785 loss)
I0817 17:02:41.529397  2446 solver.cpp:244]     Train net output #1: loss2 = 0.15474 (* 0.6 = 0.0928439 loss)
I0817 17:02:41.529409  2446 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0817 17:02:44.573388  2446 solver.cpp:228] Iteration 1860, loss = 0.132574
I0817 17:02:44.573446  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0625313 (* 0.4 = 0.0250125 loss)
I0817 17:02:44.573462  2446 solver.cpp:244]     Train net output #1: loss2 = 0.17927 (* 0.6 = 0.107562 loss)
I0817 17:02:44.573475  2446 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0817 17:02:47.610914  2446 solver.cpp:228] Iteration 1880, loss = 0.119832
I0817 17:02:47.610970  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0391138 (* 0.4 = 0.0156455 loss)
I0817 17:02:47.610986  2446 solver.cpp:244]     Train net output #1: loss2 = 0.173645 (* 0.6 = 0.104187 loss)
I0817 17:02:47.610998  2446 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0817 17:02:50.654834  2446 solver.cpp:228] Iteration 1900, loss = 0.190681
I0817 17:02:50.654898  2446 solver.cpp:244]     Train net output #0: loss1 = 0.279267 (* 0.4 = 0.111707 loss)
I0817 17:02:50.654916  2446 solver.cpp:244]     Train net output #1: loss2 = 0.131624 (* 0.6 = 0.0789741 loss)
I0817 17:02:50.654929  2446 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0817 17:02:53.685338  2446 solver.cpp:228] Iteration 1920, loss = 0.17437
I0817 17:02:53.685395  2446 solver.cpp:244]     Train net output #0: loss1 = 0.133978 (* 0.4 = 0.053591 loss)
I0817 17:02:53.685410  2446 solver.cpp:244]     Train net output #1: loss2 = 0.201299 (* 0.6 = 0.12078 loss)
I0817 17:02:53.685423  2446 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0817 17:02:56.692977  2446 solver.cpp:228] Iteration 1940, loss = 0.0980252
I0817 17:02:56.693033  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0714326 (* 0.4 = 0.028573 loss)
I0817 17:02:56.693049  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115754 (* 0.6 = 0.0694524 loss)
I0817 17:02:56.693061  2446 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0817 17:02:59.727896  2446 solver.cpp:228] Iteration 1960, loss = 0.0970049
I0817 17:02:59.727952  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0220964 (* 0.4 = 0.00883856 loss)
I0817 17:02:59.727967  2446 solver.cpp:244]     Train net output #1: loss2 = 0.146944 (* 0.6 = 0.0881666 loss)
I0817 17:02:59.727980  2446 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0817 17:03:02.764647  2446 solver.cpp:228] Iteration 1980, loss = 0.166636
I0817 17:03:02.764703  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0498586 (* 0.4 = 0.0199434 loss)
I0817 17:03:02.764719  2446 solver.cpp:244]     Train net output #1: loss2 = 0.244488 (* 0.6 = 0.146693 loss)
I0817 17:03:02.764732  2446 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0817 17:03:05.654933  2446 solver.cpp:337] Iteration 2000, Testing net (#0)
I0817 17:03:41.612530  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.826047
I0817 17:03:41.612679  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.945484
I0817 17:03:41.612699  2446 solver.cpp:404]     Test net output #2: loss1 = 0.168987 (* 0.4 = 0.0675948 loss)
I0817 17:03:41.612711  2446 solver.cpp:404]     Test net output #3: loss2 = 0.414286 (* 0.6 = 0.248572 loss)
I0817 17:03:41.658632  2446 solver.cpp:228] Iteration 2000, loss = 0.127528
I0817 17:03:41.658679  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0845816 (* 0.4 = 0.0338327 loss)
I0817 17:03:41.658695  2446 solver.cpp:244]     Train net output #1: loss2 = 0.156159 (* 0.6 = 0.0936953 loss)
I0817 17:03:41.658709  2446 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0817 17:03:44.651262  2446 solver.cpp:228] Iteration 2020, loss = 0.179383
I0817 17:03:44.651312  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0787094 (* 0.4 = 0.0314838 loss)
I0817 17:03:44.651329  2446 solver.cpp:244]     Train net output #1: loss2 = 0.2465 (* 0.6 = 0.1479 loss)
I0817 17:03:44.651340  2446 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0817 17:03:47.644493  2446 solver.cpp:228] Iteration 2040, loss = 0.108273
I0817 17:03:47.644547  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0370247 (* 0.4 = 0.0148099 loss)
I0817 17:03:47.644563  2446 solver.cpp:244]     Train net output #1: loss2 = 0.155773 (* 0.6 = 0.0934637 loss)
I0817 17:03:47.644577  2446 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0817 17:03:50.637475  2446 solver.cpp:228] Iteration 2060, loss = 0.139926
I0817 17:03:50.637526  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0447936 (* 0.4 = 0.0179174 loss)
I0817 17:03:50.637540  2446 solver.cpp:244]     Train net output #1: loss2 = 0.203348 (* 0.6 = 0.122009 loss)
I0817 17:03:50.637553  2446 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0817 17:03:53.631253  2446 solver.cpp:228] Iteration 2080, loss = 0.115026
I0817 17:03:53.631301  2446 solver.cpp:244]     Train net output #0: loss1 = 0.11042 (* 0.4 = 0.0441682 loss)
I0817 17:03:53.631316  2446 solver.cpp:244]     Train net output #1: loss2 = 0.118097 (* 0.6 = 0.070858 loss)
I0817 17:03:53.631330  2446 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0817 17:03:56.622591  2446 solver.cpp:228] Iteration 2100, loss = 0.178337
I0817 17:03:56.622642  2446 solver.cpp:244]     Train net output #0: loss1 = 0.109365 (* 0.4 = 0.0437458 loss)
I0817 17:03:56.622656  2446 solver.cpp:244]     Train net output #1: loss2 = 0.224318 (* 0.6 = 0.134591 loss)
I0817 17:03:56.622669  2446 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0817 17:03:59.618695  2446 solver.cpp:228] Iteration 2120, loss = 0.150354
I0817 17:03:59.618746  2446 solver.cpp:244]     Train net output #0: loss1 = 0.113104 (* 0.4 = 0.0452415 loss)
I0817 17:03:59.618762  2446 solver.cpp:244]     Train net output #1: loss2 = 0.175188 (* 0.6 = 0.105113 loss)
I0817 17:03:59.618774  2446 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0817 17:04:02.614243  2446 solver.cpp:228] Iteration 2140, loss = 0.113609
I0817 17:04:02.614296  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0484025 (* 0.4 = 0.019361 loss)
I0817 17:04:02.614312  2446 solver.cpp:244]     Train net output #1: loss2 = 0.15708 (* 0.6 = 0.0942481 loss)
I0817 17:04:02.614326  2446 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0817 17:04:05.607463  2446 solver.cpp:228] Iteration 2160, loss = 0.0640518
I0817 17:04:05.607517  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0137461 (* 0.4 = 0.00549844 loss)
I0817 17:04:05.607533  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0975894 (* 0.6 = 0.0585536 loss)
I0817 17:04:05.607547  2446 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0817 17:04:08.601217  2446 solver.cpp:228] Iteration 2180, loss = 0.114163
I0817 17:04:08.601269  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0312845 (* 0.4 = 0.0125138 loss)
I0817 17:04:08.601285  2446 solver.cpp:244]     Train net output #1: loss2 = 0.169416 (* 0.6 = 0.101649 loss)
I0817 17:04:08.601297  2446 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0817 17:04:11.595737  2446 solver.cpp:228] Iteration 2200, loss = 0.138708
I0817 17:04:11.595818  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0750302 (* 0.4 = 0.0300121 loss)
I0817 17:04:11.595834  2446 solver.cpp:244]     Train net output #1: loss2 = 0.18116 (* 0.6 = 0.108696 loss)
I0817 17:04:11.595847  2446 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0817 17:04:14.588340  2446 solver.cpp:228] Iteration 2220, loss = 0.125895
I0817 17:04:14.588425  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0702277 (* 0.4 = 0.0280911 loss)
I0817 17:04:14.588443  2446 solver.cpp:244]     Train net output #1: loss2 = 0.163007 (* 0.6 = 0.0978044 loss)
I0817 17:04:14.588455  2446 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0817 17:04:17.579639  2446 solver.cpp:228] Iteration 2240, loss = 0.146274
I0817 17:04:17.579694  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0663218 (* 0.4 = 0.0265287 loss)
I0817 17:04:17.579710  2446 solver.cpp:244]     Train net output #1: loss2 = 0.199577 (* 0.6 = 0.119746 loss)
I0817 17:04:17.579722  2446 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0817 17:04:20.573171  2446 solver.cpp:228] Iteration 2260, loss = 0.108549
I0817 17:04:20.573225  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0798832 (* 0.4 = 0.0319533 loss)
I0817 17:04:20.573240  2446 solver.cpp:244]     Train net output #1: loss2 = 0.127661 (* 0.6 = 0.0765964 loss)
I0817 17:04:20.573253  2446 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0817 17:04:23.567611  2446 solver.cpp:228] Iteration 2280, loss = 0.100414
I0817 17:04:23.567664  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0729745 (* 0.4 = 0.0291898 loss)
I0817 17:04:23.567679  2446 solver.cpp:244]     Train net output #1: loss2 = 0.118707 (* 0.6 = 0.071224 loss)
I0817 17:04:23.567692  2446 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0817 17:04:26.559871  2446 solver.cpp:228] Iteration 2300, loss = 0.114562
I0817 17:04:26.559923  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0223729 (* 0.4 = 0.00894918 loss)
I0817 17:04:26.559939  2446 solver.cpp:244]     Train net output #1: loss2 = 0.176023 (* 0.6 = 0.105614 loss)
I0817 17:04:26.559952  2446 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0817 17:04:29.552824  2446 solver.cpp:228] Iteration 2320, loss = 0.138324
I0817 17:04:29.552875  2446 solver.cpp:244]     Train net output #0: loss1 = 0.111434 (* 0.4 = 0.0445738 loss)
I0817 17:04:29.552891  2446 solver.cpp:244]     Train net output #1: loss2 = 0.156251 (* 0.6 = 0.0937505 loss)
I0817 17:04:29.552903  2446 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0817 17:04:32.545192  2446 solver.cpp:228] Iteration 2340, loss = 0.0882015
I0817 17:04:32.545246  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0397049 (* 0.4 = 0.015882 loss)
I0817 17:04:32.545261  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120533 (* 0.6 = 0.0723198 loss)
I0817 17:04:32.545274  2446 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0817 17:04:35.544133  2446 solver.cpp:228] Iteration 2360, loss = 0.0890709
I0817 17:04:35.544185  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0160869 (* 0.4 = 0.00643475 loss)
I0817 17:04:35.544203  2446 solver.cpp:244]     Train net output #1: loss2 = 0.137727 (* 0.6 = 0.0826364 loss)
I0817 17:04:35.544215  2446 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0817 17:04:38.545580  2446 solver.cpp:228] Iteration 2380, loss = 0.0934216
I0817 17:04:38.545634  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0658637 (* 0.4 = 0.0263455 loss)
I0817 17:04:38.545650  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111794 (* 0.6 = 0.0670764 loss)
I0817 17:04:38.545662  2446 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0817 17:04:41.544160  2446 solver.cpp:228] Iteration 2400, loss = 0.134948
I0817 17:04:41.544212  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0371169 (* 0.4 = 0.0148467 loss)
I0817 17:04:41.544229  2446 solver.cpp:244]     Train net output #1: loss2 = 0.200169 (* 0.6 = 0.120101 loss)
I0817 17:04:41.544242  2446 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0817 17:04:44.536675  2446 solver.cpp:228] Iteration 2420, loss = 0.107889
I0817 17:04:44.536726  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0664993 (* 0.4 = 0.0265997 loss)
I0817 17:04:44.536742  2446 solver.cpp:244]     Train net output #1: loss2 = 0.135483 (* 0.6 = 0.08129 loss)
I0817 17:04:44.536756  2446 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0817 17:04:47.531211  2446 solver.cpp:228] Iteration 2440, loss = 0.155521
I0817 17:04:47.531358  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0211874 (* 0.4 = 0.00847495 loss)
I0817 17:04:47.531375  2446 solver.cpp:244]     Train net output #1: loss2 = 0.245077 (* 0.6 = 0.147046 loss)
I0817 17:04:47.531388  2446 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0817 17:04:50.524361  2446 solver.cpp:228] Iteration 2460, loss = 0.0939652
I0817 17:04:50.524452  2446 solver.cpp:244]     Train net output #0: loss1 = 0.041454 (* 0.4 = 0.0165816 loss)
I0817 17:04:50.524484  2446 solver.cpp:244]     Train net output #1: loss2 = 0.128973 (* 0.6 = 0.0773838 loss)
I0817 17:04:50.524510  2446 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0817 17:04:53.518784  2446 solver.cpp:228] Iteration 2480, loss = 0.076662
I0817 17:04:53.518837  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0666381 (* 0.4 = 0.0266553 loss)
I0817 17:04:53.518853  2446 solver.cpp:244]     Train net output #1: loss2 = 0.083345 (* 0.6 = 0.050007 loss)
I0817 17:04:53.518867  2446 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0817 17:04:56.511471  2446 solver.cpp:228] Iteration 2500, loss = 0.115279
I0817 17:04:56.511528  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0861907 (* 0.4 = 0.0344763 loss)
I0817 17:04:56.511543  2446 solver.cpp:244]     Train net output #1: loss2 = 0.134672 (* 0.6 = 0.080803 loss)
I0817 17:04:56.511556  2446 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0817 17:04:59.505199  2446 solver.cpp:228] Iteration 2520, loss = 0.188921
I0817 17:04:59.505256  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0571318 (* 0.4 = 0.0228527 loss)
I0817 17:04:59.505272  2446 solver.cpp:244]     Train net output #1: loss2 = 0.27678 (* 0.6 = 0.166068 loss)
I0817 17:04:59.505285  2446 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0817 17:05:02.497741  2446 solver.cpp:228] Iteration 2540, loss = 0.105021
I0817 17:05:02.497795  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0946506 (* 0.4 = 0.0378602 loss)
I0817 17:05:02.497812  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111935 (* 0.6 = 0.0671609 loss)
I0817 17:05:02.497824  2446 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0817 17:05:05.491730  2446 solver.cpp:228] Iteration 2560, loss = 0.104605
I0817 17:05:05.491785  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0822827 (* 0.4 = 0.0329131 loss)
I0817 17:05:05.491801  2446 solver.cpp:244]     Train net output #1: loss2 = 0.119488 (* 0.6 = 0.0716925 loss)
I0817 17:05:05.491813  2446 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0817 17:05:08.486387  2446 solver.cpp:228] Iteration 2580, loss = 0.0877291
I0817 17:05:08.486440  2446 solver.cpp:244]     Train net output #0: loss1 = 0.03791 (* 0.4 = 0.015164 loss)
I0817 17:05:08.486456  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120942 (* 0.6 = 0.0725653 loss)
I0817 17:05:08.486469  2446 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0817 17:05:11.482589  2446 solver.cpp:228] Iteration 2600, loss = 0.103404
I0817 17:05:11.482638  2446 solver.cpp:244]     Train net output #0: loss1 = 0.101476 (* 0.4 = 0.0405906 loss)
I0817 17:05:11.482655  2446 solver.cpp:244]     Train net output #1: loss2 = 0.10469 (* 0.6 = 0.0628137 loss)
I0817 17:05:11.482667  2446 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0817 17:05:14.474401  2446 solver.cpp:228] Iteration 2620, loss = 0.105533
I0817 17:05:14.474457  2446 solver.cpp:244]     Train net output #0: loss1 = 0.120382 (* 0.4 = 0.0481527 loss)
I0817 17:05:14.474472  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0956339 (* 0.6 = 0.0573803 loss)
I0817 17:05:14.474485  2446 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0817 17:05:17.469697  2446 solver.cpp:228] Iteration 2640, loss = 0.158164
I0817 17:05:17.469753  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0351853 (* 0.4 = 0.0140741 loss)
I0817 17:05:17.469769  2446 solver.cpp:244]     Train net output #1: loss2 = 0.24015 (* 0.6 = 0.14409 loss)
I0817 17:05:17.469781  2446 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0817 17:05:20.463893  2446 solver.cpp:228] Iteration 2660, loss = 0.155154
I0817 17:05:20.464042  2446 solver.cpp:244]     Train net output #0: loss1 = 0.122698 (* 0.4 = 0.0490794 loss)
I0817 17:05:20.464059  2446 solver.cpp:244]     Train net output #1: loss2 = 0.176792 (* 0.6 = 0.106075 loss)
I0817 17:05:20.464072  2446 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0817 17:05:23.457448  2446 solver.cpp:228] Iteration 2680, loss = 0.0839107
I0817 17:05:23.457504  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0503409 (* 0.4 = 0.0201364 loss)
I0817 17:05:23.457520  2446 solver.cpp:244]     Train net output #1: loss2 = 0.106291 (* 0.6 = 0.0637745 loss)
I0817 17:05:23.457533  2446 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0817 17:05:26.450557  2446 solver.cpp:228] Iteration 2700, loss = 0.141972
I0817 17:05:26.450611  2446 solver.cpp:244]     Train net output #0: loss1 = 0.128194 (* 0.4 = 0.0512775 loss)
I0817 17:05:26.450628  2446 solver.cpp:244]     Train net output #1: loss2 = 0.151157 (* 0.6 = 0.0906944 loss)
I0817 17:05:26.450641  2446 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0817 17:05:29.443452  2446 solver.cpp:228] Iteration 2720, loss = 0.0812398
I0817 17:05:29.443502  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0411051 (* 0.4 = 0.016442 loss)
I0817 17:05:29.443518  2446 solver.cpp:244]     Train net output #1: loss2 = 0.107997 (* 0.6 = 0.064798 loss)
I0817 17:05:29.443531  2446 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0817 17:05:32.436316  2446 solver.cpp:228] Iteration 2740, loss = 0.143218
I0817 17:05:32.436367  2446 solver.cpp:244]     Train net output #0: loss1 = 0.063921 (* 0.4 = 0.0255684 loss)
I0817 17:05:32.436383  2446 solver.cpp:244]     Train net output #1: loss2 = 0.196083 (* 0.6 = 0.11765 loss)
I0817 17:05:32.436398  2446 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0817 17:05:35.430855  2446 solver.cpp:228] Iteration 2760, loss = 0.12908
I0817 17:05:35.430912  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0796526 (* 0.4 = 0.031861 loss)
I0817 17:05:35.430928  2446 solver.cpp:244]     Train net output #1: loss2 = 0.162033 (* 0.6 = 0.0972196 loss)
I0817 17:05:35.430941  2446 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0817 17:05:38.422771  2446 solver.cpp:228] Iteration 2780, loss = 0.0830046
I0817 17:05:38.422827  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0248216 (* 0.4 = 0.00992863 loss)
I0817 17:05:38.422842  2446 solver.cpp:244]     Train net output #1: loss2 = 0.121794 (* 0.6 = 0.0730762 loss)
I0817 17:05:38.422855  2446 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0817 17:05:41.417887  2446 solver.cpp:228] Iteration 2800, loss = 0.166044
I0817 17:05:41.417938  2446 solver.cpp:244]     Train net output #0: loss1 = 0.15069 (* 0.4 = 0.0602759 loss)
I0817 17:05:41.417954  2446 solver.cpp:244]     Train net output #1: loss2 = 0.176281 (* 0.6 = 0.105768 loss)
I0817 17:05:41.417966  2446 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0817 17:05:44.411862  2446 solver.cpp:228] Iteration 2820, loss = 0.0604295
I0817 17:05:44.411916  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0408818 (* 0.4 = 0.0163527 loss)
I0817 17:05:44.411932  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0734617 (* 0.6 = 0.044077 loss)
I0817 17:05:44.411945  2446 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0817 17:05:47.405104  2446 solver.cpp:228] Iteration 2840, loss = 0.0906807
I0817 17:05:47.405158  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0688434 (* 0.4 = 0.0275374 loss)
I0817 17:05:47.405174  2446 solver.cpp:244]     Train net output #1: loss2 = 0.105239 (* 0.6 = 0.0631435 loss)
I0817 17:05:47.405186  2446 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0817 17:05:50.397922  2446 solver.cpp:228] Iteration 2860, loss = 0.111203
I0817 17:05:50.397977  2446 solver.cpp:244]     Train net output #0: loss1 = 0.109576 (* 0.4 = 0.0438305 loss)
I0817 17:05:50.397992  2446 solver.cpp:244]     Train net output #1: loss2 = 0.112288 (* 0.6 = 0.067373 loss)
I0817 17:05:50.398005  2446 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0817 17:05:53.391888  2446 solver.cpp:228] Iteration 2880, loss = 0.0676166
I0817 17:05:53.392035  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0369753 (* 0.4 = 0.0147901 loss)
I0817 17:05:53.392051  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0880445 (* 0.6 = 0.0528267 loss)
I0817 17:05:53.392066  2446 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0817 17:05:56.387172  2446 solver.cpp:228] Iteration 2900, loss = 0.0835194
I0817 17:05:56.387228  2446 solver.cpp:244]     Train net output #0: loss1 = 0.091533 (* 0.4 = 0.0366132 loss)
I0817 17:05:56.387243  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0781774 (* 0.6 = 0.0469065 loss)
I0817 17:05:56.387256  2446 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0817 17:05:59.379912  2446 solver.cpp:228] Iteration 2920, loss = 0.0959468
I0817 17:05:59.379966  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0375024 (* 0.4 = 0.0150009 loss)
I0817 17:05:59.379982  2446 solver.cpp:244]     Train net output #1: loss2 = 0.13491 (* 0.6 = 0.0809461 loss)
I0817 17:05:59.379995  2446 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0817 17:06:02.372846  2446 solver.cpp:228] Iteration 2940, loss = 0.113932
I0817 17:06:02.372897  2446 solver.cpp:244]     Train net output #0: loss1 = 0.103711 (* 0.4 = 0.0414844 loss)
I0817 17:06:02.372913  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120746 (* 0.6 = 0.0724479 loss)
I0817 17:06:02.372926  2446 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0817 17:06:05.365530  2446 solver.cpp:228] Iteration 2960, loss = 0.139369
I0817 17:06:05.365581  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0981245 (* 0.4 = 0.0392498 loss)
I0817 17:06:05.365597  2446 solver.cpp:244]     Train net output #1: loss2 = 0.166866 (* 0.6 = 0.10012 loss)
I0817 17:06:05.365610  2446 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0817 17:06:08.360175  2446 solver.cpp:228] Iteration 2980, loss = 0.0971499
I0817 17:06:08.360229  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0376095 (* 0.4 = 0.0150438 loss)
I0817 17:06:08.360244  2446 solver.cpp:244]     Train net output #1: loss2 = 0.136844 (* 0.6 = 0.0821064 loss)
I0817 17:06:08.360256  2446 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0817 17:06:11.203435  2446 solver.cpp:337] Iteration 3000, Testing net (#0)
I0817 17:06:47.159550  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.828156
I0817 17:06:47.159657  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.942672
I0817 17:06:47.159677  2446 solver.cpp:404]     Test net output #2: loss1 = 0.172749 (* 0.4 = 0.0690996 loss)
I0817 17:06:47.159690  2446 solver.cpp:404]     Test net output #3: loss2 = 0.411828 (* 0.6 = 0.247097 loss)
I0817 17:06:47.205879  2446 solver.cpp:228] Iteration 3000, loss = 0.0868019
I0817 17:06:47.205931  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0394217 (* 0.4 = 0.0157687 loss)
I0817 17:06:47.205947  2446 solver.cpp:244]     Train net output #1: loss2 = 0.118389 (* 0.6 = 0.0710335 loss)
I0817 17:06:47.205960  2446 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0817 17:06:50.221593  2446 solver.cpp:228] Iteration 3020, loss = 0.0872973
I0817 17:06:50.221649  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0558009 (* 0.4 = 0.0223204 loss)
I0817 17:06:50.221665  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108295 (* 0.6 = 0.0649772 loss)
I0817 17:06:50.221679  2446 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0817 17:06:53.226383  2446 solver.cpp:228] Iteration 3040, loss = 0.0983824
I0817 17:06:53.226460  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0382774 (* 0.4 = 0.015311 loss)
I0817 17:06:53.226485  2446 solver.cpp:244]     Train net output #1: loss2 = 0.138453 (* 0.6 = 0.0830717 loss)
I0817 17:06:53.226505  2446 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0817 17:06:56.238735  2446 solver.cpp:228] Iteration 3060, loss = 0.102239
I0817 17:06:56.238797  2446 solver.cpp:244]     Train net output #0: loss1 = 0.10607 (* 0.4 = 0.0424279 loss)
I0817 17:06:56.238814  2446 solver.cpp:244]     Train net output #1: loss2 = 0.099685 (* 0.6 = 0.059811 loss)
I0817 17:06:56.238828  2446 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0817 17:06:59.306707  2446 solver.cpp:228] Iteration 3080, loss = 0.109593
I0817 17:06:59.306763  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0646832 (* 0.4 = 0.0258733 loss)
I0817 17:06:59.306779  2446 solver.cpp:244]     Train net output #1: loss2 = 0.139532 (* 0.6 = 0.0837195 loss)
I0817 17:06:59.306792  2446 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0817 17:07:02.362421  2446 solver.cpp:228] Iteration 3100, loss = 0.0756534
I0817 17:07:02.362478  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0197399 (* 0.4 = 0.00789596 loss)
I0817 17:07:02.362494  2446 solver.cpp:244]     Train net output #1: loss2 = 0.11293 (* 0.6 = 0.0677577 loss)
I0817 17:07:02.362507  2446 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0817 17:07:05.355763  2446 solver.cpp:228] Iteration 3120, loss = 0.119387
I0817 17:07:05.355818  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0196815 (* 0.4 = 0.00787259 loss)
I0817 17:07:05.355834  2446 solver.cpp:244]     Train net output #1: loss2 = 0.185857 (* 0.6 = 0.111514 loss)
I0817 17:07:05.355846  2446 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0817 17:07:08.457784  2446 solver.cpp:228] Iteration 3140, loss = 0.0792799
I0817 17:07:08.457841  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0523044 (* 0.4 = 0.0209217 loss)
I0817 17:07:08.457857  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0972639 (* 0.6 = 0.0583583 loss)
I0817 17:07:08.457870  2446 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0817 17:07:11.499137  2446 solver.cpp:228] Iteration 3160, loss = 0.12171
I0817 17:07:11.499194  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0582261 (* 0.4 = 0.0232904 loss)
I0817 17:07:11.499210  2446 solver.cpp:244]     Train net output #1: loss2 = 0.164033 (* 0.6 = 0.0984197 loss)
I0817 17:07:11.499222  2446 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0817 17:07:14.501292  2446 solver.cpp:228] Iteration 3180, loss = 0.144834
I0817 17:07:14.501344  2446 solver.cpp:244]     Train net output #0: loss1 = 0.10733 (* 0.4 = 0.0429321 loss)
I0817 17:07:14.501359  2446 solver.cpp:244]     Train net output #1: loss2 = 0.169837 (* 0.6 = 0.101902 loss)
I0817 17:07:14.501373  2446 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0817 17:07:17.494855  2446 solver.cpp:228] Iteration 3200, loss = 0.202217
I0817 17:07:17.495481  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0629717 (* 0.4 = 0.0251887 loss)
I0817 17:07:17.495498  2446 solver.cpp:244]     Train net output #1: loss2 = 0.295048 (* 0.6 = 0.177029 loss)
I0817 17:07:17.495512  2446 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0817 17:07:20.500452  2446 solver.cpp:228] Iteration 3220, loss = 0.122952
I0817 17:07:20.500507  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0573673 (* 0.4 = 0.0229469 loss)
I0817 17:07:20.500524  2446 solver.cpp:244]     Train net output #1: loss2 = 0.166675 (* 0.6 = 0.100005 loss)
I0817 17:07:20.500536  2446 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0817 17:07:23.527709  2446 solver.cpp:228] Iteration 3240, loss = 0.117938
I0817 17:07:23.527761  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0145707 (* 0.4 = 0.00582827 loss)
I0817 17:07:23.527777  2446 solver.cpp:244]     Train net output #1: loss2 = 0.18685 (* 0.6 = 0.11211 loss)
I0817 17:07:23.527791  2446 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0817 17:07:26.582819  2446 solver.cpp:228] Iteration 3260, loss = 0.0467512
I0817 17:07:26.582875  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0269397 (* 0.4 = 0.0107759 loss)
I0817 17:07:26.582890  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0599593 (* 0.6 = 0.0359756 loss)
I0817 17:07:26.582908  2446 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0817 17:07:29.579037  2446 solver.cpp:228] Iteration 3280, loss = 0.103194
I0817 17:07:29.579094  2446 solver.cpp:244]     Train net output #0: loss1 = 0.13082 (* 0.4 = 0.0523281 loss)
I0817 17:07:29.579110  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0847764 (* 0.6 = 0.0508659 loss)
I0817 17:07:29.579123  2446 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0817 17:07:32.581578  2446 solver.cpp:228] Iteration 3300, loss = 0.11482
I0817 17:07:32.581636  2446 solver.cpp:244]     Train net output #0: loss1 = 0.106016 (* 0.4 = 0.0424065 loss)
I0817 17:07:32.581652  2446 solver.cpp:244]     Train net output #1: loss2 = 0.12069 (* 0.6 = 0.0724138 loss)
I0817 17:07:32.581665  2446 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0817 17:07:35.607867  2446 solver.cpp:228] Iteration 3320, loss = 0.0731554
I0817 17:07:35.607928  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0246097 (* 0.4 = 0.00984386 loss)
I0817 17:07:35.607944  2446 solver.cpp:244]     Train net output #1: loss2 = 0.10552 (* 0.6 = 0.0633118 loss)
I0817 17:07:35.607956  2446 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0817 17:07:38.615478  2446 solver.cpp:228] Iteration 3340, loss = 0.115648
I0817 17:07:38.615532  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0864657 (* 0.4 = 0.0345863 loss)
I0817 17:07:38.615548  2446 solver.cpp:244]     Train net output #1: loss2 = 0.135104 (* 0.6 = 0.0810622 loss)
I0817 17:07:38.615561  2446 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0817 17:07:41.624025  2446 solver.cpp:228] Iteration 3360, loss = 0.0682588
I0817 17:07:41.624078  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0546154 (* 0.4 = 0.0218462 loss)
I0817 17:07:41.624094  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0773548 (* 0.6 = 0.0464129 loss)
I0817 17:07:41.624107  2446 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0817 17:07:44.621212  2446 solver.cpp:228] Iteration 3380, loss = 0.0865124
I0817 17:07:44.621268  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0210609 (* 0.4 = 0.00842436 loss)
I0817 17:07:44.621284  2446 solver.cpp:244]     Train net output #1: loss2 = 0.130147 (* 0.6 = 0.0780883 loss)
I0817 17:07:44.621296  2446 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0817 17:07:47.631163  2446 solver.cpp:228] Iteration 3400, loss = 0.0837464
I0817 17:07:47.631304  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0379096 (* 0.4 = 0.0151638 loss)
I0817 17:07:47.631321  2446 solver.cpp:244]     Train net output #1: loss2 = 0.114305 (* 0.6 = 0.0685828 loss)
I0817 17:07:47.631335  2446 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0817 17:07:50.660403  2446 solver.cpp:228] Iteration 3420, loss = 0.123124
I0817 17:07:50.660460  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0384398 (* 0.4 = 0.0153759 loss)
I0817 17:07:50.660475  2446 solver.cpp:244]     Train net output #1: loss2 = 0.17958 (* 0.6 = 0.107748 loss)
I0817 17:07:50.660488  2446 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0817 17:07:53.684866  2446 solver.cpp:228] Iteration 3440, loss = 0.136273
I0817 17:07:53.684918  2446 solver.cpp:244]     Train net output #0: loss1 = 0.200856 (* 0.4 = 0.0803423 loss)
I0817 17:07:53.684934  2446 solver.cpp:244]     Train net output #1: loss2 = 0.093219 (* 0.6 = 0.0559314 loss)
I0817 17:07:53.684947  2446 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0817 17:07:56.693147  2446 solver.cpp:228] Iteration 3460, loss = 0.0927034
I0817 17:07:56.693202  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0454929 (* 0.4 = 0.0181972 loss)
I0817 17:07:56.693217  2446 solver.cpp:244]     Train net output #1: loss2 = 0.124178 (* 0.6 = 0.0745065 loss)
I0817 17:07:56.693229  2446 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0817 17:07:59.717152  2446 solver.cpp:228] Iteration 3480, loss = 0.0660131
I0817 17:07:59.717209  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0379129 (* 0.4 = 0.0151651 loss)
I0817 17:07:59.717226  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0847469 (* 0.6 = 0.0508482 loss)
I0817 17:07:59.717238  2446 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0817 17:08:02.725035  2446 solver.cpp:228] Iteration 3500, loss = 0.0767998
I0817 17:08:02.725095  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0322364 (* 0.4 = 0.0128946 loss)
I0817 17:08:02.725111  2446 solver.cpp:244]     Train net output #1: loss2 = 0.106509 (* 0.6 = 0.0639055 loss)
I0817 17:08:02.725123  2446 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0817 17:08:05.735008  2446 solver.cpp:228] Iteration 3520, loss = 0.0856956
I0817 17:08:05.735064  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0514615 (* 0.4 = 0.0205846 loss)
I0817 17:08:05.735080  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108519 (* 0.6 = 0.0651113 loss)
I0817 17:08:05.735093  2446 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0817 17:08:08.730929  2446 solver.cpp:228] Iteration 3540, loss = 0.0626438
I0817 17:08:08.730985  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0330177 (* 0.4 = 0.0132071 loss)
I0817 17:08:08.731001  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0823949 (* 0.6 = 0.049437 loss)
I0817 17:08:08.731014  2446 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0817 17:08:11.723366  2446 solver.cpp:228] Iteration 3560, loss = 0.0902597
I0817 17:08:11.723417  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0329572 (* 0.4 = 0.0131829 loss)
I0817 17:08:11.723433  2446 solver.cpp:244]     Train net output #1: loss2 = 0.128462 (* 0.6 = 0.0770771 loss)
I0817 17:08:11.723445  2446 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0817 17:08:14.750497  2446 solver.cpp:228] Iteration 3580, loss = 0.118977
I0817 17:08:14.750555  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0531095 (* 0.4 = 0.0212438 loss)
I0817 17:08:14.750571  2446 solver.cpp:244]     Train net output #1: loss2 = 0.162889 (* 0.6 = 0.0977333 loss)
I0817 17:08:14.750582  2446 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0817 17:08:17.752751  2446 solver.cpp:228] Iteration 3600, loss = 0.106869
I0817 17:08:17.752934  2446 solver.cpp:244]     Train net output #0: loss1 = 0.00938096 (* 0.4 = 0.00375239 loss)
I0817 17:08:17.752959  2446 solver.cpp:244]     Train net output #1: loss2 = 0.171861 (* 0.6 = 0.103117 loss)
I0817 17:08:17.752976  2446 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0817 17:08:20.761260  2446 solver.cpp:228] Iteration 3620, loss = 0.094072
I0817 17:08:20.761318  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0410502 (* 0.4 = 0.0164201 loss)
I0817 17:08:20.761334  2446 solver.cpp:244]     Train net output #1: loss2 = 0.12942 (* 0.6 = 0.0776521 loss)
I0817 17:08:20.761346  2446 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0817 17:08:23.757707  2446 solver.cpp:228] Iteration 3640, loss = 0.0724381
I0817 17:08:23.757766  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0309948 (* 0.4 = 0.0123979 loss)
I0817 17:08:23.757783  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100067 (* 0.6 = 0.0600404 loss)
I0817 17:08:23.757805  2446 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0817 17:08:26.794769  2446 solver.cpp:228] Iteration 3660, loss = 0.0835094
I0817 17:08:26.794823  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0425495 (* 0.4 = 0.0170198 loss)
I0817 17:08:26.794838  2446 solver.cpp:244]     Train net output #1: loss2 = 0.110816 (* 0.6 = 0.0664899 loss)
I0817 17:08:26.794852  2446 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0817 17:08:29.816972  2446 solver.cpp:228] Iteration 3680, loss = 0.0826916
I0817 17:08:29.817028  2446 solver.cpp:244]     Train net output #0: loss1 = 0.046077 (* 0.4 = 0.0184308 loss)
I0817 17:08:29.817045  2446 solver.cpp:244]     Train net output #1: loss2 = 0.107102 (* 0.6 = 0.064261 loss)
I0817 17:08:29.817059  2446 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0817 17:08:32.865818  2446 solver.cpp:228] Iteration 3700, loss = 0.112518
I0817 17:08:32.865878  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0298123 (* 0.4 = 0.0119249 loss)
I0817 17:08:32.865895  2446 solver.cpp:244]     Train net output #1: loss2 = 0.167655 (* 0.6 = 0.100593 loss)
I0817 17:08:32.865907  2446 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0817 17:08:35.892199  2446 solver.cpp:228] Iteration 3720, loss = 0.0872578
I0817 17:08:35.892248  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0255965 (* 0.4 = 0.0102386 loss)
I0817 17:08:35.892259  2446 solver.cpp:244]     Train net output #1: loss2 = 0.128366 (* 0.6 = 0.0770195 loss)
I0817 17:08:35.892268  2446 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0817 17:08:38.913682  2446 solver.cpp:228] Iteration 3740, loss = 0.0828624
I0817 17:08:38.913738  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0576286 (* 0.4 = 0.0230515 loss)
I0817 17:08:38.913753  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0996852 (* 0.6 = 0.0598111 loss)
I0817 17:08:38.913765  2446 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0817 17:08:41.913882  2446 solver.cpp:228] Iteration 3760, loss = 0.0893485
I0817 17:08:41.913941  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0608236 (* 0.4 = 0.0243294 loss)
I0817 17:08:41.913957  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108365 (* 0.6 = 0.0650193 loss)
I0817 17:08:41.913969  2446 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0817 17:08:44.907107  2446 solver.cpp:228] Iteration 3780, loss = 0.0747591
I0817 17:08:44.907162  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0429196 (* 0.4 = 0.0171678 loss)
I0817 17:08:44.907179  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0959858 (* 0.6 = 0.0575915 loss)
I0817 17:08:44.907192  2446 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0817 17:08:47.904621  2446 solver.cpp:228] Iteration 3800, loss = 0.107308
I0817 17:08:47.904762  2446 solver.cpp:244]     Train net output #0: loss1 = 0.11921 (* 0.4 = 0.0476841 loss)
I0817 17:08:47.904779  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0993743 (* 0.6 = 0.0596246 loss)
I0817 17:08:47.904793  2446 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0817 17:08:50.905953  2446 solver.cpp:228] Iteration 3820, loss = 0.140544
I0817 17:08:50.906013  2446 solver.cpp:244]     Train net output #0: loss1 = 0.114609 (* 0.4 = 0.0458436 loss)
I0817 17:08:50.906030  2446 solver.cpp:244]     Train net output #1: loss2 = 0.157834 (* 0.6 = 0.0947003 loss)
I0817 17:08:50.906044  2446 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0817 17:08:53.902678  2446 solver.cpp:228] Iteration 3840, loss = 0.153331
I0817 17:08:53.902730  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0525301 (* 0.4 = 0.021012 loss)
I0817 17:08:53.902746  2446 solver.cpp:244]     Train net output #1: loss2 = 0.220532 (* 0.6 = 0.132319 loss)
I0817 17:08:53.902760  2446 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0817 17:08:56.925678  2446 solver.cpp:228] Iteration 3860, loss = 0.0884117
I0817 17:08:56.925734  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0581289 (* 0.4 = 0.0232516 loss)
I0817 17:08:56.925750  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108601 (* 0.6 = 0.0651604 loss)
I0817 17:08:56.925762  2446 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0817 17:08:59.928895  2446 solver.cpp:228] Iteration 3880, loss = 0.12802
I0817 17:08:59.928951  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0587302 (* 0.4 = 0.0234921 loss)
I0817 17:08:59.928967  2446 solver.cpp:244]     Train net output #1: loss2 = 0.174214 (* 0.6 = 0.104528 loss)
I0817 17:08:59.928980  2446 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0817 17:09:02.937882  2446 solver.cpp:228] Iteration 3900, loss = 0.0964081
I0817 17:09:02.937938  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0497467 (* 0.4 = 0.0198987 loss)
I0817 17:09:02.937953  2446 solver.cpp:244]     Train net output #1: loss2 = 0.127516 (* 0.6 = 0.0765096 loss)
I0817 17:09:02.937966  2446 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0817 17:09:05.933575  2446 solver.cpp:228] Iteration 3920, loss = 0.131787
I0817 17:09:05.933632  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0347952 (* 0.4 = 0.0139181 loss)
I0817 17:09:05.933648  2446 solver.cpp:244]     Train net output #1: loss2 = 0.196448 (* 0.6 = 0.117869 loss)
I0817 17:09:05.933661  2446 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0817 17:09:08.926219  2446 solver.cpp:228] Iteration 3940, loss = 0.101879
I0817 17:09:08.926273  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0480977 (* 0.4 = 0.0192391 loss)
I0817 17:09:08.926290  2446 solver.cpp:244]     Train net output #1: loss2 = 0.137734 (* 0.6 = 0.0826403 loss)
I0817 17:09:08.926302  2446 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0817 17:09:11.922034  2446 solver.cpp:228] Iteration 3960, loss = 0.148772
I0817 17:09:11.922091  2446 solver.cpp:244]     Train net output #0: loss1 = 0.167029 (* 0.4 = 0.0668115 loss)
I0817 17:09:11.922106  2446 solver.cpp:244]     Train net output #1: loss2 = 0.1366 (* 0.6 = 0.0819603 loss)
I0817 17:09:11.922118  2446 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0817 17:09:14.927146  2446 solver.cpp:228] Iteration 3980, loss = 0.0653647
I0817 17:09:14.927198  2446 solver.cpp:244]     Train net output #0: loss1 = 0.053271 (* 0.4 = 0.0213084 loss)
I0817 17:09:14.927215  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0734276 (* 0.6 = 0.0440565 loss)
I0817 17:09:14.927227  2446 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0817 17:09:17.800019  2446 solver.cpp:337] Iteration 4000, Testing net (#0)
I0817 17:09:53.621603  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.828828
I0817 17:09:53.621737  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.948563
I0817 17:09:53.621757  2446 solver.cpp:404]     Test net output #2: loss1 = 0.166357 (* 0.4 = 0.0665428 loss)
I0817 17:09:53.621770  2446 solver.cpp:404]     Test net output #3: loss2 = 0.417632 (* 0.6 = 0.250579 loss)
I0817 17:09:53.668097  2446 solver.cpp:228] Iteration 4000, loss = 0.192698
I0817 17:09:53.668184  2446 solver.cpp:244]     Train net output #0: loss1 = 0.124428 (* 0.4 = 0.049771 loss)
I0817 17:09:53.668201  2446 solver.cpp:244]     Train net output #1: loss2 = 0.238211 (* 0.6 = 0.142927 loss)
I0817 17:09:53.668215  2446 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0817 17:09:56.682762  2446 solver.cpp:228] Iteration 4020, loss = 0.0789229
I0817 17:09:56.682818  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0363209 (* 0.4 = 0.0145284 loss)
I0817 17:09:56.682833  2446 solver.cpp:244]     Train net output #1: loss2 = 0.107325 (* 0.6 = 0.0643947 loss)
I0817 17:09:56.682847  2446 sgd_solver.cpp:106] Iteration 4020, lr = 0.0001
I0817 17:09:59.697727  2446 solver.cpp:228] Iteration 4040, loss = 0.0861067
I0817 17:09:59.697784  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0281963 (* 0.4 = 0.0112785 loss)
I0817 17:09:59.697800  2446 solver.cpp:244]     Train net output #1: loss2 = 0.124714 (* 0.6 = 0.0748284 loss)
I0817 17:09:59.697813  2446 sgd_solver.cpp:106] Iteration 4040, lr = 0.0001
I0817 17:10:02.709919  2446 solver.cpp:228] Iteration 4060, loss = 0.100762
I0817 17:10:02.709975  2446 solver.cpp:244]     Train net output #0: loss1 = 0.129471 (* 0.4 = 0.0517885 loss)
I0817 17:10:02.709990  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0816221 (* 0.6 = 0.0489733 loss)
I0817 17:10:02.710003  2446 sgd_solver.cpp:106] Iteration 4060, lr = 0.0001
I0817 17:10:05.714126  2446 solver.cpp:228] Iteration 4080, loss = 0.101524
I0817 17:10:05.714182  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0382758 (* 0.4 = 0.0153103 loss)
I0817 17:10:05.714198  2446 solver.cpp:244]     Train net output #1: loss2 = 0.143689 (* 0.6 = 0.0862135 loss)
I0817 17:10:05.714211  2446 sgd_solver.cpp:106] Iteration 4080, lr = 0.0001
I0817 17:10:08.707576  2446 solver.cpp:228] Iteration 4100, loss = 0.0728972
I0817 17:10:08.707631  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0212135 (* 0.4 = 0.00848541 loss)
I0817 17:10:08.707648  2446 solver.cpp:244]     Train net output #1: loss2 = 0.107353 (* 0.6 = 0.064412 loss)
I0817 17:10:08.707660  2446 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0817 17:10:11.707577  2446 solver.cpp:228] Iteration 4120, loss = 0.0975107
I0817 17:10:11.707629  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0674676 (* 0.4 = 0.026987 loss)
I0817 17:10:11.707645  2446 solver.cpp:244]     Train net output #1: loss2 = 0.11754 (* 0.6 = 0.0705239 loss)
I0817 17:10:11.707659  2446 sgd_solver.cpp:106] Iteration 4120, lr = 0.0001
I0817 17:10:14.706434  2446 solver.cpp:228] Iteration 4140, loss = 0.0593087
I0817 17:10:14.706487  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0209587 (* 0.4 = 0.00838349 loss)
I0817 17:10:14.706503  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0848757 (* 0.6 = 0.0509255 loss)
I0817 17:10:14.706516  2446 sgd_solver.cpp:106] Iteration 4140, lr = 0.0001
I0817 17:10:17.700498  2446 solver.cpp:228] Iteration 4160, loss = 0.0935391
I0817 17:10:17.700549  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0419221 (* 0.4 = 0.0167688 loss)
I0817 17:10:17.700565  2446 solver.cpp:244]     Train net output #1: loss2 = 0.127951 (* 0.6 = 0.0767705 loss)
I0817 17:10:17.700578  2446 sgd_solver.cpp:106] Iteration 4160, lr = 0.0001
I0817 17:10:20.694074  2446 solver.cpp:228] Iteration 4180, loss = 0.122008
I0817 17:10:20.694131  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0655803 (* 0.4 = 0.0262321 loss)
I0817 17:10:20.694147  2446 solver.cpp:244]     Train net output #1: loss2 = 0.159626 (* 0.6 = 0.0957757 loss)
I0817 17:10:20.694160  2446 sgd_solver.cpp:106] Iteration 4180, lr = 0.0001
I0817 17:10:23.698678  2446 solver.cpp:228] Iteration 4200, loss = 0.0738255
I0817 17:10:23.698840  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0428035 (* 0.4 = 0.0171214 loss)
I0817 17:10:23.698858  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0945073 (* 0.6 = 0.0567044 loss)
I0817 17:10:23.698871  2446 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0817 17:10:26.699941  2446 solver.cpp:228] Iteration 4220, loss = 0.108328
I0817 17:10:26.699998  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0548316 (* 0.4 = 0.0219327 loss)
I0817 17:10:26.700014  2446 solver.cpp:244]     Train net output #1: loss2 = 0.143992 (* 0.6 = 0.0863953 loss)
I0817 17:10:26.700027  2446 sgd_solver.cpp:106] Iteration 4220, lr = 0.0001
I0817 17:10:29.702090  2446 solver.cpp:228] Iteration 4240, loss = 0.093924
I0817 17:10:29.702142  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0288861 (* 0.4 = 0.0115544 loss)
I0817 17:10:29.702157  2446 solver.cpp:244]     Train net output #1: loss2 = 0.137283 (* 0.6 = 0.0823698 loss)
I0817 17:10:29.702170  2446 sgd_solver.cpp:106] Iteration 4240, lr = 0.0001
I0817 17:10:32.724562  2446 solver.cpp:228] Iteration 4260, loss = 0.0663546
I0817 17:10:32.724618  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0158886 (* 0.4 = 0.00635542 loss)
I0817 17:10:32.724634  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0999991 (* 0.6 = 0.0599995 loss)
I0817 17:10:32.724647  2446 sgd_solver.cpp:106] Iteration 4260, lr = 0.0001
I0817 17:10:35.734356  2446 solver.cpp:228] Iteration 4280, loss = 0.0756275
I0817 17:10:35.734413  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0215596 (* 0.4 = 0.00862384 loss)
I0817 17:10:35.734429  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111673 (* 0.6 = 0.0670039 loss)
I0817 17:10:35.734442  2446 sgd_solver.cpp:106] Iteration 4280, lr = 0.0001
I0817 17:10:38.730823  2446 solver.cpp:228] Iteration 4300, loss = 0.0854355
I0817 17:10:38.730876  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0315908 (* 0.4 = 0.0126363 loss)
I0817 17:10:38.730896  2446 solver.cpp:244]     Train net output #1: loss2 = 0.121332 (* 0.6 = 0.0727994 loss)
I0817 17:10:38.730911  2446 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0817 17:10:41.724037  2446 solver.cpp:228] Iteration 4320, loss = 0.131658
I0817 17:10:41.724089  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0757749 (* 0.4 = 0.03031 loss)
I0817 17:10:41.724105  2446 solver.cpp:244]     Train net output #1: loss2 = 0.168914 (* 0.6 = 0.101348 loss)
I0817 17:10:41.724117  2446 sgd_solver.cpp:106] Iteration 4320, lr = 0.0001
I0817 17:10:44.733276  2446 solver.cpp:228] Iteration 4340, loss = 0.121907
I0817 17:10:44.733332  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0577 (* 0.4 = 0.02308 loss)
I0817 17:10:44.733348  2446 solver.cpp:244]     Train net output #1: loss2 = 0.164712 (* 0.6 = 0.0988271 loss)
I0817 17:10:44.733361  2446 sgd_solver.cpp:106] Iteration 4340, lr = 0.0001
I0817 17:10:47.740386  2446 solver.cpp:228] Iteration 4360, loss = 0.0764619
I0817 17:10:47.740442  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0290645 (* 0.4 = 0.0116258 loss)
I0817 17:10:47.740459  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108061 (* 0.6 = 0.0648363 loss)
I0817 17:10:47.740473  2446 sgd_solver.cpp:106] Iteration 4360, lr = 0.0001
I0817 17:10:50.739122  2446 solver.cpp:228] Iteration 4380, loss = 0.0869838
I0817 17:10:50.739179  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0658171 (* 0.4 = 0.0263269 loss)
I0817 17:10:50.739197  2446 solver.cpp:244]     Train net output #1: loss2 = 0.101095 (* 0.6 = 0.0606572 loss)
I0817 17:10:50.739209  2446 sgd_solver.cpp:106] Iteration 4380, lr = 0.0001
I0817 17:10:53.739704  2446 solver.cpp:228] Iteration 4400, loss = 0.119378
I0817 17:10:53.739859  2446 solver.cpp:244]     Train net output #0: loss1 = 0.100271 (* 0.4 = 0.0401083 loss)
I0817 17:10:53.739877  2446 solver.cpp:244]     Train net output #1: loss2 = 0.132116 (* 0.6 = 0.0792698 loss)
I0817 17:10:53.739892  2446 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0817 17:10:56.742928  2446 solver.cpp:228] Iteration 4420, loss = 0.072438
I0817 17:10:56.742985  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0214506 (* 0.4 = 0.00858025 loss)
I0817 17:10:56.743001  2446 solver.cpp:244]     Train net output #1: loss2 = 0.10643 (* 0.6 = 0.0638579 loss)
I0817 17:10:56.743015  2446 sgd_solver.cpp:106] Iteration 4420, lr = 0.0001
I0817 17:10:59.738659  2446 solver.cpp:228] Iteration 4440, loss = 0.0561807
I0817 17:10:59.738713  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0489833 (* 0.4 = 0.0195933 loss)
I0817 17:10:59.738729  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0609793 (* 0.6 = 0.0365876 loss)
I0817 17:10:59.738741  2446 sgd_solver.cpp:106] Iteration 4440, lr = 0.0001
I0817 17:11:02.735501  2446 solver.cpp:228] Iteration 4460, loss = 0.120382
I0817 17:11:02.735553  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0428906 (* 0.4 = 0.0171562 loss)
I0817 17:11:02.735569  2446 solver.cpp:244]     Train net output #1: loss2 = 0.172044 (* 0.6 = 0.103226 loss)
I0817 17:11:02.735581  2446 sgd_solver.cpp:106] Iteration 4460, lr = 0.0001
I0817 17:11:05.729543  2446 solver.cpp:228] Iteration 4480, loss = 0.0828703
I0817 17:11:05.729632  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0212781 (* 0.4 = 0.00851124 loss)
I0817 17:11:05.729666  2446 solver.cpp:244]     Train net output #1: loss2 = 0.123932 (* 0.6 = 0.0743593 loss)
I0817 17:11:05.729691  2446 sgd_solver.cpp:106] Iteration 4480, lr = 0.0001
I0817 17:11:08.734926  2446 solver.cpp:228] Iteration 4500, loss = 0.0721189
I0817 17:11:08.734982  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0103997 (* 0.4 = 0.0041599 loss)
I0817 17:11:08.734997  2446 solver.cpp:244]     Train net output #1: loss2 = 0.113265 (* 0.6 = 0.0679592 loss)
I0817 17:11:08.735010  2446 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0817 17:11:11.769896  2446 solver.cpp:228] Iteration 4520, loss = 0.0956161
I0817 17:11:11.769953  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0570475 (* 0.4 = 0.022819 loss)
I0817 17:11:11.769969  2446 solver.cpp:244]     Train net output #1: loss2 = 0.121329 (* 0.6 = 0.0727973 loss)
I0817 17:11:11.769982  2446 sgd_solver.cpp:106] Iteration 4520, lr = 0.0001
I0817 17:11:14.766355  2446 solver.cpp:228] Iteration 4540, loss = 0.120075
I0817 17:11:14.766409  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0766882 (* 0.4 = 0.0306753 loss)
I0817 17:11:14.766425  2446 solver.cpp:244]     Train net output #1: loss2 = 0.149 (* 0.6 = 0.0893999 loss)
I0817 17:11:14.766438  2446 sgd_solver.cpp:106] Iteration 4540, lr = 0.0001
I0817 17:11:17.770401  2446 solver.cpp:228] Iteration 4560, loss = 0.0907283
I0817 17:11:17.770454  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0381346 (* 0.4 = 0.0152539 loss)
I0817 17:11:17.770470  2446 solver.cpp:244]     Train net output #1: loss2 = 0.125791 (* 0.6 = 0.0754747 loss)
I0817 17:11:17.770483  2446 sgd_solver.cpp:106] Iteration 4560, lr = 0.0001
I0817 17:11:20.769052  2446 solver.cpp:228] Iteration 4580, loss = 0.0684782
I0817 17:11:20.769111  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0211828 (* 0.4 = 0.00847313 loss)
I0817 17:11:20.769127  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100009 (* 0.6 = 0.0600053 loss)
I0817 17:11:20.769140  2446 sgd_solver.cpp:106] Iteration 4580, lr = 0.0001
I0817 17:11:23.765635  2446 solver.cpp:228] Iteration 4600, loss = 0.0922103
I0817 17:11:23.765799  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0664659 (* 0.4 = 0.0265864 loss)
I0817 17:11:23.765815  2446 solver.cpp:244]     Train net output #1: loss2 = 0.109374 (* 0.6 = 0.0656242 loss)
I0817 17:11:23.765830  2446 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0817 17:11:26.763406  2446 solver.cpp:228] Iteration 4620, loss = 0.0765834
I0817 17:11:26.763456  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0372789 (* 0.4 = 0.0149116 loss)
I0817 17:11:26.763473  2446 solver.cpp:244]     Train net output #1: loss2 = 0.102787 (* 0.6 = 0.0616721 loss)
I0817 17:11:26.763485  2446 sgd_solver.cpp:106] Iteration 4620, lr = 0.0001
I0817 17:11:29.759790  2446 solver.cpp:228] Iteration 4640, loss = 0.10198
I0817 17:11:29.759840  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0360611 (* 0.4 = 0.0144245 loss)
I0817 17:11:29.759855  2446 solver.cpp:244]     Train net output #1: loss2 = 0.145926 (* 0.6 = 0.0875555 loss)
I0817 17:11:29.759868  2446 sgd_solver.cpp:106] Iteration 4640, lr = 0.0001
I0817 17:11:32.753335  2446 solver.cpp:228] Iteration 4660, loss = 0.0947667
I0817 17:11:32.753391  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0216711 (* 0.4 = 0.00866844 loss)
I0817 17:11:32.753407  2446 solver.cpp:244]     Train net output #1: loss2 = 0.143497 (* 0.6 = 0.0860985 loss)
I0817 17:11:32.753420  2446 sgd_solver.cpp:106] Iteration 4660, lr = 0.0001
I0817 17:11:35.752558  2446 solver.cpp:228] Iteration 4680, loss = 0.0711878
I0817 17:11:35.752615  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0399098 (* 0.4 = 0.0159639 loss)
I0817 17:11:35.752631  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0920402 (* 0.6 = 0.0552241 loss)
I0817 17:11:35.752645  2446 sgd_solver.cpp:106] Iteration 4680, lr = 0.0001
I0817 17:11:38.748891  2446 solver.cpp:228] Iteration 4700, loss = 0.106077
I0817 17:11:38.748947  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0438617 (* 0.4 = 0.0175447 loss)
I0817 17:11:38.748963  2446 solver.cpp:244]     Train net output #1: loss2 = 0.147554 (* 0.6 = 0.0885323 loss)
I0817 17:11:38.748976  2446 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0817 17:11:41.772366  2446 solver.cpp:228] Iteration 4720, loss = 0.0687096
I0817 17:11:41.772423  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0659594 (* 0.4 = 0.0263837 loss)
I0817 17:11:41.772439  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0705434 (* 0.6 = 0.042326 loss)
I0817 17:11:41.772451  2446 sgd_solver.cpp:106] Iteration 4720, lr = 0.0001
I0817 17:11:44.774363  2446 solver.cpp:228] Iteration 4740, loss = 0.067314
I0817 17:11:44.774418  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0742492 (* 0.4 = 0.0296997 loss)
I0817 17:11:44.774435  2446 solver.cpp:244]     Train net output #1: loss2 = 0.062691 (* 0.6 = 0.0376146 loss)
I0817 17:11:44.774447  2446 sgd_solver.cpp:106] Iteration 4740, lr = 0.0001
I0817 17:11:47.767899  2446 solver.cpp:228] Iteration 4760, loss = 0.139665
I0817 17:11:47.767952  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0633766 (* 0.4 = 0.0253506 loss)
I0817 17:11:47.767968  2446 solver.cpp:244]     Train net output #1: loss2 = 0.190524 (* 0.6 = 0.114314 loss)
I0817 17:11:47.767982  2446 sgd_solver.cpp:106] Iteration 4760, lr = 0.0001
I0817 17:11:50.765053  2446 solver.cpp:228] Iteration 4780, loss = 0.0809975
I0817 17:11:50.765110  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0604404 (* 0.4 = 0.0241762 loss)
I0817 17:11:50.765126  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0947026 (* 0.6 = 0.0568216 loss)
I0817 17:11:50.765139  2446 sgd_solver.cpp:106] Iteration 4780, lr = 0.0001
I0817 17:11:53.762531  2446 solver.cpp:228] Iteration 4800, loss = 0.109355
I0817 17:11:53.762586  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0769664 (* 0.4 = 0.0307866 loss)
I0817 17:11:53.762603  2446 solver.cpp:244]     Train net output #1: loss2 = 0.130948 (* 0.6 = 0.0785685 loss)
I0817 17:11:53.762615  2446 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0817 17:11:56.767760  2446 solver.cpp:228] Iteration 4820, loss = 0.10875
I0817 17:11:56.767910  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0638547 (* 0.4 = 0.0255419 loss)
I0817 17:11:56.767926  2446 solver.cpp:244]     Train net output #1: loss2 = 0.13868 (* 0.6 = 0.0832079 loss)
I0817 17:11:56.767940  2446 sgd_solver.cpp:106] Iteration 4820, lr = 0.0001
I0817 17:11:59.764755  2446 solver.cpp:228] Iteration 4840, loss = 0.0803779
I0817 17:11:59.764802  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0284184 (* 0.4 = 0.0113674 loss)
I0817 17:11:59.764813  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115018 (* 0.6 = 0.0690108 loss)
I0817 17:11:59.764822  2446 sgd_solver.cpp:106] Iteration 4840, lr = 0.0001
I0817 17:12:02.757361  2446 solver.cpp:228] Iteration 4860, loss = 0.1329
I0817 17:12:02.757416  2446 solver.cpp:244]     Train net output #0: loss1 = 0.180076 (* 0.4 = 0.0720304 loss)
I0817 17:12:02.757431  2446 solver.cpp:244]     Train net output #1: loss2 = 0.101449 (* 0.6 = 0.0608695 loss)
I0817 17:12:02.757443  2446 sgd_solver.cpp:106] Iteration 4860, lr = 0.0001
I0817 17:12:05.756381  2446 solver.cpp:228] Iteration 4880, loss = 0.129875
I0817 17:12:05.756438  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0390288 (* 0.4 = 0.0156115 loss)
I0817 17:12:05.756453  2446 solver.cpp:244]     Train net output #1: loss2 = 0.190439 (* 0.6 = 0.114263 loss)
I0817 17:12:05.756466  2446 sgd_solver.cpp:106] Iteration 4880, lr = 0.0001
I0817 17:12:08.753931  2446 solver.cpp:228] Iteration 4900, loss = 0.11345
I0817 17:12:08.753988  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0551179 (* 0.4 = 0.0220472 loss)
I0817 17:12:08.754004  2446 solver.cpp:244]     Train net output #1: loss2 = 0.152338 (* 0.6 = 0.0914027 loss)
I0817 17:12:08.754016  2446 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0817 17:12:11.750870  2446 solver.cpp:228] Iteration 4920, loss = 0.12109
I0817 17:12:11.750929  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0949395 (* 0.4 = 0.0379758 loss)
I0817 17:12:11.750946  2446 solver.cpp:244]     Train net output #1: loss2 = 0.138523 (* 0.6 = 0.0831141 loss)
I0817 17:12:11.750958  2446 sgd_solver.cpp:106] Iteration 4920, lr = 0.0001
I0817 17:12:14.746598  2446 solver.cpp:228] Iteration 4940, loss = 0.126596
I0817 17:12:14.746651  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0429799 (* 0.4 = 0.017192 loss)
I0817 17:12:14.746666  2446 solver.cpp:244]     Train net output #1: loss2 = 0.182341 (* 0.6 = 0.109404 loss)
I0817 17:12:14.746680  2446 sgd_solver.cpp:106] Iteration 4940, lr = 0.0001
I0817 17:12:17.740325  2446 solver.cpp:228] Iteration 4960, loss = 0.131676
I0817 17:12:17.740377  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0902239 (* 0.4 = 0.0360896 loss)
I0817 17:12:17.740393  2446 solver.cpp:244]     Train net output #1: loss2 = 0.159311 (* 0.6 = 0.0955864 loss)
I0817 17:12:17.740406  2446 sgd_solver.cpp:106] Iteration 4960, lr = 0.0001
I0817 17:12:20.738157  2446 solver.cpp:228] Iteration 4980, loss = 0.0566282
I0817 17:12:20.738212  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0527261 (* 0.4 = 0.0210904 loss)
I0817 17:12:20.738229  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0592299 (* 0.6 = 0.035538 loss)
I0817 17:12:20.738241  2446 sgd_solver.cpp:106] Iteration 4980, lr = 0.0001
I0817 17:12:23.583848  2446 solver.cpp:337] Iteration 5000, Testing net (#0)
I0817 17:12:59.553408  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.838687
I0817 17:12:59.553586  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.945594
I0817 17:12:59.553611  2446 solver.cpp:404]     Test net output #2: loss1 = 0.167595 (* 0.4 = 0.0670378 loss)
I0817 17:12:59.553624  2446 solver.cpp:404]     Test net output #3: loss2 = 0.423425 (* 0.6 = 0.254055 loss)
I0817 17:12:59.599231  2446 solver.cpp:228] Iteration 5000, loss = 0.0856485
I0817 17:12:59.599277  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0704062 (* 0.4 = 0.0281625 loss)
I0817 17:12:59.599292  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0958105 (* 0.6 = 0.0574863 loss)
I0817 17:12:59.599305  2446 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0817 17:13:02.600823  2446 solver.cpp:228] Iteration 5020, loss = 0.0648955
I0817 17:13:02.600881  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0246859 (* 0.4 = 0.00987436 loss)
I0817 17:13:02.600898  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0917023 (* 0.6 = 0.0550214 loss)
I0817 17:13:02.600911  2446 sgd_solver.cpp:106] Iteration 5020, lr = 0.0001
I0817 17:13:05.603611  2446 solver.cpp:228] Iteration 5040, loss = 0.143252
I0817 17:13:05.603668  2446 solver.cpp:244]     Train net output #0: loss1 = 0.026704 (* 0.4 = 0.0106816 loss)
I0817 17:13:05.603684  2446 solver.cpp:244]     Train net output #1: loss2 = 0.220951 (* 0.6 = 0.132571 loss)
I0817 17:13:05.603698  2446 sgd_solver.cpp:106] Iteration 5040, lr = 0.0001
I0817 17:13:08.610499  2446 solver.cpp:228] Iteration 5060, loss = 0.0478119
I0817 17:13:08.610553  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0199744 (* 0.4 = 0.00798975 loss)
I0817 17:13:08.610569  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0663707 (* 0.6 = 0.0398224 loss)
I0817 17:13:08.610582  2446 sgd_solver.cpp:106] Iteration 5060, lr = 0.0001
I0817 17:13:11.617362  2446 solver.cpp:228] Iteration 5080, loss = 0.151247
I0817 17:13:11.617419  2446 solver.cpp:244]     Train net output #0: loss1 = 0.118793 (* 0.4 = 0.0475173 loss)
I0817 17:13:11.617434  2446 solver.cpp:244]     Train net output #1: loss2 = 0.172883 (* 0.6 = 0.10373 loss)
I0817 17:13:11.617447  2446 sgd_solver.cpp:106] Iteration 5080, lr = 0.0001
I0817 17:13:14.622032  2446 solver.cpp:228] Iteration 5100, loss = 0.0802183
I0817 17:13:14.622083  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0277809 (* 0.4 = 0.0111124 loss)
I0817 17:13:14.622099  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115177 (* 0.6 = 0.0691062 loss)
I0817 17:13:14.622112  2446 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0817 17:13:17.652536  2446 solver.cpp:228] Iteration 5120, loss = 0.0430853
I0817 17:13:17.652592  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0193633 (* 0.4 = 0.00774534 loss)
I0817 17:13:17.652608  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0589004 (* 0.6 = 0.0353402 loss)
I0817 17:13:17.652621  2446 sgd_solver.cpp:106] Iteration 5120, lr = 0.0001
I0817 17:13:20.663002  2446 solver.cpp:228] Iteration 5140, loss = 0.0900325
I0817 17:13:20.663059  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0465386 (* 0.4 = 0.0186155 loss)
I0817 17:13:20.663075  2446 solver.cpp:244]     Train net output #1: loss2 = 0.119029 (* 0.6 = 0.0714173 loss)
I0817 17:13:20.663089  2446 sgd_solver.cpp:106] Iteration 5140, lr = 0.0001
I0817 17:13:23.683473  2446 solver.cpp:228] Iteration 5160, loss = 0.0971053
I0817 17:13:23.683527  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0596701 (* 0.4 = 0.0238681 loss)
I0817 17:13:23.683543  2446 solver.cpp:244]     Train net output #1: loss2 = 0.122062 (* 0.6 = 0.0732375 loss)
I0817 17:13:23.683557  2446 sgd_solver.cpp:106] Iteration 5160, lr = 0.0001
I0817 17:13:26.687152  2446 solver.cpp:228] Iteration 5180, loss = 0.121367
I0817 17:13:26.687201  2446 solver.cpp:244]     Train net output #0: loss1 = 0.129817 (* 0.4 = 0.0519268 loss)
I0817 17:13:26.687216  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115735 (* 0.6 = 0.0694409 loss)
I0817 17:13:26.687228  2446 sgd_solver.cpp:106] Iteration 5180, lr = 0.0001
I0817 17:13:29.722517  2446 solver.cpp:228] Iteration 5200, loss = 0.0860034
I0817 17:13:29.722692  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0481617 (* 0.4 = 0.0192647 loss)
I0817 17:13:29.722712  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111232 (* 0.6 = 0.066739 loss)
I0817 17:13:29.722724  2446 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0817 17:13:32.725491  2446 solver.cpp:228] Iteration 5220, loss = 0.0796444
I0817 17:13:32.725545  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0443291 (* 0.4 = 0.0177317 loss)
I0817 17:13:32.725561  2446 solver.cpp:244]     Train net output #1: loss2 = 0.103188 (* 0.6 = 0.061913 loss)
I0817 17:13:32.725574  2446 sgd_solver.cpp:106] Iteration 5220, lr = 0.0001
I0817 17:13:35.738790  2446 solver.cpp:228] Iteration 5240, loss = 0.0938232
I0817 17:13:35.738898  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0617617 (* 0.4 = 0.0247047 loss)
I0817 17:13:35.738914  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115198 (* 0.6 = 0.0691188 loss)
I0817 17:13:35.738926  2446 sgd_solver.cpp:106] Iteration 5240, lr = 0.0001
I0817 17:13:38.783064  2446 solver.cpp:228] Iteration 5260, loss = 0.0904511
I0817 17:13:38.783123  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0297128 (* 0.4 = 0.0118851 loss)
I0817 17:13:38.783138  2446 solver.cpp:244]     Train net output #1: loss2 = 0.130944 (* 0.6 = 0.0785663 loss)
I0817 17:13:38.783151  2446 sgd_solver.cpp:106] Iteration 5260, lr = 0.0001
I0817 17:13:41.814576  2446 solver.cpp:228] Iteration 5280, loss = 0.107848
I0817 17:13:41.814630  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0291496 (* 0.4 = 0.0116599 loss)
I0817 17:13:41.814646  2446 solver.cpp:244]     Train net output #1: loss2 = 0.160314 (* 0.6 = 0.0961883 loss)
I0817 17:13:41.814659  2446 sgd_solver.cpp:106] Iteration 5280, lr = 0.0001
I0817 17:13:44.829360  2446 solver.cpp:228] Iteration 5300, loss = 0.145579
I0817 17:13:44.829412  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0761639 (* 0.4 = 0.0304655 loss)
I0817 17:13:44.829428  2446 solver.cpp:244]     Train net output #1: loss2 = 0.191856 (* 0.6 = 0.115114 loss)
I0817 17:13:44.829442  2446 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0817 17:13:47.825449  2446 solver.cpp:228] Iteration 5320, loss = 0.0914991
I0817 17:13:47.825502  2446 solver.cpp:244]     Train net output #0: loss1 = 0.104132 (* 0.4 = 0.0416527 loss)
I0817 17:13:47.825518  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0830778 (* 0.6 = 0.0498467 loss)
I0817 17:13:47.825531  2446 sgd_solver.cpp:106] Iteration 5320, lr = 0.0001
I0817 17:13:50.837543  2446 solver.cpp:228] Iteration 5340, loss = 0.117449
I0817 17:13:50.837594  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0330553 (* 0.4 = 0.0132221 loss)
I0817 17:13:50.837610  2446 solver.cpp:244]     Train net output #1: loss2 = 0.173711 (* 0.6 = 0.104227 loss)
I0817 17:13:50.837623  2446 sgd_solver.cpp:106] Iteration 5340, lr = 0.0001
I0817 17:13:53.867501  2446 solver.cpp:228] Iteration 5360, loss = 0.124031
I0817 17:13:53.867557  2446 solver.cpp:244]     Train net output #0: loss1 = 0.146347 (* 0.4 = 0.0585386 loss)
I0817 17:13:53.867573  2446 solver.cpp:244]     Train net output #1: loss2 = 0.109154 (* 0.6 = 0.0654923 loss)
I0817 17:13:53.867586  2446 sgd_solver.cpp:106] Iteration 5360, lr = 0.0001
I0817 17:13:56.947420  2446 solver.cpp:228] Iteration 5380, loss = 0.0681528
I0817 17:13:56.947474  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0294688 (* 0.4 = 0.0117875 loss)
I0817 17:13:56.947490  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0939425 (* 0.6 = 0.0563655 loss)
I0817 17:13:56.947504  2446 sgd_solver.cpp:106] Iteration 5380, lr = 0.0001
I0817 17:13:59.973887  2446 solver.cpp:228] Iteration 5400, loss = 0.0987787
I0817 17:13:59.974050  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0927573 (* 0.4 = 0.0371029 loss)
I0817 17:13:59.974069  2446 solver.cpp:244]     Train net output #1: loss2 = 0.102793 (* 0.6 = 0.061676 loss)
I0817 17:13:59.974081  2446 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0817 17:14:03.034847  2446 solver.cpp:228] Iteration 5420, loss = 0.0983127
I0817 17:14:03.034906  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0218252 (* 0.4 = 0.00873008 loss)
I0817 17:14:03.034924  2446 solver.cpp:244]     Train net output #1: loss2 = 0.149305 (* 0.6 = 0.0895829 loss)
I0817 17:14:03.034936  2446 sgd_solver.cpp:106] Iteration 5420, lr = 0.0001
I0817 17:14:06.080967  2446 solver.cpp:228] Iteration 5440, loss = 0.0658223
I0817 17:14:06.081024  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0159139 (* 0.4 = 0.00636556 loss)
I0817 17:14:06.081040  2446 solver.cpp:244]     Train net output #1: loss2 = 0.099095 (* 0.6 = 0.059457 loss)
I0817 17:14:06.081053  2446 sgd_solver.cpp:106] Iteration 5440, lr = 0.0001
I0817 17:14:09.170186  2446 solver.cpp:228] Iteration 5460, loss = 0.0844176
I0817 17:14:09.170243  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0508372 (* 0.4 = 0.0203349 loss)
I0817 17:14:09.170260  2446 solver.cpp:244]     Train net output #1: loss2 = 0.106805 (* 0.6 = 0.064083 loss)
I0817 17:14:09.170274  2446 sgd_solver.cpp:106] Iteration 5460, lr = 0.0001
I0817 17:14:12.210193  2446 solver.cpp:228] Iteration 5480, loss = 0.0880557
I0817 17:14:12.210247  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0405501 (* 0.4 = 0.01622 loss)
I0817 17:14:12.210263  2446 solver.cpp:244]     Train net output #1: loss2 = 0.119727 (* 0.6 = 0.0718359 loss)
I0817 17:14:12.210276  2446 sgd_solver.cpp:106] Iteration 5480, lr = 0.0001
I0817 17:14:15.227471  2446 solver.cpp:228] Iteration 5500, loss = 0.134764
I0817 17:14:15.227524  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0560072 (* 0.4 = 0.0224029 loss)
I0817 17:14:15.227540  2446 solver.cpp:244]     Train net output #1: loss2 = 0.187268 (* 0.6 = 0.112361 loss)
I0817 17:14:15.227553  2446 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0817 17:14:18.232123  2446 solver.cpp:228] Iteration 5520, loss = 0.0993691
I0817 17:14:18.232182  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0265711 (* 0.4 = 0.0106284 loss)
I0817 17:14:18.232197  2446 solver.cpp:244]     Train net output #1: loss2 = 0.147902 (* 0.6 = 0.0887409 loss)
I0817 17:14:18.232209  2446 sgd_solver.cpp:106] Iteration 5520, lr = 0.0001
I0817 17:14:21.242972  2446 solver.cpp:228] Iteration 5540, loss = 0.094135
I0817 17:14:21.243027  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0598188 (* 0.4 = 0.0239275 loss)
I0817 17:14:21.243043  2446 solver.cpp:244]     Train net output #1: loss2 = 0.117013 (* 0.6 = 0.0702078 loss)
I0817 17:14:21.243057  2446 sgd_solver.cpp:106] Iteration 5540, lr = 0.0001
I0817 17:14:24.251798  2446 solver.cpp:228] Iteration 5560, loss = 0.0941468
I0817 17:14:24.251852  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0720104 (* 0.4 = 0.0288042 loss)
I0817 17:14:24.251868  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108905 (* 0.6 = 0.0653428 loss)
I0817 17:14:24.251881  2446 sgd_solver.cpp:106] Iteration 5560, lr = 0.0001
I0817 17:14:27.283556  2446 solver.cpp:228] Iteration 5580, loss = 0.131479
I0817 17:14:27.283614  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0294294 (* 0.4 = 0.0117718 loss)
I0817 17:14:27.283630  2446 solver.cpp:244]     Train net output #1: loss2 = 0.199512 (* 0.6 = 0.119707 loss)
I0817 17:14:27.283643  2446 sgd_solver.cpp:106] Iteration 5580, lr = 0.0001
I0817 17:14:30.289441  2446 solver.cpp:228] Iteration 5600, loss = 0.0507778
I0817 17:14:30.289628  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0216185 (* 0.4 = 0.00864739 loss)
I0817 17:14:30.289645  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0702177 (* 0.6 = 0.0421306 loss)
I0817 17:14:30.289659  2446 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0817 17:14:33.323545  2446 solver.cpp:228] Iteration 5620, loss = 0.06705
I0817 17:14:33.323603  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0168137 (* 0.4 = 0.00672548 loss)
I0817 17:14:33.323619  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100541 (* 0.6 = 0.0603248 loss)
I0817 17:14:33.323632  2446 sgd_solver.cpp:106] Iteration 5620, lr = 0.0001
I0817 17:14:36.347475  2446 solver.cpp:228] Iteration 5640, loss = 0.0598344
I0817 17:14:36.347527  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0379163 (* 0.4 = 0.0151665 loss)
I0817 17:14:36.347542  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0744469 (* 0.6 = 0.0446682 loss)
I0817 17:14:36.347554  2446 sgd_solver.cpp:106] Iteration 5640, lr = 0.0001
I0817 17:14:39.387660  2446 solver.cpp:228] Iteration 5660, loss = 0.0960048
I0817 17:14:39.387717  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0398271 (* 0.4 = 0.0159308 loss)
I0817 17:14:39.387732  2446 solver.cpp:244]     Train net output #1: loss2 = 0.133457 (* 0.6 = 0.0800742 loss)
I0817 17:14:39.387745  2446 sgd_solver.cpp:106] Iteration 5660, lr = 0.0001
I0817 17:14:42.441061  2446 solver.cpp:228] Iteration 5680, loss = 0.0683793
I0817 17:14:42.441115  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0378278 (* 0.4 = 0.0151311 loss)
I0817 17:14:42.441131  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0887474 (* 0.6 = 0.0532484 loss)
I0817 17:14:42.441144  2446 sgd_solver.cpp:106] Iteration 5680, lr = 0.0001
I0817 17:14:45.438918  2446 solver.cpp:228] Iteration 5700, loss = 0.0949808
I0817 17:14:45.438976  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0876673 (* 0.4 = 0.0350669 loss)
I0817 17:14:45.438992  2446 solver.cpp:244]     Train net output #1: loss2 = 0.099857 (* 0.6 = 0.0599142 loss)
I0817 17:14:45.439004  2446 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0817 17:14:48.455003  2446 solver.cpp:228] Iteration 5720, loss = 0.0788893
I0817 17:14:48.455057  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0218846 (* 0.4 = 0.00875385 loss)
I0817 17:14:48.455073  2446 solver.cpp:244]     Train net output #1: loss2 = 0.116893 (* 0.6 = 0.0701357 loss)
I0817 17:14:48.455086  2446 sgd_solver.cpp:106] Iteration 5720, lr = 0.0001
I0817 17:14:51.472029  2446 solver.cpp:228] Iteration 5740, loss = 0.151957
I0817 17:14:51.472085  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0710194 (* 0.4 = 0.0284077 loss)
I0817 17:14:51.472101  2446 solver.cpp:244]     Train net output #1: loss2 = 0.205916 (* 0.6 = 0.123549 loss)
I0817 17:14:51.472115  2446 sgd_solver.cpp:106] Iteration 5740, lr = 0.0001
I0817 17:14:54.496282  2446 solver.cpp:228] Iteration 5760, loss = 0.128252
I0817 17:14:54.496340  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0349269 (* 0.4 = 0.0139708 loss)
I0817 17:14:54.496356  2446 solver.cpp:244]     Train net output #1: loss2 = 0.190469 (* 0.6 = 0.114281 loss)
I0817 17:14:54.496368  2446 sgd_solver.cpp:106] Iteration 5760, lr = 0.0001
I0817 17:14:57.508321  2446 solver.cpp:228] Iteration 5780, loss = 0.0588605
I0817 17:14:57.508373  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0339238 (* 0.4 = 0.0135695 loss)
I0817 17:14:57.508389  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0754853 (* 0.6 = 0.0452912 loss)
I0817 17:14:57.508402  2446 sgd_solver.cpp:106] Iteration 5780, lr = 0.0001
I0817 17:15:00.514104  2446 solver.cpp:228] Iteration 5800, loss = 0.111224
I0817 17:15:00.514231  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0354588 (* 0.4 = 0.0141835 loss)
I0817 17:15:00.514248  2446 solver.cpp:244]     Train net output #1: loss2 = 0.161735 (* 0.6 = 0.0970408 loss)
I0817 17:15:00.514262  2446 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0817 17:15:03.516784  2446 solver.cpp:228] Iteration 5820, loss = 0.0916518
I0817 17:15:03.516841  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0406258 (* 0.4 = 0.0162503 loss)
I0817 17:15:03.516858  2446 solver.cpp:244]     Train net output #1: loss2 = 0.125669 (* 0.6 = 0.0754017 loss)
I0817 17:15:03.516871  2446 sgd_solver.cpp:106] Iteration 5820, lr = 0.0001
I0817 17:15:06.514505  2446 solver.cpp:228] Iteration 5840, loss = 0.0635146
I0817 17:15:06.514554  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0275447 (* 0.4 = 0.0110179 loss)
I0817 17:15:06.514569  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0874949 (* 0.6 = 0.0524969 loss)
I0817 17:15:06.514582  2446 sgd_solver.cpp:106] Iteration 5840, lr = 0.0001
I0817 17:15:09.512207  2446 solver.cpp:228] Iteration 5860, loss = 0.0530066
I0817 17:15:09.512259  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0610422 (* 0.4 = 0.0244169 loss)
I0817 17:15:09.512275  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0476499 (* 0.6 = 0.0285899 loss)
I0817 17:15:09.512287  2446 sgd_solver.cpp:106] Iteration 5860, lr = 0.0001
I0817 17:15:12.506793  2446 solver.cpp:228] Iteration 5880, loss = 0.0773749
I0817 17:15:12.506844  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0544359 (* 0.4 = 0.0217744 loss)
I0817 17:15:12.506860  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0926679 (* 0.6 = 0.0556007 loss)
I0817 17:15:12.506872  2446 sgd_solver.cpp:106] Iteration 5880, lr = 0.0001
I0817 17:15:15.504568  2446 solver.cpp:228] Iteration 5900, loss = 0.131608
I0817 17:15:15.504621  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0722405 (* 0.4 = 0.0288962 loss)
I0817 17:15:15.504637  2446 solver.cpp:244]     Train net output #1: loss2 = 0.171186 (* 0.6 = 0.102712 loss)
I0817 17:15:15.504649  2446 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0817 17:15:18.501379  2446 solver.cpp:228] Iteration 5920, loss = 0.0903092
I0817 17:15:18.501430  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0581569 (* 0.4 = 0.0232628 loss)
I0817 17:15:18.501444  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111744 (* 0.6 = 0.0670466 loss)
I0817 17:15:18.501457  2446 sgd_solver.cpp:106] Iteration 5920, lr = 0.0001
I0817 17:15:21.500560  2446 solver.cpp:228] Iteration 5940, loss = 0.0790107
I0817 17:15:21.500610  2446 solver.cpp:244]     Train net output #0: loss1 = 0.070363 (* 0.4 = 0.0281452 loss)
I0817 17:15:21.500627  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0847761 (* 0.6 = 0.0508657 loss)
I0817 17:15:21.500639  2446 sgd_solver.cpp:106] Iteration 5940, lr = 0.0001
I0817 17:15:24.496420  2446 solver.cpp:228] Iteration 5960, loss = 0.0898697
I0817 17:15:24.496479  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0323501 (* 0.4 = 0.01294 loss)
I0817 17:15:24.496493  2446 solver.cpp:244]     Train net output #1: loss2 = 0.128217 (* 0.6 = 0.0769299 loss)
I0817 17:15:24.496506  2446 sgd_solver.cpp:106] Iteration 5960, lr = 0.0001
I0817 17:15:27.490269  2446 solver.cpp:228] Iteration 5980, loss = 0.0842144
I0817 17:15:27.490326  2446 solver.cpp:244]     Train net output #0: loss1 = 0.079751 (* 0.4 = 0.0319004 loss)
I0817 17:15:27.490342  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0871905 (* 0.6 = 0.0523143 loss)
I0817 17:15:27.490356  2446 sgd_solver.cpp:106] Iteration 5980, lr = 0.0001
I0817 17:15:30.352177  2446 solver.cpp:337] Iteration 6000, Testing net (#0)
I0817 17:16:06.190315  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.839688
I0817 17:16:06.190439  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.943594
I0817 17:16:06.190461  2446 solver.cpp:404]     Test net output #2: loss1 = 0.16761 (* 0.4 = 0.0670439 loss)
I0817 17:16:06.190475  2446 solver.cpp:404]     Test net output #3: loss2 = 0.424614 (* 0.6 = 0.254769 loss)
I0817 17:16:06.236630  2446 solver.cpp:228] Iteration 6000, loss = 0.0669697
I0817 17:16:06.236682  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0516967 (* 0.4 = 0.0206787 loss)
I0817 17:16:06.236697  2446 solver.cpp:244]     Train net output #1: loss2 = 0.077152 (* 0.6 = 0.0462912 loss)
I0817 17:16:06.236712  2446 sgd_solver.cpp:106] Iteration 6000, lr = 1e-05
I0817 17:16:09.245453  2446 solver.cpp:228] Iteration 6020, loss = 0.0972256
I0817 17:16:09.245508  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0679984 (* 0.4 = 0.0271994 loss)
I0817 17:16:09.245524  2446 solver.cpp:244]     Train net output #1: loss2 = 0.116711 (* 0.6 = 0.0700265 loss)
I0817 17:16:09.245538  2446 sgd_solver.cpp:106] Iteration 6020, lr = 1e-05
I0817 17:16:12.254756  2446 solver.cpp:228] Iteration 6040, loss = 0.0662304
I0817 17:16:12.254813  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0317443 (* 0.4 = 0.0126977 loss)
I0817 17:16:12.254828  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0892215 (* 0.6 = 0.0535329 loss)
I0817 17:16:12.254842  2446 sgd_solver.cpp:106] Iteration 6040, lr = 1e-05
I0817 17:16:15.259850  2446 solver.cpp:228] Iteration 6060, loss = 0.080264
I0817 17:16:15.259905  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0755052 (* 0.4 = 0.0302021 loss)
I0817 17:16:15.259922  2446 solver.cpp:244]     Train net output #1: loss2 = 0.083437 (* 0.6 = 0.0500622 loss)
I0817 17:16:15.259934  2446 sgd_solver.cpp:106] Iteration 6060, lr = 1e-05
I0817 17:16:18.280926  2446 solver.cpp:228] Iteration 6080, loss = 0.047201
I0817 17:16:18.280982  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0535422 (* 0.4 = 0.0214169 loss)
I0817 17:16:18.280998  2446 solver.cpp:244]     Train net output #1: loss2 = 0.042974 (* 0.6 = 0.0257844 loss)
I0817 17:16:18.281013  2446 sgd_solver.cpp:106] Iteration 6080, lr = 1e-05
I0817 17:16:21.277518  2446 solver.cpp:228] Iteration 6100, loss = 0.0790791
I0817 17:16:21.277575  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0554309 (* 0.4 = 0.0221724 loss)
I0817 17:16:21.277590  2446 solver.cpp:244]     Train net output #1: loss2 = 0.094845 (* 0.6 = 0.056907 loss)
I0817 17:16:21.277604  2446 sgd_solver.cpp:106] Iteration 6100, lr = 1e-05
I0817 17:16:24.291865  2446 solver.cpp:228] Iteration 6120, loss = 0.109967
I0817 17:16:24.291921  2446 solver.cpp:244]     Train net output #0: loss1 = 0.123457 (* 0.4 = 0.0493829 loss)
I0817 17:16:24.291937  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100973 (* 0.6 = 0.0605839 loss)
I0817 17:16:24.291951  2446 sgd_solver.cpp:106] Iteration 6120, lr = 1e-05
I0817 17:16:27.286805  2446 solver.cpp:228] Iteration 6140, loss = 0.0953818
I0817 17:16:27.286867  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0646805 (* 0.4 = 0.0258722 loss)
I0817 17:16:27.286883  2446 solver.cpp:244]     Train net output #1: loss2 = 0.11585 (* 0.6 = 0.0695098 loss)
I0817 17:16:27.286906  2446 sgd_solver.cpp:106] Iteration 6140, lr = 1e-05
I0817 17:16:30.308629  2446 solver.cpp:228] Iteration 6160, loss = 0.138983
I0817 17:16:30.308682  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0965456 (* 0.4 = 0.0386182 loss)
I0817 17:16:30.308698  2446 solver.cpp:244]     Train net output #1: loss2 = 0.167275 (* 0.6 = 0.100365 loss)
I0817 17:16:30.308712  2446 sgd_solver.cpp:106] Iteration 6160, lr = 1e-05
I0817 17:16:33.343572  2446 solver.cpp:228] Iteration 6180, loss = 0.0587451
I0817 17:16:33.343631  2446 solver.cpp:244]     Train net output #0: loss1 = 0.036764 (* 0.4 = 0.0147056 loss)
I0817 17:16:33.343648  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0733996 (* 0.6 = 0.0440397 loss)
I0817 17:16:33.343662  2446 sgd_solver.cpp:106] Iteration 6180, lr = 1e-05
I0817 17:16:36.359588  2446 solver.cpp:228] Iteration 6200, loss = 0.0996658
I0817 17:16:36.359751  2446 solver.cpp:244]     Train net output #0: loss1 = 0.105125 (* 0.4 = 0.0420499 loss)
I0817 17:16:36.359768  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0960269 (* 0.6 = 0.0576162 loss)
I0817 17:16:36.359783  2446 sgd_solver.cpp:106] Iteration 6200, lr = 1e-05
I0817 17:16:39.376960  2446 solver.cpp:228] Iteration 6220, loss = 0.104724
I0817 17:16:39.377017  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0492156 (* 0.4 = 0.0196862 loss)
I0817 17:16:39.377033  2446 solver.cpp:244]     Train net output #1: loss2 = 0.14173 (* 0.6 = 0.0850379 loss)
I0817 17:16:39.377046  2446 sgd_solver.cpp:106] Iteration 6220, lr = 1e-05
I0817 17:16:42.410480  2446 solver.cpp:228] Iteration 6240, loss = 0.123352
I0817 17:16:42.410538  2446 solver.cpp:244]     Train net output #0: loss1 = 0.139322 (* 0.4 = 0.0557289 loss)
I0817 17:16:42.410554  2446 solver.cpp:244]     Train net output #1: loss2 = 0.112706 (* 0.6 = 0.0676236 loss)
I0817 17:16:42.410568  2446 sgd_solver.cpp:106] Iteration 6240, lr = 1e-05
I0817 17:16:45.433542  2446 solver.cpp:228] Iteration 6260, loss = 0.0695454
I0817 17:16:45.433600  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0601487 (* 0.4 = 0.0240595 loss)
I0817 17:16:45.433615  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0758102 (* 0.6 = 0.0454861 loss)
I0817 17:16:45.433629  2446 sgd_solver.cpp:106] Iteration 6260, lr = 1e-05
I0817 17:16:48.428463  2446 solver.cpp:228] Iteration 6280, loss = 0.0441512
I0817 17:16:48.428517  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0204626 (* 0.4 = 0.00818504 loss)
I0817 17:16:48.428534  2446 solver.cpp:244]     Train net output #1: loss2 = 0.059944 (* 0.6 = 0.0359664 loss)
I0817 17:16:48.428546  2446 sgd_solver.cpp:106] Iteration 6280, lr = 1e-05
I0817 17:16:51.426411  2446 solver.cpp:228] Iteration 6300, loss = 0.0735774
I0817 17:16:51.426466  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0170279 (* 0.4 = 0.00681115 loss)
I0817 17:16:51.426482  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111277 (* 0.6 = 0.0667665 loss)
I0817 17:16:51.426496  2446 sgd_solver.cpp:106] Iteration 6300, lr = 1e-05
I0817 17:16:54.422412  2446 solver.cpp:228] Iteration 6320, loss = 0.0793798
I0817 17:16:54.422466  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0498704 (* 0.4 = 0.0199482 loss)
I0817 17:16:54.422482  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0990531 (* 0.6 = 0.0594319 loss)
I0817 17:16:54.422495  2446 sgd_solver.cpp:106] Iteration 6320, lr = 1e-05
I0817 17:16:57.421638  2446 solver.cpp:228] Iteration 6340, loss = 0.0775561
I0817 17:16:57.421691  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0126473 (* 0.4 = 0.00505894 loss)
I0817 17:16:57.421707  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120829 (* 0.6 = 0.0724974 loss)
I0817 17:16:57.421721  2446 sgd_solver.cpp:106] Iteration 6340, lr = 1e-05
I0817 17:17:00.420241  2446 solver.cpp:228] Iteration 6360, loss = 0.102779
I0817 17:17:00.420295  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0433606 (* 0.4 = 0.0173442 loss)
I0817 17:17:00.420311  2446 solver.cpp:244]     Train net output #1: loss2 = 0.142391 (* 0.6 = 0.0854349 loss)
I0817 17:17:00.420325  2446 sgd_solver.cpp:106] Iteration 6360, lr = 1e-05
I0817 17:17:03.420625  2446 solver.cpp:228] Iteration 6380, loss = 0.110735
I0817 17:17:03.420680  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0600622 (* 0.4 = 0.0240249 loss)
I0817 17:17:03.420697  2446 solver.cpp:244]     Train net output #1: loss2 = 0.144517 (* 0.6 = 0.0867103 loss)
I0817 17:17:03.420711  2446 sgd_solver.cpp:106] Iteration 6380, lr = 1e-05
I0817 17:17:06.419857  2446 solver.cpp:228] Iteration 6400, loss = 0.0709539
I0817 17:17:06.419981  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0238499 (* 0.4 = 0.00953995 loss)
I0817 17:17:06.419998  2446 solver.cpp:244]     Train net output #1: loss2 = 0.102357 (* 0.6 = 0.0614142 loss)
I0817 17:17:06.420012  2446 sgd_solver.cpp:106] Iteration 6400, lr = 1e-05
I0817 17:17:09.418864  2446 solver.cpp:228] Iteration 6420, loss = 0.103136
I0817 17:17:09.418921  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0711642 (* 0.4 = 0.0284657 loss)
I0817 17:17:09.418937  2446 solver.cpp:244]     Train net output #1: loss2 = 0.124451 (* 0.6 = 0.0746706 loss)
I0817 17:17:09.418951  2446 sgd_solver.cpp:106] Iteration 6420, lr = 1e-05
I0817 17:17:12.422404  2446 solver.cpp:228] Iteration 6440, loss = 0.0794018
I0817 17:17:12.422458  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0257639 (* 0.4 = 0.0103056 loss)
I0817 17:17:12.422474  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115161 (* 0.6 = 0.0690964 loss)
I0817 17:17:12.422487  2446 sgd_solver.cpp:106] Iteration 6440, lr = 1e-05
I0817 17:17:15.421677  2446 solver.cpp:228] Iteration 6460, loss = 0.116485
I0817 17:17:15.421730  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0770057 (* 0.4 = 0.0308023 loss)
I0817 17:17:15.421746  2446 solver.cpp:244]     Train net output #1: loss2 = 0.142804 (* 0.6 = 0.0856825 loss)
I0817 17:17:15.421758  2446 sgd_solver.cpp:106] Iteration 6460, lr = 1e-05
I0817 17:17:18.419014  2446 solver.cpp:228] Iteration 6480, loss = 0.100505
I0817 17:17:18.419064  2446 solver.cpp:244]     Train net output #0: loss1 = 0.052841 (* 0.4 = 0.0211364 loss)
I0817 17:17:18.419080  2446 solver.cpp:244]     Train net output #1: loss2 = 0.132282 (* 0.6 = 0.0793692 loss)
I0817 17:17:18.419095  2446 sgd_solver.cpp:106] Iteration 6480, lr = 1e-05
I0817 17:17:21.420795  2446 solver.cpp:228] Iteration 6500, loss = 0.0673604
I0817 17:17:21.420848  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0295362 (* 0.4 = 0.0118145 loss)
I0817 17:17:21.420864  2446 solver.cpp:244]     Train net output #1: loss2 = 0.092577 (* 0.6 = 0.0555462 loss)
I0817 17:17:21.420878  2446 sgd_solver.cpp:106] Iteration 6500, lr = 1e-05
I0817 17:17:24.415732  2446 solver.cpp:228] Iteration 6520, loss = 0.115528
I0817 17:17:24.415784  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0895316 (* 0.4 = 0.0358127 loss)
I0817 17:17:24.415801  2446 solver.cpp:244]     Train net output #1: loss2 = 0.132859 (* 0.6 = 0.0797153 loss)
I0817 17:17:24.415814  2446 sgd_solver.cpp:106] Iteration 6520, lr = 1e-05
I0817 17:17:27.412104  2446 solver.cpp:228] Iteration 6540, loss = 0.0906354
I0817 17:17:27.412166  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0711773 (* 0.4 = 0.0284709 loss)
I0817 17:17:27.412183  2446 solver.cpp:244]     Train net output #1: loss2 = 0.103608 (* 0.6 = 0.0621647 loss)
I0817 17:17:27.412196  2446 sgd_solver.cpp:106] Iteration 6540, lr = 1e-05
I0817 17:17:30.409687  2446 solver.cpp:228] Iteration 6560, loss = 0.0989296
I0817 17:17:30.409742  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0438502 (* 0.4 = 0.0175401 loss)
I0817 17:17:30.409759  2446 solver.cpp:244]     Train net output #1: loss2 = 0.13565 (* 0.6 = 0.0813898 loss)
I0817 17:17:30.409771  2446 sgd_solver.cpp:106] Iteration 6560, lr = 1e-05
I0817 17:17:33.406770  2446 solver.cpp:228] Iteration 6580, loss = 0.0781078
I0817 17:17:33.406831  2446 solver.cpp:244]     Train net output #0: loss1 = 0.018646 (* 0.4 = 0.00745839 loss)
I0817 17:17:33.406847  2446 solver.cpp:244]     Train net output #1: loss2 = 0.117749 (* 0.6 = 0.0706497 loss)
I0817 17:17:33.406860  2446 sgd_solver.cpp:106] Iteration 6580, lr = 1e-05
I0817 17:17:36.402597  2446 solver.cpp:228] Iteration 6600, loss = 0.108454
I0817 17:17:36.402652  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0924524 (* 0.4 = 0.036981 loss)
I0817 17:17:36.402668  2446 solver.cpp:244]     Train net output #1: loss2 = 0.119122 (* 0.6 = 0.0714729 loss)
I0817 17:17:36.402683  2446 sgd_solver.cpp:106] Iteration 6600, lr = 1e-05
I0817 17:17:39.399904  2446 solver.cpp:228] Iteration 6620, loss = 0.0987027
I0817 17:17:39.400048  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0652527 (* 0.4 = 0.0261011 loss)
I0817 17:17:39.400065  2446 solver.cpp:244]     Train net output #1: loss2 = 0.121003 (* 0.6 = 0.0726019 loss)
I0817 17:17:39.400079  2446 sgd_solver.cpp:106] Iteration 6620, lr = 1e-05
I0817 17:17:42.412312  2446 solver.cpp:228] Iteration 6640, loss = 0.0866052
I0817 17:17:42.412365  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0435222 (* 0.4 = 0.0174089 loss)
I0817 17:17:42.412380  2446 solver.cpp:244]     Train net output #1: loss2 = 0.115328 (* 0.6 = 0.0691966 loss)
I0817 17:17:42.412395  2446 sgd_solver.cpp:106] Iteration 6640, lr = 1e-05
I0817 17:17:45.425500  2446 solver.cpp:228] Iteration 6660, loss = 0.081895
I0817 17:17:45.425554  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0179529 (* 0.4 = 0.00718116 loss)
I0817 17:17:45.425570  2446 solver.cpp:244]     Train net output #1: loss2 = 0.124524 (* 0.6 = 0.0747141 loss)
I0817 17:17:45.425583  2446 sgd_solver.cpp:106] Iteration 6660, lr = 1e-05
I0817 17:17:48.471977  2446 solver.cpp:228] Iteration 6680, loss = 0.0955039
I0817 17:17:48.472033  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0268093 (* 0.4 = 0.0107237 loss)
I0817 17:17:48.472048  2446 solver.cpp:244]     Train net output #1: loss2 = 0.141301 (* 0.6 = 0.0847805 loss)
I0817 17:17:48.472062  2446 sgd_solver.cpp:106] Iteration 6680, lr = 1e-05
I0817 17:17:51.499614  2446 solver.cpp:228] Iteration 6700, loss = 0.103284
I0817 17:17:51.499670  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0674014 (* 0.4 = 0.0269606 loss)
I0817 17:17:51.499686  2446 solver.cpp:244]     Train net output #1: loss2 = 0.127206 (* 0.6 = 0.0763236 loss)
I0817 17:17:51.499701  2446 sgd_solver.cpp:106] Iteration 6700, lr = 1e-05
I0817 17:17:54.497179  2446 solver.cpp:228] Iteration 6720, loss = 0.0543591
I0817 17:17:54.497234  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0128688 (* 0.4 = 0.00514753 loss)
I0817 17:17:54.497251  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0820197 (* 0.6 = 0.0492118 loss)
I0817 17:17:54.497263  2446 sgd_solver.cpp:106] Iteration 6720, lr = 1e-05
I0817 17:17:57.495932  2446 solver.cpp:228] Iteration 6740, loss = 0.0762438
I0817 17:17:57.495988  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0226924 (* 0.4 = 0.00907694 loss)
I0817 17:17:57.496004  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111945 (* 0.6 = 0.0671671 loss)
I0817 17:17:57.496018  2446 sgd_solver.cpp:106] Iteration 6740, lr = 1e-05
I0817 17:18:00.489840  2446 solver.cpp:228] Iteration 6760, loss = 0.0867991
I0817 17:18:00.489894  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0592083 (* 0.4 = 0.0236833 loss)
I0817 17:18:00.489909  2446 solver.cpp:244]     Train net output #1: loss2 = 0.105193 (* 0.6 = 0.063116 loss)
I0817 17:18:00.489923  2446 sgd_solver.cpp:106] Iteration 6760, lr = 1e-05
I0817 17:18:03.486806  2446 solver.cpp:228] Iteration 6780, loss = 0.11626
I0817 17:18:03.486857  2446 solver.cpp:244]     Train net output #0: loss1 = 0.115232 (* 0.4 = 0.0460929 loss)
I0817 17:18:03.486873  2446 solver.cpp:244]     Train net output #1: loss2 = 0.116945 (* 0.6 = 0.0701671 loss)
I0817 17:18:03.486886  2446 sgd_solver.cpp:106] Iteration 6780, lr = 1e-05
I0817 17:18:06.483381  2446 solver.cpp:228] Iteration 6800, loss = 0.104166
I0817 17:18:06.483438  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0444662 (* 0.4 = 0.0177865 loss)
I0817 17:18:06.483453  2446 solver.cpp:244]     Train net output #1: loss2 = 0.143966 (* 0.6 = 0.0863797 loss)
I0817 17:18:06.483467  2446 sgd_solver.cpp:106] Iteration 6800, lr = 1e-05
I0817 17:18:09.479826  2446 solver.cpp:228] Iteration 6820, loss = 0.0887153
I0817 17:18:09.479985  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0592385 (* 0.4 = 0.0236954 loss)
I0817 17:18:09.480003  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108367 (* 0.6 = 0.0650202 loss)
I0817 17:18:09.480017  2446 sgd_solver.cpp:106] Iteration 6820, lr = 1e-05
I0817 17:18:12.477061  2446 solver.cpp:228] Iteration 6840, loss = 0.0928005
I0817 17:18:12.477115  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0671191 (* 0.4 = 0.0268476 loss)
I0817 17:18:12.477131  2446 solver.cpp:244]     Train net output #1: loss2 = 0.109922 (* 0.6 = 0.0659532 loss)
I0817 17:18:12.477145  2446 sgd_solver.cpp:106] Iteration 6840, lr = 1e-05
I0817 17:18:15.474021  2446 solver.cpp:228] Iteration 6860, loss = 0.0853944
I0817 17:18:15.474076  2446 solver.cpp:244]     Train net output #0: loss1 = 0.109348 (* 0.4 = 0.0437394 loss)
I0817 17:18:15.474092  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0694255 (* 0.6 = 0.0416553 loss)
I0817 17:18:15.474105  2446 sgd_solver.cpp:106] Iteration 6860, lr = 1e-05
I0817 17:18:18.473546  2446 solver.cpp:228] Iteration 6880, loss = 0.127536
I0817 17:18:18.473601  2446 solver.cpp:244]     Train net output #0: loss1 = 0.099602 (* 0.4 = 0.0398408 loss)
I0817 17:18:18.473618  2446 solver.cpp:244]     Train net output #1: loss2 = 0.146159 (* 0.6 = 0.0876957 loss)
I0817 17:18:18.473631  2446 sgd_solver.cpp:106] Iteration 6880, lr = 1e-05
I0817 17:18:21.471536  2446 solver.cpp:228] Iteration 6900, loss = 0.0646306
I0817 17:18:21.471590  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0624181 (* 0.4 = 0.0249672 loss)
I0817 17:18:21.471604  2446 solver.cpp:244]     Train net output #1: loss2 = 0.066106 (* 0.6 = 0.0396636 loss)
I0817 17:18:21.471618  2446 sgd_solver.cpp:106] Iteration 6900, lr = 1e-05
I0817 17:18:24.471556  2446 solver.cpp:228] Iteration 6920, loss = 0.0848607
I0817 17:18:24.471612  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0374243 (* 0.4 = 0.0149697 loss)
I0817 17:18:24.471628  2446 solver.cpp:244]     Train net output #1: loss2 = 0.116485 (* 0.6 = 0.0698913 loss)
I0817 17:18:24.471642  2446 sgd_solver.cpp:106] Iteration 6920, lr = 1e-05
I0817 17:18:27.488582  2446 solver.cpp:228] Iteration 6940, loss = 0.103089
I0817 17:18:27.488636  2446 solver.cpp:244]     Train net output #0: loss1 = 0.139278 (* 0.4 = 0.0557111 loss)
I0817 17:18:27.488652  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0789633 (* 0.6 = 0.047378 loss)
I0817 17:18:27.488667  2446 sgd_solver.cpp:106] Iteration 6940, lr = 1e-05
I0817 17:18:30.508525  2446 solver.cpp:228] Iteration 6960, loss = 0.0920868
I0817 17:18:30.508585  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0186286 (* 0.4 = 0.00745144 loss)
I0817 17:18:30.508600  2446 solver.cpp:244]     Train net output #1: loss2 = 0.141059 (* 0.6 = 0.0846356 loss)
I0817 17:18:30.508615  2446 sgd_solver.cpp:106] Iteration 6960, lr = 1e-05
I0817 17:18:33.543400  2446 solver.cpp:228] Iteration 6980, loss = 0.139594
I0817 17:18:33.543454  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0510444 (* 0.4 = 0.0204177 loss)
I0817 17:18:33.543470  2446 solver.cpp:244]     Train net output #1: loss2 = 0.198627 (* 0.6 = 0.119176 loss)
I0817 17:18:33.543484  2446 sgd_solver.cpp:106] Iteration 6980, lr = 1e-05
I0817 17:18:36.424785  2446 solver.cpp:337] Iteration 7000, Testing net (#0)
I0817 17:19:12.381510  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.839641
I0817 17:19:12.381631  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.943625
I0817 17:19:12.381651  2446 solver.cpp:404]     Test net output #2: loss1 = 0.167313 (* 0.4 = 0.0669252 loss)
I0817 17:19:12.381664  2446 solver.cpp:404]     Test net output #3: loss2 = 0.424291 (* 0.6 = 0.254574 loss)
I0817 17:19:12.428799  2446 solver.cpp:228] Iteration 7000, loss = 0.0816004
I0817 17:19:12.428841  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0234088 (* 0.4 = 0.00936354 loss)
I0817 17:19:12.428853  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120395 (* 0.6 = 0.0722371 loss)
I0817 17:19:12.428863  2446 sgd_solver.cpp:106] Iteration 7000, lr = 1e-05
I0817 17:19:15.454434  2446 solver.cpp:228] Iteration 7020, loss = 0.157073
I0817 17:19:15.454490  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0783308 (* 0.4 = 0.0313323 loss)
I0817 17:19:15.454506  2446 solver.cpp:244]     Train net output #1: loss2 = 0.209569 (* 0.6 = 0.125741 loss)
I0817 17:19:15.454520  2446 sgd_solver.cpp:106] Iteration 7020, lr = 1e-05
I0817 17:19:18.468996  2446 solver.cpp:228] Iteration 7040, loss = 0.112436
I0817 17:19:18.469049  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0660752 (* 0.4 = 0.0264301 loss)
I0817 17:19:18.469065  2446 solver.cpp:244]     Train net output #1: loss2 = 0.143344 (* 0.6 = 0.0860065 loss)
I0817 17:19:18.469079  2446 sgd_solver.cpp:106] Iteration 7040, lr = 1e-05
I0817 17:19:21.524432  2446 solver.cpp:228] Iteration 7060, loss = 0.12341
I0817 17:19:21.524483  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0912039 (* 0.4 = 0.0364815 loss)
I0817 17:19:21.524498  2446 solver.cpp:244]     Train net output #1: loss2 = 0.144881 (* 0.6 = 0.0869288 loss)
I0817 17:19:21.524513  2446 sgd_solver.cpp:106] Iteration 7060, lr = 1e-05
I0817 17:19:24.534354  2446 solver.cpp:228] Iteration 7080, loss = 0.125627
I0817 17:19:24.534412  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0993268 (* 0.4 = 0.0397307 loss)
I0817 17:19:24.534428  2446 solver.cpp:244]     Train net output #1: loss2 = 0.143161 (* 0.6 = 0.0858968 loss)
I0817 17:19:24.534442  2446 sgd_solver.cpp:106] Iteration 7080, lr = 1e-05
I0817 17:19:27.526935  2446 solver.cpp:228] Iteration 7100, loss = 0.0877204
I0817 17:19:27.526988  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0546721 (* 0.4 = 0.0218688 loss)
I0817 17:19:27.527004  2446 solver.cpp:244]     Train net output #1: loss2 = 0.109753 (* 0.6 = 0.0658519 loss)
I0817 17:19:27.527019  2446 sgd_solver.cpp:106] Iteration 7100, lr = 1e-05
I0817 17:19:30.520745  2446 solver.cpp:228] Iteration 7120, loss = 0.0569573
I0817 17:19:30.520794  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0215844 (* 0.4 = 0.00863377 loss)
I0817 17:19:30.520809  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0805396 (* 0.6 = 0.0483238 loss)
I0817 17:19:30.520823  2446 sgd_solver.cpp:106] Iteration 7120, lr = 1e-05
I0817 17:19:33.522121  2446 solver.cpp:228] Iteration 7140, loss = 0.109191
I0817 17:19:33.522174  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0600617 (* 0.4 = 0.0240247 loss)
I0817 17:19:33.522191  2446 solver.cpp:244]     Train net output #1: loss2 = 0.141945 (* 0.6 = 0.085167 loss)
I0817 17:19:33.522204  2446 sgd_solver.cpp:106] Iteration 7140, lr = 1e-05
I0817 17:19:36.528547  2446 solver.cpp:228] Iteration 7160, loss = 0.116218
I0817 17:19:36.528602  2446 solver.cpp:244]     Train net output #0: loss1 = 0.108538 (* 0.4 = 0.0434151 loss)
I0817 17:19:36.528619  2446 solver.cpp:244]     Train net output #1: loss2 = 0.121339 (* 0.6 = 0.0728032 loss)
I0817 17:19:36.528631  2446 sgd_solver.cpp:106] Iteration 7160, lr = 1e-05
I0817 17:19:39.542731  2446 solver.cpp:228] Iteration 7180, loss = 0.0721581
I0817 17:19:39.542786  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0291346 (* 0.4 = 0.0116538 loss)
I0817 17:19:39.542803  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100841 (* 0.6 = 0.0605046 loss)
I0817 17:19:39.542815  2446 sgd_solver.cpp:106] Iteration 7180, lr = 1e-05
I0817 17:19:42.556917  2446 solver.cpp:228] Iteration 7200, loss = 0.0940226
I0817 17:19:42.557088  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0515731 (* 0.4 = 0.0206292 loss)
I0817 17:19:42.557107  2446 solver.cpp:244]     Train net output #1: loss2 = 0.122323 (* 0.6 = 0.0733936 loss)
I0817 17:19:42.557121  2446 sgd_solver.cpp:106] Iteration 7200, lr = 1e-05
I0817 17:19:45.561614  2446 solver.cpp:228] Iteration 7220, loss = 0.0711773
I0817 17:19:45.561673  2446 solver.cpp:244]     Train net output #0: loss1 = 0.04592 (* 0.4 = 0.018368 loss)
I0817 17:19:45.561689  2446 solver.cpp:244]     Train net output #1: loss2 = 0.088016 (* 0.6 = 0.0528096 loss)
I0817 17:19:45.561703  2446 sgd_solver.cpp:106] Iteration 7220, lr = 1e-05
I0817 17:19:48.564752  2446 solver.cpp:228] Iteration 7240, loss = 0.0858412
I0817 17:19:48.564805  2446 solver.cpp:244]     Train net output #0: loss1 = 0.037813 (* 0.4 = 0.0151252 loss)
I0817 17:19:48.564821  2446 solver.cpp:244]     Train net output #1: loss2 = 0.11786 (* 0.6 = 0.0707162 loss)
I0817 17:19:48.564836  2446 sgd_solver.cpp:106] Iteration 7240, lr = 1e-05
I0817 17:19:51.564256  2446 solver.cpp:228] Iteration 7260, loss = 0.06644
I0817 17:19:51.564311  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0651118 (* 0.4 = 0.0260447 loss)
I0817 17:19:51.564327  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0673259 (* 0.6 = 0.0403956 loss)
I0817 17:19:51.564340  2446 sgd_solver.cpp:106] Iteration 7260, lr = 1e-05
I0817 17:19:54.559406  2446 solver.cpp:228] Iteration 7280, loss = 0.0821077
I0817 17:19:54.559460  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0680193 (* 0.4 = 0.0272077 loss)
I0817 17:19:54.559478  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0915003 (* 0.6 = 0.0549002 loss)
I0817 17:19:54.559490  2446 sgd_solver.cpp:106] Iteration 7280, lr = 1e-05
I0817 17:19:57.556057  2446 solver.cpp:228] Iteration 7300, loss = 0.0752178
I0817 17:19:57.556114  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0705716 (* 0.4 = 0.0282286 loss)
I0817 17:19:57.556130  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0783158 (* 0.6 = 0.0469895 loss)
I0817 17:19:57.556144  2446 sgd_solver.cpp:106] Iteration 7300, lr = 1e-05
I0817 17:20:00.578559  2446 solver.cpp:228] Iteration 7320, loss = 0.0995517
I0817 17:20:00.578614  2446 solver.cpp:244]     Train net output #0: loss1 = 0.042673 (* 0.4 = 0.0170692 loss)
I0817 17:20:00.578630  2446 solver.cpp:244]     Train net output #1: loss2 = 0.137471 (* 0.6 = 0.0824827 loss)
I0817 17:20:00.578644  2446 sgd_solver.cpp:106] Iteration 7320, lr = 1e-05
I0817 17:20:03.573549  2446 solver.cpp:228] Iteration 7340, loss = 0.0843592
I0817 17:20:03.573601  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0669009 (* 0.4 = 0.0267604 loss)
I0817 17:20:03.573617  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0959985 (* 0.6 = 0.0575991 loss)
I0817 17:20:03.573632  2446 sgd_solver.cpp:106] Iteration 7340, lr = 1e-05
I0817 17:20:06.575366  2446 solver.cpp:228] Iteration 7360, loss = 0.0724726
I0817 17:20:06.575418  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0355578 (* 0.4 = 0.0142231 loss)
I0817 17:20:06.575434  2446 solver.cpp:244]     Train net output #1: loss2 = 0.097083 (* 0.6 = 0.0582498 loss)
I0817 17:20:06.575448  2446 sgd_solver.cpp:106] Iteration 7360, lr = 1e-05
I0817 17:20:09.590513  2446 solver.cpp:228] Iteration 7380, loss = 0.053169
I0817 17:20:09.590565  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0175483 (* 0.4 = 0.00701934 loss)
I0817 17:20:09.590581  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0769166 (* 0.6 = 0.04615 loss)
I0817 17:20:09.590595  2446 sgd_solver.cpp:106] Iteration 7380, lr = 1e-05
I0817 17:20:12.588362  2446 solver.cpp:228] Iteration 7400, loss = 0.115327
I0817 17:20:12.588511  2446 solver.cpp:244]     Train net output #0: loss1 = 0.120373 (* 0.4 = 0.0481492 loss)
I0817 17:20:12.588528  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111963 (* 0.6 = 0.0671777 loss)
I0817 17:20:12.588542  2446 sgd_solver.cpp:106] Iteration 7400, lr = 1e-05
I0817 17:20:15.581831  2446 solver.cpp:228] Iteration 7420, loss = 0.107871
I0817 17:20:15.581884  2446 solver.cpp:244]     Train net output #0: loss1 = 0.102253 (* 0.4 = 0.040901 loss)
I0817 17:20:15.581900  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111617 (* 0.6 = 0.0669705 loss)
I0817 17:20:15.581914  2446 sgd_solver.cpp:106] Iteration 7420, lr = 1e-05
I0817 17:20:18.595136  2446 solver.cpp:228] Iteration 7440, loss = 0.0790765
I0817 17:20:18.595193  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0163356 (* 0.4 = 0.00653422 loss)
I0817 17:20:18.595209  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120904 (* 0.6 = 0.0725426 loss)
I0817 17:20:18.595223  2446 sgd_solver.cpp:106] Iteration 7440, lr = 1e-05
I0817 17:20:21.601249  2446 solver.cpp:228] Iteration 7460, loss = 0.0827902
I0817 17:20:21.601302  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0663069 (* 0.4 = 0.0265227 loss)
I0817 17:20:21.601320  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0937796 (* 0.6 = 0.0562678 loss)
I0817 17:20:21.601333  2446 sgd_solver.cpp:106] Iteration 7460, lr = 1e-05
I0817 17:20:24.604373  2446 solver.cpp:228] Iteration 7480, loss = 0.0790369
I0817 17:20:24.604429  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0282515 (* 0.4 = 0.0113006 loss)
I0817 17:20:24.604445  2446 solver.cpp:244]     Train net output #1: loss2 = 0.112894 (* 0.6 = 0.0677366 loss)
I0817 17:20:24.604460  2446 sgd_solver.cpp:106] Iteration 7480, lr = 1e-05
I0817 17:20:27.605768  2446 solver.cpp:228] Iteration 7500, loss = 0.0765086
I0817 17:20:27.605821  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0678153 (* 0.4 = 0.0271261 loss)
I0817 17:20:27.605837  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0823047 (* 0.6 = 0.0493828 loss)
I0817 17:20:27.605851  2446 sgd_solver.cpp:106] Iteration 7500, lr = 1e-05
I0817 17:20:30.603560  2446 solver.cpp:228] Iteration 7520, loss = 0.107488
I0817 17:20:30.603615  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0603096 (* 0.4 = 0.0241238 loss)
I0817 17:20:30.603631  2446 solver.cpp:244]     Train net output #1: loss2 = 0.13894 (* 0.6 = 0.0833641 loss)
I0817 17:20:30.603644  2446 sgd_solver.cpp:106] Iteration 7520, lr = 1e-05
I0817 17:20:33.601622  2446 solver.cpp:228] Iteration 7540, loss = 0.0742997
I0817 17:20:33.601676  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0779548 (* 0.4 = 0.0311819 loss)
I0817 17:20:33.601692  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0718634 (* 0.6 = 0.043118 loss)
I0817 17:20:33.601706  2446 sgd_solver.cpp:106] Iteration 7540, lr = 1e-05
I0817 17:20:36.603444  2446 solver.cpp:228] Iteration 7560, loss = 0.0775769
I0817 17:20:36.603499  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0873621 (* 0.4 = 0.0349449 loss)
I0817 17:20:36.603515  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0710538 (* 0.6 = 0.0426323 loss)
I0817 17:20:36.603528  2446 sgd_solver.cpp:106] Iteration 7560, lr = 1e-05
I0817 17:20:39.605288  2446 solver.cpp:228] Iteration 7580, loss = 0.09461
I0817 17:20:39.605340  2446 solver.cpp:244]     Train net output #0: loss1 = 0.109348 (* 0.4 = 0.0437392 loss)
I0817 17:20:39.605355  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0847852 (* 0.6 = 0.0508711 loss)
I0817 17:20:39.605370  2446 sgd_solver.cpp:106] Iteration 7580, lr = 1e-05
I0817 17:20:42.611222  2446 solver.cpp:228] Iteration 7600, loss = 0.120556
I0817 17:20:42.611382  2446 solver.cpp:244]     Train net output #0: loss1 = 0.043019 (* 0.4 = 0.0172076 loss)
I0817 17:20:42.611399  2446 solver.cpp:244]     Train net output #1: loss2 = 0.172248 (* 0.6 = 0.103349 loss)
I0817 17:20:42.611413  2446 sgd_solver.cpp:106] Iteration 7600, lr = 1e-05
I0817 17:20:45.623558  2446 solver.cpp:228] Iteration 7620, loss = 0.122139
I0817 17:20:45.623615  2446 solver.cpp:244]     Train net output #0: loss1 = 0.103587 (* 0.4 = 0.0414349 loss)
I0817 17:20:45.623631  2446 solver.cpp:244]     Train net output #1: loss2 = 0.134508 (* 0.6 = 0.0807047 loss)
I0817 17:20:45.623644  2446 sgd_solver.cpp:106] Iteration 7620, lr = 1e-05
I0817 17:20:48.650988  2446 solver.cpp:228] Iteration 7640, loss = 0.149516
I0817 17:20:48.651043  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0491268 (* 0.4 = 0.0196507 loss)
I0817 17:20:48.651059  2446 solver.cpp:244]     Train net output #1: loss2 = 0.216443 (* 0.6 = 0.129866 loss)
I0817 17:20:48.651073  2446 sgd_solver.cpp:106] Iteration 7640, lr = 1e-05
I0817 17:20:51.688722  2446 solver.cpp:228] Iteration 7660, loss = 0.0796474
I0817 17:20:51.688778  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0317454 (* 0.4 = 0.0126982 loss)
I0817 17:20:51.688793  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111582 (* 0.6 = 0.0669495 loss)
I0817 17:20:51.688807  2446 sgd_solver.cpp:106] Iteration 7660, lr = 1e-05
I0817 17:20:54.712401  2446 solver.cpp:228] Iteration 7680, loss = 0.100223
I0817 17:20:54.712457  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0247839 (* 0.4 = 0.00991355 loss)
I0817 17:20:54.712473  2446 solver.cpp:244]     Train net output #1: loss2 = 0.150516 (* 0.6 = 0.0903096 loss)
I0817 17:20:54.712487  2446 sgd_solver.cpp:106] Iteration 7680, lr = 1e-05
I0817 17:20:57.746670  2446 solver.cpp:228] Iteration 7700, loss = 0.0903388
I0817 17:20:57.746724  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0672267 (* 0.4 = 0.0268907 loss)
I0817 17:20:57.746740  2446 solver.cpp:244]     Train net output #1: loss2 = 0.105747 (* 0.6 = 0.0634483 loss)
I0817 17:20:57.746753  2446 sgd_solver.cpp:106] Iteration 7700, lr = 1e-05
I0817 17:21:00.752063  2446 solver.cpp:228] Iteration 7720, loss = 0.124748
I0817 17:21:00.752123  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0736429 (* 0.4 = 0.0294572 loss)
I0817 17:21:00.752140  2446 solver.cpp:244]     Train net output #1: loss2 = 0.158818 (* 0.6 = 0.0952907 loss)
I0817 17:21:00.752153  2446 sgd_solver.cpp:106] Iteration 7720, lr = 1e-05
I0817 17:21:03.771699  2446 solver.cpp:228] Iteration 7740, loss = 0.123562
I0817 17:21:03.771765  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0502106 (* 0.4 = 0.0200842 loss)
I0817 17:21:03.771781  2446 solver.cpp:244]     Train net output #1: loss2 = 0.172463 (* 0.6 = 0.103478 loss)
I0817 17:21:03.771797  2446 sgd_solver.cpp:106] Iteration 7740, lr = 1e-05
I0817 17:21:06.788419  2446 solver.cpp:228] Iteration 7760, loss = 0.147838
I0817 17:21:06.788480  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0658519 (* 0.4 = 0.0263408 loss)
I0817 17:21:06.788496  2446 solver.cpp:244]     Train net output #1: loss2 = 0.202496 (* 0.6 = 0.121498 loss)
I0817 17:21:06.788509  2446 sgd_solver.cpp:106] Iteration 7760, lr = 1e-05
I0817 17:21:09.792629  2446 solver.cpp:228] Iteration 7780, loss = 0.08631
I0817 17:21:09.792688  2446 solver.cpp:244]     Train net output #0: loss1 = 0.056561 (* 0.4 = 0.0226244 loss)
I0817 17:21:09.792704  2446 solver.cpp:244]     Train net output #1: loss2 = 0.106143 (* 0.6 = 0.0636859 loss)
I0817 17:21:09.792718  2446 sgd_solver.cpp:106] Iteration 7780, lr = 1e-05
I0817 17:21:12.868063  2446 solver.cpp:228] Iteration 7800, loss = 0.138273
I0817 17:21:12.868218  2446 solver.cpp:244]     Train net output #0: loss1 = 0.111505 (* 0.4 = 0.044602 loss)
I0817 17:21:12.868237  2446 solver.cpp:244]     Train net output #1: loss2 = 0.156119 (* 0.6 = 0.0936714 loss)
I0817 17:21:12.868250  2446 sgd_solver.cpp:106] Iteration 7800, lr = 1e-05
I0817 17:21:15.902946  2446 solver.cpp:228] Iteration 7820, loss = 0.115795
I0817 17:21:15.903002  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0465744 (* 0.4 = 0.0186298 loss)
I0817 17:21:15.903017  2446 solver.cpp:244]     Train net output #1: loss2 = 0.161942 (* 0.6 = 0.0971652 loss)
I0817 17:21:15.903031  2446 sgd_solver.cpp:106] Iteration 7820, lr = 1e-05
I0817 17:21:18.907116  2446 solver.cpp:228] Iteration 7840, loss = 0.0633806
I0817 17:21:18.907173  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0373891 (* 0.4 = 0.0149556 loss)
I0817 17:21:18.907189  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0807087 (* 0.6 = 0.0484252 loss)
I0817 17:21:18.907202  2446 sgd_solver.cpp:106] Iteration 7840, lr = 1e-05
I0817 17:21:21.906343  2446 solver.cpp:228] Iteration 7860, loss = 0.0873906
I0817 17:21:21.906397  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0613843 (* 0.4 = 0.0245537 loss)
I0817 17:21:21.906414  2446 solver.cpp:244]     Train net output #1: loss2 = 0.104729 (* 0.6 = 0.0628372 loss)
I0817 17:21:21.906427  2446 sgd_solver.cpp:106] Iteration 7860, lr = 1e-05
I0817 17:21:24.911262  2446 solver.cpp:228] Iteration 7880, loss = 0.0955682
I0817 17:21:24.911314  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0575549 (* 0.4 = 0.023022 loss)
I0817 17:21:24.911330  2446 solver.cpp:244]     Train net output #1: loss2 = 0.120911 (* 0.6 = 0.0725466 loss)
I0817 17:21:24.911345  2446 sgd_solver.cpp:106] Iteration 7880, lr = 1e-05
I0817 17:21:27.920871  2446 solver.cpp:228] Iteration 7900, loss = 0.0661724
I0817 17:21:27.920927  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0271047 (* 0.4 = 0.0108419 loss)
I0817 17:21:27.920941  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0922181 (* 0.6 = 0.0553308 loss)
I0817 17:21:27.920955  2446 sgd_solver.cpp:106] Iteration 7900, lr = 1e-05
I0817 17:21:30.930773  2446 solver.cpp:228] Iteration 7920, loss = 0.123549
I0817 17:21:30.930826  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0569874 (* 0.4 = 0.022795 loss)
I0817 17:21:30.930842  2446 solver.cpp:244]     Train net output #1: loss2 = 0.167924 (* 0.6 = 0.100755 loss)
I0817 17:21:30.930856  2446 sgd_solver.cpp:106] Iteration 7920, lr = 1e-05
I0817 17:21:33.928169  2446 solver.cpp:228] Iteration 7940, loss = 0.0929134
I0817 17:21:33.928225  2446 solver.cpp:244]     Train net output #0: loss1 = 0.144069 (* 0.4 = 0.0576275 loss)
I0817 17:21:33.928241  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0588103 (* 0.6 = 0.0352862 loss)
I0817 17:21:33.928254  2446 sgd_solver.cpp:106] Iteration 7940, lr = 1e-05
I0817 17:21:36.921689  2446 solver.cpp:228] Iteration 7960, loss = 0.122467
I0817 17:21:36.921746  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0643755 (* 0.4 = 0.0257502 loss)
I0817 17:21:36.921762  2446 solver.cpp:244]     Train net output #1: loss2 = 0.161195 (* 0.6 = 0.0967172 loss)
I0817 17:21:36.921777  2446 sgd_solver.cpp:106] Iteration 7960, lr = 1e-05
I0817 17:21:39.918992  2446 solver.cpp:228] Iteration 7980, loss = 0.110067
I0817 17:21:39.919044  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0837793 (* 0.4 = 0.0335117 loss)
I0817 17:21:39.919060  2446 solver.cpp:244]     Train net output #1: loss2 = 0.127593 (* 0.6 = 0.076556 loss)
I0817 17:21:39.919073  2446 sgd_solver.cpp:106] Iteration 7980, lr = 1e-05
I0817 17:21:42.762784  2446 solver.cpp:337] Iteration 8000, Testing net (#0)
I0817 17:22:18.570657  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.839797
I0817 17:22:18.570803  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.944562
I0817 17:22:18.570825  2446 solver.cpp:404]     Test net output #2: loss1 = 0.167374 (* 0.4 = 0.0669496 loss)
I0817 17:22:18.570840  2446 solver.cpp:404]     Test net output #3: loss2 = 0.424902 (* 0.6 = 0.254941 loss)
I0817 17:22:18.617226  2446 solver.cpp:228] Iteration 8000, loss = 0.0807665
I0817 17:22:18.617278  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0761558 (* 0.4 = 0.0304623 loss)
I0817 17:22:18.617295  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0838407 (* 0.6 = 0.0503044 loss)
I0817 17:22:18.617308  2446 sgd_solver.cpp:106] Iteration 8000, lr = 1e-06
I0817 17:22:21.628264  2446 solver.cpp:228] Iteration 8020, loss = 0.108405
I0817 17:22:21.628319  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0936765 (* 0.4 = 0.0374706 loss)
I0817 17:22:21.628335  2446 solver.cpp:244]     Train net output #1: loss2 = 0.118225 (* 0.6 = 0.070935 loss)
I0817 17:22:21.628350  2446 sgd_solver.cpp:106] Iteration 8020, lr = 1e-06
I0817 17:22:24.625229  2446 solver.cpp:228] Iteration 8040, loss = 0.0624437
I0817 17:22:24.625283  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0238841 (* 0.4 = 0.00955365 loss)
I0817 17:22:24.625298  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0881506 (* 0.6 = 0.0528904 loss)
I0817 17:22:24.625311  2446 sgd_solver.cpp:106] Iteration 8040, lr = 1e-06
I0817 17:22:27.636031  2446 solver.cpp:228] Iteration 8060, loss = 0.0656623
I0817 17:22:27.636087  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0323897 (* 0.4 = 0.0129559 loss)
I0817 17:22:27.636104  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0878445 (* 0.6 = 0.0527067 loss)
I0817 17:22:27.636118  2446 sgd_solver.cpp:106] Iteration 8060, lr = 1e-06
I0817 17:22:30.658015  2446 solver.cpp:228] Iteration 8080, loss = 0.0954943
I0817 17:22:30.658072  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0687903 (* 0.4 = 0.0275161 loss)
I0817 17:22:30.658088  2446 solver.cpp:244]     Train net output #1: loss2 = 0.113297 (* 0.6 = 0.0679785 loss)
I0817 17:22:30.658102  2446 sgd_solver.cpp:106] Iteration 8080, lr = 1e-06
I0817 17:22:33.664043  2446 solver.cpp:228] Iteration 8100, loss = 0.111295
I0817 17:22:33.664099  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0161931 (* 0.4 = 0.00647722 loss)
I0817 17:22:33.664115  2446 solver.cpp:244]     Train net output #1: loss2 = 0.174697 (* 0.6 = 0.104818 loss)
I0817 17:22:33.664129  2446 sgd_solver.cpp:106] Iteration 8100, lr = 1e-06
I0817 17:22:36.663272  2446 solver.cpp:228] Iteration 8120, loss = 0.107889
I0817 17:22:36.663329  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0381544 (* 0.4 = 0.0152618 loss)
I0817 17:22:36.663346  2446 solver.cpp:244]     Train net output #1: loss2 = 0.15438 (* 0.6 = 0.0926277 loss)
I0817 17:22:36.663359  2446 sgd_solver.cpp:106] Iteration 8120, lr = 1e-06
I0817 17:22:39.659898  2446 solver.cpp:228] Iteration 8140, loss = 0.0815057
I0817 17:22:39.659955  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0459721 (* 0.4 = 0.0183888 loss)
I0817 17:22:39.659970  2446 solver.cpp:244]     Train net output #1: loss2 = 0.105195 (* 0.6 = 0.0631172 loss)
I0817 17:22:39.659983  2446 sgd_solver.cpp:106] Iteration 8140, lr = 1e-06
I0817 17:22:42.653530  2446 solver.cpp:228] Iteration 8160, loss = 0.0851579
I0817 17:22:42.653585  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0206145 (* 0.4 = 0.00824579 loss)
I0817 17:22:42.653601  2446 solver.cpp:244]     Train net output #1: loss2 = 0.128187 (* 0.6 = 0.0769124 loss)
I0817 17:22:42.653615  2446 sgd_solver.cpp:106] Iteration 8160, lr = 1e-06
I0817 17:22:45.672657  2446 solver.cpp:228] Iteration 8180, loss = 0.0676841
I0817 17:22:45.672713  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0369898 (* 0.4 = 0.0147959 loss)
I0817 17:22:45.672729  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0881474 (* 0.6 = 0.0528885 loss)
I0817 17:22:45.672744  2446 sgd_solver.cpp:106] Iteration 8180, lr = 1e-06
I0817 17:22:48.677799  2446 solver.cpp:228] Iteration 8200, loss = 0.0872113
I0817 17:22:48.677991  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0509347 (* 0.4 = 0.0203739 loss)
I0817 17:22:48.678015  2446 solver.cpp:244]     Train net output #1: loss2 = 0.111396 (* 0.6 = 0.0668377 loss)
I0817 17:22:48.678032  2446 sgd_solver.cpp:106] Iteration 8200, lr = 1e-06
I0817 17:22:51.676954  2446 solver.cpp:228] Iteration 8220, loss = 0.07347
I0817 17:22:51.677008  2446 solver.cpp:244]     Train net output #0: loss1 = 0.023596 (* 0.4 = 0.0094384 loss)
I0817 17:22:51.677024  2446 solver.cpp:244]     Train net output #1: loss2 = 0.10672 (* 0.6 = 0.0640319 loss)
I0817 17:22:51.677037  2446 sgd_solver.cpp:106] Iteration 8220, lr = 1e-06
I0817 17:22:54.677459  2446 solver.cpp:228] Iteration 8240, loss = 0.11817
I0817 17:22:54.677515  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0829395 (* 0.4 = 0.0331758 loss)
I0817 17:22:54.677530  2446 solver.cpp:244]     Train net output #1: loss2 = 0.141658 (* 0.6 = 0.0849945 loss)
I0817 17:22:54.677543  2446 sgd_solver.cpp:106] Iteration 8240, lr = 1e-06
I0817 17:22:57.673677  2446 solver.cpp:228] Iteration 8260, loss = 0.0707869
I0817 17:22:57.673732  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0161647 (* 0.4 = 0.00646589 loss)
I0817 17:22:57.673748  2446 solver.cpp:244]     Train net output #1: loss2 = 0.107202 (* 0.6 = 0.0643212 loss)
I0817 17:22:57.673763  2446 sgd_solver.cpp:106] Iteration 8260, lr = 1e-06
I0817 17:23:00.673681  2446 solver.cpp:228] Iteration 8280, loss = 0.0552581
I0817 17:23:00.673733  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0189621 (* 0.4 = 0.00758484 loss)
I0817 17:23:00.673749  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0794558 (* 0.6 = 0.0476735 loss)
I0817 17:23:00.673763  2446 sgd_solver.cpp:106] Iteration 8280, lr = 1e-06
I0817 17:23:03.676091  2446 solver.cpp:228] Iteration 8300, loss = 0.0692966
I0817 17:23:03.676147  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0300828 (* 0.4 = 0.0120331 loss)
I0817 17:23:03.676163  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0954396 (* 0.6 = 0.0572637 loss)
I0817 17:23:03.676177  2446 sgd_solver.cpp:106] Iteration 8300, lr = 1e-06
I0817 17:23:06.672137  2446 solver.cpp:228] Iteration 8320, loss = 0.0456691
I0817 17:23:06.672195  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0598624 (* 0.4 = 0.023945 loss)
I0817 17:23:06.672211  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0362074 (* 0.6 = 0.0217245 loss)
I0817 17:23:06.672224  2446 sgd_solver.cpp:106] Iteration 8320, lr = 1e-06
I0817 17:23:09.671499  2446 solver.cpp:228] Iteration 8340, loss = 0.0528641
I0817 17:23:09.671555  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0429512 (* 0.4 = 0.0171805 loss)
I0817 17:23:09.671571  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0594732 (* 0.6 = 0.0356839 loss)
I0817 17:23:09.671584  2446 sgd_solver.cpp:106] Iteration 8340, lr = 1e-06
I0817 17:23:12.669380  2446 solver.cpp:228] Iteration 8360, loss = 0.0629135
I0817 17:23:12.669435  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0564466 (* 0.4 = 0.0225786 loss)
I0817 17:23:12.669450  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0672251 (* 0.6 = 0.0403351 loss)
I0817 17:23:12.669463  2446 sgd_solver.cpp:106] Iteration 8360, lr = 1e-06
I0817 17:23:15.667660  2446 solver.cpp:228] Iteration 8380, loss = 0.0929017
I0817 17:23:15.667721  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0734784 (* 0.4 = 0.0293914 loss)
I0817 17:23:15.667737  2446 solver.cpp:244]     Train net output #1: loss2 = 0.105851 (* 0.6 = 0.0635106 loss)
I0817 17:23:15.667752  2446 sgd_solver.cpp:106] Iteration 8380, lr = 1e-06
I0817 17:23:18.689685  2446 solver.cpp:228] Iteration 8400, loss = 0.0945105
I0817 17:23:18.690050  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0534821 (* 0.4 = 0.0213929 loss)
I0817 17:23:18.690069  2446 solver.cpp:244]     Train net output #1: loss2 = 0.121863 (* 0.6 = 0.0731179 loss)
I0817 17:23:18.690083  2446 sgd_solver.cpp:106] Iteration 8400, lr = 1e-06
I0817 17:23:21.751122  2446 solver.cpp:228] Iteration 8420, loss = 0.0689055
I0817 17:23:21.751178  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0332182 (* 0.4 = 0.0132873 loss)
I0817 17:23:21.751194  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0926974 (* 0.6 = 0.0556185 loss)
I0817 17:23:21.751206  2446 sgd_solver.cpp:106] Iteration 8420, lr = 1e-06
I0817 17:23:24.752898  2446 solver.cpp:228] Iteration 8440, loss = 0.0731045
I0817 17:23:24.752950  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0370778 (* 0.4 = 0.0148311 loss)
I0817 17:23:24.752965  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0971228 (* 0.6 = 0.0582737 loss)
I0817 17:23:24.752979  2446 sgd_solver.cpp:106] Iteration 8440, lr = 1e-06
I0817 17:23:27.767700  2446 solver.cpp:228] Iteration 8460, loss = 0.101853
I0817 17:23:27.767755  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0917431 (* 0.4 = 0.0366972 loss)
I0817 17:23:27.767771  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108594 (* 0.6 = 0.0651564 loss)
I0817 17:23:27.767784  2446 sgd_solver.cpp:106] Iteration 8460, lr = 1e-06
I0817 17:23:30.760526  2446 solver.cpp:228] Iteration 8480, loss = 0.0583804
I0817 17:23:30.760579  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0282285 (* 0.4 = 0.0112914 loss)
I0817 17:23:30.760596  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0784821 (* 0.6 = 0.0470893 loss)
I0817 17:23:30.760609  2446 sgd_solver.cpp:106] Iteration 8480, lr = 1e-06
I0817 17:23:33.771709  2446 solver.cpp:228] Iteration 8500, loss = 0.123452
I0817 17:23:33.771762  2446 solver.cpp:244]     Train net output #0: loss1 = 0.153607 (* 0.4 = 0.0614427 loss)
I0817 17:23:33.771778  2446 solver.cpp:244]     Train net output #1: loss2 = 0.103349 (* 0.6 = 0.0620094 loss)
I0817 17:23:33.771792  2446 sgd_solver.cpp:106] Iteration 8500, lr = 1e-06
I0817 17:23:36.786778  2446 solver.cpp:228] Iteration 8520, loss = 0.151315
I0817 17:23:36.786829  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0929521 (* 0.4 = 0.0371808 loss)
I0817 17:23:36.786845  2446 solver.cpp:244]     Train net output #1: loss2 = 0.190225 (* 0.6 = 0.114135 loss)
I0817 17:23:36.786859  2446 sgd_solver.cpp:106] Iteration 8520, lr = 1e-06
I0817 17:23:39.812824  2446 solver.cpp:228] Iteration 8540, loss = 0.0803614
I0817 17:23:39.812881  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0517152 (* 0.4 = 0.0206861 loss)
I0817 17:23:39.812897  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0994593 (* 0.6 = 0.0596756 loss)
I0817 17:23:39.812911  2446 sgd_solver.cpp:106] Iteration 8540, lr = 1e-06
I0817 17:23:42.842759  2446 solver.cpp:228] Iteration 8560, loss = 0.073788
I0817 17:23:42.842813  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0443552 (* 0.4 = 0.0177421 loss)
I0817 17:23:42.842829  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0934104 (* 0.6 = 0.0560462 loss)
I0817 17:23:42.842844  2446 sgd_solver.cpp:106] Iteration 8560, lr = 1e-06
I0817 17:23:45.863189  2446 solver.cpp:228] Iteration 8580, loss = 0.0887136
I0817 17:23:45.863242  2446 solver.cpp:244]     Train net output #0: loss1 = 0.030973 (* 0.4 = 0.0123892 loss)
I0817 17:23:45.863258  2446 solver.cpp:244]     Train net output #1: loss2 = 0.127208 (* 0.6 = 0.0763247 loss)
I0817 17:23:45.863272  2446 sgd_solver.cpp:106] Iteration 8580, lr = 1e-06
I0817 17:23:48.866130  2446 solver.cpp:228] Iteration 8600, loss = 0.112259
I0817 17:23:48.866291  2446 solver.cpp:244]     Train net output #0: loss1 = 0.101532 (* 0.4 = 0.0406128 loss)
I0817 17:23:48.866308  2446 solver.cpp:244]     Train net output #1: loss2 = 0.119411 (* 0.6 = 0.0716464 loss)
I0817 17:23:48.866322  2446 sgd_solver.cpp:106] Iteration 8600, lr = 1e-06
I0817 17:23:51.885771  2446 solver.cpp:228] Iteration 8620, loss = 0.0710991
I0817 17:23:51.885828  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0204567 (* 0.4 = 0.00818267 loss)
I0817 17:23:51.885844  2446 solver.cpp:244]     Train net output #1: loss2 = 0.104861 (* 0.6 = 0.0629167 loss)
I0817 17:23:51.885857  2446 sgd_solver.cpp:106] Iteration 8620, lr = 1e-06
I0817 17:23:54.907269  2446 solver.cpp:228] Iteration 8640, loss = 0.0794268
I0817 17:23:54.907328  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0337273 (* 0.4 = 0.0134909 loss)
I0817 17:23:54.907344  2446 solver.cpp:244]     Train net output #1: loss2 = 0.109894 (* 0.6 = 0.0659362 loss)
I0817 17:23:54.907357  2446 sgd_solver.cpp:106] Iteration 8640, lr = 1e-06
I0817 17:23:57.931301  2446 solver.cpp:228] Iteration 8660, loss = 0.0898784
I0817 17:23:57.931357  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0357001 (* 0.4 = 0.0142801 loss)
I0817 17:23:57.931372  2446 solver.cpp:244]     Train net output #1: loss2 = 0.125998 (* 0.6 = 0.0755986 loss)
I0817 17:23:57.931386  2446 sgd_solver.cpp:106] Iteration 8660, lr = 1e-06
I0817 17:24:00.954689  2446 solver.cpp:228] Iteration 8680, loss = 0.132058
I0817 17:24:00.954746  2446 solver.cpp:244]     Train net output #0: loss1 = 0.131016 (* 0.4 = 0.0524063 loss)
I0817 17:24:00.954762  2446 solver.cpp:244]     Train net output #1: loss2 = 0.132753 (* 0.6 = 0.0796519 loss)
I0817 17:24:00.954777  2446 sgd_solver.cpp:106] Iteration 8680, lr = 1e-06
I0817 17:24:04.004787  2446 solver.cpp:228] Iteration 8700, loss = 0.0775464
I0817 17:24:04.004843  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0456804 (* 0.4 = 0.0182721 loss)
I0817 17:24:04.004859  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0987909 (* 0.6 = 0.0592745 loss)
I0817 17:24:04.004873  2446 sgd_solver.cpp:106] Iteration 8700, lr = 1e-06
I0817 17:24:07.012873  2446 solver.cpp:228] Iteration 8720, loss = 0.136153
I0817 17:24:07.012926  2446 solver.cpp:244]     Train net output #0: loss1 = 0.107392 (* 0.4 = 0.0429566 loss)
I0817 17:24:07.012943  2446 solver.cpp:244]     Train net output #1: loss2 = 0.155328 (* 0.6 = 0.0931969 loss)
I0817 17:24:07.012956  2446 sgd_solver.cpp:106] Iteration 8720, lr = 1e-06
I0817 17:24:10.028142  2446 solver.cpp:228] Iteration 8740, loss = 0.126532
I0817 17:24:10.028200  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0679768 (* 0.4 = 0.0271907 loss)
I0817 17:24:10.028216  2446 solver.cpp:244]     Train net output #1: loss2 = 0.165569 (* 0.6 = 0.0993415 loss)
I0817 17:24:10.028230  2446 sgd_solver.cpp:106] Iteration 8740, lr = 1e-06
I0817 17:24:13.037255  2446 solver.cpp:228] Iteration 8760, loss = 0.0989835
I0817 17:24:13.037308  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0636928 (* 0.4 = 0.0254771 loss)
I0817 17:24:13.037324  2446 solver.cpp:244]     Train net output #1: loss2 = 0.122511 (* 0.6 = 0.0735066 loss)
I0817 17:24:13.037338  2446 sgd_solver.cpp:106] Iteration 8760, lr = 1e-06
I0817 17:24:16.032732  2446 solver.cpp:228] Iteration 8780, loss = 0.0852055
I0817 17:24:16.032781  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0432799 (* 0.4 = 0.017312 loss)
I0817 17:24:16.032798  2446 solver.cpp:244]     Train net output #1: loss2 = 0.113156 (* 0.6 = 0.0678938 loss)
I0817 17:24:16.032810  2446 sgd_solver.cpp:106] Iteration 8780, lr = 1e-06
I0817 17:24:19.026787  2446 solver.cpp:228] Iteration 8800, loss = 0.118398
I0817 17:24:19.026911  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0502589 (* 0.4 = 0.0201036 loss)
I0817 17:24:19.026928  2446 solver.cpp:244]     Train net output #1: loss2 = 0.163824 (* 0.6 = 0.0982944 loss)
I0817 17:24:19.026942  2446 sgd_solver.cpp:106] Iteration 8800, lr = 1e-06
I0817 17:24:22.030611  2446 solver.cpp:228] Iteration 8820, loss = 0.0961841
I0817 17:24:22.030666  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0374623 (* 0.4 = 0.0149849 loss)
I0817 17:24:22.030683  2446 solver.cpp:244]     Train net output #1: loss2 = 0.135332 (* 0.6 = 0.0811994 loss)
I0817 17:24:22.030696  2446 sgd_solver.cpp:106] Iteration 8820, lr = 1e-06
I0817 17:24:25.025962  2446 solver.cpp:228] Iteration 8840, loss = 0.061873
I0817 17:24:25.026015  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0225418 (* 0.4 = 0.00901673 loss)
I0817 17:24:25.026031  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0880941 (* 0.6 = 0.0528565 loss)
I0817 17:24:25.026046  2446 sgd_solver.cpp:106] Iteration 8840, lr = 1e-06
I0817 17:24:28.040546  2446 solver.cpp:228] Iteration 8860, loss = 0.172462
I0817 17:24:28.040602  2446 solver.cpp:244]     Train net output #0: loss1 = 0.210206 (* 0.4 = 0.0840824 loss)
I0817 17:24:28.040618  2446 solver.cpp:244]     Train net output #1: loss2 = 0.1473 (* 0.6 = 0.0883799 loss)
I0817 17:24:28.040632  2446 sgd_solver.cpp:106] Iteration 8860, lr = 1e-06
I0817 17:24:31.106420  2446 solver.cpp:228] Iteration 8880, loss = 0.116952
I0817 17:24:31.106478  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0670293 (* 0.4 = 0.0268117 loss)
I0817 17:24:31.106495  2446 solver.cpp:244]     Train net output #1: loss2 = 0.150235 (* 0.6 = 0.0901408 loss)
I0817 17:24:31.106509  2446 sgd_solver.cpp:106] Iteration 8880, lr = 1e-06
I0817 17:24:34.114390  2446 solver.cpp:228] Iteration 8900, loss = 0.104701
I0817 17:24:34.114444  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0325827 (* 0.4 = 0.0130331 loss)
I0817 17:24:34.114460  2446 solver.cpp:244]     Train net output #1: loss2 = 0.15278 (* 0.6 = 0.0916677 loss)
I0817 17:24:34.114475  2446 sgd_solver.cpp:106] Iteration 8900, lr = 1e-06
I0817 17:24:37.118258  2446 solver.cpp:228] Iteration 8920, loss = 0.101338
I0817 17:24:37.118314  2446 solver.cpp:244]     Train net output #0: loss1 = 0.123973 (* 0.4 = 0.049589 loss)
I0817 17:24:37.118330  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0862484 (* 0.6 = 0.0517491 loss)
I0817 17:24:37.118342  2446 sgd_solver.cpp:106] Iteration 8920, lr = 1e-06
I0817 17:24:40.122337  2446 solver.cpp:228] Iteration 8940, loss = 0.0799474
I0817 17:24:40.122392  2446 solver.cpp:244]     Train net output #0: loss1 = 0.086545 (* 0.4 = 0.034618 loss)
I0817 17:24:40.122408  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0755495 (* 0.6 = 0.0453297 loss)
I0817 17:24:40.122421  2446 sgd_solver.cpp:106] Iteration 8940, lr = 1e-06
I0817 17:24:43.118471  2446 solver.cpp:228] Iteration 8960, loss = 0.045074
I0817 17:24:43.118530  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0367101 (* 0.4 = 0.014684 loss)
I0817 17:24:43.118544  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0506504 (* 0.6 = 0.0303903 loss)
I0817 17:24:43.118558  2446 sgd_solver.cpp:106] Iteration 8960, lr = 1e-06
I0817 17:24:46.114940  2446 solver.cpp:228] Iteration 8980, loss = 0.0900073
I0817 17:24:46.114995  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0751587 (* 0.4 = 0.0300635 loss)
I0817 17:24:46.115010  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0999067 (* 0.6 = 0.059944 loss)
I0817 17:24:46.115023  2446 sgd_solver.cpp:106] Iteration 8980, lr = 1e-06
I0817 17:24:48.964356  2446 solver.cpp:337] Iteration 9000, Testing net (#0)
I0817 17:25:24.904548  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.839516
I0817 17:25:24.904690  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.944672
I0817 17:25:24.904711  2446 solver.cpp:404]     Test net output #2: loss1 = 0.166802 (* 0.4 = 0.0667208 loss)
I0817 17:25:24.904723  2446 solver.cpp:404]     Test net output #3: loss2 = 0.42545 (* 0.6 = 0.25527 loss)
I0817 17:25:24.950500  2446 solver.cpp:228] Iteration 9000, loss = 0.0805376
I0817 17:25:24.950556  2446 solver.cpp:244]     Train net output #0: loss1 = 0.06049 (* 0.4 = 0.024196 loss)
I0817 17:25:24.950570  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0939032 (* 0.6 = 0.0563419 loss)
I0817 17:25:24.950584  2446 sgd_solver.cpp:106] Iteration 9000, lr = 1e-06
I0817 17:25:27.959955  2446 solver.cpp:228] Iteration 9020, loss = 0.064124
I0817 17:25:27.960012  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0503656 (* 0.4 = 0.0201462 loss)
I0817 17:25:27.960028  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0732967 (* 0.6 = 0.043978 loss)
I0817 17:25:27.960041  2446 sgd_solver.cpp:106] Iteration 9020, lr = 1e-06
I0817 17:25:30.990613  2446 solver.cpp:228] Iteration 9040, loss = 0.0738316
I0817 17:25:30.990667  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0366109 (* 0.4 = 0.0146443 loss)
I0817 17:25:30.990684  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0986458 (* 0.6 = 0.0591875 loss)
I0817 17:25:30.990697  2446 sgd_solver.cpp:106] Iteration 9040, lr = 1e-06
I0817 17:25:33.981524  2446 solver.cpp:228] Iteration 9060, loss = 0.141228
I0817 17:25:33.981577  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0206912 (* 0.4 = 0.00827647 loss)
I0817 17:25:33.981593  2446 solver.cpp:244]     Train net output #1: loss2 = 0.221587 (* 0.6 = 0.132952 loss)
I0817 17:25:33.981606  2446 sgd_solver.cpp:106] Iteration 9060, lr = 1e-06
I0817 17:25:36.977834  2446 solver.cpp:228] Iteration 9080, loss = 0.0628716
I0817 17:25:36.977886  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0178866 (* 0.4 = 0.00715465 loss)
I0817 17:25:36.977902  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0928619 (* 0.6 = 0.0557172 loss)
I0817 17:25:36.977916  2446 sgd_solver.cpp:106] Iteration 9080, lr = 1e-06
I0817 17:25:39.974417  2446 solver.cpp:228] Iteration 9100, loss = 0.0709608
I0817 17:25:39.974474  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0242698 (* 0.4 = 0.00970793 loss)
I0817 17:25:39.974490  2446 solver.cpp:244]     Train net output #1: loss2 = 0.102089 (* 0.6 = 0.0612531 loss)
I0817 17:25:39.974503  2446 sgd_solver.cpp:106] Iteration 9100, lr = 1e-06
I0817 17:25:42.970244  2446 solver.cpp:228] Iteration 9120, loss = 0.189738
I0817 17:25:42.970296  2446 solver.cpp:244]     Train net output #0: loss1 = 0.14934 (* 0.4 = 0.0597359 loss)
I0817 17:25:42.970314  2446 solver.cpp:244]     Train net output #1: loss2 = 0.216671 (* 0.6 = 0.130003 loss)
I0817 17:25:42.970326  2446 sgd_solver.cpp:106] Iteration 9120, lr = 1e-06
I0817 17:25:45.992355  2446 solver.cpp:228] Iteration 9140, loss = 0.065911
I0817 17:25:45.992411  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0871301 (* 0.4 = 0.0348521 loss)
I0817 17:25:45.992427  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0517654 (* 0.6 = 0.0310592 loss)
I0817 17:25:45.992441  2446 sgd_solver.cpp:106] Iteration 9140, lr = 1e-06
I0817 17:25:49.010834  2446 solver.cpp:228] Iteration 9160, loss = 0.0803237
I0817 17:25:49.010890  2446 solver.cpp:244]     Train net output #0: loss1 = 0.057154 (* 0.4 = 0.0228616 loss)
I0817 17:25:49.010911  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0957706 (* 0.6 = 0.0574624 loss)
I0817 17:25:49.010926  2446 sgd_solver.cpp:106] Iteration 9160, lr = 1e-06
I0817 17:25:52.015543  2446 solver.cpp:228] Iteration 9180, loss = 0.159204
I0817 17:25:52.015597  2446 solver.cpp:244]     Train net output #0: loss1 = 0.138991 (* 0.4 = 0.0555966 loss)
I0817 17:25:52.015614  2446 solver.cpp:244]     Train net output #1: loss2 = 0.17268 (* 0.6 = 0.103608 loss)
I0817 17:25:52.015627  2446 sgd_solver.cpp:106] Iteration 9180, lr = 1e-06
I0817 17:25:55.043190  2446 solver.cpp:228] Iteration 9200, loss = 0.0867711
I0817 17:25:55.043356  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0264605 (* 0.4 = 0.0105842 loss)
I0817 17:25:55.043375  2446 solver.cpp:244]     Train net output #1: loss2 = 0.126979 (* 0.6 = 0.0761872 loss)
I0817 17:25:55.043387  2446 sgd_solver.cpp:106] Iteration 9200, lr = 1e-06
I0817 17:25:58.132496  2446 solver.cpp:228] Iteration 9220, loss = 0.138829
I0817 17:25:58.132552  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0289251 (* 0.4 = 0.01157 loss)
I0817 17:25:58.132568  2446 solver.cpp:244]     Train net output #1: loss2 = 0.212099 (* 0.6 = 0.127259 loss)
I0817 17:25:58.132582  2446 sgd_solver.cpp:106] Iteration 9220, lr = 1e-06
I0817 17:26:01.135473  2446 solver.cpp:228] Iteration 9240, loss = 0.0812677
I0817 17:26:01.135530  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0273965 (* 0.4 = 0.0109586 loss)
I0817 17:26:01.135546  2446 solver.cpp:244]     Train net output #1: loss2 = 0.117182 (* 0.6 = 0.0703093 loss)
I0817 17:26:01.135560  2446 sgd_solver.cpp:106] Iteration 9240, lr = 1e-06
I0817 17:26:04.134357  2446 solver.cpp:228] Iteration 9260, loss = 0.0955393
I0817 17:26:04.134413  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0195524 (* 0.4 = 0.00782097 loss)
I0817 17:26:04.134429  2446 solver.cpp:244]     Train net output #1: loss2 = 0.146198 (* 0.6 = 0.0877186 loss)
I0817 17:26:04.134443  2446 sgd_solver.cpp:106] Iteration 9260, lr = 1e-06
I0817 17:26:07.177042  2446 solver.cpp:228] Iteration 9280, loss = 0.191495
I0817 17:26:07.177095  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0297214 (* 0.4 = 0.0118886 loss)
I0817 17:26:07.177111  2446 solver.cpp:244]     Train net output #1: loss2 = 0.299344 (* 0.6 = 0.179607 loss)
I0817 17:26:07.177125  2446 sgd_solver.cpp:106] Iteration 9280, lr = 1e-06
I0817 17:26:10.195936  2446 solver.cpp:228] Iteration 9300, loss = 0.091429
I0817 17:26:10.195994  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0232335 (* 0.4 = 0.00929339 loss)
I0817 17:26:10.196010  2446 solver.cpp:244]     Train net output #1: loss2 = 0.136893 (* 0.6 = 0.0821358 loss)
I0817 17:26:10.196023  2446 sgd_solver.cpp:106] Iteration 9300, lr = 1e-06
I0817 17:26:13.208405  2446 solver.cpp:228] Iteration 9320, loss = 0.0834576
I0817 17:26:13.208456  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0573509 (* 0.4 = 0.0229404 loss)
I0817 17:26:13.208470  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100862 (* 0.6 = 0.0605175 loss)
I0817 17:26:13.208483  2446 sgd_solver.cpp:106] Iteration 9320, lr = 1e-06
I0817 17:26:16.206553  2446 solver.cpp:228] Iteration 9340, loss = 0.118099
I0817 17:26:16.206609  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0390358 (* 0.4 = 0.0156143 loss)
I0817 17:26:16.206624  2446 solver.cpp:244]     Train net output #1: loss2 = 0.170808 (* 0.6 = 0.102485 loss)
I0817 17:26:16.206639  2446 sgd_solver.cpp:106] Iteration 9340, lr = 1e-06
I0817 17:26:19.213063  2446 solver.cpp:228] Iteration 9360, loss = 0.130363
I0817 17:26:19.213121  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0943506 (* 0.4 = 0.0377402 loss)
I0817 17:26:19.213137  2446 solver.cpp:244]     Train net output #1: loss2 = 0.154371 (* 0.6 = 0.0926226 loss)
I0817 17:26:19.213150  2446 sgd_solver.cpp:106] Iteration 9360, lr = 1e-06
I0817 17:26:22.206166  2446 solver.cpp:228] Iteration 9380, loss = 0.0969617
I0817 17:26:22.206225  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0263919 (* 0.4 = 0.0105568 loss)
I0817 17:26:22.206243  2446 solver.cpp:244]     Train net output #1: loss2 = 0.144009 (* 0.6 = 0.0864052 loss)
I0817 17:26:22.206256  2446 sgd_solver.cpp:106] Iteration 9380, lr = 1e-06
I0817 17:26:25.200044  2446 solver.cpp:228] Iteration 9400, loss = 0.0738877
I0817 17:26:25.200189  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0428027 (* 0.4 = 0.0171211 loss)
I0817 17:26:25.200206  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0946114 (* 0.6 = 0.0567669 loss)
I0817 17:26:25.200222  2446 sgd_solver.cpp:106] Iteration 9400, lr = 1e-06
I0817 17:26:28.200177  2446 solver.cpp:228] Iteration 9420, loss = 0.140142
I0817 17:26:28.200234  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0500177 (* 0.4 = 0.0200071 loss)
I0817 17:26:28.200250  2446 solver.cpp:244]     Train net output #1: loss2 = 0.200225 (* 0.6 = 0.120135 loss)
I0817 17:26:28.200264  2446 sgd_solver.cpp:106] Iteration 9420, lr = 1e-06
I0817 17:26:31.202100  2446 solver.cpp:228] Iteration 9440, loss = 0.0823358
I0817 17:26:31.202152  2446 solver.cpp:244]     Train net output #0: loss1 = 0.103792 (* 0.4 = 0.0415167 loss)
I0817 17:26:31.202168  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0680323 (* 0.6 = 0.0408194 loss)
I0817 17:26:31.202183  2446 sgd_solver.cpp:106] Iteration 9440, lr = 1e-06
I0817 17:26:34.198344  2446 solver.cpp:228] Iteration 9460, loss = 0.0876065
I0817 17:26:34.198398  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0268828 (* 0.4 = 0.0107531 loss)
I0817 17:26:34.198413  2446 solver.cpp:244]     Train net output #1: loss2 = 0.128089 (* 0.6 = 0.0768536 loss)
I0817 17:26:34.198427  2446 sgd_solver.cpp:106] Iteration 9460, lr = 1e-06
I0817 17:26:37.196779  2446 solver.cpp:228] Iteration 9480, loss = 0.0980769
I0817 17:26:37.196830  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0478096 (* 0.4 = 0.0191238 loss)
I0817 17:26:37.196846  2446 solver.cpp:244]     Train net output #1: loss2 = 0.131589 (* 0.6 = 0.0789533 loss)
I0817 17:26:37.196859  2446 sgd_solver.cpp:106] Iteration 9480, lr = 1e-06
I0817 17:26:40.190325  2446 solver.cpp:228] Iteration 9500, loss = 0.0795388
I0817 17:26:40.190381  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0365757 (* 0.4 = 0.0146303 loss)
I0817 17:26:40.190397  2446 solver.cpp:244]     Train net output #1: loss2 = 0.108181 (* 0.6 = 0.0649088 loss)
I0817 17:26:40.190412  2446 sgd_solver.cpp:106] Iteration 9500, lr = 1e-06
I0817 17:26:43.185817  2446 solver.cpp:228] Iteration 9520, loss = 0.0859522
I0817 17:26:43.185873  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0507666 (* 0.4 = 0.0203066 loss)
I0817 17:26:43.185889  2446 solver.cpp:244]     Train net output #1: loss2 = 0.10941 (* 0.6 = 0.0656458 loss)
I0817 17:26:43.185901  2446 sgd_solver.cpp:106] Iteration 9520, lr = 1e-06
I0817 17:26:46.182198  2446 solver.cpp:228] Iteration 9540, loss = 0.0686436
I0817 17:26:46.182251  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0281073 (* 0.4 = 0.0112429 loss)
I0817 17:26:46.182267  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0956681 (* 0.6 = 0.0574009 loss)
I0817 17:26:46.182281  2446 sgd_solver.cpp:106] Iteration 9540, lr = 1e-06
I0817 17:26:49.178227  2446 solver.cpp:228] Iteration 9560, loss = 0.0611613
I0817 17:26:49.178290  2446 solver.cpp:244]     Train net output #0: loss1 = 0.055793 (* 0.4 = 0.0223172 loss)
I0817 17:26:49.178308  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0647406 (* 0.6 = 0.0388444 loss)
I0817 17:26:49.178320  2446 sgd_solver.cpp:106] Iteration 9560, lr = 1e-06
I0817 17:26:52.173458  2446 solver.cpp:228] Iteration 9580, loss = 0.0756168
I0817 17:26:52.173509  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0305465 (* 0.4 = 0.0122186 loss)
I0817 17:26:52.173526  2446 solver.cpp:244]     Train net output #1: loss2 = 0.105664 (* 0.6 = 0.0633984 loss)
I0817 17:26:52.173539  2446 sgd_solver.cpp:106] Iteration 9580, lr = 1e-06
I0817 17:26:55.165853  2446 solver.cpp:228] Iteration 9600, loss = 0.0795632
I0817 17:26:55.165900  2446 solver.cpp:244]     Train net output #0: loss1 = 0.054888 (* 0.4 = 0.0219552 loss)
I0817 17:26:55.165915  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0960138 (* 0.6 = 0.0576083 loss)
I0817 17:26:55.165930  2446 sgd_solver.cpp:106] Iteration 9600, lr = 1e-06
I0817 17:26:58.168752  2446 solver.cpp:228] Iteration 9620, loss = 0.0940297
I0817 17:26:58.168910  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0236594 (* 0.4 = 0.00946377 loss)
I0817 17:26:58.168927  2446 solver.cpp:244]     Train net output #1: loss2 = 0.140944 (* 0.6 = 0.0845662 loss)
I0817 17:26:58.168941  2446 sgd_solver.cpp:106] Iteration 9620, lr = 1e-06
I0817 17:27:01.170433  2446 solver.cpp:228] Iteration 9640, loss = 0.0884181
I0817 17:27:01.170482  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0772011 (* 0.4 = 0.0308804 loss)
I0817 17:27:01.170498  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0958966 (* 0.6 = 0.057538 loss)
I0817 17:27:01.170512  2446 sgd_solver.cpp:106] Iteration 9640, lr = 1e-06
I0817 17:27:04.174734  2446 solver.cpp:228] Iteration 9660, loss = 0.104274
I0817 17:27:04.174782  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0146496 (* 0.4 = 0.00585983 loss)
I0817 17:27:04.174798  2446 solver.cpp:244]     Train net output #1: loss2 = 0.164024 (* 0.6 = 0.0984145 loss)
I0817 17:27:04.174811  2446 sgd_solver.cpp:106] Iteration 9660, lr = 1e-06
I0817 17:27:07.178326  2446 solver.cpp:228] Iteration 9680, loss = 0.10679
I0817 17:27:07.178375  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0501322 (* 0.4 = 0.0200529 loss)
I0817 17:27:07.178391  2446 solver.cpp:244]     Train net output #1: loss2 = 0.144563 (* 0.6 = 0.0867376 loss)
I0817 17:27:07.178405  2446 sgd_solver.cpp:106] Iteration 9680, lr = 1e-06
I0817 17:27:10.177146  2446 solver.cpp:228] Iteration 9700, loss = 0.100482
I0817 17:27:10.177191  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0641511 (* 0.4 = 0.0256604 loss)
I0817 17:27:10.177206  2446 solver.cpp:244]     Train net output #1: loss2 = 0.124704 (* 0.6 = 0.0748222 loss)
I0817 17:27:10.177220  2446 sgd_solver.cpp:106] Iteration 9700, lr = 1e-06
I0817 17:27:13.171797  2446 solver.cpp:228] Iteration 9720, loss = 0.115973
I0817 17:27:13.171847  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0882415 (* 0.4 = 0.0352966 loss)
I0817 17:27:13.171864  2446 solver.cpp:244]     Train net output #1: loss2 = 0.134461 (* 0.6 = 0.0806764 loss)
I0817 17:27:13.171877  2446 sgd_solver.cpp:106] Iteration 9720, lr = 1e-06
I0817 17:27:16.167204  2446 solver.cpp:228] Iteration 9740, loss = 0.109259
I0817 17:27:16.167258  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0665012 (* 0.4 = 0.0266005 loss)
I0817 17:27:16.167273  2446 solver.cpp:244]     Train net output #1: loss2 = 0.137765 (* 0.6 = 0.0826589 loss)
I0817 17:27:16.167287  2446 sgd_solver.cpp:106] Iteration 9740, lr = 1e-06
I0817 17:27:19.162930  2446 solver.cpp:228] Iteration 9760, loss = 0.119419
I0817 17:27:19.162981  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0693477 (* 0.4 = 0.0277391 loss)
I0817 17:27:19.162997  2446 solver.cpp:244]     Train net output #1: loss2 = 0.1528 (* 0.6 = 0.0916802 loss)
I0817 17:27:19.163012  2446 sgd_solver.cpp:106] Iteration 9760, lr = 1e-06
I0817 17:27:22.156626  2446 solver.cpp:228] Iteration 9780, loss = 0.10551
I0817 17:27:22.156675  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0512496 (* 0.4 = 0.0204998 loss)
I0817 17:27:22.156692  2446 solver.cpp:244]     Train net output #1: loss2 = 0.141685 (* 0.6 = 0.0850108 loss)
I0817 17:27:22.156704  2446 sgd_solver.cpp:106] Iteration 9780, lr = 1e-06
I0817 17:27:25.151445  2446 solver.cpp:228] Iteration 9800, loss = 0.0915313
I0817 17:27:25.151499  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0290811 (* 0.4 = 0.0116325 loss)
I0817 17:27:25.151515  2446 solver.cpp:244]     Train net output #1: loss2 = 0.133165 (* 0.6 = 0.0798991 loss)
I0817 17:27:25.151528  2446 sgd_solver.cpp:106] Iteration 9800, lr = 1e-06
I0817 17:27:28.153020  2446 solver.cpp:228] Iteration 9820, loss = 0.0774513
I0817 17:27:28.153074  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0430193 (* 0.4 = 0.0172077 loss)
I0817 17:27:28.153090  2446 solver.cpp:244]     Train net output #1: loss2 = 0.100406 (* 0.6 = 0.0602439 loss)
I0817 17:27:28.153103  2446 sgd_solver.cpp:106] Iteration 9820, lr = 1e-06
I0817 17:27:31.147642  2446 solver.cpp:228] Iteration 9840, loss = 0.163902
I0817 17:27:31.147792  2446 solver.cpp:244]     Train net output #0: loss1 = 0.109881 (* 0.4 = 0.0439523 loss)
I0817 17:27:31.147810  2446 solver.cpp:244]     Train net output #1: loss2 = 0.199917 (* 0.6 = 0.11995 loss)
I0817 17:27:31.147824  2446 sgd_solver.cpp:106] Iteration 9840, lr = 1e-06
I0817 17:27:34.144654  2446 solver.cpp:228] Iteration 9860, loss = 0.0834833
I0817 17:27:34.144695  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0861685 (* 0.4 = 0.0344674 loss)
I0817 17:27:34.144706  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0816936 (* 0.6 = 0.0490162 loss)
I0817 17:27:34.144716  2446 sgd_solver.cpp:106] Iteration 9860, lr = 1e-06
I0817 17:27:37.141176  2446 solver.cpp:228] Iteration 9880, loss = 0.0757843
I0817 17:27:37.141229  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0523524 (* 0.4 = 0.0209409 loss)
I0817 17:27:37.141245  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0914061 (* 0.6 = 0.0548436 loss)
I0817 17:27:37.141260  2446 sgd_solver.cpp:106] Iteration 9880, lr = 1e-06
I0817 17:27:40.133440  2446 solver.cpp:228] Iteration 9900, loss = 0.108664
I0817 17:27:40.133491  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0438984 (* 0.4 = 0.0175594 loss)
I0817 17:27:40.133507  2446 solver.cpp:244]     Train net output #1: loss2 = 0.151842 (* 0.6 = 0.0911053 loss)
I0817 17:27:40.133519  2446 sgd_solver.cpp:106] Iteration 9900, lr = 1e-06
I0817 17:27:43.132109  2446 solver.cpp:228] Iteration 9920, loss = 0.110218
I0817 17:27:43.132161  2446 solver.cpp:244]     Train net output #0: loss1 = 0.101666 (* 0.4 = 0.0406666 loss)
I0817 17:27:43.132177  2446 solver.cpp:244]     Train net output #1: loss2 = 0.11592 (* 0.6 = 0.0695521 loss)
I0817 17:27:43.132191  2446 sgd_solver.cpp:106] Iteration 9920, lr = 1e-06
I0817 17:27:46.126359  2446 solver.cpp:228] Iteration 9940, loss = 0.155974
I0817 17:27:46.126413  2446 solver.cpp:244]     Train net output #0: loss1 = 0.212525 (* 0.4 = 0.0850099 loss)
I0817 17:27:46.126430  2446 solver.cpp:244]     Train net output #1: loss2 = 0.118274 (* 0.6 = 0.0709645 loss)
I0817 17:27:46.126443  2446 sgd_solver.cpp:106] Iteration 9940, lr = 1e-06
I0817 17:27:49.123301  2446 solver.cpp:228] Iteration 9960, loss = 0.0754989
I0817 17:27:49.123353  2446 solver.cpp:244]     Train net output #0: loss1 = 0.105486 (* 0.4 = 0.0421943 loss)
I0817 17:27:49.123369  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0555081 (* 0.6 = 0.0333049 loss)
I0817 17:27:49.123383  2446 sgd_solver.cpp:106] Iteration 9960, lr = 1e-06
I0817 17:27:52.117475  2446 solver.cpp:228] Iteration 9980, loss = 0.0483714
I0817 17:27:52.117527  2446 solver.cpp:244]     Train net output #0: loss1 = 0.0399694 (* 0.4 = 0.0159878 loss)
I0817 17:27:52.117542  2446 solver.cpp:244]     Train net output #1: loss2 = 0.0539731 (* 0.6 = 0.0323839 loss)
I0817 17:27:52.117557  2446 sgd_solver.cpp:106] Iteration 9980, lr = 1e-06
I0817 17:27:54.961558  2446 solver.cpp:454] Snapshotting to binary proto file models/gender_glasses/gg_net_train_iter_10000.caffemodel
I0817 17:27:55.192432  2446 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/gender_glasses/gg_net_train_iter_10000.solverstate
I0817 17:27:55.281786  2446 solver.cpp:317] Iteration 10000, loss = 0.0955258
I0817 17:27:55.281837  2446 solver.cpp:337] Iteration 10000, Testing net (#0)
I0817 17:28:30.808475  2446 solver.cpp:404]     Test net output #0: accuracy_gender = 0.839609
I0817 17:28:30.808610  2446 solver.cpp:404]     Test net output #1: accuracy_glasses = 0.944625
I0817 17:28:30.808637  2446 solver.cpp:404]     Test net output #2: loss1 = 0.16714 (* 0.4 = 0.0668558 loss)
I0817 17:28:30.808657  2446 solver.cpp:404]     Test net output #3: loss2 = 0.425023 (* 0.6 = 0.255014 loss)
I0817 17:28:30.808670  2446 solver.cpp:322] Optimization Done.
I0817 17:28:30.808678  2446 caffe.cpp:254] Optimization Done.
